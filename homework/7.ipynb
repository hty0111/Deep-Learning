{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业第7周：GAN练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.仿照课件示例的GAN生成网络，复现Fashion_mnist数据集的GAN生成效果或Mnist数据集的GAN生成效果。<BR>（学有余力同学可以挑战一下anime faces的GAN生成，建议使用WGAN）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先执行GPU资源分配代码，勿删除。\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        physical_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) <class 'numpy.ndarray'>\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(x_train.shape, type(x_train[0]))\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "x_train = (x_train - 127.5) / 127.5\n",
    "buffer_size = 60000\n",
    "batch_size = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(buffer_size).batch(batch_size)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256,use_bias=False,input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7,7,256)))\n",
    "    assert model.output_shape == (None,7,7,256)#注意：batch size没有限制\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=False))\n",
    "    assert model.output_shape == (None,7,7,128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))\n",
    "    assert model.output_shape == (None,14,14,64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1,(5,5),strides=(2,2),padding='same',use_bias=False,activation='tanh'))\n",
    "    assert model.output_shape == (None,28,28,1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 7, 7, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd86443f5b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 判别器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding='same',input_shape=[28,28,1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "tf.Tensor([[-0.00324972]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    loss = real_loss + fake_loss\n",
    "    return loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size,noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        real_output =discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output,fake_output)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss,disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython import display\n",
    "\n",
    "def train(dataset,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        for i,image_batch in enumerate(dataset):\n",
    "            g,d = train_step(image_batch)\n",
    "            print(\"batch %d, gen_loss %f, disc_loss %f\" % (i,g.numpy(),d.numpy()))\n",
    "\n",
    "    #     display.clear_output(wait=True)\n",
    "    #     generate_images(generator,epoch+1)\n",
    "              \n",
    "        print('Time for epoch {} is {} sec'.format(epoch+1,time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 显示生成图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model,test_input):\n",
    "    predictions = model(test_input,training=False)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(predictions[i,:, :, 0]*127.5 + 127.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, gen_loss 0.973365, disc_loss 1.205098\n",
      "batch 1, gen_loss 0.949555, disc_loss 1.274268\n",
      "batch 2, gen_loss 0.927190, disc_loss 1.259077\n",
      "batch 3, gen_loss 0.920719, disc_loss 1.206595\n",
      "batch 4, gen_loss 0.895243, disc_loss 1.218703\n",
      "batch 5, gen_loss 0.863761, disc_loss 1.183457\n",
      "batch 6, gen_loss 0.843907, disc_loss 1.210892\n",
      "batch 7, gen_loss 0.810288, disc_loss 1.258498\n",
      "batch 8, gen_loss 0.786095, disc_loss 1.273002\n",
      "batch 9, gen_loss 0.752759, disc_loss 1.268821\n",
      "batch 10, gen_loss 0.740375, disc_loss 1.288656\n",
      "batch 11, gen_loss 0.724757, disc_loss 1.299481\n",
      "batch 12, gen_loss 0.687605, disc_loss 1.365397\n",
      "batch 13, gen_loss 0.683535, disc_loss 1.339993\n",
      "batch 14, gen_loss 0.666432, disc_loss 1.338384\n",
      "batch 15, gen_loss 0.677672, disc_loss 1.350474\n",
      "batch 16, gen_loss 0.671912, disc_loss 1.369936\n",
      "batch 17, gen_loss 0.667088, disc_loss 1.378995\n",
      "batch 18, gen_loss 0.676192, disc_loss 1.412810\n",
      "batch 19, gen_loss 0.676989, disc_loss 1.397547\n",
      "batch 20, gen_loss 0.670446, disc_loss 1.437206\n",
      "batch 21, gen_loss 0.702307, disc_loss 1.370023\n",
      "batch 22, gen_loss 0.731005, disc_loss 1.349154\n",
      "batch 23, gen_loss 0.748379, disc_loss 1.347971\n",
      "batch 24, gen_loss 0.736036, disc_loss 1.359277\n",
      "batch 25, gen_loss 0.755083, disc_loss 1.361431\n",
      "batch 26, gen_loss 0.782861, disc_loss 1.329975\n",
      "batch 27, gen_loss 0.779835, disc_loss 1.302941\n",
      "batch 28, gen_loss 0.807306, disc_loss 1.291271\n",
      "batch 29, gen_loss 0.803041, disc_loss 1.282002\n",
      "batch 30, gen_loss 0.810859, disc_loss 1.299763\n",
      "batch 31, gen_loss 0.821208, disc_loss 1.237876\n",
      "batch 32, gen_loss 0.817698, disc_loss 1.293270\n",
      "batch 33, gen_loss 0.807165, disc_loss 1.276721\n",
      "batch 34, gen_loss 0.826366, disc_loss 1.258327\n",
      "batch 35, gen_loss 0.828176, disc_loss 1.279528\n",
      "batch 36, gen_loss 0.836643, disc_loss 1.243344\n",
      "batch 37, gen_loss 0.829162, disc_loss 1.252155\n",
      "batch 38, gen_loss 0.834618, disc_loss 1.210253\n",
      "batch 39, gen_loss 0.853013, disc_loss 1.234757\n",
      "batch 40, gen_loss 0.833590, disc_loss 1.247661\n",
      "batch 41, gen_loss 0.860523, disc_loss 1.232782\n",
      "batch 42, gen_loss 0.852615, disc_loss 1.233717\n",
      "batch 43, gen_loss 0.849639, disc_loss 1.279605\n",
      "batch 44, gen_loss 0.860251, disc_loss 1.262008\n",
      "batch 45, gen_loss 0.851158, disc_loss 1.225350\n",
      "batch 46, gen_loss 0.855928, disc_loss 1.205704\n",
      "batch 47, gen_loss 0.864857, disc_loss 1.186368\n",
      "batch 48, gen_loss 0.873606, disc_loss 1.233269\n",
      "batch 49, gen_loss 0.882345, disc_loss 1.208006\n",
      "batch 50, gen_loss 0.871368, disc_loss 1.215185\n",
      "batch 51, gen_loss 0.880810, disc_loss 1.191291\n",
      "batch 52, gen_loss 0.886923, disc_loss 1.173252\n",
      "batch 53, gen_loss 0.891355, disc_loss 1.186111\n",
      "batch 54, gen_loss 0.885809, disc_loss 1.167989\n",
      "batch 55, gen_loss 0.878501, disc_loss 1.190438\n",
      "batch 56, gen_loss 0.893478, disc_loss 1.130136\n",
      "batch 57, gen_loss 0.888579, disc_loss 1.183391\n",
      "batch 58, gen_loss 0.901137, disc_loss 1.153675\n",
      "batch 59, gen_loss 0.918213, disc_loss 1.119223\n",
      "batch 60, gen_loss 0.935850, disc_loss 1.131236\n",
      "batch 61, gen_loss 0.941647, disc_loss 1.129389\n",
      "batch 62, gen_loss 0.956940, disc_loss 1.089386\n",
      "batch 63, gen_loss 0.951876, disc_loss 1.094133\n",
      "batch 64, gen_loss 0.968718, disc_loss 1.074779\n",
      "batch 65, gen_loss 0.989913, disc_loss 1.054598\n",
      "batch 66, gen_loss 0.981580, disc_loss 1.097534\n",
      "batch 67, gen_loss 0.990792, disc_loss 1.037567\n",
      "batch 68, gen_loss 1.012328, disc_loss 1.016473\n",
      "batch 69, gen_loss 1.009706, disc_loss 1.071339\n",
      "batch 70, gen_loss 1.023739, disc_loss 1.038462\n",
      "batch 71, gen_loss 1.016671, disc_loss 1.034002\n",
      "batch 72, gen_loss 1.008247, disc_loss 1.098591\n",
      "batch 73, gen_loss 1.013141, disc_loss 1.035682\n",
      "batch 74, gen_loss 1.014736, disc_loss 1.009611\n",
      "batch 75, gen_loss 1.002513, disc_loss 1.047099\n",
      "batch 76, gen_loss 1.017382, disc_loss 1.115448\n",
      "batch 77, gen_loss 0.999818, disc_loss 1.098100\n",
      "batch 78, gen_loss 1.006473, disc_loss 1.097554\n",
      "batch 79, gen_loss 0.998983, disc_loss 1.077294\n",
      "batch 80, gen_loss 0.982590, disc_loss 1.121446\n",
      "batch 81, gen_loss 1.019529, disc_loss 1.149659\n",
      "batch 82, gen_loss 0.990053, disc_loss 1.118010\n",
      "batch 83, gen_loss 0.969656, disc_loss 1.141720\n",
      "batch 84, gen_loss 0.945689, disc_loss 1.177670\n",
      "batch 85, gen_loss 0.917652, disc_loss 1.162449\n",
      "batch 86, gen_loss 0.890959, disc_loss 1.172510\n",
      "batch 87, gen_loss 0.885971, disc_loss 1.197050\n",
      "batch 88, gen_loss 0.874224, disc_loss 1.239019\n",
      "batch 89, gen_loss 0.848582, disc_loss 1.196457\n",
      "batch 90, gen_loss 0.826574, disc_loss 1.199795\n",
      "batch 91, gen_loss 0.797188, disc_loss 1.271999\n",
      "batch 92, gen_loss 0.789374, disc_loss 1.251505\n",
      "batch 93, gen_loss 0.757084, disc_loss 1.358321\n",
      "batch 94, gen_loss 0.746103, disc_loss 1.339360\n",
      "batch 95, gen_loss 0.724350, disc_loss 1.335586\n",
      "batch 96, gen_loss 0.733288, disc_loss 1.325655\n",
      "batch 97, gen_loss 0.708179, disc_loss 1.373447\n",
      "batch 98, gen_loss 0.692973, disc_loss 1.420212\n",
      "batch 99, gen_loss 0.694717, disc_loss 1.431144\n",
      "batch 100, gen_loss 0.692458, disc_loss 1.451093\n",
      "batch 101, gen_loss 0.701675, disc_loss 1.432599\n",
      "batch 102, gen_loss 0.697069, disc_loss 1.492226\n",
      "batch 103, gen_loss 0.701566, disc_loss 1.463228\n",
      "batch 104, gen_loss 0.700301, disc_loss 1.470170\n",
      "batch 105, gen_loss 0.689975, disc_loss 1.546368\n",
      "batch 106, gen_loss 0.694006, disc_loss 1.467424\n",
      "batch 107, gen_loss 0.677081, disc_loss 1.487542\n",
      "batch 108, gen_loss 0.694101, disc_loss 1.467804\n",
      "batch 109, gen_loss 0.685033, disc_loss 1.446759\n",
      "batch 110, gen_loss 0.708951, disc_loss 1.426318\n",
      "batch 111, gen_loss 0.698107, disc_loss 1.463823\n",
      "batch 112, gen_loss 0.711377, disc_loss 1.404300\n",
      "batch 113, gen_loss 0.710612, disc_loss 1.380873\n",
      "batch 114, gen_loss 0.714603, disc_loss 1.408303\n",
      "batch 115, gen_loss 0.756508, disc_loss 1.372428\n",
      "batch 116, gen_loss 0.775558, disc_loss 1.337580\n",
      "batch 117, gen_loss 0.785479, disc_loss 1.345569\n",
      "batch 118, gen_loss 0.796947, disc_loss 1.331803\n",
      "batch 119, gen_loss 0.815780, disc_loss 1.350232\n",
      "batch 120, gen_loss 0.795522, disc_loss 1.367463\n",
      "batch 121, gen_loss 0.781943, disc_loss 1.337706\n",
      "batch 122, gen_loss 0.796509, disc_loss 1.334515\n",
      "batch 123, gen_loss 0.774597, disc_loss 1.360575\n",
      "batch 124, gen_loss 0.788007, disc_loss 1.369950\n",
      "batch 125, gen_loss 0.771483, disc_loss 1.366390\n",
      "batch 126, gen_loss 0.739373, disc_loss 1.358374\n",
      "batch 127, gen_loss 0.743029, disc_loss 1.366632\n",
      "batch 128, gen_loss 0.719386, disc_loss 1.446894\n",
      "batch 129, gen_loss 0.713167, disc_loss 1.422961\n",
      "batch 130, gen_loss 0.686305, disc_loss 1.513932\n",
      "batch 131, gen_loss 0.699450, disc_loss 1.442122\n",
      "batch 132, gen_loss 0.687422, disc_loss 1.441723\n",
      "batch 133, gen_loss 0.684109, disc_loss 1.541744\n",
      "batch 134, gen_loss 0.700289, disc_loss 1.508759\n",
      "batch 135, gen_loss 0.709165, disc_loss 1.444159\n",
      "batch 136, gen_loss 0.713705, disc_loss 1.542866\n",
      "batch 137, gen_loss 0.718459, disc_loss 1.484946\n",
      "batch 138, gen_loss 0.762685, disc_loss 1.471269\n",
      "batch 139, gen_loss 0.785515, disc_loss 1.390706\n",
      "batch 140, gen_loss 0.783737, disc_loss 1.481953\n",
      "batch 141, gen_loss 0.793153, disc_loss 1.450849\n",
      "batch 142, gen_loss 0.804641, disc_loss 1.444444\n",
      "batch 143, gen_loss 0.831887, disc_loss 1.387987\n",
      "batch 144, gen_loss 0.840332, disc_loss 1.401464\n",
      "batch 145, gen_loss 0.847483, disc_loss 1.316302\n",
      "batch 146, gen_loss 0.881202, disc_loss 1.312369\n",
      "batch 147, gen_loss 0.873420, disc_loss 1.257056\n",
      "batch 148, gen_loss 0.885522, disc_loss 1.250705\n",
      "batch 149, gen_loss 0.916014, disc_loss 1.220780\n",
      "batch 150, gen_loss 0.919318, disc_loss 1.171967\n",
      "batch 151, gen_loss 0.939634, disc_loss 1.114522\n",
      "batch 152, gen_loss 0.926686, disc_loss 1.199837\n",
      "batch 153, gen_loss 0.960930, disc_loss 1.106598\n",
      "batch 154, gen_loss 0.965625, disc_loss 1.079183\n",
      "batch 155, gen_loss 0.971983, disc_loss 1.070931\n",
      "batch 156, gen_loss 1.000641, disc_loss 1.065687\n",
      "batch 157, gen_loss 1.011358, disc_loss 1.037865\n",
      "batch 158, gen_loss 1.016825, disc_loss 1.030115\n",
      "batch 159, gen_loss 1.035139, disc_loss 0.985448\n",
      "batch 160, gen_loss 1.032961, disc_loss 0.989601\n",
      "batch 161, gen_loss 1.025675, disc_loss 1.005276\n",
      "batch 162, gen_loss 1.053597, disc_loss 0.986978\n",
      "batch 163, gen_loss 1.032271, disc_loss 0.976263\n",
      "batch 164, gen_loss 1.045316, disc_loss 0.949463\n",
      "batch 165, gen_loss 1.017849, disc_loss 0.960455\n",
      "batch 166, gen_loss 1.025711, disc_loss 0.975847\n",
      "batch 167, gen_loss 1.021410, disc_loss 0.998004\n",
      "batch 168, gen_loss 1.028124, disc_loss 0.952805\n",
      "batch 169, gen_loss 1.024294, disc_loss 1.016225\n",
      "batch 170, gen_loss 1.018667, disc_loss 0.963570\n",
      "batch 171, gen_loss 0.985179, disc_loss 0.991348\n",
      "batch 172, gen_loss 0.965968, disc_loss 1.006472\n",
      "batch 173, gen_loss 0.966462, disc_loss 1.025545\n",
      "batch 174, gen_loss 0.927878, disc_loss 1.014227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 175, gen_loss 0.902006, disc_loss 1.039192\n",
      "batch 176, gen_loss 0.888885, disc_loss 1.028475\n",
      "batch 177, gen_loss 0.883703, disc_loss 1.030850\n",
      "batch 178, gen_loss 0.827818, disc_loss 1.101731\n",
      "batch 179, gen_loss 0.840576, disc_loss 1.048503\n",
      "batch 180, gen_loss 0.817764, disc_loss 1.112829\n",
      "batch 181, gen_loss 0.785156, disc_loss 1.155848\n",
      "batch 182, gen_loss 0.766163, disc_loss 1.157747\n",
      "batch 183, gen_loss 0.781447, disc_loss 1.157531\n",
      "batch 184, gen_loss 0.750349, disc_loss 1.217503\n",
      "batch 185, gen_loss 0.728181, disc_loss 1.257064\n",
      "batch 186, gen_loss 0.723361, disc_loss 1.285980\n",
      "batch 187, gen_loss 0.699545, disc_loss 1.291667\n",
      "batch 188, gen_loss 0.698415, disc_loss 1.300630\n",
      "batch 189, gen_loss 0.713599, disc_loss 1.381328\n",
      "batch 190, gen_loss 0.694662, disc_loss 1.457201\n",
      "batch 191, gen_loss 0.682859, disc_loss 1.455931\n",
      "batch 192, gen_loss 0.661958, disc_loss 1.557138\n",
      "batch 193, gen_loss 0.651338, disc_loss 1.551038\n",
      "batch 194, gen_loss 0.625851, disc_loss 1.611467\n",
      "batch 195, gen_loss 0.619144, disc_loss 1.652374\n",
      "batch 196, gen_loss 0.612666, disc_loss 1.601888\n",
      "batch 197, gen_loss 0.586452, disc_loss 1.678168\n",
      "batch 198, gen_loss 0.575686, disc_loss 1.626686\n",
      "batch 199, gen_loss 0.569355, disc_loss 1.776774\n",
      "batch 200, gen_loss 0.581398, disc_loss 1.818106\n",
      "batch 201, gen_loss 0.569766, disc_loss 1.860798\n",
      "batch 202, gen_loss 0.562534, disc_loss 1.833014\n",
      "batch 203, gen_loss 0.569949, disc_loss 1.851945\n",
      "batch 204, gen_loss 0.570734, disc_loss 1.890594\n",
      "batch 205, gen_loss 0.586697, disc_loss 1.869820\n",
      "batch 206, gen_loss 0.582681, disc_loss 1.872013\n",
      "batch 207, gen_loss 0.601787, disc_loss 1.853693\n",
      "batch 208, gen_loss 0.587816, disc_loss 1.868389\n",
      "batch 209, gen_loss 0.604968, disc_loss 1.851732\n",
      "batch 210, gen_loss 0.628222, disc_loss 1.788706\n",
      "batch 211, gen_loss 0.630750, disc_loss 1.911240\n",
      "batch 212, gen_loss 0.652360, disc_loss 1.786667\n",
      "batch 213, gen_loss 0.662024, disc_loss 1.772624\n",
      "batch 214, gen_loss 0.669824, disc_loss 1.750876\n",
      "batch 215, gen_loss 0.684284, disc_loss 1.683711\n",
      "batch 216, gen_loss 0.713435, disc_loss 1.667517\n",
      "batch 217, gen_loss 0.730971, disc_loss 1.626342\n",
      "batch 218, gen_loss 0.740480, disc_loss 1.589244\n",
      "batch 219, gen_loss 0.737659, disc_loss 1.665144\n",
      "batch 220, gen_loss 0.764857, disc_loss 1.535109\n",
      "batch 221, gen_loss 0.776998, disc_loss 1.501285\n",
      "batch 222, gen_loss 0.785519, disc_loss 1.531430\n",
      "batch 223, gen_loss 0.807286, disc_loss 1.483387\n",
      "batch 224, gen_loss 0.805852, disc_loss 1.482995\n",
      "batch 225, gen_loss 0.824236, disc_loss 1.453134\n",
      "batch 226, gen_loss 0.835639, disc_loss 1.440113\n",
      "batch 227, gen_loss 0.839723, disc_loss 1.436540\n",
      "batch 228, gen_loss 0.845641, disc_loss 1.392203\n",
      "batch 229, gen_loss 0.860614, disc_loss 1.353187\n",
      "batch 230, gen_loss 0.849377, disc_loss 1.309232\n",
      "batch 231, gen_loss 0.855864, disc_loss 1.311028\n",
      "batch 232, gen_loss 0.856398, disc_loss 1.349531\n",
      "batch 233, gen_loss 0.881713, disc_loss 1.349055\n",
      "batch 234, gen_loss 0.883750, disc_loss 1.224449\n",
      "Time for epoch1is 7.396165132522583 sec\n",
      "batch 0, gen_loss 0.897692, disc_loss 1.292925\n",
      "batch 1, gen_loss 0.901810, disc_loss 1.257979\n",
      "batch 2, gen_loss 0.890400, disc_loss 1.291169\n",
      "batch 3, gen_loss 0.908266, disc_loss 1.244389\n",
      "batch 4, gen_loss 0.912475, disc_loss 1.243350\n",
      "batch 5, gen_loss 0.901328, disc_loss 1.247687\n",
      "batch 6, gen_loss 0.911106, disc_loss 1.213655\n",
      "batch 7, gen_loss 0.895063, disc_loss 1.251976\n",
      "batch 8, gen_loss 0.895954, disc_loss 1.213903\n",
      "batch 9, gen_loss 0.902070, disc_loss 1.246652\n",
      "batch 10, gen_loss 0.914637, disc_loss 1.235013\n",
      "batch 11, gen_loss 0.898530, disc_loss 1.224272\n",
      "batch 12, gen_loss 0.896535, disc_loss 1.227897\n",
      "batch 13, gen_loss 0.881523, disc_loss 1.234255\n",
      "batch 14, gen_loss 0.866300, disc_loss 1.261161\n",
      "batch 15, gen_loss 0.875015, disc_loss 1.262423\n",
      "batch 16, gen_loss 0.862123, disc_loss 1.227311\n",
      "batch 17, gen_loss 0.867933, disc_loss 1.198812\n",
      "batch 18, gen_loss 0.854762, disc_loss 1.257983\n",
      "batch 19, gen_loss 0.851966, disc_loss 1.214919\n",
      "batch 20, gen_loss 0.852615, disc_loss 1.225944\n",
      "batch 21, gen_loss 0.858908, disc_loss 1.226250\n",
      "batch 22, gen_loss 0.867665, disc_loss 1.208286\n",
      "batch 23, gen_loss 0.875201, disc_loss 1.169943\n",
      "batch 24, gen_loss 0.889271, disc_loss 1.154244\n",
      "batch 25, gen_loss 0.892736, disc_loss 1.136382\n",
      "batch 26, gen_loss 0.907592, disc_loss 1.119612\n",
      "batch 27, gen_loss 0.909948, disc_loss 1.155520\n",
      "batch 28, gen_loss 0.916252, disc_loss 1.096476\n",
      "batch 29, gen_loss 0.934763, disc_loss 1.123401\n",
      "batch 30, gen_loss 0.916681, disc_loss 1.130195\n",
      "batch 31, gen_loss 0.933030, disc_loss 1.062592\n",
      "batch 32, gen_loss 0.956249, disc_loss 1.063404\n",
      "batch 33, gen_loss 0.967032, disc_loss 1.048705\n",
      "batch 34, gen_loss 0.964608, disc_loss 1.064125\n",
      "batch 35, gen_loss 0.977257, disc_loss 1.047649\n",
      "batch 36, gen_loss 0.981574, disc_loss 1.020865\n",
      "batch 37, gen_loss 1.007934, disc_loss 1.048100\n",
      "batch 38, gen_loss 0.993157, disc_loss 1.011243\n",
      "batch 39, gen_loss 0.993442, disc_loss 1.017345\n",
      "batch 40, gen_loss 0.981714, disc_loss 1.003976\n",
      "batch 41, gen_loss 1.004337, disc_loss 0.950356\n",
      "batch 42, gen_loss 0.981980, disc_loss 0.972994\n",
      "batch 43, gen_loss 1.006323, disc_loss 0.970168\n",
      "batch 44, gen_loss 1.023900, disc_loss 0.956440\n",
      "batch 45, gen_loss 0.997857, disc_loss 0.974153\n",
      "batch 46, gen_loss 1.002285, disc_loss 0.956753\n",
      "batch 47, gen_loss 0.989447, disc_loss 0.924030\n",
      "batch 48, gen_loss 0.950624, disc_loss 0.965332\n",
      "batch 49, gen_loss 0.987333, disc_loss 0.940564\n",
      "batch 50, gen_loss 0.998261, disc_loss 0.941311\n",
      "batch 51, gen_loss 0.967171, disc_loss 0.973772\n",
      "batch 52, gen_loss 0.987363, disc_loss 0.951499\n",
      "batch 53, gen_loss 0.990742, disc_loss 0.970381\n",
      "batch 54, gen_loss 0.987494, disc_loss 0.977827\n",
      "batch 55, gen_loss 0.958012, disc_loss 1.042042\n",
      "batch 56, gen_loss 0.949331, disc_loss 1.053507\n",
      "batch 57, gen_loss 0.947757, disc_loss 1.035002\n",
      "batch 58, gen_loss 0.947771, disc_loss 1.034640\n",
      "batch 59, gen_loss 0.915309, disc_loss 1.052219\n",
      "batch 60, gen_loss 0.875066, disc_loss 1.095668\n",
      "batch 61, gen_loss 0.833478, disc_loss 1.195511\n",
      "batch 62, gen_loss 0.829410, disc_loss 1.206246\n",
      "batch 63, gen_loss 0.815270, disc_loss 1.197350\n",
      "batch 64, gen_loss 0.802724, disc_loss 1.247909\n",
      "batch 65, gen_loss 0.748815, disc_loss 1.297882\n",
      "batch 66, gen_loss 0.723610, disc_loss 1.397121\n",
      "batch 67, gen_loss 0.726383, disc_loss 1.338475\n",
      "batch 68, gen_loss 0.692943, disc_loss 1.429147\n",
      "batch 69, gen_loss 0.717178, disc_loss 1.387525\n",
      "batch 70, gen_loss 0.723339, disc_loss 1.415734\n",
      "batch 71, gen_loss 0.712787, disc_loss 1.442481\n",
      "batch 72, gen_loss 0.719030, disc_loss 1.520792\n",
      "batch 73, gen_loss 0.717094, disc_loss 1.504363\n",
      "batch 74, gen_loss 0.718114, disc_loss 1.452688\n",
      "batch 75, gen_loss 0.728672, disc_loss 1.449074\n",
      "batch 76, gen_loss 0.732159, disc_loss 1.450403\n",
      "batch 77, gen_loss 0.736995, disc_loss 1.442420\n",
      "batch 78, gen_loss 0.763923, disc_loss 1.474908\n",
      "batch 79, gen_loss 0.795500, disc_loss 1.401782\n",
      "batch 80, gen_loss 0.769471, disc_loss 1.457602\n",
      "batch 81, gen_loss 0.803251, disc_loss 1.438237\n",
      "batch 82, gen_loss 0.824553, disc_loss 1.360044\n",
      "batch 83, gen_loss 0.849943, disc_loss 1.357254\n",
      "batch 84, gen_loss 0.847926, disc_loss 1.399657\n",
      "batch 85, gen_loss 0.864912, disc_loss 1.348330\n",
      "batch 86, gen_loss 0.910776, disc_loss 1.366086\n",
      "batch 87, gen_loss 0.925086, disc_loss 1.267778\n",
      "batch 88, gen_loss 0.949041, disc_loss 1.311139\n",
      "batch 89, gen_loss 0.933263, disc_loss 1.293170\n",
      "batch 90, gen_loss 0.971606, disc_loss 1.280923\n",
      "batch 91, gen_loss 1.002049, disc_loss 1.265294\n",
      "batch 92, gen_loss 0.990211, disc_loss 1.256835\n",
      "batch 93, gen_loss 1.003479, disc_loss 1.296087\n",
      "batch 94, gen_loss 1.027485, disc_loss 1.239689\n",
      "batch 95, gen_loss 1.029733, disc_loss 1.200536\n",
      "batch 96, gen_loss 1.026214, disc_loss 1.210432\n",
      "batch 97, gen_loss 1.037397, disc_loss 1.190358\n",
      "batch 98, gen_loss 1.050284, disc_loss 1.162788\n",
      "batch 99, gen_loss 1.024904, disc_loss 1.205102\n",
      "batch 100, gen_loss 1.044894, disc_loss 1.138451\n",
      "batch 101, gen_loss 1.014781, disc_loss 1.169279\n",
      "batch 102, gen_loss 1.004983, disc_loss 1.198036\n",
      "batch 103, gen_loss 1.027866, disc_loss 1.195849\n",
      "batch 104, gen_loss 0.985571, disc_loss 1.239517\n",
      "batch 105, gen_loss 1.013350, disc_loss 1.137340\n",
      "batch 106, gen_loss 0.983663, disc_loss 1.188036\n",
      "batch 107, gen_loss 0.967891, disc_loss 1.198608\n",
      "batch 108, gen_loss 0.972284, disc_loss 1.134367\n",
      "batch 109, gen_loss 0.937493, disc_loss 1.173597\n",
      "batch 110, gen_loss 0.938004, disc_loss 1.128930\n",
      "batch 111, gen_loss 0.909276, disc_loss 1.230663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 112, gen_loss 0.896744, disc_loss 1.177297\n",
      "batch 113, gen_loss 0.885314, disc_loss 1.163653\n",
      "batch 114, gen_loss 0.864775, disc_loss 1.204385\n",
      "batch 115, gen_loss 0.849493, disc_loss 1.177003\n",
      "batch 116, gen_loss 0.835165, disc_loss 1.184986\n",
      "batch 117, gen_loss 0.844606, disc_loss 1.169563\n",
      "batch 118, gen_loss 0.839876, disc_loss 1.134502\n",
      "batch 119, gen_loss 0.828468, disc_loss 1.095038\n",
      "batch 120, gen_loss 0.835174, disc_loss 1.127608\n",
      "batch 121, gen_loss 0.838710, disc_loss 1.136092\n",
      "batch 122, gen_loss 0.851445, disc_loss 1.103093\n",
      "batch 123, gen_loss 0.862296, disc_loss 1.061786\n",
      "batch 124, gen_loss 0.871627, disc_loss 1.073275\n",
      "batch 125, gen_loss 0.912722, disc_loss 1.078162\n",
      "batch 126, gen_loss 0.933097, disc_loss 1.069324\n",
      "batch 127, gen_loss 0.944709, disc_loss 0.974079\n",
      "batch 128, gen_loss 0.990704, disc_loss 1.052299\n",
      "batch 129, gen_loss 1.006728, disc_loss 1.005832\n",
      "batch 130, gen_loss 1.001412, disc_loss 1.022235\n",
      "batch 131, gen_loss 1.025192, disc_loss 1.039272\n",
      "batch 132, gen_loss 1.040839, disc_loss 0.958582\n",
      "batch 133, gen_loss 1.048942, disc_loss 0.983164\n",
      "batch 134, gen_loss 1.059282, disc_loss 0.985208\n",
      "batch 135, gen_loss 1.056435, disc_loss 0.956466\n",
      "batch 136, gen_loss 1.059907, disc_loss 0.960100\n",
      "batch 137, gen_loss 1.060379, disc_loss 0.962912\n",
      "batch 138, gen_loss 1.074877, disc_loss 0.964876\n",
      "batch 139, gen_loss 1.082590, disc_loss 0.947038\n",
      "batch 140, gen_loss 1.083067, disc_loss 0.917501\n",
      "batch 141, gen_loss 1.086678, disc_loss 0.885129\n",
      "batch 142, gen_loss 1.090669, disc_loss 0.889401\n",
      "batch 143, gen_loss 1.098221, disc_loss 0.939224\n",
      "batch 144, gen_loss 1.098105, disc_loss 0.908689\n",
      "batch 145, gen_loss 1.100047, disc_loss 0.877191\n",
      "batch 146, gen_loss 1.090514, disc_loss 0.894138\n",
      "batch 147, gen_loss 1.091978, disc_loss 0.895574\n",
      "batch 148, gen_loss 1.072665, disc_loss 0.883355\n",
      "batch 149, gen_loss 1.063203, disc_loss 0.946047\n",
      "batch 150, gen_loss 1.055965, disc_loss 0.927166\n",
      "batch 151, gen_loss 1.037803, disc_loss 0.992719\n",
      "batch 152, gen_loss 1.009330, disc_loss 0.984480\n",
      "batch 153, gen_loss 1.012949, disc_loss 0.952258\n",
      "batch 154, gen_loss 0.989456, disc_loss 0.973348\n",
      "batch 155, gen_loss 0.980155, disc_loss 0.996423\n",
      "batch 156, gen_loss 0.951270, disc_loss 1.005637\n",
      "batch 157, gen_loss 0.929761, disc_loss 1.051634\n",
      "batch 158, gen_loss 0.933441, disc_loss 1.011075\n",
      "batch 159, gen_loss 0.910629, disc_loss 1.050911\n",
      "batch 160, gen_loss 0.889234, disc_loss 1.106634\n",
      "batch 161, gen_loss 0.896016, disc_loss 1.119939\n",
      "batch 162, gen_loss 0.875360, disc_loss 1.151365\n",
      "batch 163, gen_loss 0.876252, disc_loss 1.164014\n",
      "batch 164, gen_loss 0.868333, disc_loss 1.142901\n",
      "batch 165, gen_loss 0.858733, disc_loss 1.198883\n",
      "batch 166, gen_loss 0.871028, disc_loss 1.158222\n",
      "batch 167, gen_loss 0.885207, disc_loss 1.207084\n",
      "batch 168, gen_loss 0.865219, disc_loss 1.226352\n",
      "batch 169, gen_loss 0.872416, disc_loss 1.250730\n",
      "batch 170, gen_loss 0.887823, disc_loss 1.212531\n",
      "batch 171, gen_loss 0.874231, disc_loss 1.215761\n",
      "batch 172, gen_loss 0.868025, disc_loss 1.260093\n",
      "batch 173, gen_loss 0.855366, disc_loss 1.262584\n",
      "batch 174, gen_loss 0.877309, disc_loss 1.241327\n",
      "batch 175, gen_loss 0.869760, disc_loss 1.257450\n",
      "batch 176, gen_loss 0.862509, disc_loss 1.254997\n",
      "batch 177, gen_loss 0.883258, disc_loss 1.182301\n",
      "batch 178, gen_loss 0.867359, disc_loss 1.236778\n",
      "batch 179, gen_loss 0.900055, disc_loss 1.206632\n",
      "batch 180, gen_loss 0.914527, disc_loss 1.197898\n",
      "batch 181, gen_loss 0.908327, disc_loss 1.192818\n",
      "batch 182, gen_loss 0.899486, disc_loss 1.215936\n",
      "batch 183, gen_loss 0.936673, disc_loss 1.222995\n",
      "batch 184, gen_loss 0.938157, disc_loss 1.210690\n",
      "batch 185, gen_loss 0.958505, disc_loss 1.166633\n",
      "batch 186, gen_loss 0.965730, disc_loss 1.180403\n",
      "batch 187, gen_loss 0.957797, disc_loss 1.174738\n",
      "batch 188, gen_loss 0.956302, disc_loss 1.121001\n",
      "batch 189, gen_loss 0.975121, disc_loss 1.156518\n",
      "batch 190, gen_loss 0.988234, disc_loss 1.199909\n",
      "batch 191, gen_loss 0.956024, disc_loss 1.183228\n",
      "batch 192, gen_loss 0.949437, disc_loss 1.173193\n",
      "batch 193, gen_loss 0.959586, disc_loss 1.176120\n",
      "batch 194, gen_loss 0.942159, disc_loss 1.170516\n",
      "batch 195, gen_loss 0.955264, disc_loss 1.253181\n",
      "batch 196, gen_loss 0.944375, disc_loss 1.208302\n",
      "batch 197, gen_loss 0.950684, disc_loss 1.210447\n",
      "batch 198, gen_loss 0.937002, disc_loss 1.201035\n",
      "batch 199, gen_loss 0.944673, disc_loss 1.254038\n",
      "batch 200, gen_loss 0.941176, disc_loss 1.190189\n",
      "batch 201, gen_loss 0.943971, disc_loss 1.224060\n",
      "batch 202, gen_loss 0.905524, disc_loss 1.207845\n",
      "batch 203, gen_loss 0.937752, disc_loss 1.177220\n",
      "batch 204, gen_loss 0.928889, disc_loss 1.202028\n",
      "batch 205, gen_loss 0.920918, disc_loss 1.202068\n",
      "batch 206, gen_loss 0.925776, disc_loss 1.175379\n",
      "batch 207, gen_loss 0.930109, disc_loss 1.193245\n",
      "batch 208, gen_loss 0.921645, disc_loss 1.186848\n",
      "batch 209, gen_loss 0.936532, disc_loss 1.186318\n",
      "batch 210, gen_loss 0.935765, disc_loss 1.154379\n",
      "batch 211, gen_loss 0.940855, disc_loss 1.177534\n",
      "batch 212, gen_loss 0.969745, disc_loss 1.160217\n",
      "batch 213, gen_loss 0.979204, disc_loss 1.109621\n",
      "batch 214, gen_loss 0.978024, disc_loss 1.140991\n",
      "batch 215, gen_loss 1.010301, disc_loss 1.083911\n",
      "batch 216, gen_loss 0.995944, disc_loss 1.089887\n",
      "batch 217, gen_loss 1.009704, disc_loss 1.087276\n",
      "batch 218, gen_loss 1.023379, disc_loss 1.074403\n",
      "batch 219, gen_loss 1.041375, disc_loss 1.040381\n",
      "batch 220, gen_loss 1.044085, disc_loss 1.030911\n",
      "batch 221, gen_loss 1.057270, disc_loss 1.006193\n",
      "batch 222, gen_loss 1.047176, disc_loss 0.999612\n",
      "batch 223, gen_loss 1.053793, disc_loss 0.987927\n",
      "batch 224, gen_loss 1.074613, disc_loss 0.955591\n",
      "batch 225, gen_loss 1.062188, disc_loss 0.987394\n",
      "batch 226, gen_loss 1.100315, disc_loss 0.935317\n",
      "batch 227, gen_loss 1.100560, disc_loss 0.954993\n",
      "batch 228, gen_loss 1.119609, disc_loss 0.961407\n",
      "batch 229, gen_loss 1.112925, disc_loss 0.926113\n",
      "batch 230, gen_loss 1.105217, disc_loss 0.933250\n",
      "batch 231, gen_loss 1.127918, disc_loss 0.918360\n",
      "batch 232, gen_loss 1.146761, disc_loss 0.871791\n",
      "batch 233, gen_loss 1.167195, disc_loss 0.899842\n",
      "batch 234, gen_loss 1.174094, disc_loss 0.888309\n",
      "Time for epoch2is 7.417715311050415 sec\n",
      "batch 0, gen_loss 1.191116, disc_loss 0.869031\n",
      "batch 1, gen_loss 1.174370, disc_loss 0.913025\n",
      "batch 2, gen_loss 1.186850, disc_loss 0.907220\n",
      "batch 3, gen_loss 1.203405, disc_loss 0.898893\n",
      "batch 4, gen_loss 1.202188, disc_loss 0.883990\n",
      "batch 5, gen_loss 1.221632, disc_loss 0.875488\n",
      "batch 6, gen_loss 1.240726, disc_loss 0.928220\n",
      "batch 7, gen_loss 1.205675, disc_loss 0.925593\n",
      "batch 8, gen_loss 1.187089, disc_loss 0.919711\n",
      "batch 9, gen_loss 1.174979, disc_loss 0.963875\n",
      "batch 10, gen_loss 1.125863, disc_loss 1.021923\n",
      "batch 11, gen_loss 1.140172, disc_loss 0.985639\n",
      "batch 12, gen_loss 1.153013, disc_loss 0.954831\n",
      "batch 13, gen_loss 1.122555, disc_loss 1.011744\n",
      "batch 14, gen_loss 1.121988, disc_loss 0.982222\n",
      "batch 15, gen_loss 1.087530, disc_loss 1.074005\n",
      "batch 16, gen_loss 1.114122, disc_loss 1.047753\n",
      "batch 17, gen_loss 1.098922, disc_loss 1.072632\n",
      "batch 18, gen_loss 1.058919, disc_loss 1.102525\n",
      "batch 19, gen_loss 1.042480, disc_loss 1.117529\n",
      "batch 20, gen_loss 1.018660, disc_loss 1.147940\n",
      "batch 21, gen_loss 0.996184, disc_loss 1.139137\n",
      "batch 22, gen_loss 0.968722, disc_loss 1.217584\n",
      "batch 23, gen_loss 0.943631, disc_loss 1.225376\n",
      "batch 24, gen_loss 0.884068, disc_loss 1.261219\n",
      "batch 25, gen_loss 0.865817, disc_loss 1.277127\n",
      "batch 26, gen_loss 0.797589, disc_loss 1.348774\n",
      "batch 27, gen_loss 0.778317, disc_loss 1.345613\n",
      "batch 28, gen_loss 0.817305, disc_loss 1.386323\n",
      "batch 29, gen_loss 0.780310, disc_loss 1.396310\n",
      "batch 30, gen_loss 0.773427, disc_loss 1.473770\n",
      "batch 31, gen_loss 0.745845, disc_loss 1.433748\n",
      "batch 32, gen_loss 0.728096, disc_loss 1.509783\n",
      "batch 33, gen_loss 0.711465, disc_loss 1.545276\n",
      "batch 34, gen_loss 0.713002, disc_loss 1.572081\n",
      "batch 35, gen_loss 0.683452, disc_loss 1.575529\n",
      "batch 36, gen_loss 0.684846, disc_loss 1.492013\n",
      "batch 37, gen_loss 0.686235, disc_loss 1.528886\n",
      "batch 38, gen_loss 0.697125, disc_loss 1.528470\n",
      "batch 39, gen_loss 0.695464, disc_loss 1.521766\n",
      "batch 40, gen_loss 0.697267, disc_loss 1.511069\n",
      "batch 41, gen_loss 0.716809, disc_loss 1.476178\n",
      "batch 42, gen_loss 0.713381, disc_loss 1.530366\n",
      "batch 43, gen_loss 0.747948, disc_loss 1.448918\n",
      "batch 44, gen_loss 0.764480, disc_loss 1.524194\n",
      "batch 45, gen_loss 0.780437, disc_loss 1.444897\n",
      "batch 46, gen_loss 0.837489, disc_loss 1.439658\n",
      "batch 47, gen_loss 0.841156, disc_loss 1.440982\n",
      "batch 48, gen_loss 0.852679, disc_loss 1.441465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 49, gen_loss 0.873986, disc_loss 1.438680\n",
      "batch 50, gen_loss 0.869339, disc_loss 1.439620\n",
      "batch 51, gen_loss 0.892014, disc_loss 1.403201\n",
      "batch 52, gen_loss 0.896818, disc_loss 1.334426\n",
      "batch 53, gen_loss 0.864334, disc_loss 1.406611\n",
      "batch 54, gen_loss 0.915452, disc_loss 1.313156\n",
      "batch 55, gen_loss 0.938594, disc_loss 1.319032\n",
      "batch 56, gen_loss 0.929838, disc_loss 1.345933\n",
      "batch 57, gen_loss 0.925887, disc_loss 1.260824\n",
      "batch 58, gen_loss 0.935094, disc_loss 1.288568\n",
      "batch 59, gen_loss 0.932163, disc_loss 1.197364\n",
      "batch 60, gen_loss 0.944255, disc_loss 1.217149\n",
      "batch 61, gen_loss 0.931012, disc_loss 1.241527\n",
      "batch 62, gen_loss 0.947803, disc_loss 1.206698\n",
      "batch 63, gen_loss 0.954108, disc_loss 1.176582\n",
      "batch 64, gen_loss 0.962122, disc_loss 1.162250\n",
      "batch 65, gen_loss 0.965749, disc_loss 1.148714\n",
      "batch 66, gen_loss 0.961919, disc_loss 1.160586\n",
      "batch 67, gen_loss 0.936419, disc_loss 1.168876\n",
      "batch 68, gen_loss 0.924488, disc_loss 1.138278\n",
      "batch 69, gen_loss 0.936943, disc_loss 1.153947\n",
      "batch 70, gen_loss 1.008918, disc_loss 1.045763\n",
      "batch 71, gen_loss 0.980875, disc_loss 1.105647\n",
      "batch 72, gen_loss 0.986990, disc_loss 1.109321\n",
      "batch 73, gen_loss 1.004987, disc_loss 1.083172\n",
      "batch 74, gen_loss 1.009028, disc_loss 1.070039\n",
      "batch 75, gen_loss 0.994688, disc_loss 1.070483\n",
      "batch 76, gen_loss 1.028277, disc_loss 1.058737\n",
      "batch 77, gen_loss 1.014045, disc_loss 1.043276\n",
      "batch 78, gen_loss 1.040224, disc_loss 0.993065\n",
      "batch 79, gen_loss 1.066233, disc_loss 1.020897\n",
      "batch 80, gen_loss 1.061665, disc_loss 1.026233\n",
      "batch 81, gen_loss 1.085019, disc_loss 0.997008\n",
      "batch 82, gen_loss 1.086877, disc_loss 1.041932\n",
      "batch 83, gen_loss 1.084997, disc_loss 1.004071\n",
      "batch 84, gen_loss 1.099826, disc_loss 0.951077\n",
      "batch 85, gen_loss 1.059150, disc_loss 0.988955\n",
      "batch 86, gen_loss 1.068336, disc_loss 1.008359\n",
      "batch 87, gen_loss 1.082581, disc_loss 1.033495\n",
      "batch 88, gen_loss 1.069000, disc_loss 0.982130\n",
      "batch 89, gen_loss 1.060229, disc_loss 0.979180\n",
      "batch 90, gen_loss 1.082972, disc_loss 0.982809\n",
      "batch 91, gen_loss 1.069605, disc_loss 0.974601\n",
      "batch 92, gen_loss 1.058863, disc_loss 0.971926\n",
      "batch 93, gen_loss 1.075111, disc_loss 0.969104\n",
      "batch 94, gen_loss 1.064417, disc_loss 0.996590\n",
      "batch 95, gen_loss 1.056499, disc_loss 0.976138\n",
      "batch 96, gen_loss 1.072723, disc_loss 0.947605\n",
      "batch 97, gen_loss 1.055427, disc_loss 0.957165\n",
      "batch 98, gen_loss 1.031982, disc_loss 0.948541\n",
      "batch 99, gen_loss 1.026314, disc_loss 0.973064\n",
      "batch 100, gen_loss 1.005819, disc_loss 0.981177\n",
      "batch 101, gen_loss 1.018580, disc_loss 0.945742\n",
      "batch 102, gen_loss 1.007809, disc_loss 0.989066\n",
      "batch 103, gen_loss 1.006432, disc_loss 0.990901\n",
      "batch 104, gen_loss 1.004915, disc_loss 0.951878\n",
      "batch 105, gen_loss 0.986132, disc_loss 1.019560\n",
      "batch 106, gen_loss 0.970212, disc_loss 1.001242\n",
      "batch 107, gen_loss 0.975815, disc_loss 0.989471\n",
      "batch 108, gen_loss 0.959514, disc_loss 1.035164\n",
      "batch 109, gen_loss 0.944263, disc_loss 1.062711\n",
      "batch 110, gen_loss 0.937243, disc_loss 1.023096\n",
      "batch 111, gen_loss 0.953445, disc_loss 1.061268\n",
      "batch 112, gen_loss 0.941508, disc_loss 1.080751\n",
      "batch 113, gen_loss 0.914009, disc_loss 1.066875\n",
      "batch 114, gen_loss 0.914645, disc_loss 1.071582\n",
      "batch 115, gen_loss 0.927117, disc_loss 1.065891\n",
      "batch 116, gen_loss 0.926096, disc_loss 1.117862\n",
      "batch 117, gen_loss 0.913554, disc_loss 1.087516\n",
      "batch 118, gen_loss 0.917023, disc_loss 1.078781\n",
      "batch 119, gen_loss 0.924861, disc_loss 1.084477\n",
      "batch 120, gen_loss 0.917609, disc_loss 1.098633\n",
      "batch 121, gen_loss 0.911248, disc_loss 1.069675\n",
      "batch 122, gen_loss 0.912679, disc_loss 1.229188\n",
      "batch 123, gen_loss 0.900540, disc_loss 1.144952\n",
      "batch 124, gen_loss 0.907195, disc_loss 1.106678\n",
      "batch 125, gen_loss 0.900863, disc_loss 1.150773\n",
      "batch 126, gen_loss 0.896720, disc_loss 1.106585\n",
      "batch 127, gen_loss 0.897122, disc_loss 1.160264\n",
      "batch 128, gen_loss 0.892059, disc_loss 1.190804\n",
      "batch 129, gen_loss 0.882225, disc_loss 1.213201\n",
      "batch 130, gen_loss 0.904736, disc_loss 1.183576\n",
      "batch 131, gen_loss 0.896221, disc_loss 1.228583\n",
      "batch 132, gen_loss 0.886021, disc_loss 1.224712\n",
      "batch 133, gen_loss 0.892506, disc_loss 1.280777\n",
      "batch 134, gen_loss 0.910873, disc_loss 1.300724\n",
      "batch 135, gen_loss 0.889592, disc_loss 1.233003\n",
      "batch 136, gen_loss 0.901517, disc_loss 1.257957\n",
      "batch 137, gen_loss 0.899543, disc_loss 1.273130\n",
      "batch 138, gen_loss 0.905711, disc_loss 1.299841\n",
      "batch 139, gen_loss 0.894906, disc_loss 1.282554\n",
      "batch 140, gen_loss 0.910952, disc_loss 1.230098\n",
      "batch 141, gen_loss 0.867075, disc_loss 1.275907\n",
      "batch 142, gen_loss 0.894788, disc_loss 1.236732\n",
      "batch 143, gen_loss 0.879457, disc_loss 1.274426\n",
      "batch 144, gen_loss 0.878697, disc_loss 1.271846\n",
      "batch 145, gen_loss 0.890892, disc_loss 1.267351\n",
      "batch 146, gen_loss 0.904615, disc_loss 1.257341\n",
      "batch 147, gen_loss 0.944645, disc_loss 1.269880\n",
      "batch 148, gen_loss 0.939840, disc_loss 1.304558\n",
      "batch 149, gen_loss 0.933251, disc_loss 1.334314\n",
      "batch 150, gen_loss 0.884642, disc_loss 1.365074\n",
      "batch 151, gen_loss 0.889465, disc_loss 1.313328\n",
      "batch 152, gen_loss 0.866268, disc_loss 1.329098\n",
      "batch 153, gen_loss 0.829568, disc_loss 1.389443\n",
      "batch 154, gen_loss 0.825686, disc_loss 1.300251\n",
      "batch 155, gen_loss 0.820559, disc_loss 1.386268\n",
      "batch 156, gen_loss 0.798179, disc_loss 1.410786\n",
      "batch 157, gen_loss 0.800373, disc_loss 1.418722\n",
      "batch 158, gen_loss 0.803220, disc_loss 1.429656\n",
      "batch 159, gen_loss 0.832965, disc_loss 1.364532\n",
      "batch 160, gen_loss 0.823323, disc_loss 1.448065\n",
      "batch 161, gen_loss 0.803731, disc_loss 1.376105\n",
      "batch 162, gen_loss 0.807134, disc_loss 1.402798\n",
      "batch 163, gen_loss 0.805434, disc_loss 1.418269\n",
      "batch 164, gen_loss 0.796865, disc_loss 1.414472\n",
      "batch 165, gen_loss 0.792915, disc_loss 1.439348\n",
      "batch 166, gen_loss 0.822932, disc_loss 1.400274\n",
      "batch 167, gen_loss 0.810044, disc_loss 1.387647\n",
      "batch 168, gen_loss 0.829783, disc_loss 1.433066\n",
      "batch 169, gen_loss 0.815372, disc_loss 1.406625\n",
      "batch 170, gen_loss 0.838843, disc_loss 1.395116\n",
      "batch 171, gen_loss 0.804615, disc_loss 1.432339\n",
      "batch 172, gen_loss 0.772294, disc_loss 1.451385\n",
      "batch 173, gen_loss 0.810220, disc_loss 1.385607\n",
      "batch 174, gen_loss 0.806104, disc_loss 1.375678\n",
      "batch 175, gen_loss 0.785872, disc_loss 1.362734\n",
      "batch 176, gen_loss 0.782497, disc_loss 1.313440\n",
      "batch 177, gen_loss 0.809334, disc_loss 1.327466\n",
      "batch 178, gen_loss 0.839148, disc_loss 1.288896\n",
      "batch 179, gen_loss 0.860398, disc_loss 1.318266\n",
      "batch 180, gen_loss 0.859629, disc_loss 1.307921\n",
      "batch 181, gen_loss 0.860861, disc_loss 1.298807\n",
      "batch 182, gen_loss 0.886168, disc_loss 1.231011\n",
      "batch 183, gen_loss 0.875968, disc_loss 1.346401\n",
      "batch 184, gen_loss 0.900847, disc_loss 1.279369\n",
      "batch 185, gen_loss 0.898305, disc_loss 1.224055\n",
      "batch 186, gen_loss 0.886100, disc_loss 1.290045\n",
      "batch 187, gen_loss 0.899729, disc_loss 1.202903\n",
      "batch 188, gen_loss 0.878466, disc_loss 1.235049\n",
      "batch 189, gen_loss 0.909836, disc_loss 1.173553\n",
      "batch 190, gen_loss 0.927964, disc_loss 1.220880\n",
      "batch 191, gen_loss 0.948509, disc_loss 1.154886\n",
      "batch 192, gen_loss 0.944597, disc_loss 1.163647\n",
      "batch 193, gen_loss 0.979034, disc_loss 1.137664\n",
      "batch 194, gen_loss 1.002435, disc_loss 1.155787\n",
      "batch 195, gen_loss 0.996437, disc_loss 1.135311\n",
      "batch 196, gen_loss 0.978074, disc_loss 1.158105\n",
      "batch 197, gen_loss 1.001143, disc_loss 1.155053\n",
      "batch 198, gen_loss 0.964389, disc_loss 1.142407\n",
      "batch 199, gen_loss 1.013880, disc_loss 1.112776\n",
      "batch 200, gen_loss 1.014746, disc_loss 1.115064\n",
      "batch 201, gen_loss 1.008668, disc_loss 1.058676\n",
      "batch 202, gen_loss 1.005497, disc_loss 1.122367\n",
      "batch 203, gen_loss 1.015555, disc_loss 1.130101\n",
      "batch 204, gen_loss 1.018523, disc_loss 1.084148\n",
      "batch 205, gen_loss 1.037387, disc_loss 1.069005\n",
      "batch 206, gen_loss 0.999559, disc_loss 1.117852\n",
      "batch 207, gen_loss 1.041742, disc_loss 1.134215\n",
      "batch 208, gen_loss 1.036817, disc_loss 1.073660\n",
      "batch 209, gen_loss 1.012715, disc_loss 1.116822\n",
      "batch 210, gen_loss 1.046733, disc_loss 1.067559\n",
      "batch 211, gen_loss 1.021462, disc_loss 1.112971\n",
      "batch 212, gen_loss 1.037675, disc_loss 1.122064\n",
      "batch 213, gen_loss 1.021059, disc_loss 1.118454\n",
      "batch 214, gen_loss 0.999683, disc_loss 1.152410\n",
      "batch 215, gen_loss 0.975362, disc_loss 1.155332\n",
      "batch 216, gen_loss 0.962150, disc_loss 1.144187\n",
      "batch 217, gen_loss 0.957483, disc_loss 1.174592\n",
      "batch 218, gen_loss 0.959422, disc_loss 1.143579\n",
      "batch 219, gen_loss 0.931535, disc_loss 1.229048\n",
      "batch 220, gen_loss 0.918318, disc_loss 1.248791\n",
      "batch 221, gen_loss 0.935972, disc_loss 1.230518\n",
      "batch 222, gen_loss 0.951993, disc_loss 1.242419\n",
      "batch 223, gen_loss 0.918081, disc_loss 1.318125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 224, gen_loss 0.910378, disc_loss 1.319093\n",
      "batch 225, gen_loss 0.923181, disc_loss 1.317703\n",
      "batch 226, gen_loss 0.827828, disc_loss 1.368962\n",
      "batch 227, gen_loss 0.846821, disc_loss 1.491833\n",
      "batch 228, gen_loss 0.874613, disc_loss 1.424515\n",
      "batch 229, gen_loss 0.855295, disc_loss 1.450278\n",
      "batch 230, gen_loss 0.844800, disc_loss 1.449180\n",
      "batch 231, gen_loss 0.828419, disc_loss 1.478395\n",
      "batch 232, gen_loss 0.838163, disc_loss 1.530560\n",
      "batch 233, gen_loss 0.776498, disc_loss 1.516842\n",
      "batch 234, gen_loss 0.818758, disc_loss 1.560781\n",
      "Time for epoch3is 7.527757167816162 sec\n",
      "batch 0, gen_loss 0.768889, disc_loss 1.541405\n",
      "batch 1, gen_loss 0.675157, disc_loss 1.617701\n",
      "batch 2, gen_loss 0.703712, disc_loss 1.547845\n",
      "batch 3, gen_loss 0.669272, disc_loss 1.600746\n",
      "batch 4, gen_loss 0.738614, disc_loss 1.593911\n",
      "batch 5, gen_loss 0.715689, disc_loss 1.564979\n",
      "batch 6, gen_loss 0.694689, disc_loss 1.612158\n",
      "batch 7, gen_loss 0.682387, disc_loss 1.653305\n",
      "batch 8, gen_loss 0.699238, disc_loss 1.561442\n",
      "batch 9, gen_loss 0.697949, disc_loss 1.569510\n",
      "batch 10, gen_loss 0.703755, disc_loss 1.607001\n",
      "batch 11, gen_loss 0.678006, disc_loss 1.596858\n",
      "batch 12, gen_loss 0.680161, disc_loss 1.500698\n",
      "batch 13, gen_loss 0.650443, disc_loss 1.542402\n",
      "batch 14, gen_loss 0.673107, disc_loss 1.473821\n",
      "batch 15, gen_loss 0.695462, disc_loss 1.512987\n",
      "batch 16, gen_loss 0.710908, disc_loss 1.469021\n",
      "batch 17, gen_loss 0.734677, disc_loss 1.452910\n",
      "batch 18, gen_loss 0.782162, disc_loss 1.415849\n",
      "batch 19, gen_loss 0.766693, disc_loss 1.375777\n",
      "batch 20, gen_loss 0.788346, disc_loss 1.403325\n",
      "batch 21, gen_loss 0.828618, disc_loss 1.373523\n",
      "batch 22, gen_loss 0.827582, disc_loss 1.367409\n",
      "batch 23, gen_loss 0.832618, disc_loss 1.357509\n",
      "batch 24, gen_loss 0.879807, disc_loss 1.307302\n",
      "batch 25, gen_loss 0.893466, disc_loss 1.290852\n",
      "batch 26, gen_loss 0.898071, disc_loss 1.254643\n",
      "batch 27, gen_loss 0.893892, disc_loss 1.255252\n",
      "batch 28, gen_loss 0.907479, disc_loss 1.229566\n",
      "batch 29, gen_loss 0.941842, disc_loss 1.224365\n",
      "batch 30, gen_loss 0.918252, disc_loss 1.344015\n",
      "batch 31, gen_loss 0.965234, disc_loss 1.201155\n",
      "batch 32, gen_loss 0.951694, disc_loss 1.285838\n",
      "batch 33, gen_loss 0.942762, disc_loss 1.172680\n",
      "batch 34, gen_loss 0.928108, disc_loss 1.227626\n",
      "batch 35, gen_loss 0.945924, disc_loss 1.198548\n",
      "batch 36, gen_loss 0.943714, disc_loss 1.204531\n",
      "batch 37, gen_loss 0.908147, disc_loss 1.225910\n",
      "batch 38, gen_loss 0.947942, disc_loss 1.206449\n",
      "batch 39, gen_loss 0.901092, disc_loss 1.317660\n",
      "batch 40, gen_loss 0.874704, disc_loss 1.317705\n",
      "batch 41, gen_loss 0.908280, disc_loss 1.201220\n",
      "batch 42, gen_loss 0.883392, disc_loss 1.205347\n",
      "batch 43, gen_loss 0.866731, disc_loss 1.216906\n",
      "batch 44, gen_loss 0.862600, disc_loss 1.223479\n",
      "batch 45, gen_loss 0.837632, disc_loss 1.268046\n",
      "batch 46, gen_loss 0.796792, disc_loss 1.283552\n",
      "batch 47, gen_loss 0.835871, disc_loss 1.353068\n",
      "batch 48, gen_loss 0.783220, disc_loss 1.373851\n",
      "batch 49, gen_loss 0.804688, disc_loss 1.303249\n",
      "batch 50, gen_loss 0.756892, disc_loss 1.295403\n",
      "batch 51, gen_loss 0.779172, disc_loss 1.303680\n",
      "batch 52, gen_loss 0.761307, disc_loss 1.348942\n",
      "batch 53, gen_loss 0.769111, disc_loss 1.380550\n",
      "batch 54, gen_loss 0.751661, disc_loss 1.334142\n",
      "batch 55, gen_loss 0.756855, disc_loss 1.407999\n",
      "batch 56, gen_loss 0.753872, disc_loss 1.467536\n",
      "batch 57, gen_loss 0.741794, disc_loss 1.418223\n",
      "batch 58, gen_loss 0.764503, disc_loss 1.427782\n",
      "batch 59, gen_loss 0.783512, disc_loss 1.432574\n",
      "batch 60, gen_loss 0.823317, disc_loss 1.431472\n",
      "batch 61, gen_loss 0.801077, disc_loss 1.458733\n",
      "batch 62, gen_loss 0.812430, disc_loss 1.445472\n",
      "batch 63, gen_loss 0.825715, disc_loss 1.406855\n",
      "batch 64, gen_loss 0.824807, disc_loss 1.456373\n",
      "batch 65, gen_loss 0.813170, disc_loss 1.447721\n",
      "batch 66, gen_loss 0.837926, disc_loss 1.413429\n",
      "batch 67, gen_loss 0.786588, disc_loss 1.487426\n",
      "batch 68, gen_loss 0.812646, disc_loss 1.448740\n",
      "batch 69, gen_loss 0.825534, disc_loss 1.440892\n",
      "batch 70, gen_loss 0.823803, disc_loss 1.397376\n",
      "batch 71, gen_loss 0.809481, disc_loss 1.390936\n",
      "batch 72, gen_loss 0.816025, disc_loss 1.341289\n",
      "batch 73, gen_loss 0.818804, disc_loss 1.419789\n",
      "batch 74, gen_loss 0.819586, disc_loss 1.369506\n",
      "batch 75, gen_loss 0.864093, disc_loss 1.373209\n",
      "batch 76, gen_loss 0.854440, disc_loss 1.368190\n",
      "batch 77, gen_loss 0.859633, disc_loss 1.359624\n",
      "batch 78, gen_loss 0.864802, disc_loss 1.361211\n",
      "batch 79, gen_loss 0.878631, disc_loss 1.365966\n",
      "batch 80, gen_loss 0.888319, disc_loss 1.401319\n",
      "batch 81, gen_loss 0.870901, disc_loss 1.350391\n",
      "batch 82, gen_loss 0.868757, disc_loss 1.307938\n",
      "batch 83, gen_loss 0.873513, disc_loss 1.315823\n",
      "batch 84, gen_loss 0.862497, disc_loss 1.286848\n",
      "batch 85, gen_loss 0.830131, disc_loss 1.316478\n",
      "batch 86, gen_loss 0.840225, disc_loss 1.282316\n",
      "batch 87, gen_loss 0.832873, disc_loss 1.331876\n",
      "batch 88, gen_loss 0.822962, disc_loss 1.347216\n",
      "batch 89, gen_loss 0.804379, disc_loss 1.343479\n",
      "batch 90, gen_loss 0.802077, disc_loss 1.310048\n",
      "batch 91, gen_loss 0.817291, disc_loss 1.376786\n",
      "batch 92, gen_loss 0.825974, disc_loss 1.314398\n",
      "batch 93, gen_loss 0.791871, disc_loss 1.367153\n",
      "batch 94, gen_loss 0.777550, disc_loss 1.346940\n",
      "batch 95, gen_loss 0.785910, disc_loss 1.369161\n",
      "batch 96, gen_loss 0.775451, disc_loss 1.344634\n",
      "batch 97, gen_loss 0.785300, disc_loss 1.372712\n",
      "batch 98, gen_loss 0.774411, disc_loss 1.346017\n",
      "batch 99, gen_loss 0.762321, disc_loss 1.386146\n",
      "batch 100, gen_loss 0.764758, disc_loss 1.367473\n",
      "batch 101, gen_loss 0.788429, disc_loss 1.434053\n",
      "batch 102, gen_loss 0.774702, disc_loss 1.429595\n",
      "batch 103, gen_loss 0.766644, disc_loss 1.465225\n",
      "batch 104, gen_loss 0.789095, disc_loss 1.412670\n",
      "batch 105, gen_loss 0.748555, disc_loss 1.480857\n",
      "batch 106, gen_loss 0.771653, disc_loss 1.392988\n",
      "batch 107, gen_loss 0.765961, disc_loss 1.423378\n",
      "batch 108, gen_loss 0.745731, disc_loss 1.409491\n",
      "batch 109, gen_loss 0.746704, disc_loss 1.452882\n",
      "batch 110, gen_loss 0.758681, disc_loss 1.395176\n",
      "batch 111, gen_loss 0.759295, disc_loss 1.392633\n",
      "batch 112, gen_loss 0.765837, disc_loss 1.415554\n",
      "batch 113, gen_loss 0.778072, disc_loss 1.395040\n",
      "batch 114, gen_loss 0.807388, disc_loss 1.425152\n",
      "batch 115, gen_loss 0.805500, disc_loss 1.396013\n",
      "batch 116, gen_loss 0.812794, disc_loss 1.419390\n",
      "batch 117, gen_loss 0.833535, disc_loss 1.371064\n",
      "batch 118, gen_loss 0.850971, disc_loss 1.397053\n",
      "batch 119, gen_loss 0.813559, disc_loss 1.351771\n",
      "batch 120, gen_loss 0.844455, disc_loss 1.384989\n",
      "batch 121, gen_loss 0.850995, disc_loss 1.406653\n",
      "batch 122, gen_loss 0.820884, disc_loss 1.359336\n",
      "batch 123, gen_loss 0.860650, disc_loss 1.347895\n",
      "batch 124, gen_loss 0.854900, disc_loss 1.380587\n",
      "batch 125, gen_loss 0.860492, disc_loss 1.375989\n",
      "batch 126, gen_loss 0.862211, disc_loss 1.336836\n",
      "batch 127, gen_loss 0.829625, disc_loss 1.420117\n",
      "batch 128, gen_loss 0.849534, disc_loss 1.364719\n",
      "batch 129, gen_loss 0.828656, disc_loss 1.352711\n",
      "batch 130, gen_loss 0.850312, disc_loss 1.322192\n",
      "batch 131, gen_loss 0.861812, disc_loss 1.384127\n",
      "batch 132, gen_loss 0.848532, disc_loss 1.357630\n",
      "batch 133, gen_loss 0.868935, disc_loss 1.338112\n",
      "batch 134, gen_loss 0.857526, disc_loss 1.358706\n",
      "batch 135, gen_loss 0.885041, disc_loss 1.302295\n",
      "batch 136, gen_loss 0.877516, disc_loss 1.313678\n",
      "batch 137, gen_loss 0.858367, disc_loss 1.320045\n",
      "batch 138, gen_loss 0.838612, disc_loss 1.335754\n",
      "batch 139, gen_loss 0.885090, disc_loss 1.308746\n",
      "batch 140, gen_loss 0.865311, disc_loss 1.338817\n",
      "batch 141, gen_loss 0.910045, disc_loss 1.273887\n",
      "batch 142, gen_loss 0.910126, disc_loss 1.300632\n",
      "batch 143, gen_loss 0.882467, disc_loss 1.311120\n",
      "batch 144, gen_loss 0.874370, disc_loss 1.292926\n",
      "batch 145, gen_loss 0.872573, disc_loss 1.304444\n",
      "batch 146, gen_loss 0.882285, disc_loss 1.271939\n",
      "batch 147, gen_loss 0.862040, disc_loss 1.275619\n",
      "batch 148, gen_loss 0.865949, disc_loss 1.217556\n",
      "batch 149, gen_loss 0.874061, disc_loss 1.253235\n",
      "batch 150, gen_loss 0.897535, disc_loss 1.257662\n",
      "batch 151, gen_loss 0.893182, disc_loss 1.233458\n",
      "batch 152, gen_loss 0.880460, disc_loss 1.242105\n",
      "batch 153, gen_loss 0.891112, disc_loss 1.233243\n",
      "batch 154, gen_loss 0.891010, disc_loss 1.209289\n",
      "batch 155, gen_loss 0.895623, disc_loss 1.235828\n",
      "batch 156, gen_loss 0.887597, disc_loss 1.217413\n",
      "batch 157, gen_loss 0.917355, disc_loss 1.162647\n",
      "batch 158, gen_loss 0.900361, disc_loss 1.235733\n",
      "batch 159, gen_loss 0.917779, disc_loss 1.222527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 160, gen_loss 0.924254, disc_loss 1.210369\n",
      "batch 161, gen_loss 0.932780, disc_loss 1.161019\n",
      "batch 162, gen_loss 0.943448, disc_loss 1.176529\n",
      "batch 163, gen_loss 0.954690, disc_loss 1.184012\n",
      "batch 164, gen_loss 0.959118, disc_loss 1.164186\n",
      "batch 165, gen_loss 0.938451, disc_loss 1.175733\n",
      "batch 166, gen_loss 0.963425, disc_loss 1.131889\n",
      "batch 167, gen_loss 0.959262, disc_loss 1.149305\n",
      "batch 168, gen_loss 0.975233, disc_loss 1.148172\n",
      "batch 169, gen_loss 0.937233, disc_loss 1.135040\n",
      "batch 170, gen_loss 0.967639, disc_loss 1.107081\n",
      "batch 171, gen_loss 0.937995, disc_loss 1.119603\n",
      "batch 172, gen_loss 0.941004, disc_loss 1.129576\n",
      "batch 173, gen_loss 0.956686, disc_loss 1.112550\n",
      "batch 174, gen_loss 0.947885, disc_loss 1.091616\n",
      "batch 175, gen_loss 0.967284, disc_loss 1.111860\n",
      "batch 176, gen_loss 0.984487, disc_loss 1.046351\n",
      "batch 177, gen_loss 0.968923, disc_loss 1.066885\n",
      "batch 178, gen_loss 0.975322, disc_loss 1.060869\n",
      "batch 179, gen_loss 0.979291, disc_loss 1.055957\n",
      "batch 180, gen_loss 1.015427, disc_loss 1.054300\n",
      "batch 181, gen_loss 1.012796, disc_loss 1.052458\n",
      "batch 182, gen_loss 1.043282, disc_loss 1.043310\n",
      "batch 183, gen_loss 1.049385, disc_loss 1.002068\n",
      "batch 184, gen_loss 1.037160, disc_loss 0.998653\n",
      "batch 185, gen_loss 1.054479, disc_loss 0.999397\n",
      "batch 186, gen_loss 1.044305, disc_loss 1.020359\n",
      "batch 187, gen_loss 1.050519, disc_loss 1.021621\n",
      "batch 188, gen_loss 1.027541, disc_loss 1.011648\n",
      "batch 189, gen_loss 1.059589, disc_loss 1.011459\n",
      "batch 190, gen_loss 1.056246, disc_loss 1.025729\n",
      "batch 191, gen_loss 1.050202, disc_loss 0.994168\n",
      "batch 192, gen_loss 1.047915, disc_loss 0.996660\n",
      "batch 193, gen_loss 1.042054, disc_loss 0.992121\n",
      "batch 194, gen_loss 1.057154, disc_loss 0.984551\n",
      "batch 195, gen_loss 1.066335, disc_loss 0.992083\n",
      "batch 196, gen_loss 1.081026, disc_loss 0.971707\n",
      "batch 197, gen_loss 1.090425, disc_loss 0.993055\n",
      "batch 198, gen_loss 1.102757, disc_loss 0.954520\n",
      "batch 199, gen_loss 1.109576, disc_loss 0.982728\n",
      "batch 200, gen_loss 1.118588, disc_loss 0.981913\n",
      "batch 201, gen_loss 1.162225, disc_loss 0.966164\n",
      "batch 202, gen_loss 1.166472, disc_loss 1.015580\n",
      "batch 203, gen_loss 1.152695, disc_loss 0.987846\n",
      "batch 204, gen_loss 1.128343, disc_loss 1.050972\n",
      "batch 205, gen_loss 1.105805, disc_loss 1.022726\n",
      "batch 206, gen_loss 1.139276, disc_loss 1.071465\n",
      "batch 207, gen_loss 1.142647, disc_loss 1.019571\n",
      "batch 208, gen_loss 1.131693, disc_loss 1.035910\n",
      "batch 209, gen_loss 1.117079, disc_loss 1.057081\n",
      "batch 210, gen_loss 1.159764, disc_loss 1.025726\n",
      "batch 211, gen_loss 1.138435, disc_loss 1.095058\n",
      "batch 212, gen_loss 1.087335, disc_loss 1.140451\n",
      "batch 213, gen_loss 1.073389, disc_loss 1.183102\n",
      "batch 214, gen_loss 1.058826, disc_loss 1.135519\n",
      "batch 215, gen_loss 1.026637, disc_loss 1.177067\n",
      "batch 216, gen_loss 1.048180, disc_loss 1.122790\n",
      "batch 217, gen_loss 0.982739, disc_loss 1.176851\n",
      "batch 218, gen_loss 0.995721, disc_loss 1.128916\n",
      "batch 219, gen_loss 0.975999, disc_loss 1.162187\n",
      "batch 220, gen_loss 0.977849, disc_loss 1.144027\n",
      "batch 221, gen_loss 0.968115, disc_loss 1.228575\n",
      "batch 222, gen_loss 0.981396, disc_loss 1.222932\n",
      "batch 223, gen_loss 0.974609, disc_loss 1.195842\n",
      "batch 224, gen_loss 0.944884, disc_loss 1.241294\n",
      "batch 225, gen_loss 0.926033, disc_loss 1.248522\n",
      "batch 226, gen_loss 0.918583, disc_loss 1.239141\n",
      "batch 227, gen_loss 0.911947, disc_loss 1.281557\n",
      "batch 228, gen_loss 0.917295, disc_loss 1.267039\n",
      "batch 229, gen_loss 0.857136, disc_loss 1.305544\n",
      "batch 230, gen_loss 0.833575, disc_loss 1.270216\n",
      "batch 231, gen_loss 0.839250, disc_loss 1.300709\n",
      "batch 232, gen_loss 0.787109, disc_loss 1.337765\n",
      "batch 233, gen_loss 0.841669, disc_loss 1.275703\n",
      "batch 234, gen_loss 0.781483, disc_loss 1.355537\n",
      "Time for epoch4is 7.500885009765625 sec\n",
      "batch 0, gen_loss 0.803141, disc_loss 1.410591\n",
      "batch 1, gen_loss 0.766825, disc_loss 1.373146\n",
      "batch 2, gen_loss 0.756751, disc_loss 1.446754\n",
      "batch 3, gen_loss 0.827765, disc_loss 1.377665\n",
      "batch 4, gen_loss 0.824155, disc_loss 1.359755\n",
      "batch 5, gen_loss 0.811074, disc_loss 1.437937\n",
      "batch 6, gen_loss 0.787428, disc_loss 1.407927\n",
      "batch 7, gen_loss 0.795869, disc_loss 1.384728\n",
      "batch 8, gen_loss 0.793486, disc_loss 1.383344\n",
      "batch 9, gen_loss 0.791918, disc_loss 1.453166\n",
      "batch 10, gen_loss 0.741381, disc_loss 1.396830\n",
      "batch 11, gen_loss 0.719114, disc_loss 1.481956\n",
      "batch 12, gen_loss 0.724421, disc_loss 1.459886\n",
      "batch 13, gen_loss 0.691839, disc_loss 1.457424\n",
      "batch 14, gen_loss 0.696317, disc_loss 1.419289\n",
      "batch 15, gen_loss 0.683881, disc_loss 1.516246\n",
      "batch 16, gen_loss 0.706195, disc_loss 1.458329\n",
      "batch 17, gen_loss 0.739304, disc_loss 1.410932\n",
      "batch 18, gen_loss 0.713506, disc_loss 1.459753\n",
      "batch 19, gen_loss 0.717093, disc_loss 1.407085\n",
      "batch 20, gen_loss 0.724404, disc_loss 1.463280\n",
      "batch 21, gen_loss 0.713091, disc_loss 1.403928\n",
      "batch 22, gen_loss 0.711553, disc_loss 1.438942\n",
      "batch 23, gen_loss 0.738460, disc_loss 1.477738\n",
      "batch 24, gen_loss 0.741570, disc_loss 1.443634\n",
      "batch 25, gen_loss 0.730885, disc_loss 1.458414\n",
      "batch 26, gen_loss 0.731577, disc_loss 1.494660\n",
      "batch 27, gen_loss 0.708165, disc_loss 1.382464\n",
      "batch 28, gen_loss 0.676538, disc_loss 1.481784\n",
      "batch 29, gen_loss 0.693926, disc_loss 1.380942\n",
      "batch 30, gen_loss 0.686954, disc_loss 1.409545\n",
      "batch 31, gen_loss 0.688151, disc_loss 1.448270\n",
      "batch 32, gen_loss 0.681099, disc_loss 1.355860\n",
      "batch 33, gen_loss 0.691525, disc_loss 1.409311\n",
      "batch 34, gen_loss 0.676383, disc_loss 1.418884\n",
      "batch 35, gen_loss 0.703531, disc_loss 1.389452\n",
      "batch 36, gen_loss 0.712005, disc_loss 1.438737\n",
      "batch 37, gen_loss 0.694358, disc_loss 1.424767\n",
      "batch 38, gen_loss 0.728362, disc_loss 1.394944\n",
      "batch 39, gen_loss 0.751673, disc_loss 1.378095\n",
      "batch 40, gen_loss 0.747755, disc_loss 1.341429\n",
      "batch 41, gen_loss 0.725683, disc_loss 1.385224\n",
      "batch 42, gen_loss 0.739639, disc_loss 1.347579\n",
      "batch 43, gen_loss 0.722877, disc_loss 1.381644\n",
      "batch 44, gen_loss 0.731069, disc_loss 1.289577\n",
      "batch 45, gen_loss 0.739523, disc_loss 1.310421\n",
      "batch 46, gen_loss 0.745141, disc_loss 1.308174\n",
      "batch 47, gen_loss 0.735974, disc_loss 1.293394\n",
      "batch 48, gen_loss 0.758614, disc_loss 1.333224\n",
      "batch 49, gen_loss 0.775315, disc_loss 1.289575\n",
      "batch 50, gen_loss 0.784697, disc_loss 1.261053\n",
      "batch 51, gen_loss 0.806803, disc_loss 1.264958\n",
      "batch 52, gen_loss 0.816776, disc_loss 1.285517\n",
      "batch 53, gen_loss 0.825746, disc_loss 1.237134\n",
      "batch 54, gen_loss 0.850823, disc_loss 1.281199\n",
      "batch 55, gen_loss 0.868963, disc_loss 1.200417\n",
      "batch 56, gen_loss 0.856910, disc_loss 1.245152\n",
      "batch 57, gen_loss 0.841951, disc_loss 1.229584\n",
      "batch 58, gen_loss 0.859568, disc_loss 1.209495\n",
      "batch 59, gen_loss 0.859823, disc_loss 1.252020\n",
      "batch 60, gen_loss 0.840765, disc_loss 1.243569\n",
      "batch 61, gen_loss 0.844478, disc_loss 1.252419\n",
      "batch 62, gen_loss 0.850628, disc_loss 1.216245\n",
      "batch 63, gen_loss 0.849093, disc_loss 1.189510\n",
      "batch 64, gen_loss 0.838411, disc_loss 1.213638\n",
      "batch 65, gen_loss 0.856226, disc_loss 1.178820\n",
      "batch 66, gen_loss 0.869637, disc_loss 1.192921\n",
      "batch 67, gen_loss 0.880404, disc_loss 1.175073\n",
      "batch 68, gen_loss 0.880100, disc_loss 1.153367\n",
      "batch 69, gen_loss 0.883535, disc_loss 1.188423\n",
      "batch 70, gen_loss 0.924804, disc_loss 1.169276\n",
      "batch 71, gen_loss 0.908801, disc_loss 1.186535\n",
      "batch 72, gen_loss 0.919146, disc_loss 1.158978\n",
      "batch 73, gen_loss 0.928974, disc_loss 1.163154\n",
      "batch 74, gen_loss 0.915072, disc_loss 1.173908\n",
      "batch 75, gen_loss 0.927386, disc_loss 1.134770\n",
      "batch 76, gen_loss 0.915360, disc_loss 1.154070\n",
      "batch 77, gen_loss 0.892021, disc_loss 1.157859\n",
      "batch 78, gen_loss 0.914566, disc_loss 1.156043\n",
      "batch 79, gen_loss 0.907384, disc_loss 1.168372\n",
      "batch 80, gen_loss 0.894109, disc_loss 1.142575\n",
      "batch 81, gen_loss 0.911730, disc_loss 1.126142\n",
      "batch 82, gen_loss 0.916353, disc_loss 1.127165\n",
      "batch 83, gen_loss 0.867271, disc_loss 1.129813\n",
      "batch 84, gen_loss 0.903380, disc_loss 1.098998\n",
      "batch 85, gen_loss 0.935309, disc_loss 1.092199\n",
      "batch 86, gen_loss 0.938560, disc_loss 1.066940\n",
      "batch 87, gen_loss 0.977545, disc_loss 1.058541\n",
      "batch 88, gen_loss 0.966553, disc_loss 1.141380\n",
      "batch 89, gen_loss 0.969095, disc_loss 1.127244\n",
      "batch 90, gen_loss 0.966276, disc_loss 1.077509\n",
      "batch 91, gen_loss 0.965477, disc_loss 1.102311\n",
      "batch 92, gen_loss 0.961855, disc_loss 1.108679\n",
      "batch 93, gen_loss 0.922855, disc_loss 1.099991\n",
      "batch 94, gen_loss 0.906232, disc_loss 1.094249\n",
      "batch 95, gen_loss 0.931447, disc_loss 1.067755\n",
      "batch 96, gen_loss 0.956383, disc_loss 1.071346\n",
      "batch 97, gen_loss 0.965479, disc_loss 1.102849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 98, gen_loss 0.951639, disc_loss 1.076691\n",
      "batch 99, gen_loss 0.935353, disc_loss 1.103670\n",
      "batch 100, gen_loss 0.951953, disc_loss 1.117000\n",
      "batch 101, gen_loss 0.969329, disc_loss 1.118548\n",
      "batch 102, gen_loss 0.953535, disc_loss 1.124945\n",
      "batch 103, gen_loss 0.925558, disc_loss 1.124799\n",
      "batch 104, gen_loss 0.916025, disc_loss 1.137879\n",
      "batch 105, gen_loss 0.900283, disc_loss 1.151864\n",
      "batch 106, gen_loss 0.891819, disc_loss 1.179223\n",
      "batch 107, gen_loss 0.905630, disc_loss 1.141999\n",
      "batch 108, gen_loss 0.868488, disc_loss 1.176712\n",
      "batch 109, gen_loss 0.879421, disc_loss 1.171066\n",
      "batch 110, gen_loss 0.891371, disc_loss 1.174269\n",
      "batch 111, gen_loss 0.893710, disc_loss 1.189456\n",
      "batch 112, gen_loss 0.889439, disc_loss 1.164467\n",
      "batch 113, gen_loss 0.897898, disc_loss 1.237350\n",
      "batch 114, gen_loss 0.903451, disc_loss 1.243576\n",
      "batch 115, gen_loss 0.896657, disc_loss 1.222287\n",
      "batch 116, gen_loss 0.894319, disc_loss 1.251416\n",
      "batch 117, gen_loss 0.856015, disc_loss 1.289410\n",
      "batch 118, gen_loss 0.828789, disc_loss 1.292450\n",
      "batch 119, gen_loss 0.816116, disc_loss 1.329042\n",
      "batch 120, gen_loss 0.794600, disc_loss 1.375693\n",
      "batch 121, gen_loss 0.764311, disc_loss 1.373691\n",
      "batch 122, gen_loss 0.762388, disc_loss 1.389636\n",
      "batch 123, gen_loss 0.745482, disc_loss 1.388668\n",
      "batch 124, gen_loss 0.741774, disc_loss 1.421445\n",
      "batch 125, gen_loss 0.734942, disc_loss 1.424949\n",
      "batch 126, gen_loss 0.743042, disc_loss 1.424013\n",
      "batch 127, gen_loss 0.727421, disc_loss 1.377326\n",
      "batch 128, gen_loss 0.718613, disc_loss 1.471805\n",
      "batch 129, gen_loss 0.720738, disc_loss 1.507752\n",
      "batch 130, gen_loss 0.691013, disc_loss 1.474602\n",
      "batch 131, gen_loss 0.729905, disc_loss 1.472574\n",
      "batch 132, gen_loss 0.700457, disc_loss 1.522917\n",
      "batch 133, gen_loss 0.711522, disc_loss 1.530690\n",
      "batch 134, gen_loss 0.742075, disc_loss 1.486945\n",
      "batch 135, gen_loss 0.710332, disc_loss 1.517385\n",
      "batch 136, gen_loss 0.715634, disc_loss 1.494328\n",
      "batch 137, gen_loss 0.729734, disc_loss 1.485563\n",
      "batch 138, gen_loss 0.712928, disc_loss 1.598514\n",
      "batch 139, gen_loss 0.680257, disc_loss 1.624558\n",
      "batch 140, gen_loss 0.695944, disc_loss 1.560409\n",
      "batch 141, gen_loss 0.696946, disc_loss 1.597598\n",
      "batch 142, gen_loss 0.693872, disc_loss 1.586036\n",
      "batch 143, gen_loss 0.662395, disc_loss 1.620023\n",
      "batch 144, gen_loss 0.656407, disc_loss 1.636253\n",
      "batch 145, gen_loss 0.651056, disc_loss 1.600814\n",
      "batch 146, gen_loss 0.663835, disc_loss 1.598397\n",
      "batch 147, gen_loss 0.667707, disc_loss 1.657074\n",
      "batch 148, gen_loss 0.676214, disc_loss 1.645118\n",
      "batch 149, gen_loss 0.696054, disc_loss 1.543190\n",
      "batch 150, gen_loss 0.658281, disc_loss 1.611291\n",
      "batch 151, gen_loss 0.682528, disc_loss 1.623478\n",
      "batch 152, gen_loss 0.668054, disc_loss 1.587049\n",
      "batch 153, gen_loss 0.673674, disc_loss 1.593728\n",
      "batch 154, gen_loss 0.673922, disc_loss 1.563031\n",
      "batch 155, gen_loss 0.665521, disc_loss 1.599864\n",
      "batch 156, gen_loss 0.672660, disc_loss 1.552673\n",
      "batch 157, gen_loss 0.682595, disc_loss 1.558056\n",
      "batch 158, gen_loss 0.693900, disc_loss 1.519810\n",
      "batch 159, gen_loss 0.697966, disc_loss 1.498048\n",
      "batch 160, gen_loss 0.724323, disc_loss 1.507321\n",
      "batch 161, gen_loss 0.724925, disc_loss 1.491747\n",
      "batch 162, gen_loss 0.737001, disc_loss 1.474703\n",
      "batch 163, gen_loss 0.743965, disc_loss 1.460811\n",
      "batch 164, gen_loss 0.745728, disc_loss 1.474273\n",
      "batch 165, gen_loss 0.765074, disc_loss 1.429779\n",
      "batch 166, gen_loss 0.757046, disc_loss 1.436940\n",
      "batch 167, gen_loss 0.757614, disc_loss 1.454511\n",
      "batch 168, gen_loss 0.766153, disc_loss 1.397696\n",
      "batch 169, gen_loss 0.771970, disc_loss 1.446587\n",
      "batch 170, gen_loss 0.756560, disc_loss 1.441636\n",
      "batch 171, gen_loss 0.782594, disc_loss 1.416193\n",
      "batch 172, gen_loss 0.791570, disc_loss 1.390028\n",
      "batch 173, gen_loss 0.783406, disc_loss 1.374044\n",
      "batch 174, gen_loss 0.794543, disc_loss 1.367178\n",
      "batch 175, gen_loss 0.780839, disc_loss 1.365539\n",
      "batch 176, gen_loss 0.803580, disc_loss 1.311472\n",
      "batch 177, gen_loss 0.820214, disc_loss 1.334115\n",
      "batch 178, gen_loss 0.805802, disc_loss 1.312726\n",
      "batch 179, gen_loss 0.835969, disc_loss 1.308147\n",
      "batch 180, gen_loss 0.843723, disc_loss 1.311670\n",
      "batch 181, gen_loss 0.844713, disc_loss 1.284492\n",
      "batch 182, gen_loss 0.837522, disc_loss 1.282722\n",
      "batch 183, gen_loss 0.868145, disc_loss 1.252760\n",
      "batch 184, gen_loss 0.852595, disc_loss 1.252883\n",
      "batch 185, gen_loss 0.883611, disc_loss 1.210647\n",
      "batch 186, gen_loss 0.836917, disc_loss 1.284612\n",
      "batch 187, gen_loss 0.873807, disc_loss 1.202585\n",
      "batch 188, gen_loss 0.853904, disc_loss 1.257669\n",
      "batch 189, gen_loss 0.878446, disc_loss 1.198807\n",
      "batch 190, gen_loss 0.864314, disc_loss 1.223335\n",
      "batch 191, gen_loss 0.872854, disc_loss 1.193775\n",
      "batch 192, gen_loss 0.887029, disc_loss 1.171661\n",
      "batch 193, gen_loss 0.898481, disc_loss 1.182813\n",
      "batch 194, gen_loss 0.897213, disc_loss 1.184366\n",
      "batch 195, gen_loss 0.919447, disc_loss 1.199253\n",
      "batch 196, gen_loss 0.951573, disc_loss 1.143821\n",
      "batch 197, gen_loss 0.944495, disc_loss 1.169373\n",
      "batch 198, gen_loss 0.985601, disc_loss 1.114089\n",
      "batch 199, gen_loss 0.964714, disc_loss 1.135458\n",
      "batch 200, gen_loss 0.965246, disc_loss 1.160287\n",
      "batch 201, gen_loss 0.941480, disc_loss 1.125040\n",
      "batch 202, gen_loss 0.925491, disc_loss 1.142107\n",
      "batch 203, gen_loss 0.949518, disc_loss 1.141450\n",
      "batch 204, gen_loss 0.966416, disc_loss 1.103612\n",
      "batch 205, gen_loss 0.937094, disc_loss 1.163144\n",
      "batch 206, gen_loss 0.944993, disc_loss 1.141878\n",
      "batch 207, gen_loss 0.948533, disc_loss 1.100652\n",
      "batch 208, gen_loss 0.964464, disc_loss 1.124746\n",
      "batch 209, gen_loss 0.963394, disc_loss 1.133556\n",
      "batch 210, gen_loss 1.005166, disc_loss 1.101417\n",
      "batch 211, gen_loss 0.981286, disc_loss 1.153797\n",
      "batch 212, gen_loss 0.994121, disc_loss 1.122980\n",
      "batch 213, gen_loss 0.981544, disc_loss 1.118637\n",
      "batch 214, gen_loss 0.981371, disc_loss 1.147478\n",
      "batch 215, gen_loss 1.045342, disc_loss 1.098033\n",
      "batch 216, gen_loss 0.983384, disc_loss 1.153723\n",
      "batch 217, gen_loss 0.980641, disc_loss 1.128718\n",
      "batch 218, gen_loss 0.998707, disc_loss 1.056759\n",
      "batch 219, gen_loss 0.975514, disc_loss 1.063500\n",
      "batch 220, gen_loss 0.979794, disc_loss 1.165856\n",
      "batch 221, gen_loss 0.971550, disc_loss 1.084754\n",
      "batch 222, gen_loss 1.001525, disc_loss 1.069365\n",
      "batch 223, gen_loss 1.006537, disc_loss 1.094648\n",
      "batch 224, gen_loss 0.986762, disc_loss 1.134532\n",
      "batch 225, gen_loss 0.974650, disc_loss 1.135725\n",
      "batch 226, gen_loss 1.014211, disc_loss 1.066766\n",
      "batch 227, gen_loss 0.980009, disc_loss 1.083748\n",
      "batch 228, gen_loss 0.979117, disc_loss 1.084410\n",
      "batch 229, gen_loss 0.979494, disc_loss 1.057956\n",
      "batch 230, gen_loss 0.976836, disc_loss 1.076908\n",
      "batch 231, gen_loss 0.995019, disc_loss 1.073231\n",
      "batch 232, gen_loss 1.020444, disc_loss 1.041114\n",
      "batch 233, gen_loss 1.018967, disc_loss 1.085194\n",
      "batch 234, gen_loss 1.042571, disc_loss 1.168819\n",
      "Time for epoch5is 7.449744462966919 sec\n",
      "batch 0, gen_loss 0.959280, disc_loss 1.105711\n",
      "batch 1, gen_loss 0.989764, disc_loss 1.069501\n",
      "batch 2, gen_loss 0.942752, disc_loss 1.157022\n",
      "batch 3, gen_loss 0.918324, disc_loss 1.169706\n",
      "batch 4, gen_loss 0.915448, disc_loss 1.131926\n",
      "batch 5, gen_loss 0.895622, disc_loss 1.151668\n",
      "batch 6, gen_loss 0.896879, disc_loss 1.206584\n",
      "batch 7, gen_loss 0.879472, disc_loss 1.162100\n",
      "batch 8, gen_loss 0.853639, disc_loss 1.200225\n",
      "batch 9, gen_loss 0.836954, disc_loss 1.238520\n",
      "batch 10, gen_loss 0.823873, disc_loss 1.237347\n",
      "batch 11, gen_loss 0.780989, disc_loss 1.343417\n",
      "batch 12, gen_loss 0.799662, disc_loss 1.295632\n",
      "batch 13, gen_loss 0.805421, disc_loss 1.304936\n",
      "batch 14, gen_loss 0.772515, disc_loss 1.277395\n",
      "batch 15, gen_loss 0.754997, disc_loss 1.362218\n",
      "batch 16, gen_loss 0.766757, disc_loss 1.304190\n",
      "batch 17, gen_loss 0.757442, disc_loss 1.331746\n",
      "batch 18, gen_loss 0.779950, disc_loss 1.376217\n",
      "batch 19, gen_loss 0.760446, disc_loss 1.391806\n",
      "batch 20, gen_loss 0.754286, disc_loss 1.426195\n",
      "batch 21, gen_loss 0.733279, disc_loss 1.403635\n",
      "batch 22, gen_loss 0.719364, disc_loss 1.405543\n",
      "batch 23, gen_loss 0.720009, disc_loss 1.377779\n",
      "batch 24, gen_loss 0.713390, disc_loss 1.479738\n",
      "batch 25, gen_loss 0.712986, disc_loss 1.374894\n",
      "batch 26, gen_loss 0.694536, disc_loss 1.448512\n",
      "batch 27, gen_loss 0.704145, disc_loss 1.441527\n",
      "batch 28, gen_loss 0.696588, disc_loss 1.470393\n",
      "batch 29, gen_loss 0.716946, disc_loss 1.408435\n",
      "batch 30, gen_loss 0.703342, disc_loss 1.443245\n",
      "batch 31, gen_loss 0.717931, disc_loss 1.430519\n",
      "batch 32, gen_loss 0.719329, disc_loss 1.423926\n",
      "batch 33, gen_loss 0.733953, disc_loss 1.406695\n",
      "batch 34, gen_loss 0.729708, disc_loss 1.415939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 35, gen_loss 0.722661, disc_loss 1.427700\n",
      "batch 36, gen_loss 0.753413, disc_loss 1.390822\n",
      "batch 37, gen_loss 0.742888, disc_loss 1.433477\n",
      "batch 38, gen_loss 0.730103, disc_loss 1.452434\n",
      "batch 39, gen_loss 0.761243, disc_loss 1.413728\n",
      "batch 40, gen_loss 0.758471, disc_loss 1.410486\n",
      "batch 41, gen_loss 0.761151, disc_loss 1.404961\n",
      "batch 42, gen_loss 0.753579, disc_loss 1.390191\n",
      "batch 43, gen_loss 0.757833, disc_loss 1.420213\n",
      "batch 44, gen_loss 0.743617, disc_loss 1.401225\n",
      "batch 45, gen_loss 0.734719, disc_loss 1.386405\n",
      "batch 46, gen_loss 0.744937, disc_loss 1.396183\n",
      "batch 47, gen_loss 0.749188, disc_loss 1.388594\n",
      "batch 48, gen_loss 0.736826, disc_loss 1.394167\n",
      "batch 49, gen_loss 0.733861, disc_loss 1.409954\n",
      "batch 50, gen_loss 0.745544, disc_loss 1.410465\n",
      "batch 51, gen_loss 0.730989, disc_loss 1.430820\n",
      "batch 52, gen_loss 0.739076, disc_loss 1.381236\n",
      "batch 53, gen_loss 0.762034, disc_loss 1.423095\n",
      "batch 54, gen_loss 0.742629, disc_loss 1.395052\n",
      "batch 55, gen_loss 0.761083, disc_loss 1.399709\n",
      "batch 56, gen_loss 0.751318, disc_loss 1.387940\n",
      "batch 57, gen_loss 0.737125, disc_loss 1.368937\n",
      "batch 58, gen_loss 0.736594, disc_loss 1.374664\n",
      "batch 59, gen_loss 0.755746, disc_loss 1.361711\n",
      "batch 60, gen_loss 0.753485, disc_loss 1.363059\n",
      "batch 61, gen_loss 0.738101, disc_loss 1.388726\n",
      "batch 62, gen_loss 0.745557, disc_loss 1.355183\n",
      "batch 63, gen_loss 0.746839, disc_loss 1.361587\n",
      "batch 64, gen_loss 0.726829, disc_loss 1.370899\n",
      "batch 65, gen_loss 0.735762, disc_loss 1.347951\n",
      "batch 66, gen_loss 0.744083, disc_loss 1.354095\n",
      "batch 67, gen_loss 0.745970, disc_loss 1.333509\n",
      "batch 68, gen_loss 0.746181, disc_loss 1.329422\n",
      "batch 69, gen_loss 0.774669, disc_loss 1.310365\n",
      "batch 70, gen_loss 0.759995, disc_loss 1.311274\n",
      "batch 71, gen_loss 0.785407, disc_loss 1.335940\n",
      "batch 72, gen_loss 0.798853, disc_loss 1.350287\n",
      "batch 73, gen_loss 0.803005, disc_loss 1.298867\n",
      "batch 74, gen_loss 0.824532, disc_loss 1.331877\n",
      "batch 75, gen_loss 0.800342, disc_loss 1.289594\n",
      "batch 76, gen_loss 0.807235, disc_loss 1.265185\n",
      "batch 77, gen_loss 0.780756, disc_loss 1.296123\n",
      "batch 78, gen_loss 0.795302, disc_loss 1.280932\n",
      "batch 79, gen_loss 0.794253, disc_loss 1.274385\n",
      "batch 80, gen_loss 0.814177, disc_loss 1.299611\n",
      "batch 81, gen_loss 0.809742, disc_loss 1.327435\n",
      "batch 82, gen_loss 0.780958, disc_loss 1.301982\n",
      "batch 83, gen_loss 0.774302, disc_loss 1.300870\n",
      "batch 84, gen_loss 0.774406, disc_loss 1.232917\n",
      "batch 85, gen_loss 0.780669, disc_loss 1.280388\n",
      "batch 86, gen_loss 0.798942, disc_loss 1.303184\n",
      "batch 87, gen_loss 0.805905, disc_loss 1.284946\n",
      "batch 88, gen_loss 0.807149, disc_loss 1.255530\n",
      "batch 89, gen_loss 0.795423, disc_loss 1.222075\n",
      "batch 90, gen_loss 0.844949, disc_loss 1.225978\n",
      "batch 91, gen_loss 0.832020, disc_loss 1.262037\n",
      "batch 92, gen_loss 0.826832, disc_loss 1.313495\n",
      "batch 93, gen_loss 0.853791, disc_loss 1.282215\n",
      "batch 94, gen_loss 0.842855, disc_loss 1.290486\n",
      "batch 95, gen_loss 0.860508, disc_loss 1.313673\n",
      "batch 96, gen_loss 0.832104, disc_loss 1.305765\n",
      "batch 97, gen_loss 0.831497, disc_loss 1.328491\n",
      "batch 98, gen_loss 0.805749, disc_loss 1.249395\n",
      "batch 99, gen_loss 0.792268, disc_loss 1.291705\n",
      "batch 100, gen_loss 0.782758, disc_loss 1.312445\n",
      "batch 101, gen_loss 0.813397, disc_loss 1.356222\n",
      "batch 102, gen_loss 0.795340, disc_loss 1.333332\n",
      "batch 103, gen_loss 0.781761, disc_loss 1.330758\n",
      "batch 104, gen_loss 0.787496, disc_loss 1.291634\n",
      "batch 105, gen_loss 0.790806, disc_loss 1.283552\n",
      "batch 106, gen_loss 0.773963, disc_loss 1.297061\n",
      "batch 107, gen_loss 0.796990, disc_loss 1.390063\n",
      "batch 108, gen_loss 0.800059, disc_loss 1.347389\n",
      "batch 109, gen_loss 0.827836, disc_loss 1.338257\n",
      "batch 110, gen_loss 0.821551, disc_loss 1.334727\n",
      "batch 111, gen_loss 0.818597, disc_loss 1.339279\n",
      "batch 112, gen_loss 0.819786, disc_loss 1.386174\n",
      "batch 113, gen_loss 0.828378, disc_loss 1.353795\n",
      "batch 114, gen_loss 0.827421, disc_loss 1.340193\n",
      "batch 115, gen_loss 0.829641, disc_loss 1.399906\n",
      "batch 116, gen_loss 0.824301, disc_loss 1.343502\n",
      "batch 117, gen_loss 0.814589, disc_loss 1.379123\n",
      "batch 118, gen_loss 0.822791, disc_loss 1.395096\n",
      "batch 119, gen_loss 0.777961, disc_loss 1.372286\n",
      "batch 120, gen_loss 0.812029, disc_loss 1.369023\n",
      "batch 121, gen_loss 0.756690, disc_loss 1.402078\n",
      "batch 122, gen_loss 0.785689, disc_loss 1.333034\n",
      "batch 123, gen_loss 0.797951, disc_loss 1.391227\n",
      "batch 124, gen_loss 0.775625, disc_loss 1.404815\n",
      "batch 125, gen_loss 0.824942, disc_loss 1.360742\n",
      "batch 126, gen_loss 0.837225, disc_loss 1.354362\n",
      "batch 127, gen_loss 0.819941, disc_loss 1.378857\n",
      "batch 128, gen_loss 0.859737, disc_loss 1.333163\n",
      "batch 129, gen_loss 0.863813, disc_loss 1.358862\n",
      "batch 130, gen_loss 0.833817, disc_loss 1.349063\n",
      "batch 131, gen_loss 0.860730, disc_loss 1.404300\n",
      "batch 132, gen_loss 0.837778, disc_loss 1.342261\n",
      "batch 133, gen_loss 0.854697, disc_loss 1.396381\n",
      "batch 134, gen_loss 0.858247, disc_loss 1.361983\n",
      "batch 135, gen_loss 0.830727, disc_loss 1.340793\n",
      "batch 136, gen_loss 0.862655, disc_loss 1.325834\n",
      "batch 137, gen_loss 0.846282, disc_loss 1.366288\n",
      "batch 138, gen_loss 0.852978, disc_loss 1.309596\n",
      "batch 139, gen_loss 0.834525, disc_loss 1.304482\n",
      "batch 140, gen_loss 0.856372, disc_loss 1.290520\n",
      "batch 141, gen_loss 0.846369, disc_loss 1.315969\n",
      "batch 142, gen_loss 0.894803, disc_loss 1.259516\n",
      "batch 143, gen_loss 0.875868, disc_loss 1.261837\n",
      "batch 144, gen_loss 0.874092, disc_loss 1.260220\n",
      "batch 145, gen_loss 0.860343, disc_loss 1.242553\n",
      "batch 146, gen_loss 0.891522, disc_loss 1.185413\n",
      "batch 147, gen_loss 0.869533, disc_loss 1.232958\n",
      "batch 148, gen_loss 0.909042, disc_loss 1.200094\n",
      "batch 149, gen_loss 0.908624, disc_loss 1.196772\n",
      "batch 150, gen_loss 0.923128, disc_loss 1.204951\n",
      "batch 151, gen_loss 0.926517, disc_loss 1.199066\n",
      "batch 152, gen_loss 0.947016, disc_loss 1.180043\n",
      "batch 153, gen_loss 0.937251, disc_loss 1.179357\n",
      "batch 154, gen_loss 0.927152, disc_loss 1.175565\n",
      "batch 155, gen_loss 0.937485, disc_loss 1.172833\n",
      "batch 156, gen_loss 0.906637, disc_loss 1.128444\n",
      "batch 157, gen_loss 0.904920, disc_loss 1.144015\n",
      "batch 158, gen_loss 0.907742, disc_loss 1.187526\n",
      "batch 159, gen_loss 0.909256, disc_loss 1.147691\n",
      "batch 160, gen_loss 0.889630, disc_loss 1.186811\n",
      "batch 161, gen_loss 0.888692, disc_loss 1.148850\n",
      "batch 162, gen_loss 0.892574, disc_loss 1.165452\n",
      "batch 163, gen_loss 0.882806, disc_loss 1.193382\n",
      "batch 164, gen_loss 0.879032, disc_loss 1.162851\n",
      "batch 165, gen_loss 0.871597, disc_loss 1.200924\n",
      "batch 166, gen_loss 0.891680, disc_loss 1.148798\n",
      "batch 167, gen_loss 0.885096, disc_loss 1.177203\n",
      "batch 168, gen_loss 0.895624, disc_loss 1.203191\n",
      "batch 169, gen_loss 0.893444, disc_loss 1.232056\n",
      "batch 170, gen_loss 0.886507, disc_loss 1.185888\n",
      "batch 171, gen_loss 0.915336, disc_loss 1.202050\n",
      "batch 172, gen_loss 0.915745, disc_loss 1.207235\n",
      "batch 173, gen_loss 0.899798, disc_loss 1.182667\n",
      "batch 174, gen_loss 0.937134, disc_loss 1.204123\n",
      "batch 175, gen_loss 0.908723, disc_loss 1.203037\n",
      "batch 176, gen_loss 0.923062, disc_loss 1.221254\n",
      "batch 177, gen_loss 0.894620, disc_loss 1.219558\n",
      "batch 178, gen_loss 0.926811, disc_loss 1.192485\n",
      "batch 179, gen_loss 0.899490, disc_loss 1.212508\n",
      "batch 180, gen_loss 0.917652, disc_loss 1.220716\n",
      "batch 181, gen_loss 0.897731, disc_loss 1.229301\n",
      "batch 182, gen_loss 0.891706, disc_loss 1.236151\n",
      "batch 183, gen_loss 0.902987, disc_loss 1.216976\n",
      "batch 184, gen_loss 0.896555, disc_loss 1.253936\n",
      "batch 185, gen_loss 0.902547, disc_loss 1.269118\n",
      "batch 186, gen_loss 0.901900, disc_loss 1.260668\n",
      "batch 187, gen_loss 0.928537, disc_loss 1.173684\n",
      "batch 188, gen_loss 0.905036, disc_loss 1.257222\n",
      "batch 189, gen_loss 0.909948, disc_loss 1.220946\n",
      "batch 190, gen_loss 0.888244, disc_loss 1.230583\n",
      "batch 191, gen_loss 0.897987, disc_loss 1.283057\n",
      "batch 192, gen_loss 0.910493, disc_loss 1.236995\n",
      "batch 193, gen_loss 0.906742, disc_loss 1.222204\n",
      "batch 194, gen_loss 0.890724, disc_loss 1.265080\n",
      "batch 195, gen_loss 0.896866, disc_loss 1.247212\n",
      "batch 196, gen_loss 0.854885, disc_loss 1.242863\n",
      "batch 197, gen_loss 0.858847, disc_loss 1.304805\n",
      "batch 198, gen_loss 0.860712, disc_loss 1.307623\n",
      "batch 199, gen_loss 0.837115, disc_loss 1.252086\n",
      "batch 200, gen_loss 0.866984, disc_loss 1.312954\n",
      "batch 201, gen_loss 0.872150, disc_loss 1.290276\n",
      "batch 202, gen_loss 0.850030, disc_loss 1.316658\n",
      "batch 203, gen_loss 0.864956, disc_loss 1.262773\n",
      "batch 204, gen_loss 0.830776, disc_loss 1.343595\n",
      "batch 205, gen_loss 0.824152, disc_loss 1.288836\n",
      "batch 206, gen_loss 0.876884, disc_loss 1.286012\n",
      "batch 207, gen_loss 0.873972, disc_loss 1.308335\n",
      "batch 208, gen_loss 0.843939, disc_loss 1.299922\n",
      "batch 209, gen_loss 0.844450, disc_loss 1.296442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 210, gen_loss 0.827097, disc_loss 1.354681\n",
      "batch 211, gen_loss 0.821538, disc_loss 1.339834\n",
      "batch 212, gen_loss 0.828125, disc_loss 1.294966\n",
      "batch 213, gen_loss 0.819181, disc_loss 1.363316\n",
      "batch 214, gen_loss 0.826746, disc_loss 1.370885\n",
      "batch 215, gen_loss 0.808922, disc_loss 1.352174\n",
      "batch 216, gen_loss 0.820783, disc_loss 1.324664\n",
      "batch 217, gen_loss 0.845352, disc_loss 1.298113\n",
      "batch 218, gen_loss 0.813208, disc_loss 1.312691\n",
      "batch 219, gen_loss 0.823580, disc_loss 1.289982\n",
      "batch 220, gen_loss 0.830780, disc_loss 1.362729\n",
      "batch 221, gen_loss 0.822648, disc_loss 1.359110\n",
      "batch 222, gen_loss 0.816161, disc_loss 1.364224\n",
      "batch 223, gen_loss 0.843455, disc_loss 1.320302\n",
      "batch 224, gen_loss 0.826464, disc_loss 1.318136\n",
      "batch 225, gen_loss 0.829932, disc_loss 1.320539\n",
      "batch 226, gen_loss 0.848853, disc_loss 1.320483\n",
      "batch 227, gen_loss 0.871609, disc_loss 1.307076\n",
      "batch 228, gen_loss 0.856848, disc_loss 1.335310\n",
      "batch 229, gen_loss 0.873508, disc_loss 1.295408\n",
      "batch 230, gen_loss 0.875979, disc_loss 1.373171\n",
      "batch 231, gen_loss 0.869970, disc_loss 1.290518\n",
      "batch 232, gen_loss 0.867619, disc_loss 1.294677\n",
      "batch 233, gen_loss 0.835801, disc_loss 1.316765\n",
      "batch 234, gen_loss 0.852593, disc_loss 1.305001\n",
      "Time for epoch6is 7.474435806274414 sec\n",
      "batch 0, gen_loss 0.848586, disc_loss 1.350301\n",
      "batch 1, gen_loss 0.871770, disc_loss 1.357262\n",
      "batch 2, gen_loss 0.870680, disc_loss 1.303000\n",
      "batch 3, gen_loss 0.857190, disc_loss 1.347434\n",
      "batch 4, gen_loss 0.812153, disc_loss 1.404813\n",
      "batch 5, gen_loss 0.841067, disc_loss 1.409206\n",
      "batch 6, gen_loss 0.815848, disc_loss 1.426878\n",
      "batch 7, gen_loss 0.803713, disc_loss 1.468701\n",
      "batch 8, gen_loss 0.837866, disc_loss 1.476790\n",
      "batch 9, gen_loss 0.773750, disc_loss 1.488651\n",
      "batch 10, gen_loss 0.802643, disc_loss 1.397588\n",
      "batch 11, gen_loss 0.783404, disc_loss 1.454163\n",
      "batch 12, gen_loss 0.768353, disc_loss 1.455660\n",
      "batch 13, gen_loss 0.750595, disc_loss 1.535991\n",
      "batch 14, gen_loss 0.773037, disc_loss 1.439898\n",
      "batch 15, gen_loss 0.754511, disc_loss 1.502688\n",
      "batch 16, gen_loss 0.773983, disc_loss 1.453667\n",
      "batch 17, gen_loss 0.811075, disc_loss 1.495995\n",
      "batch 18, gen_loss 0.791406, disc_loss 1.522900\n",
      "batch 19, gen_loss 0.819325, disc_loss 1.506302\n",
      "batch 20, gen_loss 0.807067, disc_loss 1.496617\n",
      "batch 21, gen_loss 0.791498, disc_loss 1.515797\n",
      "batch 22, gen_loss 0.758409, disc_loss 1.483719\n",
      "batch 23, gen_loss 0.777924, disc_loss 1.473201\n",
      "batch 24, gen_loss 0.761873, disc_loss 1.516512\n",
      "batch 25, gen_loss 0.754952, disc_loss 1.483697\n",
      "batch 26, gen_loss 0.773102, disc_loss 1.466961\n",
      "batch 27, gen_loss 0.755768, disc_loss 1.494491\n",
      "batch 28, gen_loss 0.794550, disc_loss 1.447519\n",
      "batch 29, gen_loss 0.805704, disc_loss 1.451772\n",
      "batch 30, gen_loss 0.799704, disc_loss 1.488048\n",
      "batch 31, gen_loss 0.807356, disc_loss 1.479774\n",
      "batch 32, gen_loss 0.815922, disc_loss 1.423384\n",
      "batch 33, gen_loss 0.825338, disc_loss 1.451166\n",
      "batch 34, gen_loss 0.838472, disc_loss 1.421743\n",
      "batch 35, gen_loss 0.857189, disc_loss 1.383043\n",
      "batch 36, gen_loss 0.828929, disc_loss 1.381851\n",
      "batch 37, gen_loss 0.834727, disc_loss 1.423880\n",
      "batch 38, gen_loss 0.825679, disc_loss 1.447481\n",
      "batch 39, gen_loss 0.814061, disc_loss 1.425655\n",
      "batch 40, gen_loss 0.767728, disc_loss 1.420647\n",
      "batch 41, gen_loss 0.840542, disc_loss 1.317561\n",
      "batch 42, gen_loss 0.824953, disc_loss 1.391568\n",
      "batch 43, gen_loss 0.824209, disc_loss 1.355412\n",
      "batch 44, gen_loss 0.844247, disc_loss 1.352718\n",
      "batch 45, gen_loss 0.830572, disc_loss 1.367453\n",
      "batch 46, gen_loss 0.866753, disc_loss 1.322297\n",
      "batch 47, gen_loss 0.869153, disc_loss 1.299431\n",
      "batch 48, gen_loss 0.851218, disc_loss 1.299944\n",
      "batch 49, gen_loss 0.889985, disc_loss 1.299339\n",
      "batch 50, gen_loss 0.931013, disc_loss 1.264444\n",
      "batch 51, gen_loss 0.930493, disc_loss 1.232117\n",
      "batch 52, gen_loss 0.936702, disc_loss 1.239498\n",
      "batch 53, gen_loss 0.932292, disc_loss 1.242062\n",
      "batch 54, gen_loss 0.932723, disc_loss 1.250115\n",
      "batch 55, gen_loss 0.952695, disc_loss 1.205807\n",
      "batch 56, gen_loss 0.952540, disc_loss 1.185346\n",
      "batch 57, gen_loss 0.952272, disc_loss 1.192302\n",
      "batch 58, gen_loss 0.972725, disc_loss 1.169274\n",
      "batch 59, gen_loss 0.967390, disc_loss 1.149549\n",
      "batch 60, gen_loss 0.945480, disc_loss 1.133685\n",
      "batch 61, gen_loss 0.960432, disc_loss 1.125471\n",
      "batch 62, gen_loss 0.976374, disc_loss 1.109706\n",
      "batch 63, gen_loss 0.974523, disc_loss 1.123434\n",
      "batch 64, gen_loss 1.007448, disc_loss 1.082697\n",
      "batch 65, gen_loss 1.005955, disc_loss 1.037756\n",
      "batch 66, gen_loss 1.047049, disc_loss 1.002207\n",
      "batch 67, gen_loss 1.047290, disc_loss 1.018294\n",
      "batch 68, gen_loss 1.078435, disc_loss 0.980415\n",
      "batch 69, gen_loss 1.108503, disc_loss 0.936977\n",
      "batch 70, gen_loss 1.135023, disc_loss 0.967592\n",
      "batch 71, gen_loss 1.155276, disc_loss 0.969279\n",
      "batch 72, gen_loss 1.168876, disc_loss 0.929682\n",
      "batch 73, gen_loss 1.178763, disc_loss 0.903519\n",
      "batch 74, gen_loss 1.185951, disc_loss 0.899063\n",
      "batch 75, gen_loss 1.207882, disc_loss 0.868058\n",
      "batch 76, gen_loss 1.230445, disc_loss 0.862198\n",
      "batch 77, gen_loss 1.196519, disc_loss 0.862914\n",
      "batch 78, gen_loss 1.229904, disc_loss 0.861883\n",
      "batch 79, gen_loss 1.210453, disc_loss 0.855647\n",
      "batch 80, gen_loss 1.219126, disc_loss 0.826555\n",
      "batch 81, gen_loss 1.209914, disc_loss 0.810939\n",
      "batch 82, gen_loss 1.231204, disc_loss 0.815699\n",
      "batch 83, gen_loss 1.264349, disc_loss 0.781999\n",
      "batch 84, gen_loss 1.282257, disc_loss 0.740999\n",
      "batch 85, gen_loss 1.281208, disc_loss 0.792752\n",
      "batch 86, gen_loss 1.324932, disc_loss 0.792990\n",
      "batch 87, gen_loss 1.343589, disc_loss 0.754044\n",
      "batch 88, gen_loss 1.332796, disc_loss 0.727222\n",
      "batch 89, gen_loss 1.345971, disc_loss 0.735053\n",
      "batch 90, gen_loss 1.353017, disc_loss 0.738625\n",
      "batch 91, gen_loss 1.356858, disc_loss 0.751771\n",
      "batch 92, gen_loss 1.382784, disc_loss 0.724870\n",
      "batch 93, gen_loss 1.380360, disc_loss 0.746129\n",
      "batch 94, gen_loss 1.381760, disc_loss 0.722497\n",
      "batch 95, gen_loss 1.381352, disc_loss 0.751928\n",
      "batch 96, gen_loss 1.362639, disc_loss 0.728854\n",
      "batch 97, gen_loss 1.328812, disc_loss 0.765981\n",
      "batch 98, gen_loss 1.318743, disc_loss 0.742976\n",
      "batch 99, gen_loss 1.332649, disc_loss 0.726059\n",
      "batch 100, gen_loss 1.326339, disc_loss 0.719550\n",
      "batch 101, gen_loss 1.293621, disc_loss 0.757151\n",
      "batch 102, gen_loss 1.244991, disc_loss 0.784700\n",
      "batch 103, gen_loss 1.294290, disc_loss 0.808232\n",
      "batch 104, gen_loss 1.292928, disc_loss 0.802222\n",
      "batch 105, gen_loss 1.271704, disc_loss 0.763366\n",
      "batch 106, gen_loss 1.225055, disc_loss 0.821470\n",
      "batch 107, gen_loss 1.235642, disc_loss 0.796726\n",
      "batch 108, gen_loss 1.210579, disc_loss 0.853450\n",
      "batch 109, gen_loss 1.177645, disc_loss 0.877072\n",
      "batch 110, gen_loss 1.209185, disc_loss 0.837058\n",
      "batch 111, gen_loss 1.180686, disc_loss 0.878933\n",
      "batch 112, gen_loss 1.157353, disc_loss 0.958917\n",
      "batch 113, gen_loss 1.166124, disc_loss 0.966821\n",
      "batch 114, gen_loss 1.127627, disc_loss 0.976557\n",
      "batch 115, gen_loss 1.120631, disc_loss 1.050123\n",
      "batch 116, gen_loss 1.114289, disc_loss 1.005496\n",
      "batch 117, gen_loss 1.094693, disc_loss 1.070048\n",
      "batch 118, gen_loss 1.067910, disc_loss 1.108974\n",
      "batch 119, gen_loss 0.992262, disc_loss 1.134109\n",
      "batch 120, gen_loss 0.958636, disc_loss 1.190698\n",
      "batch 121, gen_loss 0.932304, disc_loss 1.259978\n",
      "batch 122, gen_loss 0.947086, disc_loss 1.272832\n",
      "batch 123, gen_loss 0.895314, disc_loss 1.304828\n",
      "batch 124, gen_loss 0.871482, disc_loss 1.362158\n",
      "batch 125, gen_loss 0.838489, disc_loss 1.378563\n",
      "batch 126, gen_loss 0.830052, disc_loss 1.417014\n",
      "batch 127, gen_loss 0.800830, disc_loss 1.477638\n",
      "batch 128, gen_loss 0.755772, disc_loss 1.545236\n",
      "batch 129, gen_loss 0.724800, disc_loss 1.526545\n",
      "batch 130, gen_loss 0.763481, disc_loss 1.564866\n",
      "batch 131, gen_loss 0.732655, disc_loss 1.592164\n",
      "batch 132, gen_loss 0.694984, disc_loss 1.586261\n",
      "batch 133, gen_loss 0.684894, disc_loss 1.660822\n",
      "batch 134, gen_loss 0.638998, disc_loss 1.718030\n",
      "batch 135, gen_loss 0.670718, disc_loss 1.667736\n",
      "batch 136, gen_loss 0.656165, disc_loss 1.663423\n",
      "batch 137, gen_loss 0.646195, disc_loss 1.705646\n",
      "batch 138, gen_loss 0.631958, disc_loss 1.708821\n",
      "batch 139, gen_loss 0.623125, disc_loss 1.669909\n",
      "batch 140, gen_loss 0.619534, disc_loss 1.690634\n",
      "batch 141, gen_loss 0.657807, disc_loss 1.654523\n",
      "batch 142, gen_loss 0.612351, disc_loss 1.688656\n",
      "batch 143, gen_loss 0.599807, disc_loss 1.655601\n",
      "batch 144, gen_loss 0.624412, disc_loss 1.676024\n",
      "batch 145, gen_loss 0.630111, disc_loss 1.616432\n",
      "batch 146, gen_loss 0.648932, disc_loss 1.565072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 147, gen_loss 0.662868, disc_loss 1.577420\n",
      "batch 148, gen_loss 0.672519, disc_loss 1.569528\n",
      "batch 149, gen_loss 0.666022, disc_loss 1.478029\n",
      "batch 150, gen_loss 0.669299, disc_loss 1.469110\n",
      "batch 151, gen_loss 0.661088, disc_loss 1.504355\n",
      "batch 152, gen_loss 0.667843, disc_loss 1.416164\n",
      "batch 153, gen_loss 0.711101, disc_loss 1.334211\n",
      "batch 154, gen_loss 0.708579, disc_loss 1.406422\n",
      "batch 155, gen_loss 0.733416, disc_loss 1.348836\n",
      "batch 156, gen_loss 0.725515, disc_loss 1.356979\n",
      "batch 157, gen_loss 0.746652, disc_loss 1.305140\n",
      "batch 158, gen_loss 0.759087, disc_loss 1.267341\n",
      "batch 159, gen_loss 0.784556, disc_loss 1.236132\n",
      "batch 160, gen_loss 0.777707, disc_loss 1.262343\n",
      "batch 161, gen_loss 0.797613, disc_loss 1.251992\n",
      "batch 162, gen_loss 0.818694, disc_loss 1.214074\n",
      "batch 163, gen_loss 0.826772, disc_loss 1.196975\n",
      "batch 164, gen_loss 0.852768, disc_loss 1.185032\n",
      "batch 165, gen_loss 0.866673, disc_loss 1.147899\n",
      "batch 166, gen_loss 0.853643, disc_loss 1.179403\n",
      "batch 167, gen_loss 0.870585, disc_loss 1.128046\n",
      "batch 168, gen_loss 0.868943, disc_loss 1.156376\n",
      "batch 169, gen_loss 0.891756, disc_loss 1.101880\n",
      "batch 170, gen_loss 0.884506, disc_loss 1.132016\n",
      "batch 171, gen_loss 0.908617, disc_loss 1.098325\n",
      "batch 172, gen_loss 0.911486, disc_loss 1.114088\n",
      "batch 173, gen_loss 0.926497, disc_loss 1.099408\n",
      "batch 174, gen_loss 0.898913, disc_loss 1.118697\n",
      "batch 175, gen_loss 0.942024, disc_loss 1.151946\n",
      "batch 176, gen_loss 0.930258, disc_loss 1.080179\n",
      "batch 177, gen_loss 0.964626, disc_loss 1.085456\n",
      "batch 178, gen_loss 0.917233, disc_loss 1.127929\n",
      "batch 179, gen_loss 0.958222, disc_loss 1.137295\n",
      "batch 180, gen_loss 0.950945, disc_loss 1.106104\n",
      "batch 181, gen_loss 0.936707, disc_loss 1.076913\n",
      "batch 182, gen_loss 0.957466, disc_loss 1.122463\n",
      "batch 183, gen_loss 0.975905, disc_loss 1.105190\n",
      "batch 184, gen_loss 0.953524, disc_loss 1.147281\n",
      "batch 185, gen_loss 0.941282, disc_loss 1.118567\n",
      "batch 186, gen_loss 0.992542, disc_loss 1.074157\n",
      "batch 187, gen_loss 0.996765, disc_loss 1.135371\n",
      "batch 188, gen_loss 1.009947, disc_loss 1.090561\n",
      "batch 189, gen_loss 1.018237, disc_loss 1.135243\n",
      "batch 190, gen_loss 1.023290, disc_loss 1.143810\n",
      "batch 191, gen_loss 1.017576, disc_loss 1.119933\n",
      "batch 192, gen_loss 1.026043, disc_loss 1.109601\n",
      "batch 193, gen_loss 1.038376, disc_loss 1.154819\n",
      "batch 194, gen_loss 1.046292, disc_loss 1.091322\n",
      "batch 195, gen_loss 1.084621, disc_loss 1.072362\n",
      "batch 196, gen_loss 1.015692, disc_loss 1.134344\n",
      "batch 197, gen_loss 1.000124, disc_loss 1.153060\n",
      "batch 198, gen_loss 1.000260, disc_loss 1.105040\n",
      "batch 199, gen_loss 1.014534, disc_loss 1.099435\n",
      "batch 200, gen_loss 1.042926, disc_loss 1.052222\n",
      "batch 201, gen_loss 1.003108, disc_loss 1.098794\n",
      "batch 202, gen_loss 1.028350, disc_loss 1.146420\n",
      "batch 203, gen_loss 1.015196, disc_loss 1.131624\n",
      "batch 204, gen_loss 1.076954, disc_loss 1.083814\n",
      "batch 205, gen_loss 1.019804, disc_loss 1.209538\n",
      "batch 206, gen_loss 1.069389, disc_loss 1.153223\n",
      "batch 207, gen_loss 1.046354, disc_loss 1.133010\n",
      "batch 208, gen_loss 1.041281, disc_loss 1.237725\n",
      "batch 209, gen_loss 1.013563, disc_loss 1.299862\n",
      "batch 210, gen_loss 0.959012, disc_loss 1.305193\n",
      "batch 211, gen_loss 1.032408, disc_loss 1.223798\n",
      "batch 212, gen_loss 0.951020, disc_loss 1.213664\n",
      "batch 213, gen_loss 0.973472, disc_loss 1.249591\n",
      "batch 214, gen_loss 0.956753, disc_loss 1.344647\n",
      "batch 215, gen_loss 0.985716, disc_loss 1.268158\n",
      "batch 216, gen_loss 0.955327, disc_loss 1.325594\n",
      "batch 217, gen_loss 0.924498, disc_loss 1.374375\n",
      "batch 218, gen_loss 0.923716, disc_loss 1.509212\n",
      "batch 219, gen_loss 0.930934, disc_loss 1.396180\n",
      "batch 220, gen_loss 0.848920, disc_loss 1.373147\n",
      "batch 221, gen_loss 0.873433, disc_loss 1.435343\n",
      "batch 222, gen_loss 0.886912, disc_loss 1.428493\n",
      "batch 223, gen_loss 0.866351, disc_loss 1.410506\n",
      "batch 224, gen_loss 0.910044, disc_loss 1.429406\n",
      "batch 225, gen_loss 0.840825, disc_loss 1.408920\n",
      "batch 226, gen_loss 0.886525, disc_loss 1.455155\n",
      "batch 227, gen_loss 0.854539, disc_loss 1.500234\n",
      "batch 228, gen_loss 0.882406, disc_loss 1.519381\n",
      "batch 229, gen_loss 0.861161, disc_loss 1.491001\n",
      "batch 230, gen_loss 0.866037, disc_loss 1.445954\n",
      "batch 231, gen_loss 0.810804, disc_loss 1.517160\n",
      "batch 232, gen_loss 0.777764, disc_loss 1.526405\n",
      "batch 233, gen_loss 0.828951, disc_loss 1.403718\n",
      "batch 234, gen_loss 0.794510, disc_loss 1.523848\n",
      "Time for epoch7is 7.465837240219116 sec\n",
      "batch 0, gen_loss 0.771323, disc_loss 1.536962\n",
      "batch 1, gen_loss 0.760738, disc_loss 1.512989\n",
      "batch 2, gen_loss 0.759887, disc_loss 1.529969\n",
      "batch 3, gen_loss 0.730672, disc_loss 1.502777\n",
      "batch 4, gen_loss 0.760597, disc_loss 1.416857\n",
      "batch 5, gen_loss 0.801935, disc_loss 1.456346\n",
      "batch 6, gen_loss 0.838500, disc_loss 1.393944\n",
      "batch 7, gen_loss 0.843080, disc_loss 1.406184\n",
      "batch 8, gen_loss 0.861228, disc_loss 1.415452\n",
      "batch 9, gen_loss 0.885982, disc_loss 1.389906\n",
      "batch 10, gen_loss 0.833786, disc_loss 1.420214\n",
      "batch 11, gen_loss 0.820529, disc_loss 1.431208\n",
      "batch 12, gen_loss 0.818235, disc_loss 1.369492\n",
      "batch 13, gen_loss 0.793515, disc_loss 1.343272\n",
      "batch 14, gen_loss 0.778415, disc_loss 1.299563\n",
      "batch 15, gen_loss 0.795287, disc_loss 1.315175\n",
      "batch 16, gen_loss 0.815908, disc_loss 1.306000\n",
      "batch 17, gen_loss 0.824659, disc_loss 1.291605\n",
      "batch 18, gen_loss 0.838126, disc_loss 1.290076\n",
      "batch 19, gen_loss 0.886127, disc_loss 1.263545\n",
      "batch 20, gen_loss 0.943602, disc_loss 1.264315\n",
      "batch 21, gen_loss 0.934272, disc_loss 1.203800\n",
      "batch 22, gen_loss 0.934654, disc_loss 1.219787\n",
      "batch 23, gen_loss 0.958164, disc_loss 1.179059\n",
      "batch 24, gen_loss 0.917866, disc_loss 1.154359\n",
      "batch 25, gen_loss 0.918487, disc_loss 1.155793\n",
      "batch 26, gen_loss 0.901229, disc_loss 1.150012\n",
      "batch 27, gen_loss 0.907044, disc_loss 1.147887\n",
      "batch 28, gen_loss 0.908578, disc_loss 1.150993\n",
      "batch 29, gen_loss 0.889534, disc_loss 1.145002\n",
      "batch 30, gen_loss 0.932858, disc_loss 1.088724\n",
      "batch 31, gen_loss 0.945439, disc_loss 1.085799\n",
      "batch 32, gen_loss 0.950542, disc_loss 1.134590\n",
      "batch 33, gen_loss 0.971023, disc_loss 1.102657\n",
      "batch 34, gen_loss 0.993972, disc_loss 1.063415\n",
      "batch 35, gen_loss 0.989599, disc_loss 1.116702\n",
      "batch 36, gen_loss 0.986419, disc_loss 1.053056\n",
      "batch 37, gen_loss 1.002618, disc_loss 1.052054\n",
      "batch 38, gen_loss 0.976623, disc_loss 1.079661\n",
      "batch 39, gen_loss 0.985664, disc_loss 1.094206\n",
      "batch 40, gen_loss 0.960178, disc_loss 1.044648\n",
      "batch 41, gen_loss 0.953419, disc_loss 1.064800\n",
      "batch 42, gen_loss 0.964461, disc_loss 1.048289\n",
      "batch 43, gen_loss 0.975067, disc_loss 1.051251\n",
      "batch 44, gen_loss 0.972260, disc_loss 1.028257\n",
      "batch 45, gen_loss 0.980362, disc_loss 1.053705\n",
      "batch 46, gen_loss 0.998234, disc_loss 1.066277\n",
      "batch 47, gen_loss 1.011384, disc_loss 1.057697\n",
      "batch 48, gen_loss 1.004886, disc_loss 1.049033\n",
      "batch 49, gen_loss 1.001751, disc_loss 1.052365\n",
      "batch 50, gen_loss 1.013972, disc_loss 1.052440\n",
      "batch 51, gen_loss 1.005304, disc_loss 1.089555\n",
      "batch 52, gen_loss 1.024808, disc_loss 1.038640\n",
      "batch 53, gen_loss 1.009162, disc_loss 1.072260\n",
      "batch 54, gen_loss 1.046360, disc_loss 1.046247\n",
      "batch 55, gen_loss 0.994877, disc_loss 1.089424\n",
      "batch 56, gen_loss 1.001583, disc_loss 1.087775\n",
      "batch 57, gen_loss 1.042639, disc_loss 1.134699\n",
      "batch 58, gen_loss 1.006021, disc_loss 1.114873\n",
      "batch 59, gen_loss 0.987822, disc_loss 1.075205\n",
      "batch 60, gen_loss 0.995555, disc_loss 1.092776\n",
      "batch 61, gen_loss 0.994790, disc_loss 1.105160\n",
      "batch 62, gen_loss 0.996567, disc_loss 1.171271\n",
      "batch 63, gen_loss 0.988119, disc_loss 1.143554\n",
      "batch 64, gen_loss 1.011146, disc_loss 1.132838\n",
      "batch 65, gen_loss 1.046017, disc_loss 1.136576\n",
      "batch 66, gen_loss 1.036952, disc_loss 1.156399\n",
      "batch 67, gen_loss 1.052532, disc_loss 1.117279\n",
      "batch 68, gen_loss 1.070465, disc_loss 1.169317\n",
      "batch 69, gen_loss 1.059960, disc_loss 1.133384\n",
      "batch 70, gen_loss 1.073492, disc_loss 1.186653\n",
      "batch 71, gen_loss 1.067294, disc_loss 1.183448\n",
      "batch 72, gen_loss 1.049536, disc_loss 1.173324\n",
      "batch 73, gen_loss 1.014110, disc_loss 1.181551\n",
      "batch 74, gen_loss 1.038197, disc_loss 1.164792\n",
      "batch 75, gen_loss 1.009990, disc_loss 1.144723\n",
      "batch 76, gen_loss 0.976613, disc_loss 1.206486\n",
      "batch 77, gen_loss 0.949857, disc_loss 1.180477\n",
      "batch 78, gen_loss 0.999686, disc_loss 1.171865\n",
      "batch 79, gen_loss 1.006576, disc_loss 1.214417\n",
      "batch 80, gen_loss 0.979496, disc_loss 1.233443\n",
      "batch 81, gen_loss 0.984356, disc_loss 1.240806\n",
      "batch 82, gen_loss 1.002710, disc_loss 1.266479\n",
      "batch 83, gen_loss 1.009080, disc_loss 1.232921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 84, gen_loss 0.973749, disc_loss 1.209022\n",
      "batch 85, gen_loss 0.931619, disc_loss 1.261704\n",
      "batch 86, gen_loss 0.996801, disc_loss 1.250285\n",
      "batch 87, gen_loss 0.985073, disc_loss 1.236158\n",
      "batch 88, gen_loss 0.953228, disc_loss 1.267289\n",
      "batch 89, gen_loss 0.953887, disc_loss 1.295439\n",
      "batch 90, gen_loss 0.930629, disc_loss 1.311641\n",
      "batch 91, gen_loss 0.873651, disc_loss 1.331001\n",
      "batch 92, gen_loss 0.864714, disc_loss 1.290495\n",
      "batch 93, gen_loss 0.875699, disc_loss 1.303364\n",
      "batch 94, gen_loss 0.860147, disc_loss 1.347954\n",
      "batch 95, gen_loss 0.855101, disc_loss 1.346337\n",
      "batch 96, gen_loss 0.836647, disc_loss 1.378606\n",
      "batch 97, gen_loss 0.832224, disc_loss 1.356051\n",
      "batch 98, gen_loss 0.838571, disc_loss 1.371131\n",
      "batch 99, gen_loss 0.812008, disc_loss 1.366280\n",
      "batch 100, gen_loss 0.815191, disc_loss 1.395068\n",
      "batch 101, gen_loss 0.803812, disc_loss 1.406246\n",
      "batch 102, gen_loss 0.799026, disc_loss 1.399446\n",
      "batch 103, gen_loss 0.776048, disc_loss 1.399099\n",
      "batch 104, gen_loss 0.769858, disc_loss 1.447585\n",
      "batch 105, gen_loss 0.767802, disc_loss 1.470018\n",
      "batch 106, gen_loss 0.762775, disc_loss 1.431544\n",
      "batch 107, gen_loss 0.741760, disc_loss 1.426336\n",
      "batch 108, gen_loss 0.754387, disc_loss 1.424440\n",
      "batch 109, gen_loss 0.729827, disc_loss 1.477102\n",
      "batch 110, gen_loss 0.733322, disc_loss 1.462640\n",
      "batch 111, gen_loss 0.731025, disc_loss 1.438361\n",
      "batch 112, gen_loss 0.714813, disc_loss 1.487615\n",
      "batch 113, gen_loss 0.753627, disc_loss 1.508923\n",
      "batch 114, gen_loss 0.726214, disc_loss 1.518602\n",
      "batch 115, gen_loss 0.717263, disc_loss 1.508154\n",
      "batch 116, gen_loss 0.709463, disc_loss 1.527731\n",
      "batch 117, gen_loss 0.704109, disc_loss 1.518008\n",
      "batch 118, gen_loss 0.726683, disc_loss 1.460313\n",
      "batch 119, gen_loss 0.689459, disc_loss 1.478946\n",
      "batch 120, gen_loss 0.697788, disc_loss 1.475965\n",
      "batch 121, gen_loss 0.714371, disc_loss 1.434416\n",
      "batch 122, gen_loss 0.705713, disc_loss 1.480739\n",
      "batch 123, gen_loss 0.734353, disc_loss 1.444263\n",
      "batch 124, gen_loss 0.720573, disc_loss 1.435259\n",
      "batch 125, gen_loss 0.738095, disc_loss 1.383941\n",
      "batch 126, gen_loss 0.749875, disc_loss 1.436196\n",
      "batch 127, gen_loss 0.773006, disc_loss 1.409977\n",
      "batch 128, gen_loss 0.762362, disc_loss 1.366211\n",
      "batch 129, gen_loss 0.779306, disc_loss 1.323969\n",
      "batch 130, gen_loss 0.781461, disc_loss 1.290460\n",
      "batch 131, gen_loss 0.816174, disc_loss 1.269788\n",
      "batch 132, gen_loss 0.810315, disc_loss 1.287552\n",
      "batch 133, gen_loss 0.843351, disc_loss 1.257943\n",
      "batch 134, gen_loss 0.852066, disc_loss 1.241428\n",
      "batch 135, gen_loss 0.865383, disc_loss 1.207772\n",
      "batch 136, gen_loss 0.860986, disc_loss 1.197153\n",
      "batch 137, gen_loss 0.869663, disc_loss 1.177133\n",
      "batch 138, gen_loss 0.888355, disc_loss 1.161391\n",
      "batch 139, gen_loss 0.893004, disc_loss 1.131747\n",
      "batch 140, gen_loss 0.910753, disc_loss 1.089089\n",
      "batch 141, gen_loss 0.920568, disc_loss 1.093946\n",
      "batch 142, gen_loss 0.935769, disc_loss 1.112213\n",
      "batch 143, gen_loss 0.940225, disc_loss 1.105603\n",
      "batch 144, gen_loss 0.973945, disc_loss 1.087272\n",
      "batch 145, gen_loss 0.985846, disc_loss 1.052956\n",
      "batch 146, gen_loss 0.970704, disc_loss 1.078437\n",
      "batch 147, gen_loss 0.973161, disc_loss 1.063793\n",
      "batch 148, gen_loss 0.945011, disc_loss 1.053140\n",
      "batch 149, gen_loss 0.950850, disc_loss 1.077687\n",
      "batch 150, gen_loss 0.937788, disc_loss 1.029047\n",
      "batch 151, gen_loss 0.944783, disc_loss 1.046356\n",
      "batch 152, gen_loss 0.904029, disc_loss 1.083827\n",
      "batch 153, gen_loss 0.921875, disc_loss 1.046264\n",
      "batch 154, gen_loss 0.886413, disc_loss 1.065040\n",
      "batch 155, gen_loss 0.875613, disc_loss 1.062825\n",
      "batch 156, gen_loss 0.867139, disc_loss 1.096846\n",
      "batch 157, gen_loss 0.865736, disc_loss 1.089388\n",
      "batch 158, gen_loss 0.875835, disc_loss 1.105992\n",
      "batch 159, gen_loss 0.870838, disc_loss 1.097765\n",
      "batch 160, gen_loss 0.911831, disc_loss 1.118888\n",
      "batch 161, gen_loss 0.846506, disc_loss 1.176462\n",
      "batch 162, gen_loss 0.868414, disc_loss 1.159026\n",
      "batch 163, gen_loss 0.873084, disc_loss 1.130882\n",
      "batch 164, gen_loss 0.843735, disc_loss 1.192027\n",
      "batch 165, gen_loss 0.819520, disc_loss 1.183956\n",
      "batch 166, gen_loss 0.803078, disc_loss 1.209561\n",
      "batch 167, gen_loss 0.795047, disc_loss 1.198316\n",
      "batch 168, gen_loss 0.783862, disc_loss 1.253129\n",
      "batch 169, gen_loss 0.804172, disc_loss 1.209536\n",
      "batch 170, gen_loss 0.788995, disc_loss 1.195959\n",
      "batch 171, gen_loss 0.789018, disc_loss 1.229650\n",
      "batch 172, gen_loss 0.786299, disc_loss 1.261801\n",
      "batch 173, gen_loss 0.784816, disc_loss 1.200582\n",
      "batch 174, gen_loss 0.823072, disc_loss 1.193787\n",
      "batch 175, gen_loss 0.834064, disc_loss 1.193238\n",
      "batch 176, gen_loss 0.828842, disc_loss 1.220972\n",
      "batch 177, gen_loss 0.868913, disc_loss 1.205662\n",
      "batch 178, gen_loss 0.905703, disc_loss 1.134691\n",
      "batch 179, gen_loss 0.911969, disc_loss 1.159203\n",
      "batch 180, gen_loss 0.907508, disc_loss 1.192623\n",
      "batch 181, gen_loss 0.917444, disc_loss 1.203525\n",
      "batch 182, gen_loss 0.929011, disc_loss 1.134519\n",
      "batch 183, gen_loss 0.930178, disc_loss 1.193416\n",
      "batch 184, gen_loss 0.944460, disc_loss 1.138995\n",
      "batch 185, gen_loss 0.944816, disc_loss 1.125817\n",
      "batch 186, gen_loss 0.921116, disc_loss 1.151428\n",
      "batch 187, gen_loss 0.910270, disc_loss 1.131658\n",
      "batch 188, gen_loss 0.939890, disc_loss 1.172312\n",
      "batch 189, gen_loss 0.968088, disc_loss 1.113629\n",
      "batch 190, gen_loss 0.964602, disc_loss 1.122075\n",
      "batch 191, gen_loss 0.958707, disc_loss 1.139179\n",
      "batch 192, gen_loss 0.964454, disc_loss 1.150564\n",
      "batch 193, gen_loss 0.984419, disc_loss 1.128569\n",
      "batch 194, gen_loss 0.999823, disc_loss 1.104636\n",
      "batch 195, gen_loss 0.970907, disc_loss 1.132976\n",
      "batch 196, gen_loss 0.962231, disc_loss 1.170401\n",
      "batch 197, gen_loss 0.951636, disc_loss 1.106835\n",
      "batch 198, gen_loss 0.952149, disc_loss 1.173576\n",
      "batch 199, gen_loss 0.927748, disc_loss 1.182517\n",
      "batch 200, gen_loss 0.867659, disc_loss 1.136051\n",
      "batch 201, gen_loss 0.905102, disc_loss 1.124233\n",
      "batch 202, gen_loss 0.840308, disc_loss 1.207293\n",
      "batch 203, gen_loss 0.844920, disc_loss 1.245124\n",
      "batch 204, gen_loss 0.852691, disc_loss 1.186814\n",
      "batch 205, gen_loss 0.845194, disc_loss 1.236043\n",
      "batch 206, gen_loss 0.886048, disc_loss 1.194028\n",
      "batch 207, gen_loss 0.877805, disc_loss 1.201302\n",
      "batch 208, gen_loss 0.890738, disc_loss 1.258526\n",
      "batch 209, gen_loss 0.872386, disc_loss 1.224408\n",
      "batch 210, gen_loss 0.881890, disc_loss 1.268639\n",
      "batch 211, gen_loss 0.888066, disc_loss 1.293451\n",
      "batch 212, gen_loss 0.843293, disc_loss 1.296591\n",
      "batch 213, gen_loss 0.837757, disc_loss 1.361606\n",
      "batch 214, gen_loss 0.804660, disc_loss 1.326303\n",
      "batch 215, gen_loss 0.792934, disc_loss 1.342111\n",
      "batch 216, gen_loss 0.783784, disc_loss 1.394974\n",
      "batch 217, gen_loss 0.790154, disc_loss 1.363462\n",
      "batch 218, gen_loss 0.795889, disc_loss 1.416703\n",
      "batch 219, gen_loss 0.779213, disc_loss 1.447878\n",
      "batch 220, gen_loss 0.788141, disc_loss 1.433386\n",
      "batch 221, gen_loss 0.782615, disc_loss 1.425411\n",
      "batch 222, gen_loss 0.806725, disc_loss 1.497576\n",
      "batch 223, gen_loss 0.807131, disc_loss 1.443364\n",
      "batch 224, gen_loss 0.776904, disc_loss 1.494968\n",
      "batch 225, gen_loss 0.787023, disc_loss 1.515289\n",
      "batch 226, gen_loss 0.773700, disc_loss 1.477469\n",
      "batch 227, gen_loss 0.746120, disc_loss 1.515035\n",
      "batch 228, gen_loss 0.754469, disc_loss 1.458929\n",
      "batch 229, gen_loss 0.787167, disc_loss 1.448298\n",
      "batch 230, gen_loss 0.756707, disc_loss 1.495162\n",
      "batch 231, gen_loss 0.755027, disc_loss 1.488181\n",
      "batch 232, gen_loss 0.755485, disc_loss 1.508673\n",
      "batch 233, gen_loss 0.772686, disc_loss 1.551363\n",
      "batch 234, gen_loss 0.770850, disc_loss 1.533497\n",
      "Time for epoch8is 7.486226797103882 sec\n",
      "batch 0, gen_loss 0.773614, disc_loss 1.474960\n",
      "batch 1, gen_loss 0.770073, disc_loss 1.554734\n",
      "batch 2, gen_loss 0.795017, disc_loss 1.551162\n",
      "batch 3, gen_loss 0.778643, disc_loss 1.537208\n",
      "batch 4, gen_loss 0.725795, disc_loss 1.506348\n",
      "batch 5, gen_loss 0.744544, disc_loss 1.494716\n",
      "batch 6, gen_loss 0.721101, disc_loss 1.510895\n",
      "batch 7, gen_loss 0.709078, disc_loss 1.548962\n",
      "batch 8, gen_loss 0.703396, disc_loss 1.529549\n",
      "batch 9, gen_loss 0.752755, disc_loss 1.447525\n",
      "batch 10, gen_loss 0.717408, disc_loss 1.545644\n",
      "batch 11, gen_loss 0.738992, disc_loss 1.476306\n",
      "batch 12, gen_loss 0.750478, disc_loss 1.474814\n",
      "batch 13, gen_loss 0.734811, disc_loss 1.528648\n",
      "batch 14, gen_loss 0.718645, disc_loss 1.474477\n",
      "batch 15, gen_loss 0.752278, disc_loss 1.412632\n",
      "batch 16, gen_loss 0.753927, disc_loss 1.452596\n",
      "batch 17, gen_loss 0.749008, disc_loss 1.436664\n",
      "batch 18, gen_loss 0.788330, disc_loss 1.410562\n",
      "batch 19, gen_loss 0.784877, disc_loss 1.389755\n",
      "batch 20, gen_loss 0.786408, disc_loss 1.435314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 21, gen_loss 0.810004, disc_loss 1.405895\n",
      "batch 22, gen_loss 0.800359, disc_loss 1.352217\n",
      "batch 23, gen_loss 0.809503, disc_loss 1.373002\n",
      "batch 24, gen_loss 0.793625, disc_loss 1.370734\n",
      "batch 25, gen_loss 0.787652, disc_loss 1.367358\n",
      "batch 26, gen_loss 0.775353, disc_loss 1.362376\n",
      "batch 27, gen_loss 0.766735, disc_loss 1.361755\n",
      "batch 28, gen_loss 0.786645, disc_loss 1.373210\n",
      "batch 29, gen_loss 0.763986, disc_loss 1.390540\n",
      "batch 30, gen_loss 0.794587, disc_loss 1.371912\n",
      "batch 31, gen_loss 0.793894, disc_loss 1.303910\n",
      "batch 32, gen_loss 0.786043, disc_loss 1.344376\n",
      "batch 33, gen_loss 0.789002, disc_loss 1.349930\n",
      "batch 34, gen_loss 0.804354, disc_loss 1.276519\n",
      "batch 35, gen_loss 0.785917, disc_loss 1.268921\n",
      "batch 36, gen_loss 0.799768, disc_loss 1.306526\n",
      "batch 37, gen_loss 0.853165, disc_loss 1.298201\n",
      "batch 38, gen_loss 0.827080, disc_loss 1.333294\n",
      "batch 39, gen_loss 0.865185, disc_loss 1.253273\n",
      "batch 40, gen_loss 0.862826, disc_loss 1.262675\n",
      "batch 41, gen_loss 0.836493, disc_loss 1.295036\n",
      "batch 42, gen_loss 0.872912, disc_loss 1.246450\n",
      "batch 43, gen_loss 0.868170, disc_loss 1.221774\n",
      "batch 44, gen_loss 0.837293, disc_loss 1.257938\n",
      "batch 45, gen_loss 0.862529, disc_loss 1.229305\n",
      "batch 46, gen_loss 0.876646, disc_loss 1.280063\n",
      "batch 47, gen_loss 0.889635, disc_loss 1.211328\n",
      "batch 48, gen_loss 0.876428, disc_loss 1.234792\n",
      "batch 49, gen_loss 0.848119, disc_loss 1.248894\n",
      "batch 50, gen_loss 0.882012, disc_loss 1.217869\n",
      "batch 51, gen_loss 0.878812, disc_loss 1.179083\n",
      "batch 52, gen_loss 0.893840, disc_loss 1.194265\n",
      "batch 53, gen_loss 0.904355, disc_loss 1.187172\n",
      "batch 54, gen_loss 0.929133, disc_loss 1.194967\n",
      "batch 55, gen_loss 0.918555, disc_loss 1.196281\n",
      "batch 56, gen_loss 0.903330, disc_loss 1.194143\n",
      "batch 57, gen_loss 0.928595, disc_loss 1.230266\n",
      "batch 58, gen_loss 0.944903, disc_loss 1.177192\n",
      "batch 59, gen_loss 0.905889, disc_loss 1.231728\n",
      "batch 60, gen_loss 0.866956, disc_loss 1.234132\n",
      "batch 61, gen_loss 0.851046, disc_loss 1.228973\n",
      "batch 62, gen_loss 0.865727, disc_loss 1.243832\n",
      "batch 63, gen_loss 0.853219, disc_loss 1.282986\n",
      "batch 64, gen_loss 0.846195, disc_loss 1.227119\n",
      "batch 65, gen_loss 0.849890, disc_loss 1.290709\n",
      "batch 66, gen_loss 0.860192, disc_loss 1.247402\n",
      "batch 67, gen_loss 0.867282, disc_loss 1.273140\n",
      "batch 68, gen_loss 0.853308, disc_loss 1.261445\n",
      "batch 69, gen_loss 0.861386, disc_loss 1.314747\n",
      "batch 70, gen_loss 0.839922, disc_loss 1.312275\n",
      "batch 71, gen_loss 0.824718, disc_loss 1.348579\n",
      "batch 72, gen_loss 0.839414, disc_loss 1.287910\n",
      "batch 73, gen_loss 0.821429, disc_loss 1.298879\n",
      "batch 74, gen_loss 0.812539, disc_loss 1.319973\n",
      "batch 75, gen_loss 0.841168, disc_loss 1.277767\n",
      "batch 76, gen_loss 0.821738, disc_loss 1.316227\n",
      "batch 77, gen_loss 0.813519, disc_loss 1.341521\n",
      "batch 78, gen_loss 0.848948, disc_loss 1.325132\n",
      "batch 79, gen_loss 0.830678, disc_loss 1.329344\n",
      "batch 80, gen_loss 0.820258, disc_loss 1.340283\n",
      "batch 81, gen_loss 0.800124, disc_loss 1.339505\n",
      "batch 82, gen_loss 0.839142, disc_loss 1.306771\n",
      "batch 83, gen_loss 0.797547, disc_loss 1.334167\n",
      "batch 84, gen_loss 0.815473, disc_loss 1.345133\n",
      "batch 85, gen_loss 0.838954, disc_loss 1.288687\n",
      "batch 86, gen_loss 0.869030, disc_loss 1.264204\n",
      "batch 87, gen_loss 0.866132, disc_loss 1.323194\n",
      "batch 88, gen_loss 0.869093, disc_loss 1.298476\n",
      "batch 89, gen_loss 0.865234, disc_loss 1.227742\n",
      "batch 90, gen_loss 0.901882, disc_loss 1.202407\n",
      "batch 91, gen_loss 0.863643, disc_loss 1.255284\n",
      "batch 92, gen_loss 0.890131, disc_loss 1.210345\n",
      "batch 93, gen_loss 0.919231, disc_loss 1.226657\n",
      "batch 94, gen_loss 0.939980, disc_loss 1.178652\n",
      "batch 95, gen_loss 0.963267, disc_loss 1.177227\n",
      "batch 96, gen_loss 0.951412, disc_loss 1.149263\n",
      "batch 97, gen_loss 0.944126, disc_loss 1.149609\n",
      "batch 98, gen_loss 0.921259, disc_loss 1.118260\n",
      "batch 99, gen_loss 0.934399, disc_loss 1.111748\n",
      "batch 100, gen_loss 0.953553, disc_loss 1.066445\n",
      "batch 101, gen_loss 0.963172, disc_loss 1.026766\n",
      "batch 102, gen_loss 0.941734, disc_loss 1.036644\n",
      "batch 103, gen_loss 0.995250, disc_loss 1.056005\n",
      "batch 104, gen_loss 1.027334, disc_loss 1.004519\n",
      "batch 105, gen_loss 1.013643, disc_loss 1.006177\n",
      "batch 106, gen_loss 1.024906, disc_loss 1.028055\n",
      "batch 107, gen_loss 1.057490, disc_loss 0.994189\n",
      "batch 108, gen_loss 1.038676, disc_loss 1.005072\n",
      "batch 109, gen_loss 1.057458, disc_loss 0.985484\n",
      "batch 110, gen_loss 1.033787, disc_loss 0.992283\n",
      "batch 111, gen_loss 1.023892, disc_loss 0.964017\n",
      "batch 112, gen_loss 0.980651, disc_loss 0.994124\n",
      "batch 113, gen_loss 0.985078, disc_loss 0.975836\n",
      "batch 114, gen_loss 1.033028, disc_loss 0.946645\n",
      "batch 115, gen_loss 0.994978, disc_loss 0.981064\n",
      "batch 116, gen_loss 1.014609, disc_loss 0.959334\n",
      "batch 117, gen_loss 1.033782, disc_loss 0.970093\n",
      "batch 118, gen_loss 1.023275, disc_loss 0.977386\n",
      "batch 119, gen_loss 1.027418, disc_loss 1.020063\n",
      "batch 120, gen_loss 1.004789, disc_loss 1.042678\n",
      "batch 121, gen_loss 0.986857, disc_loss 1.040281\n",
      "batch 122, gen_loss 0.971475, disc_loss 1.006880\n",
      "batch 123, gen_loss 0.963752, disc_loss 1.035126\n",
      "batch 124, gen_loss 0.955741, disc_loss 1.044732\n",
      "batch 125, gen_loss 0.927957, disc_loss 1.064833\n",
      "batch 126, gen_loss 0.901565, disc_loss 1.118266\n",
      "batch 127, gen_loss 0.916641, disc_loss 1.032349\n",
      "batch 128, gen_loss 0.889372, disc_loss 1.074129\n",
      "batch 129, gen_loss 0.915118, disc_loss 1.090995\n",
      "batch 130, gen_loss 0.893175, disc_loss 1.075905\n",
      "batch 131, gen_loss 0.905056, disc_loss 1.099085\n",
      "batch 132, gen_loss 0.920229, disc_loss 1.134098\n",
      "batch 133, gen_loss 0.902476, disc_loss 1.169637\n",
      "batch 134, gen_loss 0.880554, disc_loss 1.142645\n",
      "batch 135, gen_loss 0.863597, disc_loss 1.102137\n",
      "batch 136, gen_loss 0.834831, disc_loss 1.097678\n",
      "batch 137, gen_loss 0.856213, disc_loss 1.133345\n",
      "batch 138, gen_loss 0.864111, disc_loss 1.107043\n",
      "batch 139, gen_loss 0.877870, disc_loss 1.109468\n",
      "batch 140, gen_loss 0.901426, disc_loss 1.083045\n",
      "batch 141, gen_loss 0.929624, disc_loss 1.120761\n",
      "batch 142, gen_loss 0.921435, disc_loss 1.110134\n",
      "batch 143, gen_loss 0.958240, disc_loss 1.104403\n",
      "batch 144, gen_loss 0.984500, disc_loss 1.067433\n",
      "batch 145, gen_loss 0.996316, disc_loss 1.099712\n",
      "batch 146, gen_loss 0.985551, disc_loss 1.123804\n",
      "batch 147, gen_loss 1.045642, disc_loss 1.099590\n",
      "batch 148, gen_loss 1.045182, disc_loss 1.116002\n",
      "batch 149, gen_loss 1.032970, disc_loss 1.146723\n",
      "batch 150, gen_loss 1.037057, disc_loss 1.089543\n",
      "batch 151, gen_loss 1.020947, disc_loss 1.092137\n",
      "batch 152, gen_loss 1.013796, disc_loss 1.147919\n",
      "batch 153, gen_loss 1.041979, disc_loss 1.171554\n",
      "batch 154, gen_loss 1.028985, disc_loss 1.139186\n",
      "batch 155, gen_loss 1.024968, disc_loss 1.150888\n",
      "batch 156, gen_loss 1.005428, disc_loss 1.103741\n",
      "batch 157, gen_loss 1.020892, disc_loss 1.097746\n",
      "batch 158, gen_loss 1.011585, disc_loss 1.138871\n",
      "batch 159, gen_loss 1.038962, disc_loss 1.148031\n",
      "batch 160, gen_loss 1.042073, disc_loss 1.122747\n",
      "batch 161, gen_loss 1.043051, disc_loss 1.095042\n",
      "batch 162, gen_loss 1.025509, disc_loss 1.188395\n",
      "batch 163, gen_loss 1.016960, disc_loss 1.247234\n",
      "batch 164, gen_loss 0.973578, disc_loss 1.159453\n",
      "batch 165, gen_loss 0.986951, disc_loss 1.159166\n",
      "batch 166, gen_loss 0.958565, disc_loss 1.128663\n",
      "batch 167, gen_loss 0.973937, disc_loss 1.184534\n",
      "batch 168, gen_loss 0.937175, disc_loss 1.252128\n",
      "batch 169, gen_loss 0.935122, disc_loss 1.196659\n",
      "batch 170, gen_loss 0.977393, disc_loss 1.183228\n",
      "batch 171, gen_loss 0.957540, disc_loss 1.241988\n",
      "batch 172, gen_loss 0.929952, disc_loss 1.326844\n",
      "batch 173, gen_loss 0.933464, disc_loss 1.270720\n",
      "batch 174, gen_loss 0.946287, disc_loss 1.287799\n",
      "batch 175, gen_loss 0.894900, disc_loss 1.246883\n",
      "batch 176, gen_loss 0.889954, disc_loss 1.365150\n",
      "batch 177, gen_loss 0.888775, disc_loss 1.373327\n",
      "batch 178, gen_loss 0.843379, disc_loss 1.359483\n",
      "batch 179, gen_loss 0.844727, disc_loss 1.426662\n",
      "batch 180, gen_loss 0.849398, disc_loss 1.391917\n",
      "batch 181, gen_loss 0.812294, disc_loss 1.462596\n",
      "batch 182, gen_loss 0.842786, disc_loss 1.472346\n",
      "batch 183, gen_loss 0.797235, disc_loss 1.471409\n",
      "batch 184, gen_loss 0.801629, disc_loss 1.472416\n",
      "batch 185, gen_loss 0.795258, disc_loss 1.501351\n",
      "batch 186, gen_loss 0.764630, disc_loss 1.576491\n",
      "batch 187, gen_loss 0.758559, disc_loss 1.599666\n",
      "batch 188, gen_loss 0.725685, disc_loss 1.602040\n",
      "batch 189, gen_loss 0.720512, disc_loss 1.609841\n",
      "batch 190, gen_loss 0.690455, disc_loss 1.647506\n",
      "batch 191, gen_loss 0.697823, disc_loss 1.651911\n",
      "batch 192, gen_loss 0.704361, disc_loss 1.703767\n",
      "batch 193, gen_loss 0.673848, disc_loss 1.816367\n",
      "batch 194, gen_loss 0.673203, disc_loss 1.701162\n",
      "batch 195, gen_loss 0.668297, disc_loss 1.910844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 196, gen_loss 0.670863, disc_loss 1.911515\n",
      "batch 197, gen_loss 0.633821, disc_loss 1.857857\n",
      "batch 198, gen_loss 0.646735, disc_loss 1.897283\n",
      "batch 199, gen_loss 0.611709, disc_loss 1.838414\n",
      "batch 200, gen_loss 0.623183, disc_loss 1.850710\n",
      "batch 201, gen_loss 0.611948, disc_loss 1.819591\n",
      "batch 202, gen_loss 0.629776, disc_loss 1.776833\n",
      "batch 203, gen_loss 0.590322, disc_loss 1.815200\n",
      "batch 204, gen_loss 0.599935, disc_loss 1.869425\n",
      "batch 205, gen_loss 0.661258, disc_loss 1.843721\n",
      "batch 206, gen_loss 0.654077, disc_loss 1.761563\n",
      "batch 207, gen_loss 0.670138, disc_loss 1.775016\n",
      "batch 208, gen_loss 0.700946, disc_loss 1.796274\n",
      "batch 209, gen_loss 0.705779, disc_loss 1.705191\n",
      "batch 210, gen_loss 0.719556, disc_loss 1.712088\n",
      "batch 211, gen_loss 0.724765, disc_loss 1.636659\n",
      "batch 212, gen_loss 0.722296, disc_loss 1.609260\n",
      "batch 213, gen_loss 0.713163, disc_loss 1.628874\n",
      "batch 214, gen_loss 0.702035, disc_loss 1.587710\n",
      "batch 215, gen_loss 0.711967, disc_loss 1.511604\n",
      "batch 216, gen_loss 0.693038, disc_loss 1.500958\n",
      "batch 217, gen_loss 0.738655, disc_loss 1.438073\n",
      "batch 218, gen_loss 0.745082, disc_loss 1.408433\n",
      "batch 219, gen_loss 0.760185, disc_loss 1.401978\n",
      "batch 220, gen_loss 0.786686, disc_loss 1.437148\n",
      "batch 221, gen_loss 0.817682, disc_loss 1.348580\n",
      "batch 222, gen_loss 0.846701, disc_loss 1.390749\n",
      "batch 223, gen_loss 0.856023, disc_loss 1.322569\n",
      "batch 224, gen_loss 0.883667, disc_loss 1.300469\n",
      "batch 225, gen_loss 0.881954, disc_loss 1.301282\n",
      "batch 226, gen_loss 0.863380, disc_loss 1.258373\n",
      "batch 227, gen_loss 0.869966, disc_loss 1.278386\n",
      "batch 228, gen_loss 0.861355, disc_loss 1.223800\n",
      "batch 229, gen_loss 0.867356, disc_loss 1.243832\n",
      "batch 230, gen_loss 0.877877, disc_loss 1.225059\n",
      "batch 231, gen_loss 0.849966, disc_loss 1.234149\n",
      "batch 232, gen_loss 0.884095, disc_loss 1.211435\n",
      "batch 233, gen_loss 0.879529, disc_loss 1.194721\n",
      "batch 234, gen_loss 0.866266, disc_loss 1.161161\n",
      "Time for epoch9is 7.509631395339966 sec\n",
      "batch 0, gen_loss 0.892981, disc_loss 1.172486\n",
      "batch 1, gen_loss 0.887568, disc_loss 1.183012\n",
      "batch 2, gen_loss 0.898571, disc_loss 1.160063\n",
      "batch 3, gen_loss 0.911975, disc_loss 1.196450\n",
      "batch 4, gen_loss 0.912381, disc_loss 1.119008\n",
      "batch 5, gen_loss 0.944249, disc_loss 1.128520\n",
      "batch 6, gen_loss 0.936211, disc_loss 1.142558\n",
      "batch 7, gen_loss 0.932502, disc_loss 1.139026\n",
      "batch 8, gen_loss 0.951241, disc_loss 1.089701\n",
      "batch 9, gen_loss 0.947358, disc_loss 1.104840\n",
      "batch 10, gen_loss 0.927135, disc_loss 1.149756\n",
      "batch 11, gen_loss 0.946398, disc_loss 1.079922\n",
      "batch 12, gen_loss 0.954145, disc_loss 1.064381\n",
      "batch 13, gen_loss 0.947505, disc_loss 1.112440\n",
      "batch 14, gen_loss 0.963914, disc_loss 1.098123\n",
      "batch 15, gen_loss 0.937800, disc_loss 1.108555\n",
      "batch 16, gen_loss 0.962241, disc_loss 1.067177\n",
      "batch 17, gen_loss 0.968237, disc_loss 1.051225\n",
      "batch 18, gen_loss 0.965734, disc_loss 1.106035\n",
      "batch 19, gen_loss 0.970343, disc_loss 1.072917\n",
      "batch 20, gen_loss 0.974847, disc_loss 1.071817\n",
      "batch 21, gen_loss 0.963735, disc_loss 1.088541\n",
      "batch 22, gen_loss 0.990742, disc_loss 1.025200\n",
      "batch 23, gen_loss 0.987027, disc_loss 1.048118\n",
      "batch 24, gen_loss 1.021072, disc_loss 1.018231\n",
      "batch 25, gen_loss 1.009557, disc_loss 1.023732\n",
      "batch 26, gen_loss 1.002051, disc_loss 1.015948\n",
      "batch 27, gen_loss 1.026424, disc_loss 1.031559\n",
      "batch 28, gen_loss 1.034383, disc_loss 1.027778\n",
      "batch 29, gen_loss 1.029157, disc_loss 1.009709\n",
      "batch 30, gen_loss 1.044396, disc_loss 1.034643\n",
      "batch 31, gen_loss 1.047468, disc_loss 1.006680\n",
      "batch 32, gen_loss 1.053962, disc_loss 1.030583\n",
      "batch 33, gen_loss 1.088308, disc_loss 1.023129\n",
      "batch 34, gen_loss 1.067747, disc_loss 0.981911\n",
      "batch 35, gen_loss 1.064858, disc_loss 0.996473\n",
      "batch 36, gen_loss 1.068920, disc_loss 1.019171\n",
      "batch 37, gen_loss 1.028080, disc_loss 1.084735\n",
      "batch 38, gen_loss 1.006465, disc_loss 1.057313\n",
      "batch 39, gen_loss 1.046706, disc_loss 1.073621\n",
      "batch 40, gen_loss 0.997542, disc_loss 1.042630\n",
      "batch 41, gen_loss 1.019327, disc_loss 1.000169\n",
      "batch 42, gen_loss 0.991272, disc_loss 1.034522\n",
      "batch 43, gen_loss 0.979041, disc_loss 1.010649\n",
      "batch 44, gen_loss 0.991354, disc_loss 1.083493\n",
      "batch 45, gen_loss 0.999105, disc_loss 1.057325\n",
      "batch 46, gen_loss 1.004387, disc_loss 1.058187\n",
      "batch 47, gen_loss 1.040333, disc_loss 1.068981\n",
      "batch 48, gen_loss 1.015913, disc_loss 1.054436\n",
      "batch 49, gen_loss 0.976568, disc_loss 1.098659\n",
      "batch 50, gen_loss 1.007245, disc_loss 1.082396\n",
      "batch 51, gen_loss 0.982135, disc_loss 1.147820\n",
      "batch 52, gen_loss 0.943841, disc_loss 1.137079\n",
      "batch 53, gen_loss 0.942682, disc_loss 1.162909\n",
      "batch 54, gen_loss 0.913244, disc_loss 1.176733\n",
      "batch 55, gen_loss 0.923018, disc_loss 1.168722\n",
      "batch 56, gen_loss 0.884558, disc_loss 1.244246\n",
      "batch 57, gen_loss 0.865474, disc_loss 1.181279\n",
      "batch 58, gen_loss 0.890623, disc_loss 1.165615\n",
      "batch 59, gen_loss 0.849376, disc_loss 1.238402\n",
      "batch 60, gen_loss 0.841691, disc_loss 1.254308\n",
      "batch 61, gen_loss 0.840805, disc_loss 1.224968\n",
      "batch 62, gen_loss 0.838625, disc_loss 1.271610\n",
      "batch 63, gen_loss 0.861949, disc_loss 1.293377\n",
      "batch 64, gen_loss 0.833670, disc_loss 1.295435\n",
      "batch 65, gen_loss 0.809111, disc_loss 1.295129\n",
      "batch 66, gen_loss 0.814173, disc_loss 1.296988\n",
      "batch 67, gen_loss 0.826376, disc_loss 1.248616\n",
      "batch 68, gen_loss 0.806169, disc_loss 1.379068\n",
      "batch 69, gen_loss 0.827053, disc_loss 1.285651\n",
      "batch 70, gen_loss 0.778947, disc_loss 1.345774\n",
      "batch 71, gen_loss 0.793248, disc_loss 1.347031\n",
      "batch 72, gen_loss 0.791953, disc_loss 1.296861\n",
      "batch 73, gen_loss 0.802157, disc_loss 1.319544\n",
      "batch 74, gen_loss 0.777735, disc_loss 1.314333\n",
      "batch 75, gen_loss 0.801327, disc_loss 1.287312\n",
      "batch 76, gen_loss 0.781684, disc_loss 1.381153\n",
      "batch 77, gen_loss 0.806766, disc_loss 1.372121\n",
      "batch 78, gen_loss 0.786672, disc_loss 1.299857\n",
      "batch 79, gen_loss 0.826738, disc_loss 1.316881\n",
      "batch 80, gen_loss 0.815843, disc_loss 1.317091\n",
      "batch 81, gen_loss 0.819981, disc_loss 1.301871\n",
      "batch 82, gen_loss 0.846773, disc_loss 1.268366\n",
      "batch 83, gen_loss 0.848389, disc_loss 1.251261\n",
      "batch 84, gen_loss 0.822337, disc_loss 1.364305\n",
      "batch 85, gen_loss 0.846223, disc_loss 1.249709\n",
      "batch 86, gen_loss 0.826072, disc_loss 1.324795\n",
      "batch 87, gen_loss 0.828277, disc_loss 1.274666\n",
      "batch 88, gen_loss 0.819472, disc_loss 1.265359\n",
      "batch 89, gen_loss 0.832161, disc_loss 1.265574\n",
      "batch 90, gen_loss 0.812027, disc_loss 1.231820\n",
      "batch 91, gen_loss 0.799924, disc_loss 1.281697\n",
      "batch 92, gen_loss 0.823888, disc_loss 1.264968\n",
      "batch 93, gen_loss 0.838502, disc_loss 1.246861\n",
      "batch 94, gen_loss 0.862427, disc_loss 1.208686\n",
      "batch 95, gen_loss 0.866747, disc_loss 1.235647\n",
      "batch 96, gen_loss 0.843677, disc_loss 1.251544\n",
      "batch 97, gen_loss 0.839751, disc_loss 1.231542\n",
      "batch 98, gen_loss 0.877515, disc_loss 1.214766\n",
      "batch 99, gen_loss 0.853020, disc_loss 1.220972\n",
      "batch 100, gen_loss 0.848391, disc_loss 1.222144\n",
      "batch 101, gen_loss 0.849830, disc_loss 1.228903\n",
      "batch 102, gen_loss 0.864925, disc_loss 1.199695\n",
      "batch 103, gen_loss 0.853852, disc_loss 1.216696\n",
      "batch 104, gen_loss 0.871331, disc_loss 1.230121\n",
      "batch 105, gen_loss 0.855786, disc_loss 1.219023\n",
      "batch 106, gen_loss 0.851559, disc_loss 1.230763\n",
      "batch 107, gen_loss 0.868147, disc_loss 1.177860\n",
      "batch 108, gen_loss 0.853760, disc_loss 1.179821\n",
      "batch 109, gen_loss 0.849000, disc_loss 1.243107\n",
      "batch 110, gen_loss 0.876961, disc_loss 1.173225\n",
      "batch 111, gen_loss 0.845740, disc_loss 1.215335\n",
      "batch 112, gen_loss 0.862384, disc_loss 1.227838\n",
      "batch 113, gen_loss 0.852891, disc_loss 1.225837\n",
      "batch 114, gen_loss 0.852797, disc_loss 1.221238\n",
      "batch 115, gen_loss 0.841912, disc_loss 1.219145\n",
      "batch 116, gen_loss 0.873096, disc_loss 1.185339\n",
      "batch 117, gen_loss 0.855275, disc_loss 1.197887\n",
      "batch 118, gen_loss 0.866132, disc_loss 1.176246\n",
      "batch 119, gen_loss 0.862873, disc_loss 1.185544\n",
      "batch 120, gen_loss 0.869964, disc_loss 1.176630\n",
      "batch 121, gen_loss 0.865830, disc_loss 1.191906\n",
      "batch 122, gen_loss 0.882495, disc_loss 1.190946\n",
      "batch 123, gen_loss 0.859763, disc_loss 1.185728\n",
      "batch 124, gen_loss 0.882501, disc_loss 1.157281\n",
      "batch 125, gen_loss 0.880010, disc_loss 1.176937\n",
      "batch 126, gen_loss 0.895103, disc_loss 1.161470\n",
      "batch 127, gen_loss 0.888096, disc_loss 1.179167\n",
      "batch 128, gen_loss 0.899716, disc_loss 1.153369\n",
      "batch 129, gen_loss 0.911790, disc_loss 1.145662\n",
      "batch 130, gen_loss 0.919416, disc_loss 1.141640\n",
      "batch 131, gen_loss 0.926459, disc_loss 1.157563\n",
      "batch 132, gen_loss 0.940149, disc_loss 1.085435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 133, gen_loss 0.930044, disc_loss 1.149492\n",
      "batch 134, gen_loss 0.954088, disc_loss 1.101883\n",
      "batch 135, gen_loss 0.961213, disc_loss 1.087577\n",
      "batch 136, gen_loss 0.944689, disc_loss 1.151497\n",
      "batch 137, gen_loss 0.948945, disc_loss 1.095387\n",
      "batch 138, gen_loss 0.964087, disc_loss 1.105906\n",
      "batch 139, gen_loss 0.962434, disc_loss 1.082392\n",
      "batch 140, gen_loss 0.953424, disc_loss 1.108527\n",
      "batch 141, gen_loss 0.938141, disc_loss 1.094415\n",
      "batch 142, gen_loss 0.946779, disc_loss 1.131871\n",
      "batch 143, gen_loss 0.943747, disc_loss 1.103653\n",
      "batch 144, gen_loss 0.932112, disc_loss 1.078037\n",
      "batch 145, gen_loss 0.959096, disc_loss 1.049177\n",
      "batch 146, gen_loss 0.925700, disc_loss 1.107397\n",
      "batch 147, gen_loss 0.924035, disc_loss 1.067814\n",
      "batch 148, gen_loss 0.947805, disc_loss 1.074437\n",
      "batch 149, gen_loss 0.925249, disc_loss 1.053197\n",
      "batch 150, gen_loss 0.943375, disc_loss 1.065826\n",
      "batch 151, gen_loss 0.953040, disc_loss 1.069690\n",
      "batch 152, gen_loss 0.974230, disc_loss 1.039874\n",
      "batch 153, gen_loss 0.957785, disc_loss 1.066707\n",
      "batch 154, gen_loss 0.949038, disc_loss 1.059877\n",
      "batch 155, gen_loss 0.954062, disc_loss 1.096527\n",
      "batch 156, gen_loss 0.943364, disc_loss 1.075516\n",
      "batch 157, gen_loss 0.964370, disc_loss 1.074569\n",
      "batch 158, gen_loss 0.913244, disc_loss 1.062248\n",
      "batch 159, gen_loss 0.927132, disc_loss 1.047671\n",
      "batch 160, gen_loss 0.918721, disc_loss 1.073623\n",
      "batch 161, gen_loss 0.957310, disc_loss 1.044706\n",
      "batch 162, gen_loss 0.959459, disc_loss 1.072817\n",
      "batch 163, gen_loss 0.918227, disc_loss 1.078547\n",
      "batch 164, gen_loss 0.950689, disc_loss 1.068005\n",
      "batch 165, gen_loss 0.973162, disc_loss 1.092943\n",
      "batch 166, gen_loss 1.004309, disc_loss 1.054743\n",
      "batch 167, gen_loss 0.995462, disc_loss 1.052973\n",
      "batch 168, gen_loss 0.977092, disc_loss 1.035539\n",
      "batch 169, gen_loss 0.995761, disc_loss 1.020599\n",
      "batch 170, gen_loss 0.975061, disc_loss 1.036676\n",
      "batch 171, gen_loss 0.983371, disc_loss 1.046837\n",
      "batch 172, gen_loss 1.004079, disc_loss 1.029774\n",
      "batch 173, gen_loss 0.998473, disc_loss 1.036554\n",
      "batch 174, gen_loss 1.005984, disc_loss 1.043421\n",
      "batch 175, gen_loss 1.032548, disc_loss 1.081248\n",
      "batch 176, gen_loss 0.998879, disc_loss 1.060592\n",
      "batch 177, gen_loss 0.982230, disc_loss 1.070619\n",
      "batch 178, gen_loss 1.009291, disc_loss 1.028477\n",
      "batch 179, gen_loss 0.968003, disc_loss 1.052045\n",
      "batch 180, gen_loss 0.974812, disc_loss 1.060792\n",
      "batch 181, gen_loss 0.920601, disc_loss 1.081392\n",
      "batch 182, gen_loss 0.961010, disc_loss 1.079717\n",
      "batch 183, gen_loss 0.985400, disc_loss 1.069483\n",
      "batch 184, gen_loss 0.988713, disc_loss 1.101992\n",
      "batch 185, gen_loss 1.018817, disc_loss 1.065354\n",
      "batch 186, gen_loss 1.007600, disc_loss 1.093303\n",
      "batch 187, gen_loss 0.980498, disc_loss 1.037597\n",
      "batch 188, gen_loss 0.998771, disc_loss 1.079232\n",
      "batch 189, gen_loss 0.982170, disc_loss 1.098847\n",
      "batch 190, gen_loss 0.957652, disc_loss 1.119412\n",
      "batch 191, gen_loss 0.967852, disc_loss 1.133042\n",
      "batch 192, gen_loss 0.917577, disc_loss 1.141459\n",
      "batch 193, gen_loss 0.931102, disc_loss 1.150138\n",
      "batch 194, gen_loss 0.892323, disc_loss 1.159192\n",
      "batch 195, gen_loss 0.930238, disc_loss 1.154486\n",
      "batch 196, gen_loss 0.937150, disc_loss 1.168974\n",
      "batch 197, gen_loss 0.948741, disc_loss 1.141023\n",
      "batch 198, gen_loss 0.921584, disc_loss 1.139927\n",
      "batch 199, gen_loss 0.925028, disc_loss 1.223666\n",
      "batch 200, gen_loss 0.941772, disc_loss 1.206009\n",
      "batch 201, gen_loss 0.937323, disc_loss 1.213829\n",
      "batch 202, gen_loss 0.921599, disc_loss 1.141152\n",
      "batch 203, gen_loss 0.935541, disc_loss 1.167340\n",
      "batch 204, gen_loss 0.936788, disc_loss 1.224087\n",
      "batch 205, gen_loss 0.832202, disc_loss 1.233789\n",
      "batch 206, gen_loss 0.901801, disc_loss 1.198706\n",
      "batch 207, gen_loss 0.911264, disc_loss 1.192816\n",
      "batch 208, gen_loss 0.909954, disc_loss 1.233822\n",
      "batch 209, gen_loss 0.918934, disc_loss 1.215892\n",
      "batch 210, gen_loss 0.928986, disc_loss 1.212600\n",
      "batch 211, gen_loss 0.925863, disc_loss 1.199581\n",
      "batch 212, gen_loss 0.895490, disc_loss 1.198388\n",
      "batch 213, gen_loss 0.915438, disc_loss 1.218928\n",
      "batch 214, gen_loss 0.875442, disc_loss 1.207485\n",
      "batch 215, gen_loss 0.880408, disc_loss 1.213525\n",
      "batch 216, gen_loss 0.866031, disc_loss 1.200436\n",
      "batch 217, gen_loss 0.876396, disc_loss 1.231734\n",
      "batch 218, gen_loss 0.878736, disc_loss 1.230542\n",
      "batch 219, gen_loss 0.914856, disc_loss 1.200826\n",
      "batch 220, gen_loss 0.912597, disc_loss 1.232892\n",
      "batch 221, gen_loss 0.918351, disc_loss 1.177384\n",
      "batch 222, gen_loss 0.900936, disc_loss 1.260128\n",
      "batch 223, gen_loss 0.898047, disc_loss 1.200837\n",
      "batch 224, gen_loss 0.861123, disc_loss 1.190343\n",
      "batch 225, gen_loss 0.886482, disc_loss 1.226728\n",
      "batch 226, gen_loss 0.888800, disc_loss 1.247806\n",
      "batch 227, gen_loss 0.878853, disc_loss 1.166643\n",
      "batch 228, gen_loss 0.886342, disc_loss 1.153371\n",
      "batch 229, gen_loss 0.883607, disc_loss 1.233872\n",
      "batch 230, gen_loss 0.921758, disc_loss 1.160872\n",
      "batch 231, gen_loss 0.904197, disc_loss 1.230029\n",
      "batch 232, gen_loss 0.933604, disc_loss 1.186194\n",
      "batch 233, gen_loss 0.971230, disc_loss 1.163119\n",
      "batch 234, gen_loss 0.973211, disc_loss 1.284389\n",
      "Time for epoch10is 7.483142614364624 sec\n",
      "batch 0, gen_loss 0.950395, disc_loss 1.199683\n",
      "batch 1, gen_loss 0.963759, disc_loss 1.132776\n",
      "batch 2, gen_loss 0.944687, disc_loss 1.148928\n",
      "batch 3, gen_loss 0.960894, disc_loss 1.205165\n",
      "batch 4, gen_loss 0.929303, disc_loss 1.201204\n",
      "batch 5, gen_loss 1.007142, disc_loss 1.185567\n",
      "batch 6, gen_loss 1.013347, disc_loss 1.190942\n",
      "batch 7, gen_loss 1.030376, disc_loss 1.139796\n",
      "batch 8, gen_loss 1.013761, disc_loss 1.161858\n",
      "batch 9, gen_loss 1.004033, disc_loss 1.187100\n",
      "batch 10, gen_loss 1.047924, disc_loss 1.155910\n",
      "batch 11, gen_loss 1.013888, disc_loss 1.193448\n",
      "batch 12, gen_loss 1.021074, disc_loss 1.122113\n",
      "batch 13, gen_loss 1.029647, disc_loss 1.195731\n",
      "batch 14, gen_loss 1.028240, disc_loss 1.163295\n",
      "batch 15, gen_loss 0.999106, disc_loss 1.204913\n",
      "batch 16, gen_loss 1.008828, disc_loss 1.162784\n",
      "batch 17, gen_loss 1.052435, disc_loss 1.203395\n",
      "batch 18, gen_loss 1.059549, disc_loss 1.162204\n",
      "batch 19, gen_loss 1.039998, disc_loss 1.215245\n",
      "batch 20, gen_loss 1.019293, disc_loss 1.159547\n",
      "batch 21, gen_loss 1.029238, disc_loss 1.183115\n",
      "batch 22, gen_loss 1.073159, disc_loss 1.208376\n",
      "batch 23, gen_loss 1.087795, disc_loss 1.256946\n",
      "batch 24, gen_loss 1.029801, disc_loss 1.244258\n",
      "batch 25, gen_loss 1.071369, disc_loss 1.233689\n",
      "batch 26, gen_loss 0.986025, disc_loss 1.240884\n",
      "batch 27, gen_loss 0.983838, disc_loss 1.289523\n",
      "batch 28, gen_loss 0.951650, disc_loss 1.227032\n",
      "batch 29, gen_loss 0.962472, disc_loss 1.194487\n",
      "batch 30, gen_loss 0.965355, disc_loss 1.278967\n",
      "batch 31, gen_loss 0.988830, disc_loss 1.356214\n",
      "batch 32, gen_loss 0.952277, disc_loss 1.263128\n",
      "batch 33, gen_loss 0.987564, disc_loss 1.254119\n",
      "batch 34, gen_loss 1.005824, disc_loss 1.339086\n",
      "batch 35, gen_loss 0.954568, disc_loss 1.425598\n",
      "batch 36, gen_loss 0.963831, disc_loss 1.273530\n",
      "batch 37, gen_loss 0.931360, disc_loss 1.330847\n",
      "batch 38, gen_loss 0.925161, disc_loss 1.342677\n",
      "batch 39, gen_loss 0.917770, disc_loss 1.304832\n",
      "batch 40, gen_loss 0.874796, disc_loss 1.338197\n",
      "batch 41, gen_loss 0.884159, disc_loss 1.341655\n",
      "batch 42, gen_loss 0.862029, disc_loss 1.419270\n",
      "batch 43, gen_loss 0.866897, disc_loss 1.306537\n",
      "batch 44, gen_loss 0.832091, disc_loss 1.346264\n",
      "batch 45, gen_loss 0.836710, disc_loss 1.401069\n",
      "batch 46, gen_loss 0.870678, disc_loss 1.385842\n",
      "batch 47, gen_loss 0.880237, disc_loss 1.319818\n",
      "batch 48, gen_loss 0.876257, disc_loss 1.308925\n",
      "batch 49, gen_loss 0.882111, disc_loss 1.357011\n",
      "batch 50, gen_loss 0.841984, disc_loss 1.355316\n",
      "batch 51, gen_loss 0.864344, disc_loss 1.363944\n",
      "batch 52, gen_loss 0.911578, disc_loss 1.372393\n",
      "batch 53, gen_loss 0.878604, disc_loss 1.267272\n",
      "batch 54, gen_loss 0.899258, disc_loss 1.404270\n",
      "batch 55, gen_loss 0.895128, disc_loss 1.345278\n",
      "batch 56, gen_loss 0.894052, disc_loss 1.307365\n",
      "batch 57, gen_loss 0.869651, disc_loss 1.316104\n",
      "batch 58, gen_loss 0.852851, disc_loss 1.347743\n",
      "batch 59, gen_loss 0.843796, disc_loss 1.337543\n",
      "batch 60, gen_loss 0.862018, disc_loss 1.344104\n",
      "batch 61, gen_loss 0.826719, disc_loss 1.319795\n",
      "batch 62, gen_loss 0.835713, disc_loss 1.342302\n",
      "batch 63, gen_loss 0.820410, disc_loss 1.289428\n",
      "batch 64, gen_loss 0.858204, disc_loss 1.282080\n",
      "batch 65, gen_loss 0.878284, disc_loss 1.295342\n",
      "batch 66, gen_loss 0.854514, disc_loss 1.300307\n",
      "batch 67, gen_loss 0.845247, disc_loss 1.315803\n",
      "batch 68, gen_loss 0.840333, disc_loss 1.276165\n",
      "batch 69, gen_loss 0.868146, disc_loss 1.236275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 70, gen_loss 0.834831, disc_loss 1.343467\n",
      "batch 71, gen_loss 0.846229, disc_loss 1.253455\n",
      "batch 72, gen_loss 0.849528, disc_loss 1.293105\n",
      "batch 73, gen_loss 0.848886, disc_loss 1.295573\n",
      "batch 74, gen_loss 0.845080, disc_loss 1.321161\n",
      "batch 75, gen_loss 0.839137, disc_loss 1.319376\n",
      "batch 76, gen_loss 0.851516, disc_loss 1.297832\n",
      "batch 77, gen_loss 0.837584, disc_loss 1.294483\n",
      "batch 78, gen_loss 0.822818, disc_loss 1.290583\n",
      "batch 79, gen_loss 0.824225, disc_loss 1.330554\n",
      "batch 80, gen_loss 0.834971, disc_loss 1.320791\n",
      "batch 81, gen_loss 0.811894, disc_loss 1.358621\n",
      "batch 82, gen_loss 0.805492, disc_loss 1.325562\n",
      "batch 83, gen_loss 0.817154, disc_loss 1.323121\n",
      "batch 84, gen_loss 0.800193, disc_loss 1.348005\n",
      "batch 85, gen_loss 0.810385, disc_loss 1.315757\n",
      "batch 86, gen_loss 0.818538, disc_loss 1.363790\n",
      "batch 87, gen_loss 0.861627, disc_loss 1.310974\n",
      "batch 88, gen_loss 0.836310, disc_loss 1.269483\n",
      "batch 89, gen_loss 0.894755, disc_loss 1.238176\n",
      "batch 90, gen_loss 0.873696, disc_loss 1.274597\n",
      "batch 91, gen_loss 0.917737, disc_loss 1.175627\n",
      "batch 92, gen_loss 0.928142, disc_loss 1.207707\n",
      "batch 93, gen_loss 0.930423, disc_loss 1.219898\n",
      "batch 94, gen_loss 0.916144, disc_loss 1.255692\n",
      "batch 95, gen_loss 0.957115, disc_loss 1.134700\n",
      "batch 96, gen_loss 0.956373, disc_loss 1.147446\n",
      "batch 97, gen_loss 0.971573, disc_loss 1.116117\n",
      "batch 98, gen_loss 0.985574, disc_loss 1.087224\n",
      "batch 99, gen_loss 1.009856, disc_loss 1.111315\n",
      "batch 100, gen_loss 1.033755, disc_loss 1.035021\n",
      "batch 101, gen_loss 1.041268, disc_loss 1.006752\n",
      "batch 102, gen_loss 1.059708, disc_loss 1.017502\n",
      "batch 103, gen_loss 1.098542, disc_loss 0.959247\n",
      "batch 104, gen_loss 1.091916, disc_loss 0.956070\n",
      "batch 105, gen_loss 1.116632, disc_loss 0.871704\n",
      "batch 106, gen_loss 1.141800, disc_loss 0.922256\n",
      "batch 107, gen_loss 1.176890, disc_loss 0.878363\n",
      "batch 108, gen_loss 1.202645, disc_loss 0.875738\n",
      "batch 109, gen_loss 1.237386, disc_loss 0.873631\n",
      "batch 110, gen_loss 1.235235, disc_loss 0.820278\n",
      "batch 111, gen_loss 1.293824, disc_loss 0.813915\n",
      "batch 112, gen_loss 1.283077, disc_loss 0.807413\n",
      "batch 113, gen_loss 1.275524, disc_loss 0.807225\n",
      "batch 114, gen_loss 1.307544, disc_loss 0.776226\n",
      "batch 115, gen_loss 1.320844, disc_loss 0.777209\n",
      "batch 116, gen_loss 1.350436, disc_loss 0.774714\n",
      "batch 117, gen_loss 1.376691, disc_loss 0.757224\n",
      "batch 118, gen_loss 1.348209, disc_loss 0.776378\n",
      "batch 119, gen_loss 1.324576, disc_loss 0.747925\n",
      "batch 120, gen_loss 1.320215, disc_loss 0.773294\n",
      "batch 121, gen_loss 1.346126, disc_loss 0.757056\n",
      "batch 122, gen_loss 1.319094, disc_loss 0.778595\n",
      "batch 123, gen_loss 1.335361, disc_loss 0.749435\n",
      "batch 124, gen_loss 1.316149, disc_loss 0.742952\n",
      "batch 125, gen_loss 1.282928, disc_loss 0.821158\n",
      "batch 126, gen_loss 1.292926, disc_loss 0.774275\n",
      "batch 127, gen_loss 1.271447, disc_loss 0.796252\n",
      "batch 128, gen_loss 1.302297, disc_loss 0.817737\n",
      "batch 129, gen_loss 1.313721, disc_loss 0.772301\n",
      "batch 130, gen_loss 1.242160, disc_loss 0.802323\n",
      "batch 131, gen_loss 1.249262, disc_loss 0.864888\n",
      "batch 132, gen_loss 1.203789, disc_loss 0.790448\n",
      "batch 133, gen_loss 1.170649, disc_loss 0.852570\n",
      "batch 134, gen_loss 1.198187, disc_loss 0.816891\n",
      "batch 135, gen_loss 1.184700, disc_loss 0.861486\n",
      "batch 136, gen_loss 1.144595, disc_loss 0.827188\n",
      "batch 137, gen_loss 1.218098, disc_loss 0.796596\n",
      "batch 138, gen_loss 1.167420, disc_loss 0.930742\n",
      "batch 139, gen_loss 1.186011, disc_loss 0.913883\n",
      "batch 140, gen_loss 1.200675, disc_loss 0.933090\n",
      "batch 141, gen_loss 1.207079, disc_loss 0.931145\n",
      "batch 142, gen_loss 1.160478, disc_loss 0.970317\n",
      "batch 143, gen_loss 1.180576, disc_loss 0.931940\n",
      "batch 144, gen_loss 1.156578, disc_loss 0.990422\n",
      "batch 145, gen_loss 1.163982, disc_loss 0.980144\n",
      "batch 146, gen_loss 1.152905, disc_loss 0.949690\n",
      "batch 147, gen_loss 1.112465, disc_loss 1.003952\n",
      "batch 148, gen_loss 1.088571, disc_loss 1.061085\n",
      "batch 149, gen_loss 1.115280, disc_loss 1.067164\n",
      "batch 150, gen_loss 1.104817, disc_loss 1.054830\n",
      "batch 151, gen_loss 1.035958, disc_loss 1.138933\n",
      "batch 152, gen_loss 1.053776, disc_loss 1.113350\n",
      "batch 153, gen_loss 1.078923, disc_loss 1.112903\n",
      "batch 154, gen_loss 1.105190, disc_loss 1.074121\n",
      "batch 155, gen_loss 1.086566, disc_loss 1.139156\n",
      "batch 156, gen_loss 1.064677, disc_loss 1.112951\n",
      "batch 157, gen_loss 1.014678, disc_loss 1.152860\n",
      "batch 158, gen_loss 1.044857, disc_loss 1.203439\n",
      "batch 159, gen_loss 1.005604, disc_loss 1.132852\n",
      "batch 160, gen_loss 0.969301, disc_loss 1.117764\n",
      "batch 161, gen_loss 0.900605, disc_loss 1.273135\n",
      "batch 162, gen_loss 0.881019, disc_loss 1.299843\n",
      "batch 163, gen_loss 0.874353, disc_loss 1.204080\n",
      "batch 164, gen_loss 0.833198, disc_loss 1.223476\n",
      "batch 165, gen_loss 0.800241, disc_loss 1.330778\n",
      "batch 166, gen_loss 0.825563, disc_loss 1.287055\n",
      "batch 167, gen_loss 0.815267, disc_loss 1.288257\n",
      "batch 168, gen_loss 0.833507, disc_loss 1.291068\n",
      "batch 169, gen_loss 0.826682, disc_loss 1.335238\n",
      "batch 170, gen_loss 0.828689, disc_loss 1.381277\n",
      "batch 171, gen_loss 0.770203, disc_loss 1.369109\n",
      "batch 172, gen_loss 0.823317, disc_loss 1.381963\n",
      "batch 173, gen_loss 0.816411, disc_loss 1.363068\n",
      "batch 174, gen_loss 0.803060, disc_loss 1.386928\n",
      "batch 175, gen_loss 0.776379, disc_loss 1.473773\n",
      "batch 176, gen_loss 0.780190, disc_loss 1.530040\n",
      "batch 177, gen_loss 0.769129, disc_loss 1.493106\n",
      "batch 178, gen_loss 0.754380, disc_loss 1.581980\n",
      "batch 179, gen_loss 0.733032, disc_loss 1.460441\n",
      "batch 180, gen_loss 0.736014, disc_loss 1.529341\n",
      "batch 181, gen_loss 0.794611, disc_loss 1.545587\n",
      "batch 182, gen_loss 0.760371, disc_loss 1.593629\n",
      "batch 183, gen_loss 0.781794, disc_loss 1.642221\n",
      "batch 184, gen_loss 0.784066, disc_loss 1.607749\n",
      "batch 185, gen_loss 0.826976, disc_loss 1.654532\n",
      "batch 186, gen_loss 0.863019, disc_loss 1.581747\n",
      "batch 187, gen_loss 0.849824, disc_loss 1.516544\n",
      "batch 188, gen_loss 0.850503, disc_loss 1.475831\n",
      "batch 189, gen_loss 0.861413, disc_loss 1.625101\n",
      "batch 190, gen_loss 0.899837, disc_loss 1.550397\n",
      "batch 191, gen_loss 0.887024, disc_loss 1.632262\n",
      "batch 192, gen_loss 0.936134, disc_loss 1.559367\n",
      "batch 193, gen_loss 0.876771, disc_loss 1.511367\n",
      "batch 194, gen_loss 0.897001, disc_loss 1.483260\n",
      "batch 195, gen_loss 0.959500, disc_loss 1.346170\n",
      "batch 196, gen_loss 0.982104, disc_loss 1.362591\n",
      "batch 197, gen_loss 0.999305, disc_loss 1.365419\n",
      "batch 198, gen_loss 0.998774, disc_loss 1.264818\n",
      "batch 199, gen_loss 1.061724, disc_loss 1.180936\n",
      "batch 200, gen_loss 1.006577, disc_loss 1.200240\n",
      "batch 201, gen_loss 1.025898, disc_loss 1.222885\n",
      "batch 202, gen_loss 1.111833, disc_loss 1.073407\n",
      "batch 203, gen_loss 1.146655, disc_loss 1.063174\n",
      "batch 204, gen_loss 1.115403, disc_loss 1.054019\n",
      "batch 205, gen_loss 1.157052, disc_loss 0.987121\n",
      "batch 206, gen_loss 1.194082, disc_loss 0.965048\n",
      "batch 207, gen_loss 1.232900, disc_loss 0.939274\n",
      "batch 208, gen_loss 1.206587, disc_loss 0.971776\n",
      "batch 209, gen_loss 1.262701, disc_loss 0.921461\n",
      "batch 210, gen_loss 1.307099, disc_loss 0.804346\n",
      "batch 211, gen_loss 1.284582, disc_loss 0.941656\n",
      "batch 212, gen_loss 1.301661, disc_loss 0.941351\n",
      "batch 213, gen_loss 1.264962, disc_loss 0.860287\n",
      "batch 214, gen_loss 1.244040, disc_loss 0.900751\n",
      "batch 215, gen_loss 1.205695, disc_loss 0.859135\n",
      "batch 216, gen_loss 1.240206, disc_loss 0.850300\n",
      "batch 217, gen_loss 1.231918, disc_loss 0.909636\n",
      "batch 218, gen_loss 1.267636, disc_loss 0.906102\n",
      "batch 219, gen_loss 1.220018, disc_loss 0.869902\n",
      "batch 220, gen_loss 1.265673, disc_loss 0.903280\n",
      "batch 221, gen_loss 1.297959, disc_loss 0.864093\n",
      "batch 222, gen_loss 1.258140, disc_loss 0.893368\n",
      "batch 223, gen_loss 1.181206, disc_loss 0.956820\n",
      "batch 224, gen_loss 1.205498, disc_loss 0.862533\n",
      "batch 225, gen_loss 1.272883, disc_loss 0.896052\n",
      "batch 226, gen_loss 1.270434, disc_loss 0.968453\n",
      "batch 227, gen_loss 1.208888, disc_loss 0.907651\n",
      "batch 228, gen_loss 1.207126, disc_loss 0.977879\n",
      "batch 229, gen_loss 1.185763, disc_loss 0.980603\n",
      "batch 230, gen_loss 1.143584, disc_loss 0.934725\n",
      "batch 231, gen_loss 1.149062, disc_loss 0.964925\n",
      "batch 232, gen_loss 1.113759, disc_loss 1.018593\n",
      "batch 233, gen_loss 1.099713, disc_loss 0.965357\n",
      "batch 234, gen_loss 1.081602, disc_loss 0.985645\n",
      "Time for epoch11is 7.498922824859619 sec\n",
      "batch 0, gen_loss 1.119675, disc_loss 0.959361\n",
      "batch 1, gen_loss 1.123861, disc_loss 1.006243\n",
      "batch 2, gen_loss 1.103763, disc_loss 1.033969\n",
      "batch 3, gen_loss 1.061114, disc_loss 0.996591\n",
      "batch 4, gen_loss 1.155402, disc_loss 1.041823\n",
      "batch 5, gen_loss 1.106497, disc_loss 1.024476\n",
      "batch 6, gen_loss 1.086661, disc_loss 1.020156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 7, gen_loss 1.027970, disc_loss 1.089208\n",
      "batch 8, gen_loss 1.019162, disc_loss 1.002986\n",
      "batch 9, gen_loss 1.015030, disc_loss 1.091826\n",
      "batch 10, gen_loss 1.004354, disc_loss 1.119779\n",
      "batch 11, gen_loss 1.044177, disc_loss 1.119809\n",
      "batch 12, gen_loss 0.989762, disc_loss 1.103877\n",
      "batch 13, gen_loss 1.004578, disc_loss 1.109686\n",
      "batch 14, gen_loss 0.943235, disc_loss 1.130026\n",
      "batch 15, gen_loss 0.935043, disc_loss 1.179228\n",
      "batch 16, gen_loss 0.943323, disc_loss 1.148976\n",
      "batch 17, gen_loss 0.984920, disc_loss 1.191445\n",
      "batch 18, gen_loss 0.948049, disc_loss 1.192547\n",
      "batch 19, gen_loss 0.959202, disc_loss 1.164872\n",
      "batch 20, gen_loss 0.942893, disc_loss 1.270298\n",
      "batch 21, gen_loss 0.911040, disc_loss 1.205078\n",
      "batch 22, gen_loss 0.924773, disc_loss 1.241055\n",
      "batch 23, gen_loss 0.961671, disc_loss 1.227915\n",
      "batch 24, gen_loss 0.938885, disc_loss 1.297727\n",
      "batch 25, gen_loss 0.949446, disc_loss 1.264143\n",
      "batch 26, gen_loss 0.971465, disc_loss 1.206584\n",
      "batch 27, gen_loss 0.989331, disc_loss 1.232214\n",
      "batch 28, gen_loss 0.973215, disc_loss 1.282832\n",
      "batch 29, gen_loss 0.979533, disc_loss 1.133441\n",
      "batch 30, gen_loss 1.003434, disc_loss 1.230965\n",
      "batch 31, gen_loss 1.003784, disc_loss 1.215635\n",
      "batch 32, gen_loss 1.018646, disc_loss 1.137086\n",
      "batch 33, gen_loss 1.051821, disc_loss 1.140060\n",
      "batch 34, gen_loss 1.039647, disc_loss 1.133025\n",
      "batch 35, gen_loss 1.097668, disc_loss 1.032691\n",
      "batch 36, gen_loss 1.137445, disc_loss 1.102839\n",
      "batch 37, gen_loss 1.169681, disc_loss 1.051606\n",
      "batch 38, gen_loss 1.181685, disc_loss 1.065663\n",
      "batch 39, gen_loss 1.126593, disc_loss 1.078109\n",
      "batch 40, gen_loss 1.102728, disc_loss 1.037584\n",
      "batch 41, gen_loss 1.082102, disc_loss 1.007319\n",
      "batch 42, gen_loss 1.104958, disc_loss 1.031417\n",
      "batch 43, gen_loss 1.201369, disc_loss 0.977474\n",
      "batch 44, gen_loss 1.124745, disc_loss 0.970805\n",
      "batch 45, gen_loss 1.157751, disc_loss 0.985413\n",
      "batch 46, gen_loss 1.207463, disc_loss 0.998903\n",
      "batch 47, gen_loss 1.202826, disc_loss 1.035048\n",
      "batch 48, gen_loss 1.245656, disc_loss 1.014165\n",
      "batch 49, gen_loss 1.174683, disc_loss 0.987036\n",
      "batch 50, gen_loss 1.126428, disc_loss 1.076788\n",
      "batch 51, gen_loss 1.104983, disc_loss 1.012628\n",
      "batch 52, gen_loss 1.025169, disc_loss 1.112230\n",
      "batch 53, gen_loss 1.012293, disc_loss 1.053046\n",
      "batch 54, gen_loss 1.038146, disc_loss 1.117440\n",
      "batch 55, gen_loss 1.068421, disc_loss 1.104429\n",
      "batch 56, gen_loss 1.014098, disc_loss 1.141903\n",
      "batch 57, gen_loss 1.056776, disc_loss 1.209743\n",
      "batch 58, gen_loss 0.995161, disc_loss 1.226399\n",
      "batch 59, gen_loss 0.948741, disc_loss 1.287877\n",
      "batch 60, gen_loss 0.929181, disc_loss 1.201004\n",
      "batch 61, gen_loss 0.885532, disc_loss 1.257110\n",
      "batch 62, gen_loss 0.845823, disc_loss 1.297480\n",
      "batch 63, gen_loss 0.847042, disc_loss 1.263094\n",
      "batch 64, gen_loss 0.847311, disc_loss 1.400589\n",
      "batch 65, gen_loss 0.903109, disc_loss 1.321978\n",
      "batch 66, gen_loss 0.865142, disc_loss 1.271998\n",
      "batch 67, gen_loss 0.875461, disc_loss 1.253590\n",
      "batch 68, gen_loss 0.861108, disc_loss 1.347078\n",
      "batch 69, gen_loss 0.898701, disc_loss 1.278697\n",
      "batch 70, gen_loss 0.882955, disc_loss 1.359306\n",
      "batch 71, gen_loss 0.863336, disc_loss 1.355333\n",
      "batch 72, gen_loss 0.883900, disc_loss 1.290310\n",
      "batch 73, gen_loss 0.919468, disc_loss 1.276197\n",
      "batch 74, gen_loss 0.882098, disc_loss 1.300052\n",
      "batch 75, gen_loss 0.928835, disc_loss 1.287700\n",
      "batch 76, gen_loss 0.982335, disc_loss 1.260153\n",
      "batch 77, gen_loss 0.922831, disc_loss 1.357867\n",
      "batch 78, gen_loss 0.933112, disc_loss 1.268233\n",
      "batch 79, gen_loss 0.986210, disc_loss 1.237534\n",
      "batch 80, gen_loss 0.988343, disc_loss 1.283343\n",
      "batch 81, gen_loss 1.016720, disc_loss 1.217116\n",
      "batch 82, gen_loss 1.045899, disc_loss 1.205525\n",
      "batch 83, gen_loss 1.053692, disc_loss 1.187053\n",
      "batch 84, gen_loss 1.083410, disc_loss 1.224548\n",
      "batch 85, gen_loss 1.113579, disc_loss 1.146448\n",
      "batch 86, gen_loss 1.108577, disc_loss 1.180009\n",
      "batch 87, gen_loss 1.119361, disc_loss 1.181964\n",
      "batch 88, gen_loss 1.121664, disc_loss 1.091381\n",
      "batch 89, gen_loss 1.111829, disc_loss 1.132308\n",
      "batch 90, gen_loss 1.107465, disc_loss 1.096120\n",
      "batch 91, gen_loss 1.072170, disc_loss 1.127194\n",
      "batch 92, gen_loss 1.132464, disc_loss 1.089432\n",
      "batch 93, gen_loss 1.148460, disc_loss 1.009907\n",
      "batch 94, gen_loss 1.118899, disc_loss 1.063431\n",
      "batch 95, gen_loss 1.161701, disc_loss 1.021510\n",
      "batch 96, gen_loss 1.204367, disc_loss 1.010151\n",
      "batch 97, gen_loss 1.224282, disc_loss 1.081713\n",
      "batch 98, gen_loss 1.179556, disc_loss 1.013901\n",
      "batch 99, gen_loss 1.187202, disc_loss 1.053884\n",
      "batch 100, gen_loss 1.217318, disc_loss 1.066388\n",
      "batch 101, gen_loss 1.162011, disc_loss 1.005719\n",
      "batch 102, gen_loss 1.211581, disc_loss 1.030744\n",
      "batch 103, gen_loss 1.171951, disc_loss 1.028049\n",
      "batch 104, gen_loss 1.211864, disc_loss 0.952461\n",
      "batch 105, gen_loss 1.169550, disc_loss 0.989411\n",
      "batch 106, gen_loss 1.192981, disc_loss 0.979587\n",
      "batch 107, gen_loss 1.192765, disc_loss 0.943499\n",
      "batch 108, gen_loss 1.231439, disc_loss 0.996364\n",
      "batch 109, gen_loss 1.244902, disc_loss 0.910661\n",
      "batch 110, gen_loss 1.196213, disc_loss 1.007780\n",
      "batch 111, gen_loss 1.236991, disc_loss 0.971656\n",
      "batch 112, gen_loss 1.195880, disc_loss 1.020404\n",
      "batch 113, gen_loss 1.188984, disc_loss 0.983828\n",
      "batch 114, gen_loss 1.215016, disc_loss 0.967581\n",
      "batch 115, gen_loss 1.179708, disc_loss 0.975578\n",
      "batch 116, gen_loss 1.154017, disc_loss 0.956657\n",
      "batch 117, gen_loss 1.188787, disc_loss 0.989549\n",
      "batch 118, gen_loss 1.157483, disc_loss 0.971204\n",
      "batch 119, gen_loss 1.133307, disc_loss 0.934989\n",
      "batch 120, gen_loss 1.132415, disc_loss 0.986672\n",
      "batch 121, gen_loss 1.130178, disc_loss 1.007661\n",
      "batch 122, gen_loss 1.157258, disc_loss 1.009114\n",
      "batch 123, gen_loss 1.171647, disc_loss 0.962302\n",
      "batch 124, gen_loss 1.156729, disc_loss 0.965484\n",
      "batch 125, gen_loss 1.155880, disc_loss 0.966716\n",
      "batch 126, gen_loss 1.149651, disc_loss 0.948222\n",
      "batch 127, gen_loss 1.113532, disc_loss 0.974167\n",
      "batch 128, gen_loss 1.158120, disc_loss 0.971311\n",
      "batch 129, gen_loss 1.170083, disc_loss 1.013512\n",
      "batch 130, gen_loss 1.145428, disc_loss 1.000730\n",
      "batch 131, gen_loss 1.137297, disc_loss 0.942382\n",
      "batch 132, gen_loss 1.119930, disc_loss 0.983234\n",
      "batch 133, gen_loss 1.116284, disc_loss 0.981039\n",
      "batch 134, gen_loss 1.087077, disc_loss 0.975664\n",
      "batch 135, gen_loss 1.101443, disc_loss 0.998647\n",
      "batch 136, gen_loss 1.116237, disc_loss 1.006360\n",
      "batch 137, gen_loss 1.134740, disc_loss 1.003698\n",
      "batch 138, gen_loss 1.140148, disc_loss 0.989006\n",
      "batch 139, gen_loss 1.131757, disc_loss 0.997587\n",
      "batch 140, gen_loss 1.191964, disc_loss 1.006600\n",
      "batch 141, gen_loss 1.154599, disc_loss 1.008520\n",
      "batch 142, gen_loss 1.215300, disc_loss 0.999432\n",
      "batch 143, gen_loss 1.181365, disc_loss 0.997772\n",
      "batch 144, gen_loss 1.151640, disc_loss 0.981715\n",
      "batch 145, gen_loss 1.162837, disc_loss 0.986513\n",
      "batch 146, gen_loss 1.130672, disc_loss 0.990336\n",
      "batch 147, gen_loss 1.133312, disc_loss 1.045087\n",
      "batch 148, gen_loss 1.149266, disc_loss 1.057137\n",
      "batch 149, gen_loss 1.115250, disc_loss 1.025687\n",
      "batch 150, gen_loss 1.141773, disc_loss 1.006344\n",
      "batch 151, gen_loss 1.136522, disc_loss 0.971364\n",
      "batch 152, gen_loss 1.130041, disc_loss 1.015093\n",
      "batch 153, gen_loss 1.137435, disc_loss 1.032443\n",
      "batch 154, gen_loss 1.142623, disc_loss 1.074266\n",
      "batch 155, gen_loss 1.177050, disc_loss 1.011216\n",
      "batch 156, gen_loss 1.165212, disc_loss 1.052264\n",
      "batch 157, gen_loss 1.116750, disc_loss 1.075721\n",
      "batch 158, gen_loss 1.070621, disc_loss 1.031272\n",
      "batch 159, gen_loss 1.071672, disc_loss 1.026329\n",
      "batch 160, gen_loss 1.074854, disc_loss 1.035981\n",
      "batch 161, gen_loss 1.024353, disc_loss 1.098723\n",
      "batch 162, gen_loss 1.043057, disc_loss 1.076179\n",
      "batch 163, gen_loss 1.011196, disc_loss 1.086139\n",
      "batch 164, gen_loss 1.057040, disc_loss 1.101395\n",
      "batch 165, gen_loss 1.101009, disc_loss 1.069913\n",
      "batch 166, gen_loss 1.055616, disc_loss 1.133159\n",
      "batch 167, gen_loss 1.078045, disc_loss 1.189620\n",
      "batch 168, gen_loss 1.013098, disc_loss 1.187301\n",
      "batch 169, gen_loss 0.967365, disc_loss 1.160870\n",
      "batch 170, gen_loss 0.942337, disc_loss 1.233635\n",
      "batch 171, gen_loss 0.891745, disc_loss 1.322666\n",
      "batch 172, gen_loss 0.875794, disc_loss 1.354093\n",
      "batch 173, gen_loss 0.896483, disc_loss 1.344616\n",
      "batch 174, gen_loss 0.875368, disc_loss 1.382324\n",
      "batch 175, gen_loss 0.925965, disc_loss 1.338410\n",
      "batch 176, gen_loss 0.897129, disc_loss 1.474470\n",
      "batch 177, gen_loss 0.903863, disc_loss 1.404709\n",
      "batch 178, gen_loss 0.905299, disc_loss 1.512900\n",
      "batch 179, gen_loss 0.894151, disc_loss 1.436655\n",
      "batch 180, gen_loss 0.934263, disc_loss 1.447434\n",
      "batch 181, gen_loss 0.922649, disc_loss 1.391451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 182, gen_loss 0.899238, disc_loss 1.490325\n",
      "batch 183, gen_loss 0.979770, disc_loss 1.417559\n",
      "batch 184, gen_loss 0.985026, disc_loss 1.388412\n",
      "batch 185, gen_loss 0.979915, disc_loss 1.353887\n",
      "batch 186, gen_loss 1.039434, disc_loss 1.357293\n",
      "batch 187, gen_loss 1.053824, disc_loss 1.253016\n",
      "batch 188, gen_loss 1.079989, disc_loss 1.264043\n",
      "batch 189, gen_loss 1.075142, disc_loss 1.194067\n",
      "batch 190, gen_loss 1.084162, disc_loss 1.247698\n",
      "batch 191, gen_loss 1.083896, disc_loss 1.201075\n",
      "batch 192, gen_loss 1.158949, disc_loss 1.165356\n",
      "batch 193, gen_loss 1.116642, disc_loss 1.059262\n",
      "batch 194, gen_loss 1.128865, disc_loss 1.084353\n",
      "batch 195, gen_loss 1.064244, disc_loss 1.095017\n",
      "batch 196, gen_loss 1.093372, disc_loss 1.045364\n",
      "batch 197, gen_loss 1.166162, disc_loss 0.968803\n",
      "batch 198, gen_loss 1.087731, disc_loss 1.064604\n",
      "batch 199, gen_loss 1.140714, disc_loss 0.950479\n",
      "batch 200, gen_loss 1.180762, disc_loss 0.951956\n",
      "batch 201, gen_loss 1.216661, disc_loss 0.948685\n",
      "batch 202, gen_loss 1.277980, disc_loss 0.948582\n",
      "batch 203, gen_loss 1.263579, disc_loss 0.959706\n",
      "batch 204, gen_loss 1.296971, disc_loss 0.902221\n",
      "batch 205, gen_loss 1.249391, disc_loss 0.904074\n",
      "batch 206, gen_loss 1.171012, disc_loss 0.946586\n",
      "batch 207, gen_loss 1.211891, disc_loss 0.927397\n",
      "batch 208, gen_loss 1.195931, disc_loss 0.914366\n",
      "batch 209, gen_loss 1.186030, disc_loss 0.914880\n",
      "batch 210, gen_loss 1.180099, disc_loss 0.897968\n",
      "batch 211, gen_loss 1.146845, disc_loss 0.896927\n",
      "batch 212, gen_loss 1.234714, disc_loss 0.836666\n",
      "batch 213, gen_loss 1.300774, disc_loss 0.857876\n",
      "batch 214, gen_loss 1.287991, disc_loss 0.825719\n",
      "batch 215, gen_loss 1.327404, disc_loss 0.849188\n",
      "batch 216, gen_loss 1.393034, disc_loss 0.947251\n",
      "batch 217, gen_loss 1.355855, disc_loss 0.848881\n",
      "batch 218, gen_loss 1.280703, disc_loss 0.930658\n",
      "batch 219, gen_loss 1.276098, disc_loss 0.820416\n",
      "batch 220, gen_loss 1.196339, disc_loss 0.970061\n",
      "batch 221, gen_loss 1.134662, disc_loss 0.985433\n",
      "batch 222, gen_loss 1.171207, disc_loss 0.942441\n",
      "batch 223, gen_loss 1.238798, disc_loss 0.909159\n",
      "batch 224, gen_loss 1.283851, disc_loss 0.982580\n",
      "batch 225, gen_loss 1.332725, disc_loss 0.893745\n",
      "batch 226, gen_loss 1.353542, disc_loss 0.898288\n",
      "batch 227, gen_loss 1.350508, disc_loss 0.902862\n",
      "batch 228, gen_loss 1.373322, disc_loss 0.894693\n",
      "batch 229, gen_loss 1.300738, disc_loss 0.941130\n",
      "batch 230, gen_loss 1.337736, disc_loss 0.968510\n",
      "batch 231, gen_loss 1.269454, disc_loss 0.934734\n",
      "batch 232, gen_loss 1.309114, disc_loss 0.894305\n",
      "batch 233, gen_loss 1.310698, disc_loss 0.955222\n",
      "batch 234, gen_loss 1.336513, disc_loss 0.930970\n",
      "Time for epoch12is 7.519573450088501 sec\n",
      "batch 0, gen_loss 1.330744, disc_loss 0.950767\n",
      "batch 1, gen_loss 1.355841, disc_loss 0.953045\n",
      "batch 2, gen_loss 1.363469, disc_loss 1.023185\n",
      "batch 3, gen_loss 1.313572, disc_loss 0.960118\n",
      "batch 4, gen_loss 1.266928, disc_loss 1.020317\n",
      "batch 5, gen_loss 1.242222, disc_loss 1.050377\n",
      "batch 6, gen_loss 1.226451, disc_loss 1.053729\n",
      "batch 7, gen_loss 1.232597, disc_loss 1.028357\n",
      "batch 8, gen_loss 1.209032, disc_loss 1.045546\n",
      "batch 9, gen_loss 1.228878, disc_loss 0.967347\n",
      "batch 10, gen_loss 1.265552, disc_loss 1.035844\n",
      "batch 11, gen_loss 1.250007, disc_loss 1.006621\n",
      "batch 12, gen_loss 1.301612, disc_loss 0.998334\n",
      "batch 13, gen_loss 1.343047, disc_loss 0.991565\n",
      "batch 14, gen_loss 1.400810, disc_loss 0.973541\n",
      "batch 15, gen_loss 1.249806, disc_loss 1.028598\n",
      "batch 16, gen_loss 1.231897, disc_loss 1.023683\n",
      "batch 17, gen_loss 1.235874, disc_loss 1.040596\n",
      "batch 18, gen_loss 1.184921, disc_loss 1.040648\n",
      "batch 19, gen_loss 1.192203, disc_loss 1.020392\n",
      "batch 20, gen_loss 1.151547, disc_loss 1.098481\n",
      "batch 21, gen_loss 1.163038, disc_loss 1.007113\n",
      "batch 22, gen_loss 1.154459, disc_loss 1.073908\n",
      "batch 23, gen_loss 1.177819, disc_loss 1.057292\n",
      "batch 24, gen_loss 1.263180, disc_loss 1.038146\n",
      "batch 25, gen_loss 1.234290, disc_loss 1.022471\n",
      "batch 26, gen_loss 1.208442, disc_loss 1.094350\n",
      "batch 27, gen_loss 1.163496, disc_loss 1.107288\n",
      "batch 28, gen_loss 1.141548, disc_loss 1.058079\n",
      "batch 29, gen_loss 1.193952, disc_loss 1.094928\n",
      "batch 30, gen_loss 1.184732, disc_loss 1.044721\n",
      "batch 31, gen_loss 1.144067, disc_loss 1.031762\n",
      "batch 32, gen_loss 1.097588, disc_loss 1.128150\n",
      "batch 33, gen_loss 1.111629, disc_loss 1.075352\n",
      "batch 34, gen_loss 1.169168, disc_loss 1.003598\n",
      "batch 35, gen_loss 1.174905, disc_loss 1.083486\n",
      "batch 36, gen_loss 1.210926, disc_loss 1.062528\n",
      "batch 37, gen_loss 1.184588, disc_loss 1.106691\n",
      "batch 38, gen_loss 1.177824, disc_loss 1.091893\n",
      "batch 39, gen_loss 1.139497, disc_loss 1.047047\n",
      "batch 40, gen_loss 1.110334, disc_loss 1.113039\n",
      "batch 41, gen_loss 1.110214, disc_loss 1.048684\n",
      "batch 42, gen_loss 1.068603, disc_loss 1.125515\n",
      "batch 43, gen_loss 1.105566, disc_loss 1.092438\n",
      "batch 44, gen_loss 1.114576, disc_loss 1.106776\n",
      "batch 45, gen_loss 1.068014, disc_loss 1.067052\n",
      "batch 46, gen_loss 1.128368, disc_loss 1.088589\n",
      "batch 47, gen_loss 1.100374, disc_loss 1.141011\n",
      "batch 48, gen_loss 1.128778, disc_loss 1.150695\n",
      "batch 49, gen_loss 1.097067, disc_loss 1.166967\n",
      "batch 50, gen_loss 1.107741, disc_loss 1.127264\n",
      "batch 51, gen_loss 1.082883, disc_loss 1.152515\n",
      "batch 52, gen_loss 1.048077, disc_loss 1.222672\n",
      "batch 53, gen_loss 1.040241, disc_loss 1.150931\n",
      "batch 54, gen_loss 1.026892, disc_loss 1.117647\n",
      "batch 55, gen_loss 0.994232, disc_loss 1.188223\n",
      "batch 56, gen_loss 0.995812, disc_loss 1.213437\n",
      "batch 57, gen_loss 0.971868, disc_loss 1.200698\n",
      "batch 58, gen_loss 0.994284, disc_loss 1.243217\n",
      "batch 59, gen_loss 0.976761, disc_loss 1.134514\n",
      "batch 60, gen_loss 0.942179, disc_loss 1.287759\n",
      "batch 61, gen_loss 0.985233, disc_loss 1.232283\n",
      "batch 62, gen_loss 0.983149, disc_loss 1.263178\n",
      "batch 63, gen_loss 1.002713, disc_loss 1.206199\n",
      "batch 64, gen_loss 0.958970, disc_loss 1.298722\n",
      "batch 65, gen_loss 0.986020, disc_loss 1.242349\n",
      "batch 66, gen_loss 0.979789, disc_loss 1.288498\n",
      "batch 67, gen_loss 0.961446, disc_loss 1.228668\n",
      "batch 68, gen_loss 0.935308, disc_loss 1.228434\n",
      "batch 69, gen_loss 0.923371, disc_loss 1.263478\n",
      "batch 70, gen_loss 0.883772, disc_loss 1.309213\n",
      "batch 71, gen_loss 0.908020, disc_loss 1.307920\n",
      "batch 72, gen_loss 0.920912, disc_loss 1.315017\n",
      "batch 73, gen_loss 0.926801, disc_loss 1.271099\n",
      "batch 74, gen_loss 0.911863, disc_loss 1.242784\n",
      "batch 75, gen_loss 0.931251, disc_loss 1.290074\n",
      "batch 76, gen_loss 0.931501, disc_loss 1.317720\n",
      "batch 77, gen_loss 0.929588, disc_loss 1.263481\n",
      "batch 78, gen_loss 0.910047, disc_loss 1.302363\n",
      "batch 79, gen_loss 0.922221, disc_loss 1.359784\n",
      "batch 80, gen_loss 0.908747, disc_loss 1.368906\n",
      "batch 81, gen_loss 0.895048, disc_loss 1.347660\n",
      "batch 82, gen_loss 0.870380, disc_loss 1.396036\n",
      "batch 83, gen_loss 0.829235, disc_loss 1.380986\n",
      "batch 84, gen_loss 0.826550, disc_loss 1.385612\n",
      "batch 85, gen_loss 0.804144, disc_loss 1.418301\n",
      "batch 86, gen_loss 0.817526, disc_loss 1.468036\n",
      "batch 87, gen_loss 0.814737, disc_loss 1.476785\n",
      "batch 88, gen_loss 0.813425, disc_loss 1.504501\n",
      "batch 89, gen_loss 0.825548, disc_loss 1.398039\n",
      "batch 90, gen_loss 0.796065, disc_loss 1.530947\n",
      "batch 91, gen_loss 0.803177, disc_loss 1.502164\n",
      "batch 92, gen_loss 0.844672, disc_loss 1.506589\n",
      "batch 93, gen_loss 0.845581, disc_loss 1.449641\n",
      "batch 94, gen_loss 0.867457, disc_loss 1.442680\n",
      "batch 95, gen_loss 0.853646, disc_loss 1.414997\n",
      "batch 96, gen_loss 0.877172, disc_loss 1.412812\n",
      "batch 97, gen_loss 0.884945, disc_loss 1.467055\n",
      "batch 98, gen_loss 0.871206, disc_loss 1.463118\n",
      "batch 99, gen_loss 0.921518, disc_loss 1.438829\n",
      "batch 100, gen_loss 0.871657, disc_loss 1.451166\n",
      "batch 101, gen_loss 0.861720, disc_loss 1.404644\n",
      "batch 102, gen_loss 0.892434, disc_loss 1.451550\n",
      "batch 103, gen_loss 0.878740, disc_loss 1.348172\n",
      "batch 104, gen_loss 0.885554, disc_loss 1.334707\n",
      "batch 105, gen_loss 0.871614, disc_loss 1.372192\n",
      "batch 106, gen_loss 0.908497, disc_loss 1.216415\n",
      "batch 107, gen_loss 0.909098, disc_loss 1.228981\n",
      "batch 108, gen_loss 0.936664, disc_loss 1.196779\n",
      "batch 109, gen_loss 0.936397, disc_loss 1.242470\n",
      "batch 110, gen_loss 1.010019, disc_loss 1.114492\n",
      "batch 111, gen_loss 1.010529, disc_loss 1.133018\n",
      "batch 112, gen_loss 1.025338, disc_loss 1.164697\n",
      "batch 113, gen_loss 1.019621, disc_loss 1.095931\n",
      "batch 114, gen_loss 1.025418, disc_loss 1.113363\n",
      "batch 115, gen_loss 1.038216, disc_loss 1.051246\n",
      "batch 116, gen_loss 1.081186, disc_loss 1.038085\n",
      "batch 117, gen_loss 1.083285, disc_loss 1.058074\n",
      "batch 118, gen_loss 1.082744, disc_loss 1.043815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 119, gen_loss 1.075938, disc_loss 0.990020\n",
      "batch 120, gen_loss 1.076029, disc_loss 0.986800\n",
      "batch 121, gen_loss 1.080725, disc_loss 0.982528\n",
      "batch 122, gen_loss 1.083221, disc_loss 0.987665\n",
      "batch 123, gen_loss 1.134743, disc_loss 0.952243\n",
      "batch 124, gen_loss 1.102740, disc_loss 0.946613\n",
      "batch 125, gen_loss 1.145133, disc_loss 0.904061\n",
      "batch 126, gen_loss 1.150661, disc_loss 0.914550\n",
      "batch 127, gen_loss 1.173855, disc_loss 0.872590\n",
      "batch 128, gen_loss 1.173089, disc_loss 0.895891\n",
      "batch 129, gen_loss 1.187350, disc_loss 0.882609\n",
      "batch 130, gen_loss 1.130084, disc_loss 0.883542\n",
      "batch 131, gen_loss 1.172971, disc_loss 0.814471\n",
      "batch 132, gen_loss 1.160503, disc_loss 0.823054\n",
      "batch 133, gen_loss 1.207390, disc_loss 0.846953\n",
      "batch 134, gen_loss 1.248263, disc_loss 0.807545\n",
      "batch 135, gen_loss 1.200394, disc_loss 0.839465\n",
      "batch 136, gen_loss 1.245302, disc_loss 0.832572\n",
      "batch 137, gen_loss 1.235084, disc_loss 0.817096\n",
      "batch 138, gen_loss 1.249182, disc_loss 0.835394\n",
      "batch 139, gen_loss 1.229445, disc_loss 0.829110\n",
      "batch 140, gen_loss 1.207337, disc_loss 0.779431\n",
      "batch 141, gen_loss 1.235937, disc_loss 0.790927\n",
      "batch 142, gen_loss 1.212503, disc_loss 0.820652\n",
      "batch 143, gen_loss 1.166840, disc_loss 0.794220\n",
      "batch 144, gen_loss 1.198857, disc_loss 0.854456\n",
      "batch 145, gen_loss 1.215107, disc_loss 0.771019\n",
      "batch 146, gen_loss 1.180464, disc_loss 0.819927\n",
      "batch 147, gen_loss 1.158304, disc_loss 0.857199\n",
      "batch 148, gen_loss 1.253155, disc_loss 0.852768\n",
      "batch 149, gen_loss 1.220202, disc_loss 0.882856\n",
      "batch 150, gen_loss 1.157506, disc_loss 0.831959\n",
      "batch 151, gen_loss 1.157936, disc_loss 0.887417\n",
      "batch 152, gen_loss 1.068351, disc_loss 0.905306\n",
      "batch 153, gen_loss 1.075052, disc_loss 0.897613\n",
      "batch 154, gen_loss 1.094059, disc_loss 0.930981\n",
      "batch 155, gen_loss 1.089432, disc_loss 0.862773\n",
      "batch 156, gen_loss 1.095357, disc_loss 0.970606\n",
      "batch 157, gen_loss 1.090014, disc_loss 1.024614\n",
      "batch 158, gen_loss 1.067638, disc_loss 0.981905\n",
      "batch 159, gen_loss 1.111079, disc_loss 0.964244\n",
      "batch 160, gen_loss 1.020799, disc_loss 1.028904\n",
      "batch 161, gen_loss 0.995647, disc_loss 1.042019\n",
      "batch 162, gen_loss 0.988617, disc_loss 1.048980\n",
      "batch 163, gen_loss 0.967323, disc_loss 1.049222\n",
      "batch 164, gen_loss 0.971028, disc_loss 1.029364\n",
      "batch 165, gen_loss 1.013871, disc_loss 1.083235\n",
      "batch 166, gen_loss 1.044687, disc_loss 1.067718\n",
      "batch 167, gen_loss 0.976768, disc_loss 1.125748\n",
      "batch 168, gen_loss 0.961399, disc_loss 1.163922\n",
      "batch 169, gen_loss 0.946724, disc_loss 1.127568\n",
      "batch 170, gen_loss 0.925761, disc_loss 1.124728\n",
      "batch 171, gen_loss 0.914849, disc_loss 1.185370\n",
      "batch 172, gen_loss 0.936688, disc_loss 1.157991\n",
      "batch 173, gen_loss 0.934648, disc_loss 1.185955\n",
      "batch 174, gen_loss 0.939171, disc_loss 1.177994\n",
      "batch 175, gen_loss 0.966870, disc_loss 1.106572\n",
      "batch 176, gen_loss 0.953023, disc_loss 1.223519\n",
      "batch 177, gen_loss 0.991784, disc_loss 1.194738\n",
      "batch 178, gen_loss 0.943836, disc_loss 1.208350\n",
      "batch 179, gen_loss 0.948701, disc_loss 1.199441\n",
      "batch 180, gen_loss 0.954209, disc_loss 1.197403\n",
      "batch 181, gen_loss 0.980960, disc_loss 1.185035\n",
      "batch 182, gen_loss 0.954315, disc_loss 1.227811\n",
      "batch 183, gen_loss 0.919190, disc_loss 1.230084\n",
      "batch 184, gen_loss 0.886969, disc_loss 1.163071\n",
      "batch 185, gen_loss 0.869397, disc_loss 1.213679\n",
      "batch 186, gen_loss 0.889650, disc_loss 1.203681\n",
      "batch 187, gen_loss 0.840218, disc_loss 1.198220\n",
      "batch 188, gen_loss 0.851199, disc_loss 1.161891\n",
      "batch 189, gen_loss 0.856330, disc_loss 1.221369\n",
      "batch 190, gen_loss 0.902246, disc_loss 1.188478\n",
      "batch 191, gen_loss 0.903959, disc_loss 1.180736\n",
      "batch 192, gen_loss 0.935541, disc_loss 1.194000\n",
      "batch 193, gen_loss 0.916589, disc_loss 1.151141\n",
      "batch 194, gen_loss 0.939430, disc_loss 1.128996\n",
      "batch 195, gen_loss 0.973809, disc_loss 1.182515\n",
      "batch 196, gen_loss 0.926355, disc_loss 1.104528\n",
      "batch 197, gen_loss 0.947275, disc_loss 1.133901\n",
      "batch 198, gen_loss 0.912169, disc_loss 1.095229\n",
      "batch 199, gen_loss 0.936810, disc_loss 1.105476\n",
      "batch 200, gen_loss 0.928504, disc_loss 1.102809\n",
      "batch 201, gen_loss 0.950005, disc_loss 1.120284\n",
      "batch 202, gen_loss 1.020226, disc_loss 1.106501\n",
      "batch 203, gen_loss 1.011101, disc_loss 1.137979\n",
      "batch 204, gen_loss 1.037114, disc_loss 1.073308\n",
      "batch 205, gen_loss 1.069532, disc_loss 1.085534\n",
      "batch 206, gen_loss 1.070914, disc_loss 1.082768\n",
      "batch 207, gen_loss 1.027921, disc_loss 1.082044\n",
      "batch 208, gen_loss 0.996335, disc_loss 1.050076\n",
      "batch 209, gen_loss 0.982081, disc_loss 1.016827\n",
      "batch 210, gen_loss 0.990789, disc_loss 1.035836\n",
      "batch 211, gen_loss 1.036256, disc_loss 1.002275\n",
      "batch 212, gen_loss 1.078160, disc_loss 1.038022\n",
      "batch 213, gen_loss 1.060238, disc_loss 1.001449\n",
      "batch 214, gen_loss 1.125359, disc_loss 1.029303\n",
      "batch 215, gen_loss 1.087729, disc_loss 0.984432\n",
      "batch 216, gen_loss 1.093942, disc_loss 1.022164\n",
      "batch 217, gen_loss 1.129086, disc_loss 0.955482\n",
      "batch 218, gen_loss 1.096471, disc_loss 0.976161\n",
      "batch 219, gen_loss 1.106946, disc_loss 0.942445\n",
      "batch 220, gen_loss 1.057789, disc_loss 0.939440\n",
      "batch 221, gen_loss 1.111652, disc_loss 0.974112\n",
      "batch 222, gen_loss 1.119372, disc_loss 0.937191\n",
      "batch 223, gen_loss 1.069659, disc_loss 0.947305\n",
      "batch 224, gen_loss 1.154827, disc_loss 0.915869\n",
      "batch 225, gen_loss 1.142448, disc_loss 0.980079\n",
      "batch 226, gen_loss 1.211625, disc_loss 0.946795\n",
      "batch 227, gen_loss 1.216588, disc_loss 0.923094\n",
      "batch 228, gen_loss 1.115345, disc_loss 0.993682\n",
      "batch 229, gen_loss 1.110726, disc_loss 0.933412\n",
      "batch 230, gen_loss 1.142437, disc_loss 0.917372\n",
      "batch 231, gen_loss 1.118689, disc_loss 0.936325\n",
      "batch 232, gen_loss 1.151610, disc_loss 0.896083\n",
      "batch 233, gen_loss 1.135244, disc_loss 0.938217\n",
      "batch 234, gen_loss 1.087851, disc_loss 0.944704\n",
      "Time for epoch13is 7.5575127601623535 sec\n",
      "batch 0, gen_loss 1.133766, disc_loss 0.946767\n",
      "batch 1, gen_loss 1.181230, disc_loss 0.909243\n",
      "batch 2, gen_loss 1.178862, disc_loss 0.966712\n",
      "batch 3, gen_loss 1.193166, disc_loss 0.938430\n",
      "batch 4, gen_loss 1.166145, disc_loss 1.002683\n",
      "batch 5, gen_loss 1.169171, disc_loss 0.950332\n",
      "batch 6, gen_loss 1.126981, disc_loss 1.016182\n",
      "batch 7, gen_loss 1.164762, disc_loss 0.992222\n",
      "batch 8, gen_loss 1.066171, disc_loss 0.987998\n",
      "batch 9, gen_loss 1.024472, disc_loss 0.982724\n",
      "batch 10, gen_loss 1.043283, disc_loss 0.994639\n",
      "batch 11, gen_loss 1.068172, disc_loss 1.072322\n",
      "batch 12, gen_loss 1.135821, disc_loss 1.014590\n",
      "batch 13, gen_loss 1.073718, disc_loss 1.006021\n",
      "batch 14, gen_loss 1.033749, disc_loss 1.040576\n",
      "batch 15, gen_loss 1.105708, disc_loss 1.035363\n",
      "batch 16, gen_loss 1.081524, disc_loss 1.029943\n",
      "batch 17, gen_loss 1.075188, disc_loss 1.040368\n",
      "batch 18, gen_loss 1.073357, disc_loss 1.036642\n",
      "batch 19, gen_loss 1.043679, disc_loss 1.030679\n",
      "batch 20, gen_loss 1.032963, disc_loss 1.044034\n",
      "batch 21, gen_loss 1.007483, disc_loss 1.037443\n",
      "batch 22, gen_loss 1.051122, disc_loss 1.059203\n",
      "batch 23, gen_loss 0.990758, disc_loss 1.085959\n",
      "batch 24, gen_loss 1.046874, disc_loss 1.070554\n",
      "batch 25, gen_loss 0.999587, disc_loss 1.135159\n",
      "batch 26, gen_loss 1.075390, disc_loss 1.093009\n",
      "batch 27, gen_loss 1.047397, disc_loss 1.107441\n",
      "batch 28, gen_loss 1.020469, disc_loss 1.053813\n",
      "batch 29, gen_loss 0.947697, disc_loss 1.118444\n",
      "batch 30, gen_loss 0.980334, disc_loss 1.080761\n",
      "batch 31, gen_loss 1.024424, disc_loss 1.086879\n",
      "batch 32, gen_loss 1.004037, disc_loss 1.141472\n",
      "batch 33, gen_loss 1.015497, disc_loss 1.137892\n",
      "batch 34, gen_loss 0.975196, disc_loss 1.132748\n",
      "batch 35, gen_loss 0.984461, disc_loss 1.169837\n",
      "batch 36, gen_loss 0.926780, disc_loss 1.142728\n",
      "batch 37, gen_loss 0.956603, disc_loss 1.139648\n",
      "batch 38, gen_loss 1.006553, disc_loss 1.123734\n",
      "batch 39, gen_loss 0.953199, disc_loss 1.178805\n",
      "batch 40, gen_loss 0.968729, disc_loss 1.109679\n",
      "batch 41, gen_loss 0.954104, disc_loss 1.167757\n",
      "batch 42, gen_loss 0.969387, disc_loss 1.171102\n",
      "batch 43, gen_loss 0.952114, disc_loss 1.199419\n",
      "batch 44, gen_loss 0.933207, disc_loss 1.209343\n",
      "batch 45, gen_loss 0.978388, disc_loss 1.160684\n",
      "batch 46, gen_loss 0.946861, disc_loss 1.210236\n",
      "batch 47, gen_loss 0.985225, disc_loss 1.117317\n",
      "batch 48, gen_loss 1.022419, disc_loss 1.135769\n",
      "batch 49, gen_loss 1.001782, disc_loss 1.189546\n",
      "batch 50, gen_loss 0.989653, disc_loss 1.180674\n",
      "batch 51, gen_loss 0.983875, disc_loss 1.121684\n",
      "batch 52, gen_loss 0.943460, disc_loss 1.253173\n",
      "batch 53, gen_loss 0.957885, disc_loss 1.167576\n",
      "batch 54, gen_loss 0.989263, disc_loss 1.103923\n",
      "batch 55, gen_loss 0.959796, disc_loss 1.203735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 56, gen_loss 0.992143, disc_loss 1.180685\n",
      "batch 57, gen_loss 1.024573, disc_loss 1.173926\n",
      "batch 58, gen_loss 1.010016, disc_loss 1.130738\n",
      "batch 59, gen_loss 0.942066, disc_loss 1.159889\n",
      "batch 60, gen_loss 0.961347, disc_loss 1.200956\n",
      "batch 61, gen_loss 1.025697, disc_loss 1.189162\n",
      "batch 62, gen_loss 0.968138, disc_loss 1.175130\n",
      "batch 63, gen_loss 0.954769, disc_loss 1.178937\n",
      "batch 64, gen_loss 0.985453, disc_loss 1.157687\n",
      "batch 65, gen_loss 0.955974, disc_loss 1.194878\n",
      "batch 66, gen_loss 1.025681, disc_loss 1.154714\n",
      "batch 67, gen_loss 0.960182, disc_loss 1.280585\n",
      "batch 68, gen_loss 1.031046, disc_loss 1.112694\n",
      "batch 69, gen_loss 1.040729, disc_loss 1.179870\n",
      "batch 70, gen_loss 0.988868, disc_loss 1.178150\n",
      "batch 71, gen_loss 1.006277, disc_loss 1.188797\n",
      "batch 72, gen_loss 0.992549, disc_loss 1.169017\n",
      "batch 73, gen_loss 0.978850, disc_loss 1.100296\n",
      "batch 74, gen_loss 0.962078, disc_loss 1.198587\n",
      "batch 75, gen_loss 1.027733, disc_loss 1.166317\n",
      "batch 76, gen_loss 1.072585, disc_loss 1.148721\n",
      "batch 77, gen_loss 1.024163, disc_loss 1.212610\n",
      "batch 78, gen_loss 1.000280, disc_loss 1.167544\n",
      "batch 79, gen_loss 0.978837, disc_loss 1.217920\n",
      "batch 80, gen_loss 1.011179, disc_loss 1.171638\n",
      "batch 81, gen_loss 0.941571, disc_loss 1.154099\n",
      "batch 82, gen_loss 0.937121, disc_loss 1.187259\n",
      "batch 83, gen_loss 0.979365, disc_loss 1.258655\n",
      "batch 84, gen_loss 0.995864, disc_loss 1.191590\n",
      "batch 85, gen_loss 1.009258, disc_loss 1.188563\n",
      "batch 86, gen_loss 1.003752, disc_loss 1.186076\n",
      "batch 87, gen_loss 0.975010, disc_loss 1.167430\n",
      "batch 88, gen_loss 0.951538, disc_loss 1.183224\n",
      "batch 89, gen_loss 0.904641, disc_loss 1.281697\n",
      "batch 90, gen_loss 0.923191, disc_loss 1.241447\n",
      "batch 91, gen_loss 0.916285, disc_loss 1.209841\n",
      "batch 92, gen_loss 0.995436, disc_loss 1.223542\n",
      "batch 93, gen_loss 0.930916, disc_loss 1.279492\n",
      "batch 94, gen_loss 0.928523, disc_loss 1.335089\n",
      "batch 95, gen_loss 0.917940, disc_loss 1.297005\n",
      "batch 96, gen_loss 0.842905, disc_loss 1.338199\n",
      "batch 97, gen_loss 0.851473, disc_loss 1.291374\n",
      "batch 98, gen_loss 0.868979, disc_loss 1.280640\n",
      "batch 99, gen_loss 0.885132, disc_loss 1.234575\n",
      "batch 100, gen_loss 0.936151, disc_loss 1.263646\n",
      "batch 101, gen_loss 0.905988, disc_loss 1.289189\n",
      "batch 102, gen_loss 0.929881, disc_loss 1.258646\n",
      "batch 103, gen_loss 0.935885, disc_loss 1.245556\n",
      "batch 104, gen_loss 0.973057, disc_loss 1.220590\n",
      "batch 105, gen_loss 0.938735, disc_loss 1.253163\n",
      "batch 106, gen_loss 0.912238, disc_loss 1.254905\n",
      "batch 107, gen_loss 0.940322, disc_loss 1.195686\n",
      "batch 108, gen_loss 0.930536, disc_loss 1.232690\n",
      "batch 109, gen_loss 0.895015, disc_loss 1.187617\n",
      "batch 110, gen_loss 0.916656, disc_loss 1.190531\n",
      "batch 111, gen_loss 0.961353, disc_loss 1.191028\n",
      "batch 112, gen_loss 0.998176, disc_loss 1.149814\n",
      "batch 113, gen_loss 0.984980, disc_loss 1.172129\n",
      "batch 114, gen_loss 0.979566, disc_loss 1.188122\n",
      "batch 115, gen_loss 0.992772, disc_loss 1.121443\n",
      "batch 116, gen_loss 0.983894, disc_loss 1.108261\n",
      "batch 117, gen_loss 0.970390, disc_loss 1.113719\n",
      "batch 118, gen_loss 0.990039, disc_loss 1.154500\n",
      "batch 119, gen_loss 1.083894, disc_loss 1.081205\n",
      "batch 120, gen_loss 1.057410, disc_loss 1.068910\n",
      "batch 121, gen_loss 1.082221, disc_loss 1.057954\n",
      "batch 122, gen_loss 1.013421, disc_loss 1.059994\n",
      "batch 123, gen_loss 1.029931, disc_loss 1.002800\n",
      "batch 124, gen_loss 1.060315, disc_loss 1.063143\n",
      "batch 125, gen_loss 1.155474, disc_loss 1.001569\n",
      "batch 126, gen_loss 1.154773, disc_loss 1.052662\n",
      "batch 127, gen_loss 1.112581, disc_loss 1.003798\n",
      "batch 128, gen_loss 1.044811, disc_loss 1.013361\n",
      "batch 129, gen_loss 1.073359, disc_loss 0.986098\n",
      "batch 130, gen_loss 1.032501, disc_loss 1.007899\n",
      "batch 131, gen_loss 1.079561, disc_loss 1.017213\n",
      "batch 132, gen_loss 1.123286, disc_loss 0.987075\n",
      "batch 133, gen_loss 1.128280, disc_loss 1.035392\n",
      "batch 134, gen_loss 1.179024, disc_loss 0.999404\n",
      "batch 135, gen_loss 1.093212, disc_loss 1.027269\n",
      "batch 136, gen_loss 1.092010, disc_loss 1.078360\n",
      "batch 137, gen_loss 1.049147, disc_loss 1.030703\n",
      "batch 138, gen_loss 1.029653, disc_loss 1.037673\n",
      "batch 139, gen_loss 1.048568, disc_loss 1.063134\n",
      "batch 140, gen_loss 1.036148, disc_loss 1.072043\n",
      "batch 141, gen_loss 1.067079, disc_loss 1.055586\n",
      "batch 142, gen_loss 1.123389, disc_loss 1.155864\n",
      "batch 143, gen_loss 1.099277, disc_loss 1.093410\n",
      "batch 144, gen_loss 1.062731, disc_loss 1.051548\n",
      "batch 145, gen_loss 0.992808, disc_loss 1.041907\n",
      "batch 146, gen_loss 1.030454, disc_loss 1.044553\n",
      "batch 147, gen_loss 1.128707, disc_loss 1.087903\n",
      "batch 148, gen_loss 1.144450, disc_loss 1.105883\n",
      "batch 149, gen_loss 1.139571, disc_loss 1.120984\n",
      "batch 150, gen_loss 1.037902, disc_loss 1.096512\n",
      "batch 151, gen_loss 1.028784, disc_loss 1.064841\n",
      "batch 152, gen_loss 0.977975, disc_loss 1.054494\n",
      "batch 153, gen_loss 1.014952, disc_loss 1.056144\n",
      "batch 154, gen_loss 1.096312, disc_loss 1.126737\n",
      "batch 155, gen_loss 1.083121, disc_loss 1.087207\n",
      "batch 156, gen_loss 1.109071, disc_loss 1.115585\n",
      "batch 157, gen_loss 1.132231, disc_loss 1.107535\n",
      "batch 158, gen_loss 1.060452, disc_loss 1.093865\n",
      "batch 159, gen_loss 1.075357, disc_loss 1.036061\n",
      "batch 160, gen_loss 1.029314, disc_loss 0.990673\n",
      "batch 161, gen_loss 1.103034, disc_loss 1.018774\n",
      "batch 162, gen_loss 1.123741, disc_loss 1.078081\n",
      "batch 163, gen_loss 1.096147, disc_loss 1.039537\n",
      "batch 164, gen_loss 1.163492, disc_loss 1.024011\n",
      "batch 165, gen_loss 1.215416, disc_loss 1.036555\n",
      "batch 166, gen_loss 1.229190, disc_loss 1.128709\n",
      "batch 167, gen_loss 1.204331, disc_loss 1.041923\n",
      "batch 168, gen_loss 1.143274, disc_loss 1.055807\n",
      "batch 169, gen_loss 1.171000, disc_loss 1.092305\n",
      "batch 170, gen_loss 1.064928, disc_loss 1.051911\n",
      "batch 171, gen_loss 1.076720, disc_loss 1.041765\n",
      "batch 172, gen_loss 1.085699, disc_loss 1.095769\n",
      "batch 173, gen_loss 1.076516, disc_loss 1.032749\n",
      "batch 174, gen_loss 1.227751, disc_loss 1.058990\n",
      "batch 175, gen_loss 1.215647, disc_loss 1.011915\n",
      "batch 176, gen_loss 1.256257, disc_loss 1.014130\n",
      "batch 177, gen_loss 1.212508, disc_loss 1.044130\n",
      "batch 178, gen_loss 1.264691, disc_loss 1.028708\n",
      "batch 179, gen_loss 1.189042, disc_loss 1.071112\n",
      "batch 180, gen_loss 1.188036, disc_loss 1.007683\n",
      "batch 181, gen_loss 1.205674, disc_loss 0.993596\n",
      "batch 182, gen_loss 1.168216, disc_loss 1.043368\n",
      "batch 183, gen_loss 1.171956, disc_loss 1.034522\n",
      "batch 184, gen_loss 1.203443, disc_loss 0.980507\n",
      "batch 185, gen_loss 1.235073, disc_loss 1.029289\n",
      "batch 186, gen_loss 1.324273, disc_loss 0.958658\n",
      "batch 187, gen_loss 1.238870, disc_loss 0.981087\n",
      "batch 188, gen_loss 1.304935, disc_loss 0.993255\n",
      "batch 189, gen_loss 1.316091, disc_loss 1.009653\n",
      "batch 190, gen_loss 1.290900, disc_loss 0.998188\n",
      "batch 191, gen_loss 1.236641, disc_loss 0.934475\n",
      "batch 192, gen_loss 1.234780, disc_loss 0.999552\n",
      "batch 193, gen_loss 1.256959, disc_loss 0.930432\n",
      "batch 194, gen_loss 1.240458, disc_loss 0.985100\n",
      "batch 195, gen_loss 1.294700, disc_loss 0.963500\n",
      "batch 196, gen_loss 1.331444, disc_loss 0.935740\n",
      "batch 197, gen_loss 1.271513, disc_loss 1.009757\n",
      "batch 198, gen_loss 1.379429, disc_loss 0.914431\n",
      "batch 199, gen_loss 1.349328, disc_loss 0.963862\n",
      "batch 200, gen_loss 1.336753, disc_loss 0.977416\n",
      "batch 201, gen_loss 1.342530, disc_loss 0.933643\n",
      "batch 202, gen_loss 1.357254, disc_loss 0.994754\n",
      "batch 203, gen_loss 1.320462, disc_loss 0.937477\n",
      "batch 204, gen_loss 1.287093, disc_loss 0.942805\n",
      "batch 205, gen_loss 1.286132, disc_loss 0.929992\n",
      "batch 206, gen_loss 1.249460, disc_loss 1.007617\n",
      "batch 207, gen_loss 1.227776, disc_loss 1.086829\n",
      "batch 208, gen_loss 1.222308, disc_loss 0.945054\n",
      "batch 209, gen_loss 1.212477, disc_loss 0.940516\n",
      "batch 210, gen_loss 1.183456, disc_loss 1.047338\n",
      "batch 211, gen_loss 1.201120, disc_loss 0.968334\n",
      "batch 212, gen_loss 1.192233, disc_loss 1.004303\n",
      "batch 213, gen_loss 1.217152, disc_loss 1.006777\n",
      "batch 214, gen_loss 1.178574, disc_loss 1.002005\n",
      "batch 215, gen_loss 1.170424, disc_loss 1.008611\n",
      "batch 216, gen_loss 1.145356, disc_loss 1.026539\n",
      "batch 217, gen_loss 1.149106, disc_loss 1.039887\n",
      "batch 218, gen_loss 1.102004, disc_loss 1.082971\n",
      "batch 219, gen_loss 1.209667, disc_loss 1.055295\n",
      "batch 220, gen_loss 1.139656, disc_loss 1.122550\n",
      "batch 221, gen_loss 1.157758, disc_loss 1.075432\n",
      "batch 222, gen_loss 1.127300, disc_loss 1.106745\n",
      "batch 223, gen_loss 1.070490, disc_loss 1.161518\n",
      "batch 224, gen_loss 1.076679, disc_loss 1.178329\n",
      "batch 225, gen_loss 1.060940, disc_loss 1.174084\n",
      "batch 226, gen_loss 1.068536, disc_loss 1.205078\n",
      "batch 227, gen_loss 1.105023, disc_loss 1.228620\n",
      "batch 228, gen_loss 1.074404, disc_loss 1.157150\n",
      "batch 229, gen_loss 1.032260, disc_loss 1.166559\n",
      "batch 230, gen_loss 1.017984, disc_loss 1.209800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 231, gen_loss 1.022829, disc_loss 1.217269\n",
      "batch 232, gen_loss 0.974268, disc_loss 1.278015\n",
      "batch 233, gen_loss 0.971906, disc_loss 1.290306\n",
      "batch 234, gen_loss 0.992087, disc_loss 1.223649\n",
      "Time for epoch14is 7.556152820587158 sec\n",
      "batch 0, gen_loss 1.013043, disc_loss 1.321532\n",
      "batch 1, gen_loss 0.992091, disc_loss 1.324971\n",
      "batch 2, gen_loss 0.965964, disc_loss 1.319601\n",
      "batch 3, gen_loss 0.933128, disc_loss 1.348042\n",
      "batch 4, gen_loss 0.966968, disc_loss 1.336639\n",
      "batch 5, gen_loss 0.977185, disc_loss 1.275127\n",
      "batch 6, gen_loss 0.966936, disc_loss 1.325719\n",
      "batch 7, gen_loss 0.989061, disc_loss 1.270114\n",
      "batch 8, gen_loss 0.992178, disc_loss 1.285482\n",
      "batch 9, gen_loss 1.040692, disc_loss 1.241925\n",
      "batch 10, gen_loss 1.014473, disc_loss 1.225545\n",
      "batch 11, gen_loss 0.987238, disc_loss 1.266042\n",
      "batch 12, gen_loss 1.029918, disc_loss 1.238937\n",
      "batch 13, gen_loss 1.027752, disc_loss 1.207366\n",
      "batch 14, gen_loss 1.044624, disc_loss 1.256414\n",
      "batch 15, gen_loss 1.117126, disc_loss 1.128281\n",
      "batch 16, gen_loss 1.107918, disc_loss 1.097413\n",
      "batch 17, gen_loss 1.118477, disc_loss 1.099490\n",
      "batch 18, gen_loss 1.105873, disc_loss 1.022404\n",
      "batch 19, gen_loss 1.146785, disc_loss 1.022099\n",
      "batch 20, gen_loss 1.150714, disc_loss 0.950196\n",
      "batch 21, gen_loss 1.139867, disc_loss 0.977999\n",
      "batch 22, gen_loss 1.209671, disc_loss 0.867488\n",
      "batch 23, gen_loss 1.277662, disc_loss 0.877845\n",
      "batch 24, gen_loss 1.274895, disc_loss 0.878914\n",
      "batch 25, gen_loss 1.289603, disc_loss 0.855142\n",
      "batch 26, gen_loss 1.339968, disc_loss 0.777582\n",
      "batch 27, gen_loss 1.346291, disc_loss 0.789384\n",
      "batch 28, gen_loss 1.340347, disc_loss 0.754463\n",
      "batch 29, gen_loss 1.322025, disc_loss 0.781700\n",
      "batch 30, gen_loss 1.351062, disc_loss 0.767600\n",
      "batch 31, gen_loss 1.337345, disc_loss 0.771554\n",
      "batch 32, gen_loss 1.285120, disc_loss 0.709499\n",
      "batch 33, gen_loss 1.326937, disc_loss 0.724435\n",
      "batch 34, gen_loss 1.310018, disc_loss 0.739607\n",
      "batch 35, gen_loss 1.341679, disc_loss 0.763775\n",
      "batch 36, gen_loss 1.439406, disc_loss 0.701428\n",
      "batch 37, gen_loss 1.425143, disc_loss 0.736593\n",
      "batch 38, gen_loss 1.431791, disc_loss 0.724986\n",
      "batch 39, gen_loss 1.468015, disc_loss 0.783517\n",
      "batch 40, gen_loss 1.418755, disc_loss 0.806829\n",
      "batch 41, gen_loss 1.357921, disc_loss 0.837988\n",
      "batch 42, gen_loss 1.338652, disc_loss 0.791525\n",
      "batch 43, gen_loss 1.261881, disc_loss 0.857286\n",
      "batch 44, gen_loss 1.264209, disc_loss 0.786122\n",
      "batch 45, gen_loss 1.186215, disc_loss 0.924367\n",
      "batch 46, gen_loss 1.205121, disc_loss 0.866066\n",
      "batch 47, gen_loss 1.190346, disc_loss 0.842511\n",
      "batch 48, gen_loss 1.273915, disc_loss 0.872504\n",
      "batch 49, gen_loss 1.284048, disc_loss 0.818033\n",
      "batch 50, gen_loss 1.309135, disc_loss 0.957464\n",
      "batch 51, gen_loss 1.257897, disc_loss 0.938959\n",
      "batch 52, gen_loss 1.256910, disc_loss 0.924455\n",
      "batch 53, gen_loss 1.192660, disc_loss 0.921256\n",
      "batch 54, gen_loss 1.143036, disc_loss 0.984178\n",
      "batch 55, gen_loss 1.070928, disc_loss 1.078658\n",
      "batch 56, gen_loss 1.019659, disc_loss 1.057222\n",
      "batch 57, gen_loss 1.011382, disc_loss 0.968361\n",
      "batch 58, gen_loss 1.020179, disc_loss 0.993021\n",
      "batch 59, gen_loss 1.102797, disc_loss 1.000237\n",
      "batch 60, gen_loss 1.143920, disc_loss 1.043453\n",
      "batch 61, gen_loss 1.126952, disc_loss 1.088437\n",
      "batch 62, gen_loss 1.173324, disc_loss 1.005742\n",
      "batch 63, gen_loss 1.181912, disc_loss 1.014892\n",
      "batch 64, gen_loss 1.097118, disc_loss 1.115058\n",
      "batch 65, gen_loss 1.115592, disc_loss 1.042009\n",
      "batch 66, gen_loss 1.027132, disc_loss 1.124372\n",
      "batch 67, gen_loss 1.012743, disc_loss 1.036038\n",
      "batch 68, gen_loss 1.016837, disc_loss 1.072921\n",
      "batch 69, gen_loss 1.009592, disc_loss 1.188570\n",
      "batch 70, gen_loss 1.018208, disc_loss 1.078454\n",
      "batch 71, gen_loss 1.053993, disc_loss 1.119323\n",
      "batch 72, gen_loss 1.049152, disc_loss 1.143724\n",
      "batch 73, gen_loss 1.091320, disc_loss 1.081280\n",
      "batch 74, gen_loss 1.144298, disc_loss 1.114877\n",
      "batch 75, gen_loss 1.076224, disc_loss 1.109944\n",
      "batch 76, gen_loss 1.059268, disc_loss 1.073698\n",
      "batch 77, gen_loss 1.039118, disc_loss 1.087990\n",
      "batch 78, gen_loss 1.000172, disc_loss 1.185423\n",
      "batch 79, gen_loss 0.991511, disc_loss 1.149536\n",
      "batch 80, gen_loss 1.018972, disc_loss 1.075651\n",
      "batch 81, gen_loss 0.998462, disc_loss 1.160063\n",
      "batch 82, gen_loss 1.027448, disc_loss 1.108173\n",
      "batch 83, gen_loss 1.070911, disc_loss 1.163813\n",
      "batch 84, gen_loss 1.063344, disc_loss 1.110634\n",
      "batch 85, gen_loss 1.118761, disc_loss 1.050328\n",
      "batch 86, gen_loss 1.099722, disc_loss 1.067322\n",
      "batch 87, gen_loss 1.099625, disc_loss 1.083341\n",
      "batch 88, gen_loss 1.064551, disc_loss 1.075325\n",
      "batch 89, gen_loss 1.058928, disc_loss 1.037982\n",
      "batch 90, gen_loss 0.993826, disc_loss 1.048139\n",
      "batch 91, gen_loss 1.044657, disc_loss 1.085360\n",
      "batch 92, gen_loss 1.053060, disc_loss 1.096280\n",
      "batch 93, gen_loss 1.092500, disc_loss 1.025146\n",
      "batch 94, gen_loss 1.110716, disc_loss 1.004641\n",
      "batch 95, gen_loss 1.100781, disc_loss 1.096995\n",
      "batch 96, gen_loss 1.111745, disc_loss 1.083041\n",
      "batch 97, gen_loss 1.124464, disc_loss 1.062360\n",
      "batch 98, gen_loss 1.092276, disc_loss 0.955375\n",
      "batch 99, gen_loss 1.086905, disc_loss 1.013221\n",
      "batch 100, gen_loss 1.101743, disc_loss 1.039339\n",
      "batch 101, gen_loss 1.099765, disc_loss 1.032688\n",
      "batch 102, gen_loss 1.081227, disc_loss 1.053181\n",
      "batch 103, gen_loss 1.114619, disc_loss 1.007907\n",
      "batch 104, gen_loss 1.098664, disc_loss 1.004699\n",
      "batch 105, gen_loss 1.109355, disc_loss 0.999961\n",
      "batch 106, gen_loss 1.087580, disc_loss 0.988331\n",
      "batch 107, gen_loss 1.145669, disc_loss 1.008181\n",
      "batch 108, gen_loss 1.180832, disc_loss 0.962941\n",
      "batch 109, gen_loss 1.207049, disc_loss 1.018967\n",
      "batch 110, gen_loss 1.181266, disc_loss 0.993190\n",
      "batch 111, gen_loss 1.195283, disc_loss 0.994121\n",
      "batch 112, gen_loss 1.161022, disc_loss 0.991637\n",
      "batch 113, gen_loss 1.171513, disc_loss 0.953991\n",
      "batch 114, gen_loss 1.090923, disc_loss 0.995556\n",
      "batch 115, gen_loss 1.109117, disc_loss 1.021252\n",
      "batch 116, gen_loss 1.107040, disc_loss 1.028481\n",
      "batch 117, gen_loss 1.156163, disc_loss 0.954594\n",
      "batch 118, gen_loss 1.192407, disc_loss 0.997101\n",
      "batch 119, gen_loss 1.202342, disc_loss 0.965348\n",
      "batch 120, gen_loss 1.213394, disc_loss 0.961443\n",
      "batch 121, gen_loss 1.159257, disc_loss 1.046746\n",
      "batch 122, gen_loss 1.143646, disc_loss 0.971849\n",
      "batch 123, gen_loss 1.122754, disc_loss 0.999785\n",
      "batch 124, gen_loss 1.124073, disc_loss 0.930048\n",
      "batch 125, gen_loss 1.129764, disc_loss 1.013249\n",
      "batch 126, gen_loss 1.117162, disc_loss 1.007245\n",
      "batch 127, gen_loss 1.090229, disc_loss 1.033383\n",
      "batch 128, gen_loss 1.123602, disc_loss 0.972959\n",
      "batch 129, gen_loss 1.215385, disc_loss 1.003421\n",
      "batch 130, gen_loss 1.186918, disc_loss 1.029185\n",
      "batch 131, gen_loss 1.159675, disc_loss 0.988580\n",
      "batch 132, gen_loss 1.177546, disc_loss 0.955617\n",
      "batch 133, gen_loss 1.135121, disc_loss 0.976787\n",
      "batch 134, gen_loss 1.124927, disc_loss 1.029460\n",
      "batch 135, gen_loss 1.109411, disc_loss 1.041630\n",
      "batch 136, gen_loss 1.086937, disc_loss 1.066762\n",
      "batch 137, gen_loss 1.053624, disc_loss 1.064443\n",
      "batch 138, gen_loss 1.086379, disc_loss 1.018824\n",
      "batch 139, gen_loss 1.171887, disc_loss 1.006500\n",
      "batch 140, gen_loss 1.171541, disc_loss 1.031161\n",
      "batch 141, gen_loss 1.164492, disc_loss 1.040115\n",
      "batch 142, gen_loss 1.219066, disc_loss 1.054133\n",
      "batch 143, gen_loss 1.130976, disc_loss 1.113316\n",
      "batch 144, gen_loss 1.080217, disc_loss 1.025691\n",
      "batch 145, gen_loss 1.057846, disc_loss 0.993478\n",
      "batch 146, gen_loss 1.045303, disc_loss 1.047469\n",
      "batch 147, gen_loss 1.070585, disc_loss 1.027884\n",
      "batch 148, gen_loss 1.086681, disc_loss 0.967024\n",
      "batch 149, gen_loss 1.131269, disc_loss 1.085965\n",
      "batch 150, gen_loss 1.186528, disc_loss 1.048001\n",
      "batch 151, gen_loss 1.129821, disc_loss 1.147925\n",
      "batch 152, gen_loss 1.055935, disc_loss 1.095645\n",
      "batch 153, gen_loss 1.054036, disc_loss 1.045826\n",
      "batch 154, gen_loss 1.035612, disc_loss 1.142381\n",
      "batch 155, gen_loss 0.979244, disc_loss 1.124659\n",
      "batch 156, gen_loss 1.004987, disc_loss 1.136805\n",
      "batch 157, gen_loss 1.037102, disc_loss 1.087408\n",
      "batch 158, gen_loss 1.030733, disc_loss 1.105015\n",
      "batch 159, gen_loss 1.064496, disc_loss 1.125436\n",
      "batch 160, gen_loss 1.082163, disc_loss 1.106027\n",
      "batch 161, gen_loss 1.119399, disc_loss 1.160611\n",
      "batch 162, gen_loss 1.053263, disc_loss 1.171486\n",
      "batch 163, gen_loss 1.045289, disc_loss 1.124536\n",
      "batch 164, gen_loss 1.035817, disc_loss 1.107159\n",
      "batch 165, gen_loss 1.044500, disc_loss 1.127471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 166, gen_loss 1.000409, disc_loss 1.162887\n",
      "batch 167, gen_loss 1.073774, disc_loss 1.160338\n",
      "batch 168, gen_loss 1.023712, disc_loss 1.198633\n",
      "batch 169, gen_loss 1.027810, disc_loss 1.201932\n",
      "batch 170, gen_loss 1.017627, disc_loss 1.165823\n",
      "batch 171, gen_loss 1.011724, disc_loss 1.203415\n",
      "batch 172, gen_loss 1.012289, disc_loss 1.227988\n",
      "batch 173, gen_loss 1.033559, disc_loss 1.235369\n",
      "batch 174, gen_loss 1.017314, disc_loss 1.153848\n",
      "batch 175, gen_loss 0.971230, disc_loss 1.162654\n",
      "batch 176, gen_loss 0.989115, disc_loss 1.195904\n",
      "batch 177, gen_loss 0.944423, disc_loss 1.281629\n",
      "batch 178, gen_loss 0.967863, disc_loss 1.224590\n",
      "batch 179, gen_loss 0.990281, disc_loss 1.144081\n",
      "batch 180, gen_loss 1.022257, disc_loss 1.198763\n",
      "batch 181, gen_loss 1.008838, disc_loss 1.261997\n",
      "batch 182, gen_loss 0.990326, disc_loss 1.226795\n",
      "batch 183, gen_loss 1.039137, disc_loss 1.180701\n",
      "batch 184, gen_loss 0.976582, disc_loss 1.218911\n",
      "batch 185, gen_loss 0.944184, disc_loss 1.217811\n",
      "batch 186, gen_loss 0.973144, disc_loss 1.212211\n",
      "batch 187, gen_loss 0.912830, disc_loss 1.240536\n",
      "batch 188, gen_loss 0.987111, disc_loss 1.212922\n",
      "batch 189, gen_loss 1.074147, disc_loss 1.157513\n",
      "batch 190, gen_loss 1.039963, disc_loss 1.211544\n",
      "batch 191, gen_loss 1.035252, disc_loss 1.212303\n",
      "batch 192, gen_loss 0.981971, disc_loss 1.189466\n",
      "batch 193, gen_loss 0.935476, disc_loss 1.181847\n",
      "batch 194, gen_loss 0.963792, disc_loss 1.252366\n",
      "batch 195, gen_loss 0.938072, disc_loss 1.194239\n",
      "batch 196, gen_loss 0.990456, disc_loss 1.178959\n",
      "batch 197, gen_loss 1.066720, disc_loss 1.124114\n",
      "batch 198, gen_loss 1.107227, disc_loss 1.097139\n",
      "batch 199, gen_loss 1.104636, disc_loss 1.156872\n",
      "batch 200, gen_loss 1.026439, disc_loss 1.251277\n",
      "batch 201, gen_loss 0.962139, disc_loss 1.150987\n",
      "batch 202, gen_loss 0.917690, disc_loss 1.129163\n",
      "batch 203, gen_loss 0.944463, disc_loss 1.118335\n",
      "batch 204, gen_loss 1.003978, disc_loss 1.103806\n",
      "batch 205, gen_loss 1.102797, disc_loss 1.137603\n",
      "batch 206, gen_loss 1.103378, disc_loss 1.093566\n",
      "batch 207, gen_loss 1.101483, disc_loss 1.122890\n",
      "batch 208, gen_loss 1.139396, disc_loss 1.078179\n",
      "batch 209, gen_loss 1.063827, disc_loss 1.124212\n",
      "batch 210, gen_loss 1.013174, disc_loss 1.055707\n",
      "batch 211, gen_loss 0.954863, disc_loss 1.077502\n",
      "batch 212, gen_loss 1.002916, disc_loss 1.099799\n",
      "batch 213, gen_loss 1.113669, disc_loss 1.064831\n",
      "batch 214, gen_loss 1.170376, disc_loss 1.039663\n",
      "batch 215, gen_loss 1.228065, disc_loss 1.100490\n",
      "batch 216, gen_loss 1.169074, disc_loss 0.990812\n",
      "batch 217, gen_loss 1.096554, disc_loss 1.128443\n",
      "batch 218, gen_loss 1.061505, disc_loss 1.033684\n",
      "batch 219, gen_loss 1.036642, disc_loss 0.987816\n",
      "batch 220, gen_loss 1.124485, disc_loss 1.038309\n",
      "batch 221, gen_loss 1.116716, disc_loss 1.007106\n",
      "batch 222, gen_loss 1.190249, disc_loss 1.031223\n",
      "batch 223, gen_loss 1.242444, disc_loss 0.996458\n",
      "batch 224, gen_loss 1.256674, disc_loss 0.999665\n",
      "batch 225, gen_loss 1.223660, disc_loss 0.965824\n",
      "batch 226, gen_loss 1.217039, disc_loss 0.969747\n",
      "batch 227, gen_loss 1.128158, disc_loss 1.010195\n",
      "batch 228, gen_loss 1.125956, disc_loss 0.948749\n",
      "batch 229, gen_loss 1.154599, disc_loss 0.996327\n",
      "batch 230, gen_loss 1.177784, disc_loss 0.942284\n",
      "batch 231, gen_loss 1.257744, disc_loss 0.983689\n",
      "batch 232, gen_loss 1.251744, disc_loss 1.007951\n",
      "batch 233, gen_loss 1.265642, disc_loss 0.950100\n",
      "batch 234, gen_loss 1.229194, disc_loss 0.958257\n",
      "Time for epoch15is 7.835766315460205 sec\n",
      "batch 0, gen_loss 1.177262, disc_loss 0.977883\n",
      "batch 1, gen_loss 1.130488, disc_loss 0.950140\n",
      "batch 2, gen_loss 1.183897, disc_loss 1.035967\n",
      "batch 3, gen_loss 1.102595, disc_loss 0.945848\n",
      "batch 4, gen_loss 1.092642, disc_loss 1.012858\n",
      "batch 5, gen_loss 1.096567, disc_loss 1.035135\n",
      "batch 6, gen_loss 1.112332, disc_loss 1.063362\n",
      "batch 7, gen_loss 1.095057, disc_loss 1.015294\n",
      "batch 8, gen_loss 1.095489, disc_loss 1.119636\n",
      "batch 9, gen_loss 1.094726, disc_loss 1.038546\n",
      "batch 10, gen_loss 1.095952, disc_loss 1.061152\n",
      "batch 11, gen_loss 1.122492, disc_loss 1.093890\n",
      "batch 12, gen_loss 1.149969, disc_loss 1.063030\n",
      "batch 13, gen_loss 1.092934, disc_loss 1.104759\n",
      "batch 14, gen_loss 1.128075, disc_loss 1.009332\n",
      "batch 15, gen_loss 1.102843, disc_loss 1.075762\n",
      "batch 16, gen_loss 1.130226, disc_loss 1.043695\n",
      "batch 17, gen_loss 1.164161, disc_loss 1.112825\n",
      "batch 18, gen_loss 1.190491, disc_loss 1.093655\n",
      "batch 19, gen_loss 1.206737, disc_loss 1.083984\n",
      "batch 20, gen_loss 1.158004, disc_loss 1.048372\n",
      "batch 21, gen_loss 1.130284, disc_loss 1.166293\n",
      "batch 22, gen_loss 1.117087, disc_loss 1.071083\n",
      "batch 23, gen_loss 1.062888, disc_loss 1.041222\n",
      "batch 24, gen_loss 1.131605, disc_loss 1.094439\n",
      "batch 25, gen_loss 1.170382, disc_loss 1.096090\n",
      "batch 26, gen_loss 1.142226, disc_loss 1.149034\n",
      "batch 27, gen_loss 1.154559, disc_loss 1.102802\n",
      "batch 28, gen_loss 1.120215, disc_loss 1.135038\n",
      "batch 29, gen_loss 1.111810, disc_loss 1.096765\n",
      "batch 30, gen_loss 1.098554, disc_loss 1.094670\n",
      "batch 31, gen_loss 1.121794, disc_loss 1.093252\n",
      "batch 32, gen_loss 1.091401, disc_loss 1.093296\n",
      "batch 33, gen_loss 1.103190, disc_loss 1.085528\n",
      "batch 34, gen_loss 1.168664, disc_loss 1.006889\n",
      "batch 35, gen_loss 1.130939, disc_loss 1.064197\n",
      "batch 36, gen_loss 1.120594, disc_loss 1.089265\n",
      "batch 37, gen_loss 1.164488, disc_loss 1.108029\n",
      "batch 38, gen_loss 1.136056, disc_loss 1.073836\n",
      "batch 39, gen_loss 1.168490, disc_loss 0.973772\n",
      "batch 40, gen_loss 1.167704, disc_loss 1.060831\n",
      "batch 41, gen_loss 1.226662, disc_loss 0.975625\n",
      "batch 42, gen_loss 1.246503, disc_loss 1.022341\n",
      "batch 43, gen_loss 1.274217, disc_loss 0.960286\n",
      "batch 44, gen_loss 1.298553, disc_loss 0.879259\n",
      "batch 45, gen_loss 1.290142, disc_loss 0.998081\n",
      "batch 46, gen_loss 1.234859, disc_loss 0.985569\n",
      "batch 47, gen_loss 1.179236, disc_loss 0.947615\n",
      "batch 48, gen_loss 1.189023, disc_loss 0.949544\n",
      "batch 49, gen_loss 1.146908, disc_loss 0.952820\n",
      "batch 50, gen_loss 1.186192, disc_loss 0.908996\n",
      "batch 51, gen_loss 1.210947, disc_loss 0.921776\n",
      "batch 52, gen_loss 1.295214, disc_loss 0.949534\n",
      "batch 53, gen_loss 1.321810, disc_loss 0.890028\n",
      "batch 54, gen_loss 1.344714, disc_loss 0.861840\n",
      "batch 55, gen_loss 1.336079, disc_loss 0.921739\n",
      "batch 56, gen_loss 1.343802, disc_loss 0.872930\n",
      "batch 57, gen_loss 1.331201, disc_loss 0.894657\n",
      "batch 58, gen_loss 1.304175, disc_loss 0.809960\n",
      "batch 59, gen_loss 1.252116, disc_loss 0.883434\n",
      "batch 60, gen_loss 1.236168, disc_loss 0.888149\n",
      "batch 61, gen_loss 1.225505, disc_loss 0.884048\n",
      "batch 62, gen_loss 1.243260, disc_loss 0.843332\n",
      "batch 63, gen_loss 1.307061, disc_loss 0.872712\n",
      "batch 64, gen_loss 1.306267, disc_loss 0.899015\n",
      "batch 65, gen_loss 1.370125, disc_loss 0.877600\n",
      "batch 66, gen_loss 1.320867, disc_loss 0.861718\n",
      "batch 67, gen_loss 1.415205, disc_loss 0.831627\n",
      "batch 68, gen_loss 1.368200, disc_loss 0.828628\n",
      "batch 69, gen_loss 1.315545, disc_loss 0.881553\n",
      "batch 70, gen_loss 1.279979, disc_loss 0.865544\n",
      "batch 71, gen_loss 1.272110, disc_loss 0.894124\n",
      "batch 72, gen_loss 1.213627, disc_loss 0.887274\n",
      "batch 73, gen_loss 1.232355, disc_loss 0.882690\n",
      "batch 74, gen_loss 1.174202, disc_loss 0.917349\n",
      "batch 75, gen_loss 1.194303, disc_loss 0.867020\n",
      "batch 76, gen_loss 1.207557, disc_loss 0.852343\n",
      "batch 77, gen_loss 1.237541, disc_loss 0.930696\n",
      "batch 78, gen_loss 1.291656, disc_loss 0.869951\n",
      "batch 79, gen_loss 1.342125, disc_loss 0.901869\n",
      "batch 80, gen_loss 1.310802, disc_loss 0.927012\n",
      "batch 81, gen_loss 1.325817, disc_loss 0.913004\n",
      "batch 82, gen_loss 1.249745, disc_loss 0.859598\n",
      "batch 83, gen_loss 1.166308, disc_loss 0.939238\n",
      "batch 84, gen_loss 1.143125, disc_loss 0.972372\n",
      "batch 85, gen_loss 1.122567, disc_loss 0.911645\n",
      "batch 86, gen_loss 1.164421, disc_loss 0.906051\n",
      "batch 87, gen_loss 1.223753, disc_loss 0.939323\n",
      "batch 88, gen_loss 1.176169, disc_loss 0.917704\n",
      "batch 89, gen_loss 1.229143, disc_loss 0.932428\n",
      "batch 90, gen_loss 1.253035, disc_loss 0.937484\n",
      "batch 91, gen_loss 1.255581, disc_loss 1.003114\n",
      "batch 92, gen_loss 1.301984, disc_loss 0.942450\n",
      "batch 93, gen_loss 1.307237, disc_loss 0.948604\n",
      "batch 94, gen_loss 1.274214, disc_loss 1.003091\n",
      "batch 95, gen_loss 1.178865, disc_loss 0.964516\n",
      "batch 96, gen_loss 1.145571, disc_loss 0.963332\n",
      "batch 97, gen_loss 1.080031, disc_loss 1.021209\n",
      "batch 98, gen_loss 1.081542, disc_loss 0.999640\n",
      "batch 99, gen_loss 1.175573, disc_loss 0.864671\n",
      "batch 100, gen_loss 1.129892, disc_loss 1.007664\n",
      "batch 101, gen_loss 1.250307, disc_loss 0.894938\n",
      "batch 102, gen_loss 1.302498, disc_loss 0.908948\n",
      "batch 103, gen_loss 1.331442, disc_loss 0.885759\n",
      "batch 104, gen_loss 1.356549, disc_loss 0.894780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 105, gen_loss 1.441017, disc_loss 0.804822\n",
      "batch 106, gen_loss 1.408482, disc_loss 0.836503\n",
      "batch 107, gen_loss 1.278850, disc_loss 0.879051\n",
      "batch 108, gen_loss 1.316027, disc_loss 0.834108\n",
      "batch 109, gen_loss 1.248734, disc_loss 0.860162\n",
      "batch 110, gen_loss 1.257708, disc_loss 0.797181\n",
      "batch 111, gen_loss 1.230979, disc_loss 0.825609\n",
      "batch 112, gen_loss 1.370390, disc_loss 0.773032\n",
      "batch 113, gen_loss 1.361386, disc_loss 0.773451\n",
      "batch 114, gen_loss 1.351438, disc_loss 0.785064\n",
      "batch 115, gen_loss 1.448323, disc_loss 0.774537\n",
      "batch 116, gen_loss 1.420585, disc_loss 0.724396\n",
      "batch 117, gen_loss 1.443273, disc_loss 0.734739\n",
      "batch 118, gen_loss 1.432819, disc_loss 0.729314\n",
      "batch 119, gen_loss 1.398066, disc_loss 0.727339\n",
      "batch 120, gen_loss 1.388625, disc_loss 0.717673\n",
      "batch 121, gen_loss 1.390097, disc_loss 0.760442\n",
      "batch 122, gen_loss 1.409959, disc_loss 0.750046\n",
      "batch 123, gen_loss 1.361653, disc_loss 0.748405\n",
      "batch 124, gen_loss 1.317304, disc_loss 0.719648\n",
      "batch 125, gen_loss 1.344161, disc_loss 0.725643\n",
      "batch 126, gen_loss 1.347616, disc_loss 0.814829\n",
      "batch 127, gen_loss 1.386039, disc_loss 0.745395\n",
      "batch 128, gen_loss 1.387424, disc_loss 0.758788\n",
      "batch 129, gen_loss 1.344826, disc_loss 0.761100\n",
      "batch 130, gen_loss 1.483147, disc_loss 0.788348\n",
      "batch 131, gen_loss 1.441117, disc_loss 0.801899\n",
      "batch 132, gen_loss 1.321508, disc_loss 0.786974\n",
      "batch 133, gen_loss 1.342228, disc_loss 0.740308\n",
      "batch 134, gen_loss 1.336019, disc_loss 0.818284\n",
      "batch 135, gen_loss 1.438528, disc_loss 0.812450\n",
      "batch 136, gen_loss 1.330439, disc_loss 0.836032\n",
      "batch 137, gen_loss 1.435776, disc_loss 0.832200\n",
      "batch 138, gen_loss 1.397877, disc_loss 0.786205\n",
      "batch 139, gen_loss 1.421887, disc_loss 0.810621\n",
      "batch 140, gen_loss 1.432633, disc_loss 0.807290\n",
      "batch 141, gen_loss 1.391584, disc_loss 0.882341\n",
      "batch 142, gen_loss 1.333382, disc_loss 0.874218\n",
      "batch 143, gen_loss 1.355839, disc_loss 0.843460\n",
      "batch 144, gen_loss 1.346985, disc_loss 0.864028\n",
      "batch 145, gen_loss 1.354639, disc_loss 0.876399\n",
      "batch 146, gen_loss 1.434070, disc_loss 0.841943\n",
      "batch 147, gen_loss 1.423734, disc_loss 0.862335\n",
      "batch 148, gen_loss 1.433134, disc_loss 0.849640\n",
      "batch 149, gen_loss 1.402694, disc_loss 0.867533\n",
      "batch 150, gen_loss 1.418128, disc_loss 0.891816\n",
      "batch 151, gen_loss 1.377421, disc_loss 0.889978\n",
      "batch 152, gen_loss 1.481319, disc_loss 0.838176\n",
      "batch 153, gen_loss 1.469395, disc_loss 0.865111\n",
      "batch 154, gen_loss 1.439321, disc_loss 0.856899\n",
      "batch 155, gen_loss 1.427329, disc_loss 0.913327\n",
      "batch 156, gen_loss 1.394234, disc_loss 0.870675\n",
      "batch 157, gen_loss 1.402732, disc_loss 0.803580\n",
      "batch 158, gen_loss 1.442683, disc_loss 0.867774\n",
      "batch 159, gen_loss 1.384884, disc_loss 0.875202\n",
      "batch 160, gen_loss 1.503921, disc_loss 0.820704\n",
      "batch 161, gen_loss 1.589136, disc_loss 0.847439\n",
      "batch 162, gen_loss 1.501182, disc_loss 0.923974\n",
      "batch 163, gen_loss 1.479975, disc_loss 0.836621\n",
      "batch 164, gen_loss 1.421121, disc_loss 0.847366\n",
      "batch 165, gen_loss 1.379158, disc_loss 0.896690\n",
      "batch 166, gen_loss 1.336277, disc_loss 0.843055\n",
      "batch 167, gen_loss 1.355679, disc_loss 0.876208\n",
      "batch 168, gen_loss 1.407174, disc_loss 0.889676\n",
      "batch 169, gen_loss 1.472720, disc_loss 0.800778\n",
      "batch 170, gen_loss 1.390530, disc_loss 0.820062\n",
      "batch 171, gen_loss 1.395182, disc_loss 0.827664\n",
      "batch 172, gen_loss 1.426909, disc_loss 0.872657\n",
      "batch 173, gen_loss 1.398688, disc_loss 0.836931\n",
      "batch 174, gen_loss 1.471451, disc_loss 0.890581\n",
      "batch 175, gen_loss 1.397756, disc_loss 0.836607\n",
      "batch 176, gen_loss 1.344246, disc_loss 0.892872\n",
      "batch 177, gen_loss 1.381809, disc_loss 0.854197\n",
      "batch 178, gen_loss 1.303037, disc_loss 0.879383\n",
      "batch 179, gen_loss 1.356277, disc_loss 0.899039\n",
      "batch 180, gen_loss 1.313270, disc_loss 0.876235\n",
      "batch 181, gen_loss 1.322028, disc_loss 0.916479\n",
      "batch 182, gen_loss 1.408451, disc_loss 0.925748\n",
      "batch 183, gen_loss 1.388990, disc_loss 0.839465\n",
      "batch 184, gen_loss 1.395454, disc_loss 0.838045\n",
      "batch 185, gen_loss 1.366903, disc_loss 0.896640\n",
      "batch 186, gen_loss 1.363800, disc_loss 0.919679\n",
      "batch 187, gen_loss 1.279853, disc_loss 0.887753\n",
      "batch 188, gen_loss 1.292442, disc_loss 0.852698\n",
      "batch 189, gen_loss 1.439880, disc_loss 0.887302\n",
      "batch 190, gen_loss 1.435355, disc_loss 0.882773\n",
      "batch 191, gen_loss 1.367245, disc_loss 0.847514\n",
      "batch 192, gen_loss 1.404895, disc_loss 0.870640\n",
      "batch 193, gen_loss 1.360826, disc_loss 0.877827\n",
      "batch 194, gen_loss 1.313117, disc_loss 0.885376\n",
      "batch 195, gen_loss 1.389823, disc_loss 0.905407\n",
      "batch 196, gen_loss 1.349872, disc_loss 0.939819\n",
      "batch 197, gen_loss 1.379414, disc_loss 0.892910\n",
      "batch 198, gen_loss 1.390008, disc_loss 0.894171\n",
      "batch 199, gen_loss 1.371749, disc_loss 0.944836\n",
      "batch 200, gen_loss 1.358470, disc_loss 0.875858\n",
      "batch 201, gen_loss 1.307705, disc_loss 0.919106\n",
      "batch 202, gen_loss 1.318370, disc_loss 0.908944\n",
      "batch 203, gen_loss 1.270995, disc_loss 0.956599\n",
      "batch 204, gen_loss 1.263604, disc_loss 0.977720\n",
      "batch 205, gen_loss 1.213900, disc_loss 1.024784\n",
      "batch 206, gen_loss 1.294168, disc_loss 1.004054\n",
      "batch 207, gen_loss 1.223768, disc_loss 1.005119\n",
      "batch 208, gen_loss 1.223370, disc_loss 0.978860\n",
      "batch 209, gen_loss 1.188262, disc_loss 1.040345\n",
      "batch 210, gen_loss 1.173838, disc_loss 1.085900\n",
      "batch 211, gen_loss 1.177907, disc_loss 1.104707\n",
      "batch 212, gen_loss 1.248992, disc_loss 1.121719\n",
      "batch 213, gen_loss 1.151952, disc_loss 1.162483\n",
      "batch 214, gen_loss 1.085941, disc_loss 1.234832\n",
      "batch 215, gen_loss 1.103458, disc_loss 1.168527\n",
      "batch 216, gen_loss 1.047512, disc_loss 1.273925\n",
      "batch 217, gen_loss 1.072923, disc_loss 1.194873\n",
      "batch 218, gen_loss 1.010053, disc_loss 1.291363\n",
      "batch 219, gen_loss 1.003128, disc_loss 1.235051\n",
      "batch 220, gen_loss 1.015330, disc_loss 1.254726\n",
      "batch 221, gen_loss 0.988668, disc_loss 1.397372\n",
      "batch 222, gen_loss 1.159310, disc_loss 1.281258\n",
      "batch 223, gen_loss 1.111540, disc_loss 1.310026\n",
      "batch 224, gen_loss 1.029268, disc_loss 1.418159\n",
      "batch 225, gen_loss 1.040838, disc_loss 1.293250\n",
      "batch 226, gen_loss 0.953810, disc_loss 1.278141\n",
      "batch 227, gen_loss 1.015567, disc_loss 1.339300\n",
      "batch 228, gen_loss 1.087015, disc_loss 1.304900\n",
      "batch 229, gen_loss 1.089450, disc_loss 1.322119\n",
      "batch 230, gen_loss 1.025601, disc_loss 1.433341\n",
      "batch 231, gen_loss 1.053062, disc_loss 1.354676\n",
      "batch 232, gen_loss 1.047017, disc_loss 1.246386\n",
      "batch 233, gen_loss 1.028295, disc_loss 1.302329\n",
      "batch 234, gen_loss 1.064357, disc_loss 1.241139\n",
      "Time for epoch16is 7.553532361984253 sec\n",
      "batch 0, gen_loss 1.091361, disc_loss 1.222814\n",
      "batch 1, gen_loss 1.072523, disc_loss 1.301991\n",
      "batch 2, gen_loss 1.163384, disc_loss 1.133615\n",
      "batch 3, gen_loss 1.248163, disc_loss 1.135231\n",
      "batch 4, gen_loss 1.246609, disc_loss 1.172745\n",
      "batch 5, gen_loss 1.255598, disc_loss 1.096539\n",
      "batch 6, gen_loss 1.212669, disc_loss 0.987570\n",
      "batch 7, gen_loss 1.244043, disc_loss 0.995066\n",
      "batch 8, gen_loss 1.251533, disc_loss 1.096242\n",
      "batch 9, gen_loss 1.248065, disc_loss 0.969474\n",
      "batch 10, gen_loss 1.215004, disc_loss 0.925911\n",
      "batch 11, gen_loss 1.237909, disc_loss 0.954587\n",
      "batch 12, gen_loss 1.385784, disc_loss 0.838448\n",
      "batch 13, gen_loss 1.398406, disc_loss 0.898673\n",
      "batch 14, gen_loss 1.404634, disc_loss 0.830246\n",
      "batch 15, gen_loss 1.392614, disc_loss 0.819847\n",
      "batch 16, gen_loss 1.460948, disc_loss 0.760590\n",
      "batch 17, gen_loss 1.426435, disc_loss 0.731443\n",
      "batch 18, gen_loss 1.461817, disc_loss 0.751361\n",
      "batch 19, gen_loss 1.472936, disc_loss 0.727652\n",
      "batch 20, gen_loss 1.507685, disc_loss 0.730790\n",
      "batch 21, gen_loss 1.507952, disc_loss 0.723328\n",
      "batch 22, gen_loss 1.501508, disc_loss 0.712337\n",
      "batch 23, gen_loss 1.513198, disc_loss 0.710932\n",
      "batch 24, gen_loss 1.539198, disc_loss 0.681232\n",
      "batch 25, gen_loss 1.528895, disc_loss 0.705131\n",
      "batch 26, gen_loss 1.495361, disc_loss 0.747681\n",
      "batch 27, gen_loss 1.454985, disc_loss 0.718374\n",
      "batch 28, gen_loss 1.505110, disc_loss 0.702383\n",
      "batch 29, gen_loss 1.441626, disc_loss 0.726639\n",
      "batch 30, gen_loss 1.426303, disc_loss 0.685941\n",
      "batch 31, gen_loss 1.434418, disc_loss 0.796448\n",
      "batch 32, gen_loss 1.466846, disc_loss 0.720033\n",
      "batch 33, gen_loss 1.391300, disc_loss 0.780006\n",
      "batch 34, gen_loss 1.419706, disc_loss 0.784492\n",
      "batch 35, gen_loss 1.375471, disc_loss 0.807631\n",
      "batch 36, gen_loss 1.368458, disc_loss 0.801393\n",
      "batch 37, gen_loss 1.402324, disc_loss 0.789562\n",
      "batch 38, gen_loss 1.421649, disc_loss 0.836618\n",
      "batch 39, gen_loss 1.383673, disc_loss 0.836344\n",
      "batch 40, gen_loss 1.402479, disc_loss 0.857314\n",
      "batch 41, gen_loss 1.333040, disc_loss 0.852642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 42, gen_loss 1.343042, disc_loss 0.858261\n",
      "batch 43, gen_loss 1.361913, disc_loss 0.877189\n",
      "batch 44, gen_loss 1.289383, disc_loss 0.834129\n",
      "batch 45, gen_loss 1.290267, disc_loss 0.920330\n",
      "batch 46, gen_loss 1.271238, disc_loss 0.897967\n",
      "batch 47, gen_loss 1.311360, disc_loss 0.880519\n",
      "batch 48, gen_loss 1.296859, disc_loss 0.882728\n",
      "batch 49, gen_loss 1.360159, disc_loss 0.826674\n",
      "batch 50, gen_loss 1.410351, disc_loss 0.852736\n",
      "batch 51, gen_loss 1.342537, disc_loss 0.925600\n",
      "batch 52, gen_loss 1.374928, disc_loss 0.851975\n",
      "batch 53, gen_loss 1.323138, disc_loss 0.881090\n",
      "batch 54, gen_loss 1.337353, disc_loss 0.915267\n",
      "batch 55, gen_loss 1.348848, disc_loss 0.854712\n",
      "batch 56, gen_loss 1.377855, disc_loss 0.842793\n",
      "batch 57, gen_loss 1.411918, disc_loss 0.837190\n",
      "batch 58, gen_loss 1.395457, disc_loss 0.823300\n",
      "batch 59, gen_loss 1.459644, disc_loss 0.850650\n",
      "batch 60, gen_loss 1.413692, disc_loss 0.857861\n",
      "batch 61, gen_loss 1.481609, disc_loss 0.842485\n",
      "batch 62, gen_loss 1.461771, disc_loss 0.827544\n",
      "batch 63, gen_loss 1.396980, disc_loss 0.811863\n",
      "batch 64, gen_loss 1.507145, disc_loss 0.782430\n",
      "batch 65, gen_loss 1.538552, disc_loss 0.793181\n",
      "batch 66, gen_loss 1.473105, disc_loss 0.815958\n",
      "batch 67, gen_loss 1.500357, disc_loss 0.815476\n",
      "batch 68, gen_loss 1.422343, disc_loss 0.808023\n",
      "batch 69, gen_loss 1.535289, disc_loss 0.805250\n",
      "batch 70, gen_loss 1.539911, disc_loss 0.773819\n",
      "batch 71, gen_loss 1.567335, disc_loss 0.848178\n",
      "batch 72, gen_loss 1.517976, disc_loss 0.915828\n",
      "batch 73, gen_loss 1.574204, disc_loss 0.839693\n",
      "batch 74, gen_loss 1.580314, disc_loss 0.774895\n",
      "batch 75, gen_loss 1.473213, disc_loss 0.755654\n",
      "batch 76, gen_loss 1.482760, disc_loss 0.764648\n",
      "batch 77, gen_loss 1.467406, disc_loss 0.779202\n",
      "batch 78, gen_loss 1.539743, disc_loss 0.746428\n",
      "batch 79, gen_loss 1.603862, disc_loss 0.720158\n",
      "batch 80, gen_loss 1.628887, disc_loss 0.692474\n",
      "batch 81, gen_loss 1.488284, disc_loss 0.863440\n",
      "batch 82, gen_loss 1.655136, disc_loss 0.778768\n",
      "batch 83, gen_loss 1.518444, disc_loss 0.884354\n",
      "batch 84, gen_loss 1.475398, disc_loss 0.756311\n",
      "batch 85, gen_loss 1.499313, disc_loss 0.764334\n",
      "batch 86, gen_loss 1.454793, disc_loss 0.728648\n",
      "batch 87, gen_loss 1.413821, disc_loss 0.853819\n",
      "batch 88, gen_loss 1.516515, disc_loss 0.806217\n",
      "batch 89, gen_loss 1.532010, disc_loss 0.845046\n",
      "batch 90, gen_loss 1.500549, disc_loss 0.796291\n",
      "batch 91, gen_loss 1.480917, disc_loss 0.803664\n",
      "batch 92, gen_loss 1.479474, disc_loss 0.735835\n",
      "batch 93, gen_loss 1.467067, disc_loss 0.827771\n",
      "batch 94, gen_loss 1.336411, disc_loss 0.826366\n",
      "batch 95, gen_loss 1.480211, disc_loss 0.827203\n",
      "batch 96, gen_loss 1.420564, disc_loss 0.847273\n",
      "batch 97, gen_loss 1.381355, disc_loss 0.845172\n",
      "batch 98, gen_loss 1.349083, disc_loss 0.865219\n",
      "batch 99, gen_loss 1.338682, disc_loss 0.878008\n",
      "batch 100, gen_loss 1.298192, disc_loss 0.949845\n",
      "batch 101, gen_loss 1.382532, disc_loss 0.947759\n",
      "batch 102, gen_loss 1.336313, disc_loss 0.899209\n",
      "batch 103, gen_loss 1.364263, disc_loss 0.863676\n",
      "batch 104, gen_loss 1.334427, disc_loss 0.908606\n",
      "batch 105, gen_loss 1.387355, disc_loss 0.958216\n",
      "batch 106, gen_loss 1.332857, disc_loss 0.972400\n",
      "batch 107, gen_loss 1.381102, disc_loss 1.013776\n",
      "batch 108, gen_loss 1.301443, disc_loss 1.044210\n",
      "batch 109, gen_loss 1.338271, disc_loss 0.999232\n",
      "batch 110, gen_loss 1.291776, disc_loss 0.964737\n",
      "batch 111, gen_loss 1.376264, disc_loss 0.996267\n",
      "batch 112, gen_loss 1.400464, disc_loss 0.990805\n",
      "batch 113, gen_loss 1.435001, disc_loss 1.042515\n",
      "batch 114, gen_loss 1.376733, disc_loss 0.956209\n",
      "batch 115, gen_loss 1.475083, disc_loss 0.994974\n",
      "batch 116, gen_loss 1.465446, disc_loss 0.886865\n",
      "batch 117, gen_loss 1.446044, disc_loss 0.869867\n",
      "batch 118, gen_loss 1.511543, disc_loss 0.893435\n",
      "batch 119, gen_loss 1.526609, disc_loss 0.856658\n",
      "batch 120, gen_loss 1.636514, disc_loss 0.772742\n",
      "batch 121, gen_loss 1.656836, disc_loss 0.714757\n",
      "batch 122, gen_loss 1.600026, disc_loss 0.747595\n",
      "batch 123, gen_loss 1.702268, disc_loss 0.678198\n",
      "batch 124, gen_loss 1.671402, disc_loss 0.726031\n",
      "batch 125, gen_loss 1.754639, disc_loss 0.663457\n",
      "batch 126, gen_loss 1.849019, disc_loss 0.573527\n",
      "batch 127, gen_loss 1.861391, disc_loss 0.597004\n",
      "batch 128, gen_loss 1.969735, disc_loss 0.546753\n",
      "batch 129, gen_loss 1.925595, disc_loss 0.546219\n",
      "batch 130, gen_loss 1.995069, disc_loss 0.546452\n",
      "batch 131, gen_loss 1.995625, disc_loss 0.453354\n",
      "batch 132, gen_loss 2.058498, disc_loss 0.546346\n",
      "batch 133, gen_loss 1.926541, disc_loss 0.542409\n",
      "batch 134, gen_loss 1.985880, disc_loss 0.572604\n",
      "batch 135, gen_loss 1.945250, disc_loss 0.611436\n",
      "batch 136, gen_loss 1.987317, disc_loss 0.550987\n",
      "batch 137, gen_loss 1.885581, disc_loss 0.616134\n",
      "batch 138, gen_loss 1.861561, disc_loss 0.545166\n",
      "batch 139, gen_loss 1.816703, disc_loss 0.631381\n",
      "batch 140, gen_loss 1.860178, disc_loss 0.650445\n",
      "batch 141, gen_loss 1.806496, disc_loss 0.591042\n",
      "batch 142, gen_loss 1.839223, disc_loss 0.647005\n",
      "batch 143, gen_loss 1.823931, disc_loss 0.728353\n",
      "batch 144, gen_loss 1.710690, disc_loss 0.667915\n",
      "batch 145, gen_loss 1.728739, disc_loss 0.742495\n",
      "batch 146, gen_loss 1.680385, disc_loss 0.738268\n",
      "batch 147, gen_loss 1.540271, disc_loss 0.848345\n",
      "batch 148, gen_loss 1.540572, disc_loss 0.780918\n",
      "batch 149, gen_loss 1.533682, disc_loss 0.846645\n",
      "batch 150, gen_loss 1.559913, disc_loss 0.818674\n",
      "batch 151, gen_loss 1.388264, disc_loss 0.956946\n",
      "batch 152, gen_loss 1.452958, disc_loss 0.916915\n",
      "batch 153, gen_loss 1.358302, disc_loss 0.973984\n",
      "batch 154, gen_loss 1.287301, disc_loss 1.066629\n",
      "batch 155, gen_loss 1.235186, disc_loss 0.946507\n",
      "batch 156, gen_loss 1.297319, disc_loss 0.963321\n",
      "batch 157, gen_loss 1.274285, disc_loss 0.977615\n",
      "batch 158, gen_loss 1.288254, disc_loss 0.977225\n",
      "batch 159, gen_loss 1.312707, disc_loss 1.006237\n",
      "batch 160, gen_loss 1.321473, disc_loss 1.014685\n",
      "batch 161, gen_loss 1.240734, disc_loss 1.110705\n",
      "batch 162, gen_loss 1.253626, disc_loss 1.094585\n",
      "batch 163, gen_loss 1.207749, disc_loss 1.074122\n",
      "batch 164, gen_loss 1.241381, disc_loss 1.009174\n",
      "batch 165, gen_loss 1.182517, disc_loss 1.096445\n",
      "batch 166, gen_loss 1.196711, disc_loss 1.101762\n",
      "batch 167, gen_loss 1.236464, disc_loss 1.045019\n",
      "batch 168, gen_loss 1.227367, disc_loss 1.091888\n",
      "batch 169, gen_loss 1.243917, disc_loss 1.101067\n",
      "batch 170, gen_loss 1.193038, disc_loss 1.089961\n",
      "batch 171, gen_loss 1.165232, disc_loss 1.065875\n",
      "batch 172, gen_loss 1.140648, disc_loss 1.070705\n",
      "batch 173, gen_loss 1.173543, disc_loss 1.069875\n",
      "batch 174, gen_loss 1.190100, disc_loss 1.133494\n",
      "batch 175, gen_loss 1.136171, disc_loss 1.181588\n",
      "batch 176, gen_loss 1.133175, disc_loss 1.104751\n",
      "batch 177, gen_loss 1.144969, disc_loss 1.132117\n",
      "batch 178, gen_loss 1.057277, disc_loss 1.109694\n",
      "batch 179, gen_loss 1.121494, disc_loss 1.052265\n",
      "batch 180, gen_loss 1.087583, disc_loss 1.136637\n",
      "batch 181, gen_loss 1.038594, disc_loss 1.109807\n",
      "batch 182, gen_loss 1.130479, disc_loss 1.061892\n",
      "batch 183, gen_loss 1.140681, disc_loss 0.958400\n",
      "batch 184, gen_loss 1.256456, disc_loss 1.110471\n",
      "batch 185, gen_loss 1.287266, disc_loss 1.021230\n",
      "batch 186, gen_loss 1.199909, disc_loss 1.021273\n",
      "batch 187, gen_loss 1.207927, disc_loss 0.995924\n",
      "batch 188, gen_loss 1.261197, disc_loss 0.914830\n",
      "batch 189, gen_loss 1.174396, disc_loss 1.009152\n",
      "batch 190, gen_loss 1.244871, disc_loss 0.876553\n",
      "batch 191, gen_loss 1.278369, disc_loss 0.875947\n",
      "batch 192, gen_loss 1.327148, disc_loss 0.937197\n",
      "batch 193, gen_loss 1.338560, disc_loss 0.833186\n",
      "batch 194, gen_loss 1.412577, disc_loss 0.886196\n",
      "batch 195, gen_loss 1.388069, disc_loss 0.851395\n",
      "batch 196, gen_loss 1.429443, disc_loss 0.814551\n",
      "batch 197, gen_loss 1.375303, disc_loss 0.845216\n",
      "batch 198, gen_loss 1.361377, disc_loss 0.813240\n",
      "batch 199, gen_loss 1.367454, disc_loss 0.792992\n",
      "batch 200, gen_loss 1.345400, disc_loss 0.727660\n",
      "batch 201, gen_loss 1.348566, disc_loss 0.813537\n",
      "batch 202, gen_loss 1.379906, disc_loss 0.779216\n",
      "batch 203, gen_loss 1.414033, disc_loss 0.732060\n",
      "batch 204, gen_loss 1.517666, disc_loss 0.785339\n",
      "batch 205, gen_loss 1.549510, disc_loss 0.700249\n",
      "batch 206, gen_loss 1.460279, disc_loss 0.767134\n",
      "batch 207, gen_loss 1.486738, disc_loss 0.708263\n",
      "batch 208, gen_loss 1.445840, disc_loss 0.768511\n",
      "batch 209, gen_loss 1.400878, disc_loss 0.705626\n",
      "batch 210, gen_loss 1.435178, disc_loss 0.693353\n",
      "batch 211, gen_loss 1.478287, disc_loss 0.651044\n",
      "batch 212, gen_loss 1.498989, disc_loss 0.772678\n",
      "batch 213, gen_loss 1.608337, disc_loss 0.633759\n",
      "batch 214, gen_loss 1.621760, disc_loss 0.720664\n",
      "batch 215, gen_loss 1.580532, disc_loss 0.698579\n",
      "batch 216, gen_loss 1.536755, disc_loss 0.701933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 217, gen_loss 1.535252, disc_loss 0.754070\n",
      "batch 218, gen_loss 1.413568, disc_loss 0.716676\n",
      "batch 219, gen_loss 1.411873, disc_loss 0.723790\n",
      "batch 220, gen_loss 1.476271, disc_loss 0.722264\n",
      "batch 221, gen_loss 1.550099, disc_loss 0.678135\n",
      "batch 222, gen_loss 1.535796, disc_loss 0.685403\n",
      "batch 223, gen_loss 1.571085, disc_loss 0.642523\n",
      "batch 224, gen_loss 1.566824, disc_loss 0.705164\n",
      "batch 225, gen_loss 1.609060, disc_loss 0.641591\n",
      "batch 226, gen_loss 1.554867, disc_loss 0.631334\n",
      "batch 227, gen_loss 1.520871, disc_loss 0.659076\n",
      "batch 228, gen_loss 1.609366, disc_loss 0.612971\n",
      "batch 229, gen_loss 1.649114, disc_loss 0.654653\n",
      "batch 230, gen_loss 1.630011, disc_loss 0.642618\n",
      "batch 231, gen_loss 1.689687, disc_loss 0.635919\n",
      "batch 232, gen_loss 1.659850, disc_loss 0.644120\n",
      "batch 233, gen_loss 1.609723, disc_loss 0.661556\n",
      "batch 234, gen_loss 1.641129, disc_loss 0.721564\n",
      "Time for epoch17is 7.578449010848999 sec\n",
      "batch 0, gen_loss 1.500582, disc_loss 0.603913\n",
      "batch 1, gen_loss 1.527505, disc_loss 0.549882\n",
      "batch 2, gen_loss 1.580844, disc_loss 0.628722\n",
      "batch 3, gen_loss 1.751396, disc_loss 0.625002\n",
      "batch 4, gen_loss 1.766021, disc_loss 0.660915\n",
      "batch 5, gen_loss 1.740113, disc_loss 0.677638\n",
      "batch 6, gen_loss 1.641929, disc_loss 0.732489\n",
      "batch 7, gen_loss 1.712766, disc_loss 0.672970\n",
      "batch 8, gen_loss 1.518445, disc_loss 0.728099\n",
      "batch 9, gen_loss 1.394959, disc_loss 0.741595\n",
      "batch 10, gen_loss 1.372239, disc_loss 0.753091\n",
      "batch 11, gen_loss 1.457841, disc_loss 0.740764\n",
      "batch 12, gen_loss 1.611326, disc_loss 0.698223\n",
      "batch 13, gen_loss 1.646576, disc_loss 0.776512\n",
      "batch 14, gen_loss 1.789638, disc_loss 0.813457\n",
      "batch 15, gen_loss 1.671040, disc_loss 0.852930\n",
      "batch 16, gen_loss 1.444526, disc_loss 0.821157\n",
      "batch 17, gen_loss 1.266758, disc_loss 0.891375\n",
      "batch 18, gen_loss 1.307340, disc_loss 0.834346\n",
      "batch 19, gen_loss 1.285369, disc_loss 0.913269\n",
      "batch 20, gen_loss 1.316902, disc_loss 0.966711\n",
      "batch 21, gen_loss 1.497320, disc_loss 0.946754\n",
      "batch 22, gen_loss 1.501410, disc_loss 0.936896\n",
      "batch 23, gen_loss 1.478906, disc_loss 1.033556\n",
      "batch 24, gen_loss 1.426152, disc_loss 1.009382\n",
      "batch 25, gen_loss 1.369588, disc_loss 1.010765\n",
      "batch 26, gen_loss 1.252136, disc_loss 1.097580\n",
      "batch 27, gen_loss 1.150298, disc_loss 1.002840\n",
      "batch 28, gen_loss 1.139824, disc_loss 1.018115\n",
      "batch 29, gen_loss 1.105498, disc_loss 1.077366\n",
      "batch 30, gen_loss 1.227445, disc_loss 1.106743\n",
      "batch 31, gen_loss 1.363735, disc_loss 1.128184\n",
      "batch 32, gen_loss 1.497093, disc_loss 1.019387\n",
      "batch 33, gen_loss 1.427063, disc_loss 1.050283\n",
      "batch 34, gen_loss 1.412448, disc_loss 1.086722\n",
      "batch 35, gen_loss 1.226435, disc_loss 1.057441\n",
      "batch 36, gen_loss 1.151094, disc_loss 1.081285\n",
      "batch 37, gen_loss 1.092341, disc_loss 1.107153\n",
      "batch 38, gen_loss 1.162670, disc_loss 1.069310\n",
      "batch 39, gen_loss 1.304855, disc_loss 1.041458\n",
      "batch 40, gen_loss 1.294205, disc_loss 1.081657\n",
      "batch 41, gen_loss 1.396832, disc_loss 0.974933\n",
      "batch 42, gen_loss 1.383115, disc_loss 0.920338\n",
      "batch 43, gen_loss 1.327237, disc_loss 1.061678\n",
      "batch 44, gen_loss 1.296917, disc_loss 1.027948\n",
      "batch 45, gen_loss 1.267261, disc_loss 0.939398\n",
      "batch 46, gen_loss 1.181152, disc_loss 0.997587\n",
      "batch 47, gen_loss 1.244743, disc_loss 0.911407\n",
      "batch 48, gen_loss 1.207934, disc_loss 0.960274\n",
      "batch 49, gen_loss 1.325723, disc_loss 0.922860\n",
      "batch 50, gen_loss 1.338904, disc_loss 0.918454\n",
      "batch 51, gen_loss 1.392068, disc_loss 0.924611\n",
      "batch 52, gen_loss 1.409453, disc_loss 0.945250\n",
      "batch 53, gen_loss 1.269683, disc_loss 0.939382\n",
      "batch 54, gen_loss 1.198244, disc_loss 0.898803\n",
      "batch 55, gen_loss 1.267209, disc_loss 0.887122\n",
      "batch 56, gen_loss 1.218961, disc_loss 0.890013\n",
      "batch 57, gen_loss 1.273767, disc_loss 0.854057\n",
      "batch 58, gen_loss 1.386734, disc_loss 0.976536\n",
      "batch 59, gen_loss 1.325705, disc_loss 0.962735\n",
      "batch 60, gen_loss 1.236863, disc_loss 0.900785\n",
      "batch 61, gen_loss 1.260536, disc_loss 0.822021\n",
      "batch 62, gen_loss 1.172770, disc_loss 0.861217\n",
      "batch 63, gen_loss 1.241537, disc_loss 0.859343\n",
      "batch 64, gen_loss 1.232648, disc_loss 0.868458\n",
      "batch 65, gen_loss 1.313475, disc_loss 0.874016\n",
      "batch 66, gen_loss 1.381669, disc_loss 0.820591\n",
      "batch 67, gen_loss 1.400057, disc_loss 0.911659\n",
      "batch 68, gen_loss 1.272039, disc_loss 0.874144\n",
      "batch 69, gen_loss 1.260519, disc_loss 0.848124\n",
      "batch 70, gen_loss 1.233265, disc_loss 0.862271\n",
      "batch 71, gen_loss 1.203352, disc_loss 0.849857\n",
      "batch 72, gen_loss 1.298840, disc_loss 0.878025\n",
      "batch 73, gen_loss 1.356108, disc_loss 0.822893\n",
      "batch 74, gen_loss 1.392014, disc_loss 0.832013\n",
      "batch 75, gen_loss 1.384367, disc_loss 0.849099\n",
      "batch 76, gen_loss 1.436762, disc_loss 0.828515\n",
      "batch 77, gen_loss 1.330681, disc_loss 0.850254\n",
      "batch 78, gen_loss 1.294393, disc_loss 0.790069\n",
      "batch 79, gen_loss 1.273798, disc_loss 0.789291\n",
      "batch 80, gen_loss 1.339761, disc_loss 0.769782\n",
      "batch 81, gen_loss 1.397394, disc_loss 0.701351\n",
      "batch 82, gen_loss 1.447599, disc_loss 0.713119\n",
      "batch 83, gen_loss 1.554324, disc_loss 0.829701\n",
      "batch 84, gen_loss 1.594286, disc_loss 0.737676\n",
      "batch 85, gen_loss 1.514853, disc_loss 0.745559\n",
      "batch 86, gen_loss 1.498481, disc_loss 0.679235\n",
      "batch 87, gen_loss 1.302765, disc_loss 0.806651\n",
      "batch 88, gen_loss 1.431941, disc_loss 0.720155\n",
      "batch 89, gen_loss 1.389770, disc_loss 0.765568\n",
      "batch 90, gen_loss 1.492553, disc_loss 0.731036\n",
      "batch 91, gen_loss 1.556708, disc_loss 0.642674\n",
      "batch 92, gen_loss 1.632892, disc_loss 0.667831\n",
      "batch 93, gen_loss 1.609058, disc_loss 0.684656\n",
      "batch 94, gen_loss 1.627376, disc_loss 0.687840\n",
      "batch 95, gen_loss 1.538042, disc_loss 0.692417\n",
      "batch 96, gen_loss 1.497563, disc_loss 0.745182\n",
      "batch 97, gen_loss 1.520931, disc_loss 0.728923\n",
      "batch 98, gen_loss 1.589446, disc_loss 0.650735\n",
      "batch 99, gen_loss 1.518864, disc_loss 0.686574\n",
      "batch 100, gen_loss 1.573677, disc_loss 0.677640\n",
      "batch 101, gen_loss 1.583140, disc_loss 0.689557\n",
      "batch 102, gen_loss 1.696947, disc_loss 0.689330\n",
      "batch 103, gen_loss 1.563816, disc_loss 0.709671\n",
      "batch 104, gen_loss 1.604582, disc_loss 0.739998\n",
      "batch 105, gen_loss 1.552766, disc_loss 0.738693\n",
      "batch 106, gen_loss 1.496930, disc_loss 0.712654\n",
      "batch 107, gen_loss 1.450640, disc_loss 0.740547\n",
      "batch 108, gen_loss 1.467005, disc_loss 0.757361\n",
      "batch 109, gen_loss 1.488463, disc_loss 0.715825\n",
      "batch 110, gen_loss 1.597785, disc_loss 0.710416\n",
      "batch 111, gen_loss 1.592698, disc_loss 0.760832\n",
      "batch 112, gen_loss 1.564111, disc_loss 0.740979\n",
      "batch 113, gen_loss 1.457951, disc_loss 0.759953\n",
      "batch 114, gen_loss 1.427215, disc_loss 0.728022\n",
      "batch 115, gen_loss 1.295767, disc_loss 0.844621\n",
      "batch 116, gen_loss 1.369717, disc_loss 0.773672\n",
      "batch 117, gen_loss 1.417454, disc_loss 0.811087\n",
      "batch 118, gen_loss 1.483624, disc_loss 0.871058\n",
      "batch 119, gen_loss 1.543646, disc_loss 0.839643\n",
      "batch 120, gen_loss 1.503213, disc_loss 0.804414\n",
      "batch 121, gen_loss 1.393868, disc_loss 0.916128\n",
      "batch 122, gen_loss 1.204095, disc_loss 1.007058\n",
      "batch 123, gen_loss 1.275324, disc_loss 0.920578\n",
      "batch 124, gen_loss 1.229810, disc_loss 0.943971\n",
      "batch 125, gen_loss 1.229692, disc_loss 0.960444\n",
      "batch 126, gen_loss 1.311347, disc_loss 0.971369\n",
      "batch 127, gen_loss 1.421036, disc_loss 0.896220\n",
      "batch 128, gen_loss 1.404773, disc_loss 0.962813\n",
      "batch 129, gen_loss 1.386368, disc_loss 1.028005\n",
      "batch 130, gen_loss 1.392180, disc_loss 0.973976\n",
      "batch 131, gen_loss 1.211740, disc_loss 1.057476\n",
      "batch 132, gen_loss 1.289809, disc_loss 1.097094\n",
      "batch 133, gen_loss 1.213943, disc_loss 1.035618\n",
      "batch 134, gen_loss 1.133157, disc_loss 1.054165\n",
      "batch 135, gen_loss 1.131551, disc_loss 1.042243\n",
      "batch 136, gen_loss 1.278579, disc_loss 1.117047\n",
      "batch 137, gen_loss 1.429277, disc_loss 1.115154\n",
      "batch 138, gen_loss 1.365269, disc_loss 1.153324\n",
      "batch 139, gen_loss 1.269969, disc_loss 1.074053\n",
      "batch 140, gen_loss 1.184180, disc_loss 1.173360\n",
      "batch 141, gen_loss 1.146677, disc_loss 1.091787\n",
      "batch 142, gen_loss 1.149644, disc_loss 1.097036\n",
      "batch 143, gen_loss 1.235969, disc_loss 1.093597\n",
      "batch 144, gen_loss 1.310207, disc_loss 1.102319\n",
      "batch 145, gen_loss 1.356309, disc_loss 1.095289\n",
      "batch 146, gen_loss 1.258836, disc_loss 1.140255\n",
      "batch 147, gen_loss 1.249371, disc_loss 1.115192\n",
      "batch 148, gen_loss 1.226910, disc_loss 1.144987\n",
      "batch 149, gen_loss 1.242222, disc_loss 1.014834\n",
      "batch 150, gen_loss 1.174082, disc_loss 1.124344\n",
      "batch 151, gen_loss 1.194440, disc_loss 1.159917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 152, gen_loss 1.242770, disc_loss 1.143825\n",
      "batch 153, gen_loss 1.308245, disc_loss 1.004654\n",
      "batch 154, gen_loss 1.317695, disc_loss 1.103099\n",
      "batch 155, gen_loss 1.227899, disc_loss 1.072037\n",
      "batch 156, gen_loss 1.162045, disc_loss 1.098661\n",
      "batch 157, gen_loss 1.220358, disc_loss 1.056269\n",
      "batch 158, gen_loss 1.300359, disc_loss 0.980078\n",
      "batch 159, gen_loss 1.277387, disc_loss 1.015945\n",
      "batch 160, gen_loss 1.348459, disc_loss 0.947617\n",
      "batch 161, gen_loss 1.285624, disc_loss 1.015674\n",
      "batch 162, gen_loss 1.282547, disc_loss 1.061364\n",
      "batch 163, gen_loss 1.317166, disc_loss 1.039459\n",
      "batch 164, gen_loss 1.315811, disc_loss 0.999173\n",
      "batch 165, gen_loss 1.343803, disc_loss 0.950451\n",
      "batch 166, gen_loss 1.270928, disc_loss 0.987964\n",
      "batch 167, gen_loss 1.266083, disc_loss 0.932941\n",
      "batch 168, gen_loss 1.286135, disc_loss 0.981074\n",
      "batch 169, gen_loss 1.434503, disc_loss 0.926365\n",
      "batch 170, gen_loss 1.375338, disc_loss 0.950448\n",
      "batch 171, gen_loss 1.420277, disc_loss 1.010320\n",
      "batch 172, gen_loss 1.327223, disc_loss 0.910020\n",
      "batch 173, gen_loss 1.261981, disc_loss 0.971625\n",
      "batch 174, gen_loss 1.263743, disc_loss 0.949147\n",
      "batch 175, gen_loss 1.331288, disc_loss 0.926021\n",
      "batch 176, gen_loss 1.364725, disc_loss 0.906280\n",
      "batch 177, gen_loss 1.395933, disc_loss 0.977886\n",
      "batch 178, gen_loss 1.510590, disc_loss 0.931759\n",
      "batch 179, gen_loss 1.391580, disc_loss 0.883572\n",
      "batch 180, gen_loss 1.342330, disc_loss 0.976989\n",
      "batch 181, gen_loss 1.365273, disc_loss 0.934373\n",
      "batch 182, gen_loss 1.347897, disc_loss 0.808507\n",
      "batch 183, gen_loss 1.373206, disc_loss 0.910237\n",
      "batch 184, gen_loss 1.384294, disc_loss 0.851135\n",
      "batch 185, gen_loss 1.532794, disc_loss 0.843375\n",
      "batch 186, gen_loss 1.446186, disc_loss 0.838856\n",
      "batch 187, gen_loss 1.571482, disc_loss 0.802682\n",
      "batch 188, gen_loss 1.532951, disc_loss 0.849130\n",
      "batch 189, gen_loss 1.506155, disc_loss 0.794226\n",
      "batch 190, gen_loss 1.475005, disc_loss 0.825868\n",
      "batch 191, gen_loss 1.601563, disc_loss 0.801448\n",
      "batch 192, gen_loss 1.546589, disc_loss 0.746508\n",
      "batch 193, gen_loss 1.445349, disc_loss 0.812754\n",
      "batch 194, gen_loss 1.541196, disc_loss 0.844692\n",
      "batch 195, gen_loss 1.462169, disc_loss 0.825524\n",
      "batch 196, gen_loss 1.435279, disc_loss 0.803352\n",
      "batch 197, gen_loss 1.475740, disc_loss 0.817883\n",
      "batch 198, gen_loss 1.505820, disc_loss 0.824503\n",
      "batch 199, gen_loss 1.610548, disc_loss 0.828201\n",
      "batch 200, gen_loss 1.608707, disc_loss 0.762865\n",
      "batch 201, gen_loss 1.643610, disc_loss 0.817270\n",
      "batch 202, gen_loss 1.666322, disc_loss 0.751920\n",
      "batch 203, gen_loss 1.507364, disc_loss 0.853187\n",
      "batch 204, gen_loss 1.598163, disc_loss 0.795334\n",
      "batch 205, gen_loss 1.505598, disc_loss 0.835179\n",
      "batch 206, gen_loss 1.567010, disc_loss 0.771833\n",
      "batch 207, gen_loss 1.479473, disc_loss 0.798253\n",
      "batch 208, gen_loss 1.478536, disc_loss 0.783854\n",
      "batch 209, gen_loss 1.559896, disc_loss 0.739939\n",
      "batch 210, gen_loss 1.643898, disc_loss 0.723023\n",
      "batch 211, gen_loss 1.673620, disc_loss 0.815759\n",
      "batch 212, gen_loss 1.717391, disc_loss 0.847016\n",
      "batch 213, gen_loss 1.742880, disc_loss 0.822260\n",
      "batch 214, gen_loss 1.717603, disc_loss 0.746040\n",
      "batch 215, gen_loss 1.474807, disc_loss 0.762230\n",
      "batch 216, gen_loss 1.521731, disc_loss 0.778313\n",
      "batch 217, gen_loss 1.427012, disc_loss 0.873532\n",
      "batch 218, gen_loss 1.476561, disc_loss 0.793336\n",
      "batch 219, gen_loss 1.565028, disc_loss 0.759840\n",
      "batch 220, gen_loss 1.618805, disc_loss 0.830647\n",
      "batch 221, gen_loss 1.608682, disc_loss 0.816018\n",
      "batch 222, gen_loss 1.641324, disc_loss 0.850744\n",
      "batch 223, gen_loss 1.660264, disc_loss 0.799843\n",
      "batch 224, gen_loss 1.584596, disc_loss 0.792378\n",
      "batch 225, gen_loss 1.547760, disc_loss 0.807267\n",
      "batch 226, gen_loss 1.489647, disc_loss 0.815298\n",
      "batch 227, gen_loss 1.500786, disc_loss 0.826134\n",
      "batch 228, gen_loss 1.547092, disc_loss 0.814538\n",
      "batch 229, gen_loss 1.450690, disc_loss 0.885145\n",
      "batch 230, gen_loss 1.514779, disc_loss 0.863859\n",
      "batch 231, gen_loss 1.490507, disc_loss 0.816093\n",
      "batch 232, gen_loss 1.502490, disc_loss 0.887114\n",
      "batch 233, gen_loss 1.568534, disc_loss 0.827957\n",
      "batch 234, gen_loss 1.393562, disc_loss 0.864879\n",
      "Time for epoch18is 8.02685546875 sec\n",
      "batch 0, gen_loss 1.425656, disc_loss 0.886769\n",
      "batch 1, gen_loss 1.340524, disc_loss 0.901839\n",
      "batch 2, gen_loss 1.436636, disc_loss 0.874738\n",
      "batch 3, gen_loss 1.437989, disc_loss 0.840480\n",
      "batch 4, gen_loss 1.391834, disc_loss 0.924001\n",
      "batch 5, gen_loss 1.483992, disc_loss 0.940458\n",
      "batch 6, gen_loss 1.488853, disc_loss 0.925346\n",
      "batch 7, gen_loss 1.453154, disc_loss 0.930259\n",
      "batch 8, gen_loss 1.432756, disc_loss 0.944376\n",
      "batch 9, gen_loss 1.283248, disc_loss 0.937159\n",
      "batch 10, gen_loss 1.344595, disc_loss 0.918810\n",
      "batch 11, gen_loss 1.318087, disc_loss 0.963939\n",
      "batch 12, gen_loss 1.342502, disc_loss 1.015066\n",
      "batch 13, gen_loss 1.435065, disc_loss 0.931124\n",
      "batch 14, gen_loss 1.488478, disc_loss 0.895388\n",
      "batch 15, gen_loss 1.453918, disc_loss 0.931118\n",
      "batch 16, gen_loss 1.380040, disc_loss 0.941437\n",
      "batch 17, gen_loss 1.384392, disc_loss 0.884379\n",
      "batch 18, gen_loss 1.327378, disc_loss 0.950673\n",
      "batch 19, gen_loss 1.349610, disc_loss 0.906601\n",
      "batch 20, gen_loss 1.369235, disc_loss 0.993576\n",
      "batch 21, gen_loss 1.323671, disc_loss 0.931256\n",
      "batch 22, gen_loss 1.287784, disc_loss 0.973774\n",
      "batch 23, gen_loss 1.300164, disc_loss 0.906501\n",
      "batch 24, gen_loss 1.308583, disc_loss 0.919508\n",
      "batch 25, gen_loss 1.263764, disc_loss 0.980379\n",
      "batch 26, gen_loss 1.305335, disc_loss 0.928323\n",
      "batch 27, gen_loss 1.400742, disc_loss 1.012892\n",
      "batch 28, gen_loss 1.279366, disc_loss 0.870640\n",
      "batch 29, gen_loss 1.261475, disc_loss 0.954412\n",
      "batch 30, gen_loss 1.266435, disc_loss 1.006960\n",
      "batch 31, gen_loss 1.208380, disc_loss 0.981988\n",
      "batch 32, gen_loss 1.273604, disc_loss 0.956358\n",
      "batch 33, gen_loss 1.250048, disc_loss 0.993520\n",
      "batch 34, gen_loss 1.235345, disc_loss 0.940110\n",
      "batch 35, gen_loss 1.359178, disc_loss 0.908038\n",
      "batch 36, gen_loss 1.368818, disc_loss 1.006420\n",
      "batch 37, gen_loss 1.358288, disc_loss 0.933327\n",
      "batch 38, gen_loss 1.342893, disc_loss 0.984317\n",
      "batch 39, gen_loss 1.354723, disc_loss 0.937266\n",
      "batch 40, gen_loss 1.267348, disc_loss 0.950573\n",
      "batch 41, gen_loss 1.218409, disc_loss 0.980747\n",
      "batch 42, gen_loss 1.314932, disc_loss 0.938602\n",
      "batch 43, gen_loss 1.251364, disc_loss 0.987730\n",
      "batch 44, gen_loss 1.163919, disc_loss 0.957716\n",
      "batch 45, gen_loss 1.312676, disc_loss 0.989513\n",
      "batch 46, gen_loss 1.325234, disc_loss 0.946820\n",
      "batch 47, gen_loss 1.328590, disc_loss 0.974437\n",
      "batch 48, gen_loss 1.349741, disc_loss 0.962526\n",
      "batch 49, gen_loss 1.235346, disc_loss 0.926746\n",
      "batch 50, gen_loss 1.211542, disc_loss 0.938050\n",
      "batch 51, gen_loss 1.278481, disc_loss 0.894710\n",
      "batch 52, gen_loss 1.367883, disc_loss 0.850659\n",
      "batch 53, gen_loss 1.415871, disc_loss 0.828918\n",
      "batch 54, gen_loss 1.417168, disc_loss 0.972744\n",
      "batch 55, gen_loss 1.397898, disc_loss 0.834096\n",
      "batch 56, gen_loss 1.340642, disc_loss 0.818594\n",
      "batch 57, gen_loss 1.322175, disc_loss 0.845498\n",
      "batch 58, gen_loss 1.421504, disc_loss 0.780789\n",
      "batch 59, gen_loss 1.393036, disc_loss 0.845562\n",
      "batch 60, gen_loss 1.436061, disc_loss 0.813052\n",
      "batch 61, gen_loss 1.415244, disc_loss 0.682169\n",
      "batch 62, gen_loss 1.484230, disc_loss 0.742931\n",
      "batch 63, gen_loss 1.554322, disc_loss 0.797637\n",
      "batch 64, gen_loss 1.611931, disc_loss 0.739750\n",
      "batch 65, gen_loss 1.581838, disc_loss 0.643119\n",
      "batch 66, gen_loss 1.508639, disc_loss 0.673859\n",
      "batch 67, gen_loss 1.613077, disc_loss 0.690172\n",
      "batch 68, gen_loss 1.672655, disc_loss 0.650343\n",
      "batch 69, gen_loss 1.658488, disc_loss 0.625127\n",
      "batch 70, gen_loss 1.728744, disc_loss 0.633126\n",
      "batch 71, gen_loss 1.692952, disc_loss 0.648005\n",
      "batch 72, gen_loss 1.669139, disc_loss 0.591078\n",
      "batch 73, gen_loss 1.726988, disc_loss 0.610616\n",
      "batch 74, gen_loss 1.847848, disc_loss 0.572783\n",
      "batch 75, gen_loss 1.769794, disc_loss 0.572366\n",
      "batch 76, gen_loss 1.849316, disc_loss 0.552078\n",
      "batch 77, gen_loss 1.872413, disc_loss 0.579819\n",
      "batch 78, gen_loss 1.703991, disc_loss 0.620907\n",
      "batch 79, gen_loss 1.756646, disc_loss 0.587218\n",
      "batch 80, gen_loss 1.701855, disc_loss 0.582780\n",
      "batch 81, gen_loss 1.689095, disc_loss 0.598505\n",
      "batch 82, gen_loss 1.766816, disc_loss 0.596587\n",
      "batch 83, gen_loss 1.821550, disc_loss 0.631442\n",
      "batch 84, gen_loss 1.828667, disc_loss 0.581927\n",
      "batch 85, gen_loss 1.779192, disc_loss 0.639031\n",
      "batch 86, gen_loss 1.768541, disc_loss 0.623822\n",
      "batch 87, gen_loss 1.680161, disc_loss 0.608540\n",
      "batch 88, gen_loss 1.687178, disc_loss 0.762370\n",
      "batch 89, gen_loss 1.663144, disc_loss 0.686437\n",
      "batch 90, gen_loss 1.550825, disc_loss 0.658555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 91, gen_loss 1.501279, disc_loss 0.691531\n",
      "batch 92, gen_loss 1.631975, disc_loss 0.693806\n",
      "batch 93, gen_loss 1.777838, disc_loss 0.706055\n",
      "batch 94, gen_loss 1.929050, disc_loss 0.730693\n",
      "batch 95, gen_loss 1.746015, disc_loss 0.680247\n",
      "batch 96, gen_loss 1.603575, disc_loss 0.753168\n",
      "batch 97, gen_loss 1.571275, disc_loss 0.729003\n",
      "batch 98, gen_loss 1.654548, disc_loss 0.718388\n",
      "batch 99, gen_loss 1.628403, disc_loss 0.733948\n",
      "batch 100, gen_loss 1.699843, disc_loss 0.868149\n",
      "batch 101, gen_loss 1.741200, disc_loss 0.890423\n",
      "batch 102, gen_loss 1.512136, disc_loss 0.825806\n",
      "batch 103, gen_loss 1.582860, disc_loss 0.825388\n",
      "batch 104, gen_loss 1.483491, disc_loss 0.834309\n",
      "batch 105, gen_loss 1.487448, disc_loss 0.850884\n",
      "batch 106, gen_loss 1.530693, disc_loss 0.894530\n",
      "batch 107, gen_loss 1.653936, disc_loss 0.919857\n",
      "batch 108, gen_loss 1.643410, disc_loss 0.819639\n",
      "batch 109, gen_loss 1.516125, disc_loss 0.837367\n",
      "batch 110, gen_loss 1.493814, disc_loss 0.911128\n",
      "batch 111, gen_loss 1.571677, disc_loss 0.890284\n",
      "batch 112, gen_loss 1.498699, disc_loss 0.894528\n",
      "batch 113, gen_loss 1.580882, disc_loss 0.941092\n",
      "batch 114, gen_loss 1.529824, disc_loss 1.062368\n",
      "batch 115, gen_loss 1.494471, disc_loss 0.874873\n",
      "batch 116, gen_loss 1.461201, disc_loss 0.961808\n",
      "batch 117, gen_loss 1.360559, disc_loss 0.928226\n",
      "batch 118, gen_loss 1.292038, disc_loss 0.933318\n",
      "batch 119, gen_loss 1.373308, disc_loss 1.012752\n",
      "batch 120, gen_loss 1.587656, disc_loss 1.008806\n",
      "batch 121, gen_loss 1.569428, disc_loss 0.956441\n",
      "batch 122, gen_loss 1.564496, disc_loss 0.987239\n",
      "batch 123, gen_loss 1.491612, disc_loss 0.924654\n",
      "batch 124, gen_loss 1.386294, disc_loss 0.928463\n",
      "batch 125, gen_loss 1.211795, disc_loss 0.982360\n",
      "batch 126, gen_loss 1.231094, disc_loss 1.080087\n",
      "batch 127, gen_loss 1.238024, disc_loss 0.997261\n",
      "batch 128, gen_loss 1.472599, disc_loss 0.880835\n",
      "batch 129, gen_loss 1.547424, disc_loss 0.927546\n",
      "batch 130, gen_loss 1.596449, disc_loss 0.865196\n",
      "batch 131, gen_loss 1.660226, disc_loss 0.913491\n",
      "batch 132, gen_loss 1.546186, disc_loss 0.901659\n",
      "batch 133, gen_loss 1.359365, disc_loss 0.898619\n",
      "batch 134, gen_loss 1.243516, disc_loss 0.896019\n",
      "batch 135, gen_loss 1.317756, disc_loss 0.892695\n",
      "batch 136, gen_loss 1.286910, disc_loss 1.007425\n",
      "batch 137, gen_loss 1.368359, disc_loss 0.841594\n",
      "batch 138, gen_loss 1.458658, disc_loss 0.874149\n",
      "batch 139, gen_loss 1.666454, disc_loss 0.882079\n",
      "batch 140, gen_loss 1.679260, disc_loss 0.919411\n",
      "batch 141, gen_loss 1.636533, disc_loss 0.731618\n",
      "batch 142, gen_loss 1.542680, disc_loss 0.833051\n",
      "batch 143, gen_loss 1.355360, disc_loss 0.799314\n",
      "batch 144, gen_loss 1.432921, disc_loss 0.747192\n",
      "batch 145, gen_loss 1.488780, disc_loss 0.676949\n",
      "batch 146, gen_loss 1.522226, disc_loss 0.713056\n",
      "batch 147, gen_loss 1.614335, disc_loss 0.741661\n",
      "batch 148, gen_loss 1.753521, disc_loss 0.601818\n",
      "batch 149, gen_loss 1.924823, disc_loss 0.664381\n",
      "batch 150, gen_loss 1.956872, disc_loss 0.674784\n",
      "batch 151, gen_loss 1.862680, disc_loss 0.624906\n",
      "batch 152, gen_loss 1.783026, disc_loss 0.654153\n",
      "batch 153, gen_loss 1.711702, disc_loss 0.636198\n",
      "batch 154, gen_loss 1.745629, disc_loss 0.587606\n",
      "batch 155, gen_loss 1.562952, disc_loss 0.605713\n",
      "batch 156, gen_loss 1.543180, disc_loss 0.634458\n",
      "batch 157, gen_loss 1.633697, disc_loss 0.531532\n",
      "batch 158, gen_loss 1.669913, disc_loss 0.589605\n",
      "batch 159, gen_loss 1.833439, disc_loss 0.572272\n",
      "batch 160, gen_loss 1.830954, disc_loss 0.554293\n",
      "batch 161, gen_loss 1.925052, disc_loss 0.535683\n",
      "batch 162, gen_loss 2.009369, disc_loss 0.568004\n",
      "batch 163, gen_loss 1.948266, disc_loss 0.507937\n",
      "batch 164, gen_loss 1.917828, disc_loss 0.519168\n",
      "batch 165, gen_loss 1.839286, disc_loss 0.506040\n",
      "batch 166, gen_loss 1.829694, disc_loss 0.520821\n",
      "batch 167, gen_loss 1.876771, disc_loss 0.464703\n",
      "batch 168, gen_loss 1.908771, disc_loss 0.459939\n",
      "batch 169, gen_loss 1.951213, disc_loss 0.487579\n",
      "batch 170, gen_loss 1.996088, disc_loss 0.428275\n",
      "batch 171, gen_loss 2.054550, disc_loss 0.434143\n",
      "batch 172, gen_loss 2.091643, disc_loss 0.425335\n",
      "batch 173, gen_loss 2.045400, disc_loss 0.435275\n",
      "batch 174, gen_loss 2.088687, disc_loss 0.425898\n",
      "batch 175, gen_loss 2.193234, disc_loss 0.423503\n",
      "batch 176, gen_loss 2.081244, disc_loss 0.482894\n",
      "batch 177, gen_loss 2.089094, disc_loss 0.526053\n",
      "batch 178, gen_loss 2.039025, disc_loss 0.422422\n",
      "batch 179, gen_loss 2.035331, disc_loss 0.453009\n",
      "batch 180, gen_loss 1.985561, disc_loss 0.417295\n",
      "batch 181, gen_loss 2.091551, disc_loss 0.454590\n",
      "batch 182, gen_loss 2.018057, disc_loss 0.477165\n",
      "batch 183, gen_loss 2.121782, disc_loss 0.465041\n",
      "batch 184, gen_loss 2.083555, disc_loss 0.485701\n",
      "batch 185, gen_loss 2.102679, disc_loss 0.542798\n",
      "batch 186, gen_loss 2.078098, disc_loss 0.430278\n",
      "batch 187, gen_loss 2.143736, disc_loss 0.501031\n",
      "batch 188, gen_loss 2.068149, disc_loss 0.473626\n",
      "batch 189, gen_loss 2.141098, disc_loss 0.556941\n",
      "batch 190, gen_loss 1.964566, disc_loss 0.572419\n",
      "batch 191, gen_loss 1.948219, disc_loss 0.524777\n",
      "batch 192, gen_loss 1.925060, disc_loss 0.571002\n",
      "batch 193, gen_loss 1.917437, disc_loss 0.585823\n",
      "batch 194, gen_loss 1.913623, disc_loss 0.577454\n",
      "batch 195, gen_loss 1.929366, disc_loss 0.702291\n",
      "batch 196, gen_loss 1.973095, disc_loss 0.675264\n",
      "batch 197, gen_loss 1.963449, disc_loss 0.633395\n",
      "batch 198, gen_loss 1.911356, disc_loss 0.764303\n",
      "batch 199, gen_loss 1.868291, disc_loss 0.784471\n",
      "batch 200, gen_loss 1.714531, disc_loss 0.824951\n",
      "batch 201, gen_loss 1.586813, disc_loss 0.908173\n",
      "batch 202, gen_loss 1.544503, disc_loss 0.822506\n",
      "batch 203, gen_loss 1.577594, disc_loss 0.876145\n",
      "batch 204, gen_loss 1.563529, disc_loss 0.909353\n",
      "batch 205, gen_loss 1.598323, disc_loss 0.951920\n",
      "batch 206, gen_loss 1.592439, disc_loss 1.009905\n",
      "batch 207, gen_loss 1.616519, disc_loss 1.079336\n",
      "batch 208, gen_loss 1.546878, disc_loss 1.020589\n",
      "batch 209, gen_loss 1.563135, disc_loss 1.002797\n",
      "batch 210, gen_loss 1.565966, disc_loss 1.065057\n",
      "batch 211, gen_loss 1.545584, disc_loss 1.102203\n",
      "batch 212, gen_loss 1.366374, disc_loss 1.051733\n",
      "batch 213, gen_loss 1.337256, disc_loss 1.145857\n",
      "batch 214, gen_loss 1.260118, disc_loss 1.102095\n",
      "batch 215, gen_loss 1.351655, disc_loss 0.996321\n",
      "batch 216, gen_loss 1.243519, disc_loss 1.050699\n",
      "batch 217, gen_loss 1.372654, disc_loss 1.104986\n",
      "batch 218, gen_loss 1.378284, disc_loss 1.075410\n",
      "batch 219, gen_loss 1.506732, disc_loss 0.998098\n",
      "batch 220, gen_loss 1.533186, disc_loss 1.154752\n",
      "batch 221, gen_loss 1.521835, disc_loss 1.078009\n",
      "batch 222, gen_loss 1.301468, disc_loss 1.070410\n",
      "batch 223, gen_loss 1.300730, disc_loss 1.034006\n",
      "batch 224, gen_loss 1.238166, disc_loss 1.097503\n",
      "batch 225, gen_loss 1.201642, disc_loss 1.109889\n",
      "batch 226, gen_loss 1.280565, disc_loss 0.996661\n",
      "batch 227, gen_loss 1.253309, disc_loss 1.023360\n",
      "batch 228, gen_loss 1.371672, disc_loss 1.047661\n",
      "batch 229, gen_loss 1.498821, disc_loss 0.944242\n",
      "batch 230, gen_loss 1.616432, disc_loss 0.853929\n",
      "batch 231, gen_loss 1.664426, disc_loss 0.917671\n",
      "batch 232, gen_loss 1.656682, disc_loss 0.855876\n",
      "batch 233, gen_loss 1.566309, disc_loss 0.932183\n",
      "batch 234, gen_loss 1.592017, disc_loss 0.799603\n",
      "Time for epoch19is 7.579554319381714 sec\n",
      "batch 0, gen_loss 1.500008, disc_loss 0.924483\n",
      "batch 1, gen_loss 1.472622, disc_loss 0.834820\n",
      "batch 2, gen_loss 1.432152, disc_loss 0.920659\n",
      "batch 3, gen_loss 1.377434, disc_loss 0.861695\n",
      "batch 4, gen_loss 1.501095, disc_loss 0.778302\n",
      "batch 5, gen_loss 1.537109, disc_loss 0.758215\n",
      "batch 6, gen_loss 1.691410, disc_loss 0.807485\n",
      "batch 7, gen_loss 1.679079, disc_loss 0.761844\n",
      "batch 8, gen_loss 1.837550, disc_loss 0.686113\n",
      "batch 9, gen_loss 1.692605, disc_loss 0.823890\n",
      "batch 10, gen_loss 1.574928, disc_loss 0.724321\n",
      "batch 11, gen_loss 1.682140, disc_loss 0.662236\n",
      "batch 12, gen_loss 1.508202, disc_loss 0.677741\n",
      "batch 13, gen_loss 1.545977, disc_loss 0.672597\n",
      "batch 14, gen_loss 1.567695, disc_loss 0.589655\n",
      "batch 15, gen_loss 1.690601, disc_loss 0.612017\n",
      "batch 16, gen_loss 1.734623, disc_loss 0.635951\n",
      "batch 17, gen_loss 1.944100, disc_loss 0.620220\n",
      "batch 18, gen_loss 1.905357, disc_loss 0.587164\n",
      "batch 19, gen_loss 1.734013, disc_loss 0.647262\n",
      "batch 20, gen_loss 1.716336, disc_loss 0.612706\n",
      "batch 21, gen_loss 1.604637, disc_loss 0.611642\n",
      "batch 22, gen_loss 1.593875, disc_loss 0.642967\n",
      "batch 23, gen_loss 1.619306, disc_loss 0.656862\n",
      "batch 24, gen_loss 1.743489, disc_loss 0.641573\n",
      "batch 25, gen_loss 1.709813, disc_loss 0.689478\n",
      "batch 26, gen_loss 1.742352, disc_loss 0.682841\n",
      "batch 27, gen_loss 1.721015, disc_loss 0.658910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 28, gen_loss 1.669997, disc_loss 0.676019\n",
      "batch 29, gen_loss 1.624387, disc_loss 0.719104\n",
      "batch 30, gen_loss 1.596181, disc_loss 0.708387\n",
      "batch 31, gen_loss 1.652350, disc_loss 0.722430\n",
      "batch 32, gen_loss 1.655508, disc_loss 0.739909\n",
      "batch 33, gen_loss 1.688340, disc_loss 0.792706\n",
      "batch 34, gen_loss 1.670311, disc_loss 0.705552\n",
      "batch 35, gen_loss 1.489519, disc_loss 0.753163\n",
      "batch 36, gen_loss 1.591409, disc_loss 0.839694\n",
      "batch 37, gen_loss 1.576482, disc_loss 0.809829\n",
      "batch 38, gen_loss 1.587494, disc_loss 0.900209\n",
      "batch 39, gen_loss 1.604152, disc_loss 0.844949\n",
      "batch 40, gen_loss 1.624118, disc_loss 0.920940\n",
      "batch 41, gen_loss 1.518953, disc_loss 0.952015\n",
      "batch 42, gen_loss 1.490936, disc_loss 0.985835\n",
      "batch 43, gen_loss 1.346290, disc_loss 1.007135\n",
      "batch 44, gen_loss 1.304922, disc_loss 1.035154\n",
      "batch 45, gen_loss 1.433017, disc_loss 0.899207\n",
      "batch 46, gen_loss 1.476355, disc_loss 1.108534\n",
      "batch 47, gen_loss 1.415701, disc_loss 1.040722\n",
      "batch 48, gen_loss 1.443517, disc_loss 1.136285\n",
      "batch 49, gen_loss 1.417672, disc_loss 1.145926\n",
      "batch 50, gen_loss 1.352251, disc_loss 1.220922\n",
      "batch 51, gen_loss 1.240802, disc_loss 1.181892\n",
      "batch 52, gen_loss 1.136992, disc_loss 1.326353\n",
      "batch 53, gen_loss 1.189629, disc_loss 1.308982\n",
      "batch 54, gen_loss 1.184796, disc_loss 1.219043\n",
      "batch 55, gen_loss 1.279316, disc_loss 1.193906\n",
      "batch 56, gen_loss 1.346499, disc_loss 1.265336\n",
      "batch 57, gen_loss 1.401771, disc_loss 1.254783\n",
      "batch 58, gen_loss 1.479473, disc_loss 1.168343\n",
      "batch 59, gen_loss 1.378397, disc_loss 1.056566\n",
      "batch 60, gen_loss 1.283664, disc_loss 1.052339\n",
      "batch 61, gen_loss 1.341683, disc_loss 1.075654\n",
      "batch 62, gen_loss 1.385655, disc_loss 1.082138\n",
      "batch 63, gen_loss 1.519971, disc_loss 1.000730\n",
      "batch 64, gen_loss 1.489823, disc_loss 1.003688\n",
      "batch 65, gen_loss 1.475747, disc_loss 0.931640\n",
      "batch 66, gen_loss 1.431789, disc_loss 1.012161\n",
      "batch 67, gen_loss 1.666987, disc_loss 0.807403\n",
      "batch 68, gen_loss 1.767323, disc_loss 0.724162\n",
      "batch 69, gen_loss 1.805997, disc_loss 0.787455\n",
      "batch 70, gen_loss 1.926402, disc_loss 0.704133\n",
      "batch 71, gen_loss 1.961626, disc_loss 0.709008\n",
      "batch 72, gen_loss 2.091245, disc_loss 0.674014\n",
      "batch 73, gen_loss 1.941928, disc_loss 0.651504\n",
      "batch 74, gen_loss 2.012489, disc_loss 0.619060\n",
      "batch 75, gen_loss 2.138510, disc_loss 0.475702\n",
      "batch 76, gen_loss 2.125308, disc_loss 0.532911\n",
      "batch 77, gen_loss 2.221066, disc_loss 0.510638\n",
      "batch 78, gen_loss 2.314702, disc_loss 0.509505\n",
      "batch 79, gen_loss 2.385105, disc_loss 0.458898\n",
      "batch 80, gen_loss 2.432431, disc_loss 0.448888\n",
      "batch 81, gen_loss 2.392853, disc_loss 0.414501\n",
      "batch 82, gen_loss 2.335487, disc_loss 0.420933\n",
      "batch 83, gen_loss 2.345578, disc_loss 0.446389\n",
      "batch 84, gen_loss 2.211401, disc_loss 0.500637\n",
      "batch 85, gen_loss 2.303129, disc_loss 0.474241\n",
      "batch 86, gen_loss 2.287726, disc_loss 0.433982\n",
      "batch 87, gen_loss 2.275121, disc_loss 0.474999\n",
      "batch 88, gen_loss 2.167443, disc_loss 0.447317\n",
      "batch 89, gen_loss 2.161270, disc_loss 0.603143\n",
      "batch 90, gen_loss 2.114484, disc_loss 0.490175\n",
      "batch 91, gen_loss 1.989934, disc_loss 0.527831\n",
      "batch 92, gen_loss 1.891974, disc_loss 0.557895\n",
      "batch 93, gen_loss 1.845523, disc_loss 0.593492\n",
      "batch 94, gen_loss 1.890448, disc_loss 0.592226\n",
      "batch 95, gen_loss 1.840149, disc_loss 0.648004\n",
      "batch 96, gen_loss 1.842336, disc_loss 0.805234\n",
      "batch 97, gen_loss 1.778181, disc_loss 0.631013\n",
      "batch 98, gen_loss 1.567733, disc_loss 0.680535\n",
      "batch 99, gen_loss 1.655946, disc_loss 0.703517\n",
      "batch 100, gen_loss 1.655011, disc_loss 0.720788\n",
      "batch 101, gen_loss 1.694064, disc_loss 0.692709\n",
      "batch 102, gen_loss 1.594511, disc_loss 0.788318\n",
      "batch 103, gen_loss 1.641145, disc_loss 0.789118\n",
      "batch 104, gen_loss 1.760304, disc_loss 0.793577\n",
      "batch 105, gen_loss 1.645784, disc_loss 0.802085\n",
      "batch 106, gen_loss 1.614307, disc_loss 0.845300\n",
      "batch 107, gen_loss 1.560061, disc_loss 0.796139\n",
      "batch 108, gen_loss 1.505307, disc_loss 0.903109\n",
      "batch 109, gen_loss 1.516606, disc_loss 0.867749\n",
      "batch 110, gen_loss 1.555744, disc_loss 0.965422\n",
      "batch 111, gen_loss 1.430766, disc_loss 0.889068\n",
      "batch 112, gen_loss 1.336606, disc_loss 0.956472\n",
      "batch 113, gen_loss 1.293182, disc_loss 1.019709\n",
      "batch 114, gen_loss 1.318097, disc_loss 1.009118\n",
      "batch 115, gen_loss 1.277418, disc_loss 1.037925\n",
      "batch 116, gen_loss 1.316978, disc_loss 1.066655\n",
      "batch 117, gen_loss 1.308924, disc_loss 1.005399\n",
      "batch 118, gen_loss 1.302873, disc_loss 1.018273\n",
      "batch 119, gen_loss 1.333009, disc_loss 1.059984\n",
      "batch 120, gen_loss 1.287151, disc_loss 1.061259\n",
      "batch 121, gen_loss 1.295298, disc_loss 1.135716\n",
      "batch 122, gen_loss 1.205687, disc_loss 1.164345\n",
      "batch 123, gen_loss 1.175618, disc_loss 1.122484\n",
      "batch 124, gen_loss 1.150064, disc_loss 1.147473\n",
      "batch 125, gen_loss 1.204350, disc_loss 1.118775\n",
      "batch 126, gen_loss 1.281129, disc_loss 1.120730\n",
      "batch 127, gen_loss 1.318815, disc_loss 1.126946\n",
      "batch 128, gen_loss 1.362079, disc_loss 1.184506\n",
      "batch 129, gen_loss 1.356421, disc_loss 1.242628\n",
      "batch 130, gen_loss 1.265591, disc_loss 1.160067\n",
      "batch 131, gen_loss 1.180870, disc_loss 1.096790\n",
      "batch 132, gen_loss 1.177995, disc_loss 1.188008\n",
      "batch 133, gen_loss 1.179488, disc_loss 1.192218\n",
      "batch 134, gen_loss 1.168385, disc_loss 1.121923\n",
      "batch 135, gen_loss 1.292831, disc_loss 1.143844\n",
      "batch 136, gen_loss 1.265138, disc_loss 1.177164\n",
      "batch 137, gen_loss 1.250996, disc_loss 1.189375\n",
      "batch 138, gen_loss 1.145021, disc_loss 1.181341\n",
      "batch 139, gen_loss 1.268883, disc_loss 1.155972\n",
      "batch 140, gen_loss 1.219679, disc_loss 1.154887\n",
      "batch 141, gen_loss 1.186129, disc_loss 1.131058\n",
      "batch 142, gen_loss 1.215169, disc_loss 1.251353\n",
      "batch 143, gen_loss 1.201062, disc_loss 1.108941\n",
      "batch 144, gen_loss 1.189215, disc_loss 1.092095\n",
      "batch 145, gen_loss 1.355984, disc_loss 1.057769\n",
      "batch 146, gen_loss 1.365849, disc_loss 1.070740\n",
      "batch 147, gen_loss 1.433082, disc_loss 1.036940\n",
      "batch 148, gen_loss 1.342697, disc_loss 1.016222\n",
      "batch 149, gen_loss 1.483031, disc_loss 0.889597\n",
      "batch 150, gen_loss 1.517996, disc_loss 0.963528\n",
      "batch 151, gen_loss 1.545961, disc_loss 0.914263\n",
      "batch 152, gen_loss 1.492630, disc_loss 0.887734\n",
      "batch 153, gen_loss 1.431622, disc_loss 0.908432\n",
      "batch 154, gen_loss 1.374837, disc_loss 0.860036\n",
      "batch 155, gen_loss 1.319239, disc_loss 0.930149\n",
      "batch 156, gen_loss 1.355626, disc_loss 0.857426\n",
      "batch 157, gen_loss 1.406743, disc_loss 0.768273\n",
      "batch 158, gen_loss 1.611413, disc_loss 0.783886\n",
      "batch 159, gen_loss 1.615353, disc_loss 0.768565\n",
      "batch 160, gen_loss 1.756710, disc_loss 0.777162\n",
      "batch 161, gen_loss 1.701592, disc_loss 0.694859\n",
      "batch 162, gen_loss 1.682566, disc_loss 0.727029\n",
      "batch 163, gen_loss 1.606716, disc_loss 0.746097\n",
      "batch 164, gen_loss 1.592507, disc_loss 0.799947\n",
      "batch 165, gen_loss 1.514221, disc_loss 0.739106\n",
      "batch 166, gen_loss 1.475496, disc_loss 0.772365\n",
      "batch 167, gen_loss 1.540545, disc_loss 0.701872\n",
      "batch 168, gen_loss 1.589799, disc_loss 0.724035\n",
      "batch 169, gen_loss 1.625167, disc_loss 0.663880\n",
      "batch 170, gen_loss 1.689711, disc_loss 0.667802\n",
      "batch 171, gen_loss 1.803119, disc_loss 0.715481\n",
      "batch 172, gen_loss 1.781214, disc_loss 0.787904\n",
      "batch 173, gen_loss 1.731312, disc_loss 0.822684\n",
      "batch 174, gen_loss 1.661612, disc_loss 0.766652\n",
      "batch 175, gen_loss 1.419700, disc_loss 0.793969\n",
      "batch 176, gen_loss 1.401533, disc_loss 0.778935\n",
      "batch 177, gen_loss 1.499665, disc_loss 0.854052\n",
      "batch 178, gen_loss 1.481641, disc_loss 0.888365\n",
      "batch 179, gen_loss 1.557074, disc_loss 0.784623\n",
      "batch 180, gen_loss 1.633967, disc_loss 0.798178\n",
      "batch 181, gen_loss 1.662278, disc_loss 0.899587\n",
      "batch 182, gen_loss 1.675837, disc_loss 0.906620\n",
      "batch 183, gen_loss 1.449307, disc_loss 0.808751\n",
      "batch 184, gen_loss 1.353964, disc_loss 0.847983\n",
      "batch 185, gen_loss 1.442638, disc_loss 0.842925\n",
      "batch 186, gen_loss 1.335083, disc_loss 0.899015\n",
      "batch 187, gen_loss 1.507506, disc_loss 0.873476\n",
      "batch 188, gen_loss 1.606163, disc_loss 0.944149\n",
      "batch 189, gen_loss 1.556502, disc_loss 0.904605\n",
      "batch 190, gen_loss 1.694101, disc_loss 0.849955\n",
      "batch 191, gen_loss 1.740635, disc_loss 0.865538\n",
      "batch 192, gen_loss 1.656578, disc_loss 0.871480\n",
      "batch 193, gen_loss 1.474964, disc_loss 0.771955\n",
      "batch 194, gen_loss 1.376647, disc_loss 0.856674\n",
      "batch 195, gen_loss 1.388034, disc_loss 0.876385\n",
      "batch 196, gen_loss 1.432644, disc_loss 0.877208\n",
      "batch 197, gen_loss 1.396053, disc_loss 0.909495\n",
      "batch 198, gen_loss 1.574682, disc_loss 0.884022\n",
      "batch 199, gen_loss 1.491190, disc_loss 0.903911\n",
      "batch 200, gen_loss 1.504356, disc_loss 0.915179\n",
      "batch 201, gen_loss 1.512912, disc_loss 0.895654\n",
      "batch 202, gen_loss 1.386580, disc_loss 0.902153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 203, gen_loss 1.394048, disc_loss 0.922243\n",
      "batch 204, gen_loss 1.316135, disc_loss 0.928988\n",
      "batch 205, gen_loss 1.387753, disc_loss 0.846603\n",
      "batch 206, gen_loss 1.416278, disc_loss 0.895127\n",
      "batch 207, gen_loss 1.430215, disc_loss 0.882215\n",
      "batch 208, gen_loss 1.430339, disc_loss 0.918037\n",
      "batch 209, gen_loss 1.455655, disc_loss 0.876649\n",
      "batch 210, gen_loss 1.535171, disc_loss 0.862882\n",
      "batch 211, gen_loss 1.486662, disc_loss 0.892207\n",
      "batch 212, gen_loss 1.513358, disc_loss 0.893194\n",
      "batch 213, gen_loss 1.434102, disc_loss 0.821072\n",
      "batch 214, gen_loss 1.475885, disc_loss 0.861402\n",
      "batch 215, gen_loss 1.344587, disc_loss 0.940089\n",
      "batch 216, gen_loss 1.384505, disc_loss 0.919912\n",
      "batch 217, gen_loss 1.386135, disc_loss 0.866691\n",
      "batch 218, gen_loss 1.341981, disc_loss 0.885817\n",
      "batch 219, gen_loss 1.438775, disc_loss 0.809093\n",
      "batch 220, gen_loss 1.381358, disc_loss 0.855979\n",
      "batch 221, gen_loss 1.473537, disc_loss 0.914023\n",
      "batch 222, gen_loss 1.487942, disc_loss 0.907977\n",
      "batch 223, gen_loss 1.426790, disc_loss 0.936811\n",
      "batch 224, gen_loss 1.346836, disc_loss 0.951472\n",
      "batch 225, gen_loss 1.224505, disc_loss 0.956948\n",
      "batch 226, gen_loss 1.142869, disc_loss 0.895411\n",
      "batch 227, gen_loss 1.165828, disc_loss 0.884153\n",
      "batch 228, gen_loss 1.290970, disc_loss 0.942392\n",
      "batch 229, gen_loss 1.354583, disc_loss 0.876610\n",
      "batch 230, gen_loss 1.435220, disc_loss 0.933512\n",
      "batch 231, gen_loss 1.521896, disc_loss 1.011296\n",
      "batch 232, gen_loss 1.443650, disc_loss 1.016028\n",
      "batch 233, gen_loss 1.329326, disc_loss 1.019901\n",
      "batch 234, gen_loss 1.260544, disc_loss 1.101901\n",
      "Time for epoch20is 7.612335681915283 sec\n",
      "batch 0, gen_loss 1.183900, disc_loss 0.907947\n",
      "batch 1, gen_loss 1.092024, disc_loss 1.007147\n",
      "batch 2, gen_loss 1.162614, disc_loss 1.074603\n",
      "batch 3, gen_loss 1.249471, disc_loss 1.001712\n",
      "batch 4, gen_loss 1.357501, disc_loss 0.981814\n",
      "batch 5, gen_loss 1.359834, disc_loss 1.043190\n",
      "batch 6, gen_loss 1.414023, disc_loss 1.071056\n",
      "batch 7, gen_loss 1.354472, disc_loss 1.057214\n",
      "batch 8, gen_loss 1.241770, disc_loss 0.983260\n",
      "batch 9, gen_loss 1.108331, disc_loss 0.996186\n",
      "batch 10, gen_loss 1.012803, disc_loss 1.148629\n",
      "batch 11, gen_loss 1.051808, disc_loss 1.170774\n",
      "batch 12, gen_loss 1.150149, disc_loss 1.169066\n",
      "batch 13, gen_loss 1.252955, disc_loss 1.089889\n",
      "batch 14, gen_loss 1.263642, disc_loss 1.125734\n",
      "batch 15, gen_loss 1.266896, disc_loss 1.063808\n",
      "batch 16, gen_loss 1.203272, disc_loss 1.106748\n",
      "batch 17, gen_loss 1.138742, disc_loss 1.132449\n",
      "batch 18, gen_loss 1.202137, disc_loss 1.060396\n",
      "batch 19, gen_loss 1.146025, disc_loss 1.165005\n",
      "batch 20, gen_loss 1.177698, disc_loss 1.149841\n",
      "batch 21, gen_loss 1.186523, disc_loss 1.093090\n",
      "batch 22, gen_loss 1.191649, disc_loss 1.077273\n",
      "batch 23, gen_loss 1.215027, disc_loss 1.157547\n",
      "batch 24, gen_loss 1.266667, disc_loss 1.201963\n",
      "batch 25, gen_loss 1.220351, disc_loss 1.093914\n",
      "batch 26, gen_loss 1.207916, disc_loss 1.143139\n",
      "batch 27, gen_loss 1.192210, disc_loss 1.189892\n",
      "batch 28, gen_loss 1.077802, disc_loss 1.136402\n",
      "batch 29, gen_loss 1.097233, disc_loss 1.178831\n",
      "batch 30, gen_loss 1.042839, disc_loss 1.201209\n",
      "batch 31, gen_loss 1.088846, disc_loss 1.210289\n",
      "batch 32, gen_loss 1.097962, disc_loss 1.263952\n",
      "batch 33, gen_loss 1.081266, disc_loss 1.170987\n",
      "batch 34, gen_loss 1.120399, disc_loss 1.175919\n",
      "batch 35, gen_loss 1.211296, disc_loss 1.174885\n",
      "batch 36, gen_loss 1.197424, disc_loss 1.181535\n",
      "batch 37, gen_loss 1.274391, disc_loss 1.155600\n",
      "batch 38, gen_loss 1.166758, disc_loss 1.121618\n",
      "batch 39, gen_loss 1.126911, disc_loss 1.129117\n",
      "batch 40, gen_loss 1.111794, disc_loss 1.147113\n",
      "batch 41, gen_loss 1.092423, disc_loss 1.166387\n",
      "batch 42, gen_loss 1.091248, disc_loss 1.206387\n",
      "batch 43, gen_loss 1.071994, disc_loss 1.114896\n",
      "batch 44, gen_loss 1.237341, disc_loss 1.029668\n",
      "batch 45, gen_loss 1.226473, disc_loss 1.096866\n",
      "batch 46, gen_loss 1.299993, disc_loss 1.114241\n",
      "batch 47, gen_loss 1.250802, disc_loss 1.108733\n",
      "batch 48, gen_loss 1.172821, disc_loss 1.003132\n",
      "batch 49, gen_loss 1.201192, disc_loss 1.091640\n",
      "batch 50, gen_loss 1.305959, disc_loss 0.981052\n",
      "batch 51, gen_loss 1.280221, disc_loss 0.985489\n",
      "batch 52, gen_loss 1.238739, disc_loss 0.953763\n",
      "batch 53, gen_loss 1.203449, disc_loss 1.020402\n",
      "batch 54, gen_loss 1.300786, disc_loss 0.925359\n",
      "batch 55, gen_loss 1.248151, disc_loss 0.928739\n",
      "batch 56, gen_loss 1.382551, disc_loss 0.903604\n",
      "batch 57, gen_loss 1.361327, disc_loss 0.868099\n",
      "batch 58, gen_loss 1.385376, disc_loss 0.910360\n",
      "batch 59, gen_loss 1.406480, disc_loss 0.839977\n",
      "batch 60, gen_loss 1.400012, disc_loss 0.836075\n",
      "batch 61, gen_loss 1.370977, disc_loss 0.799937\n",
      "batch 62, gen_loss 1.381741, disc_loss 0.812979\n",
      "batch 63, gen_loss 1.382844, disc_loss 0.775952\n",
      "batch 64, gen_loss 1.433829, disc_loss 0.745264\n",
      "batch 65, gen_loss 1.556414, disc_loss 0.768533\n",
      "batch 66, gen_loss 1.633650, disc_loss 0.744820\n",
      "batch 67, gen_loss 1.509776, disc_loss 0.740592\n",
      "batch 68, gen_loss 1.595752, disc_loss 0.672843\n",
      "batch 69, gen_loss 1.514696, disc_loss 0.694083\n",
      "batch 70, gen_loss 1.561661, disc_loss 0.697733\n",
      "batch 71, gen_loss 1.600991, disc_loss 0.673865\n",
      "batch 72, gen_loss 1.648804, disc_loss 0.669191\n",
      "batch 73, gen_loss 1.624284, disc_loss 0.657201\n",
      "batch 74, gen_loss 1.744829, disc_loss 0.637542\n",
      "batch 75, gen_loss 1.724734, disc_loss 0.648495\n",
      "batch 76, gen_loss 1.643927, disc_loss 0.631236\n",
      "batch 77, gen_loss 1.671250, disc_loss 0.609372\n",
      "batch 78, gen_loss 1.630366, disc_loss 0.614912\n",
      "batch 79, gen_loss 1.742836, disc_loss 0.613915\n",
      "batch 80, gen_loss 1.720252, disc_loss 0.656025\n",
      "batch 81, gen_loss 1.695004, disc_loss 0.617070\n",
      "batch 82, gen_loss 1.698637, disc_loss 0.581205\n",
      "batch 83, gen_loss 1.616425, disc_loss 0.659193\n",
      "batch 84, gen_loss 1.633075, disc_loss 0.598949\n",
      "batch 85, gen_loss 1.631239, disc_loss 0.640065\n",
      "batch 86, gen_loss 1.646733, disc_loss 0.649970\n",
      "batch 87, gen_loss 1.703248, disc_loss 0.610453\n",
      "batch 88, gen_loss 1.697103, disc_loss 0.655081\n",
      "batch 89, gen_loss 1.779061, disc_loss 0.655729\n",
      "batch 90, gen_loss 1.734809, disc_loss 0.590536\n",
      "batch 91, gen_loss 1.697995, disc_loss 0.602192\n",
      "batch 92, gen_loss 1.694027, disc_loss 0.630670\n",
      "batch 93, gen_loss 1.603101, disc_loss 0.651646\n",
      "batch 94, gen_loss 1.737262, disc_loss 0.604912\n",
      "batch 95, gen_loss 1.828862, disc_loss 0.615002\n",
      "batch 96, gen_loss 1.804086, disc_loss 0.651934\n",
      "batch 97, gen_loss 1.748220, disc_loss 0.622086\n",
      "batch 98, gen_loss 1.714846, disc_loss 0.654618\n",
      "batch 99, gen_loss 1.657889, disc_loss 0.605292\n",
      "batch 100, gen_loss 1.766413, disc_loss 0.617868\n",
      "batch 101, gen_loss 1.782681, disc_loss 0.693233\n",
      "batch 102, gen_loss 1.745709, disc_loss 0.675653\n",
      "batch 103, gen_loss 1.734712, disc_loss 0.680282\n",
      "batch 104, gen_loss 1.662209, disc_loss 0.673676\n",
      "batch 105, gen_loss 1.732614, disc_loss 0.709106\n",
      "batch 106, gen_loss 1.719427, disc_loss 0.732209\n",
      "batch 107, gen_loss 1.712605, disc_loss 0.649791\n",
      "batch 108, gen_loss 1.709760, disc_loss 0.634752\n",
      "batch 109, gen_loss 1.699650, disc_loss 0.712888\n",
      "batch 110, gen_loss 1.740198, disc_loss 0.721492\n",
      "batch 111, gen_loss 1.680103, disc_loss 0.731047\n",
      "batch 112, gen_loss 1.614830, disc_loss 0.695133\n",
      "batch 113, gen_loss 1.610222, disc_loss 0.704826\n",
      "batch 114, gen_loss 1.635685, disc_loss 0.745727\n",
      "batch 115, gen_loss 1.550463, disc_loss 0.741404\n",
      "batch 116, gen_loss 1.582671, disc_loss 0.764584\n",
      "batch 117, gen_loss 1.663050, disc_loss 0.702265\n",
      "batch 118, gen_loss 1.617694, disc_loss 0.799433\n",
      "batch 119, gen_loss 1.643998, disc_loss 0.756804\n",
      "batch 120, gen_loss 1.529310, disc_loss 0.739884\n",
      "batch 121, gen_loss 1.556162, disc_loss 0.733741\n",
      "batch 122, gen_loss 1.490726, disc_loss 0.790876\n",
      "batch 123, gen_loss 1.551775, disc_loss 0.779141\n",
      "batch 124, gen_loss 1.501535, disc_loss 0.794646\n",
      "batch 125, gen_loss 1.630878, disc_loss 0.751861\n",
      "batch 126, gen_loss 1.636509, disc_loss 0.719865\n",
      "batch 127, gen_loss 1.565388, disc_loss 0.808396\n",
      "batch 128, gen_loss 1.496314, disc_loss 0.842954\n",
      "batch 129, gen_loss 1.400984, disc_loss 0.801064\n",
      "batch 130, gen_loss 1.483753, disc_loss 0.727372\n",
      "batch 131, gen_loss 1.583535, disc_loss 0.781508\n",
      "batch 132, gen_loss 1.576619, disc_loss 0.776042\n",
      "batch 133, gen_loss 1.586441, disc_loss 0.746641\n",
      "batch 134, gen_loss 1.585859, disc_loss 0.865012\n",
      "batch 135, gen_loss 1.529366, disc_loss 0.766575\n",
      "batch 136, gen_loss 1.504210, disc_loss 0.697876\n",
      "batch 137, gen_loss 1.416517, disc_loss 0.817907\n",
      "batch 138, gen_loss 1.400354, disc_loss 0.832665\n",
      "batch 139, gen_loss 1.506887, disc_loss 0.800618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 140, gen_loss 1.558348, disc_loss 0.794105\n",
      "batch 141, gen_loss 1.595312, disc_loss 0.788344\n",
      "batch 142, gen_loss 1.589227, disc_loss 0.713117\n",
      "batch 143, gen_loss 1.512027, disc_loss 0.811686\n",
      "batch 144, gen_loss 1.572992, disc_loss 0.760399\n",
      "batch 145, gen_loss 1.553528, disc_loss 0.786722\n",
      "batch 146, gen_loss 1.626755, disc_loss 0.732511\n",
      "batch 147, gen_loss 1.631189, disc_loss 0.791485\n",
      "batch 148, gen_loss 1.563071, disc_loss 0.729850\n",
      "batch 149, gen_loss 1.556672, disc_loss 0.685926\n",
      "batch 150, gen_loss 1.560990, disc_loss 0.813920\n",
      "batch 151, gen_loss 1.549000, disc_loss 0.745132\n",
      "batch 152, gen_loss 1.575956, disc_loss 0.848560\n",
      "batch 153, gen_loss 1.563007, disc_loss 0.709463\n",
      "batch 154, gen_loss 1.503820, disc_loss 0.751377\n",
      "batch 155, gen_loss 1.698534, disc_loss 0.759328\n",
      "batch 156, gen_loss 1.767657, disc_loss 0.816555\n",
      "batch 157, gen_loss 1.652316, disc_loss 0.799137\n",
      "batch 158, gen_loss 1.605231, disc_loss 0.770600\n",
      "batch 159, gen_loss 1.502410, disc_loss 0.759316\n",
      "batch 160, gen_loss 1.511258, disc_loss 0.870663\n",
      "batch 161, gen_loss 1.600362, disc_loss 0.810789\n",
      "batch 162, gen_loss 1.524660, disc_loss 0.773193\n",
      "batch 163, gen_loss 1.649169, disc_loss 0.820471\n",
      "batch 164, gen_loss 1.600392, disc_loss 0.905226\n",
      "batch 165, gen_loss 1.610164, disc_loss 0.832989\n",
      "batch 166, gen_loss 1.577425, disc_loss 0.900347\n",
      "batch 167, gen_loss 1.522583, disc_loss 0.786071\n",
      "batch 168, gen_loss 1.438473, disc_loss 0.873261\n",
      "batch 169, gen_loss 1.495110, disc_loss 0.831751\n",
      "batch 170, gen_loss 1.557275, disc_loss 0.789504\n",
      "batch 171, gen_loss 1.644282, disc_loss 0.849852\n",
      "batch 172, gen_loss 1.749850, disc_loss 0.882059\n",
      "batch 173, gen_loss 1.690905, disc_loss 0.830369\n",
      "batch 174, gen_loss 1.635723, disc_loss 0.782508\n",
      "batch 175, gen_loss 1.456314, disc_loss 0.881689\n",
      "batch 176, gen_loss 1.539964, disc_loss 0.867578\n",
      "batch 177, gen_loss 1.555510, disc_loss 0.816954\n",
      "batch 178, gen_loss 1.482397, disc_loss 0.943508\n",
      "batch 179, gen_loss 1.572144, disc_loss 0.775645\n",
      "batch 180, gen_loss 1.640364, disc_loss 0.858901\n",
      "batch 181, gen_loss 1.672592, disc_loss 0.819953\n",
      "batch 182, gen_loss 1.591576, disc_loss 0.802974\n",
      "batch 183, gen_loss 1.610102, disc_loss 0.855770\n",
      "batch 184, gen_loss 1.626440, disc_loss 0.835997\n",
      "batch 185, gen_loss 1.617936, disc_loss 0.761513\n",
      "batch 186, gen_loss 1.635291, disc_loss 0.774559\n",
      "batch 187, gen_loss 1.491368, disc_loss 0.778874\n",
      "batch 188, gen_loss 1.521388, disc_loss 0.782449\n",
      "batch 189, gen_loss 1.547508, disc_loss 0.803053\n",
      "batch 190, gen_loss 1.615263, disc_loss 0.727100\n",
      "batch 191, gen_loss 1.672041, disc_loss 0.773568\n",
      "batch 192, gen_loss 1.660063, disc_loss 0.821319\n",
      "batch 193, gen_loss 1.746050, disc_loss 0.735645\n",
      "batch 194, gen_loss 1.737806, disc_loss 0.784859\n",
      "batch 195, gen_loss 1.668649, disc_loss 0.763579\n",
      "batch 196, gen_loss 1.646620, disc_loss 0.747362\n",
      "batch 197, gen_loss 1.567087, disc_loss 0.685247\n",
      "batch 198, gen_loss 1.583227, disc_loss 0.688570\n",
      "batch 199, gen_loss 1.643216, disc_loss 0.688586\n",
      "batch 200, gen_loss 1.763669, disc_loss 0.609969\n",
      "batch 201, gen_loss 1.978119, disc_loss 0.640379\n",
      "batch 202, gen_loss 2.089946, disc_loss 0.657366\n",
      "batch 203, gen_loss 1.944100, disc_loss 0.637692\n",
      "batch 204, gen_loss 1.884072, disc_loss 0.766392\n",
      "batch 205, gen_loss 1.760773, disc_loss 0.620687\n",
      "batch 206, gen_loss 1.705512, disc_loss 0.698160\n",
      "batch 207, gen_loss 1.812927, disc_loss 0.607828\n",
      "batch 208, gen_loss 1.690377, disc_loss 0.683282\n",
      "batch 209, gen_loss 1.673398, disc_loss 0.711289\n",
      "batch 210, gen_loss 1.848247, disc_loss 0.637156\n",
      "batch 211, gen_loss 1.957257, disc_loss 0.652510\n",
      "batch 212, gen_loss 1.909284, disc_loss 0.773567\n",
      "batch 213, gen_loss 1.876789, disc_loss 0.695118\n",
      "batch 214, gen_loss 1.864372, disc_loss 0.705515\n",
      "batch 215, gen_loss 1.824664, disc_loss 0.647161\n",
      "batch 216, gen_loss 1.832938, disc_loss 0.683234\n",
      "batch 217, gen_loss 2.035684, disc_loss 0.667696\n",
      "batch 218, gen_loss 1.925199, disc_loss 0.652224\n",
      "batch 219, gen_loss 1.758434, disc_loss 0.687275\n",
      "batch 220, gen_loss 1.871770, disc_loss 0.766710\n",
      "batch 221, gen_loss 1.887486, disc_loss 0.735832\n",
      "batch 222, gen_loss 1.871224, disc_loss 0.791098\n",
      "batch 223, gen_loss 1.856741, disc_loss 0.725175\n",
      "batch 224, gen_loss 1.804313, disc_loss 0.806302\n",
      "batch 225, gen_loss 1.826127, disc_loss 0.705033\n",
      "batch 226, gen_loss 1.653183, disc_loss 0.796440\n",
      "batch 227, gen_loss 1.796676, disc_loss 0.762236\n",
      "batch 228, gen_loss 1.878092, disc_loss 0.766299\n",
      "batch 229, gen_loss 2.024741, disc_loss 0.770338\n",
      "batch 230, gen_loss 1.894097, disc_loss 0.798794\n",
      "batch 231, gen_loss 1.951737, disc_loss 0.660489\n",
      "batch 232, gen_loss 1.847655, disc_loss 0.759431\n",
      "batch 233, gen_loss 1.870872, disc_loss 0.711201\n",
      "batch 234, gen_loss 2.040269, disc_loss 0.708531\n",
      "Time for epoch21is 7.603698492050171 sec\n",
      "batch 0, gen_loss 1.802312, disc_loss 0.728080\n",
      "batch 1, gen_loss 1.969615, disc_loss 0.659646\n",
      "batch 2, gen_loss 1.869116, disc_loss 0.697165\n",
      "batch 3, gen_loss 1.957930, disc_loss 0.721431\n",
      "batch 4, gen_loss 1.913627, disc_loss 0.754711\n",
      "batch 5, gen_loss 1.956164, disc_loss 0.726336\n",
      "batch 6, gen_loss 1.863818, disc_loss 0.739557\n",
      "batch 7, gen_loss 1.779299, disc_loss 0.697179\n",
      "batch 8, gen_loss 1.870274, disc_loss 0.639705\n",
      "batch 9, gen_loss 1.907906, disc_loss 0.721613\n",
      "batch 10, gen_loss 1.896867, disc_loss 0.785242\n",
      "batch 11, gen_loss 1.921209, disc_loss 0.608826\n",
      "batch 12, gen_loss 2.010109, disc_loss 0.623613\n",
      "batch 13, gen_loss 1.951084, disc_loss 0.657884\n",
      "batch 14, gen_loss 1.888062, disc_loss 0.771053\n",
      "batch 15, gen_loss 2.018948, disc_loss 0.635803\n",
      "batch 16, gen_loss 1.727023, disc_loss 0.715161\n",
      "batch 17, gen_loss 1.827340, disc_loss 0.675649\n",
      "batch 18, gen_loss 1.816725, disc_loss 0.740301\n",
      "batch 19, gen_loss 1.775040, disc_loss 0.740411\n",
      "batch 20, gen_loss 1.878731, disc_loss 0.706165\n",
      "batch 21, gen_loss 1.786323, disc_loss 0.741244\n",
      "batch 22, gen_loss 1.799889, disc_loss 0.699223\n",
      "batch 23, gen_loss 1.739196, disc_loss 0.794615\n",
      "batch 24, gen_loss 1.667271, disc_loss 0.736120\n",
      "batch 25, gen_loss 1.591224, disc_loss 0.789134\n",
      "batch 26, gen_loss 1.509076, disc_loss 0.816581\n",
      "batch 27, gen_loss 1.564279, disc_loss 0.776861\n",
      "batch 28, gen_loss 1.760238, disc_loss 0.696289\n",
      "batch 29, gen_loss 1.631991, disc_loss 0.912539\n",
      "batch 30, gen_loss 1.607444, disc_loss 0.993769\n",
      "batch 31, gen_loss 1.632739, disc_loss 0.947455\n",
      "batch 32, gen_loss 1.473996, disc_loss 0.937544\n",
      "batch 33, gen_loss 1.366156, disc_loss 0.914033\n",
      "batch 34, gen_loss 1.306716, disc_loss 0.945281\n",
      "batch 35, gen_loss 1.250365, disc_loss 0.913350\n",
      "batch 36, gen_loss 1.388675, disc_loss 0.993169\n",
      "batch 37, gen_loss 1.444870, disc_loss 0.993693\n",
      "batch 38, gen_loss 1.510874, disc_loss 0.882004\n",
      "batch 39, gen_loss 1.516433, disc_loss 0.985854\n",
      "batch 40, gen_loss 1.374535, disc_loss 1.065867\n",
      "batch 41, gen_loss 1.195347, disc_loss 1.142295\n",
      "batch 42, gen_loss 1.175301, disc_loss 1.165834\n",
      "batch 43, gen_loss 1.313214, disc_loss 1.020116\n",
      "batch 44, gen_loss 1.376225, disc_loss 1.118994\n",
      "batch 45, gen_loss 1.331843, disc_loss 1.134008\n",
      "batch 46, gen_loss 1.272215, disc_loss 1.153028\n",
      "batch 47, gen_loss 1.236540, disc_loss 1.075933\n",
      "batch 48, gen_loss 1.141525, disc_loss 1.170240\n",
      "batch 49, gen_loss 1.229036, disc_loss 1.191253\n",
      "batch 50, gen_loss 1.235974, disc_loss 1.190580\n",
      "batch 51, gen_loss 1.308932, disc_loss 1.173426\n",
      "batch 52, gen_loss 1.302524, disc_loss 1.164543\n",
      "batch 53, gen_loss 1.210906, disc_loss 1.260834\n",
      "batch 54, gen_loss 1.208067, disc_loss 1.177368\n",
      "batch 55, gen_loss 1.256859, disc_loss 1.042850\n",
      "batch 56, gen_loss 1.197789, disc_loss 1.164785\n",
      "batch 57, gen_loss 1.264334, disc_loss 1.214886\n",
      "batch 58, gen_loss 1.115168, disc_loss 1.257905\n",
      "batch 59, gen_loss 1.149930, disc_loss 1.074241\n",
      "batch 60, gen_loss 1.031495, disc_loss 1.216397\n",
      "batch 61, gen_loss 1.157201, disc_loss 1.073574\n",
      "batch 62, gen_loss 1.348752, disc_loss 1.088498\n",
      "batch 63, gen_loss 1.414766, disc_loss 1.079522\n",
      "batch 64, gen_loss 1.382622, disc_loss 1.146020\n",
      "batch 65, gen_loss 1.258255, disc_loss 1.054840\n",
      "batch 66, gen_loss 1.246689, disc_loss 0.960564\n",
      "batch 67, gen_loss 1.179431, disc_loss 1.064748\n",
      "batch 68, gen_loss 1.294904, disc_loss 0.877994\n",
      "batch 69, gen_loss 1.403109, disc_loss 0.929633\n",
      "batch 70, gen_loss 1.490581, disc_loss 0.971724\n",
      "batch 71, gen_loss 1.561361, disc_loss 0.994143\n",
      "batch 72, gen_loss 1.417460, disc_loss 0.837909\n",
      "batch 73, gen_loss 1.394115, disc_loss 0.920662\n",
      "batch 74, gen_loss 1.351792, disc_loss 0.973658\n",
      "batch 75, gen_loss 1.417081, disc_loss 0.893972\n",
      "batch 76, gen_loss 1.417109, disc_loss 0.804405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 77, gen_loss 1.443743, disc_loss 0.819736\n",
      "batch 78, gen_loss 1.476006, disc_loss 0.856813\n",
      "batch 79, gen_loss 1.603155, disc_loss 0.777545\n",
      "batch 80, gen_loss 1.653087, disc_loss 0.725973\n",
      "batch 81, gen_loss 1.648309, disc_loss 0.788149\n",
      "batch 82, gen_loss 1.641639, disc_loss 0.710036\n",
      "batch 83, gen_loss 1.507335, disc_loss 0.713283\n",
      "batch 84, gen_loss 1.594149, disc_loss 0.653226\n",
      "batch 85, gen_loss 1.653851, disc_loss 0.667687\n",
      "batch 86, gen_loss 1.836340, disc_loss 0.712922\n",
      "batch 87, gen_loss 1.865585, disc_loss 0.661480\n",
      "batch 88, gen_loss 1.748076, disc_loss 0.697483\n",
      "batch 89, gen_loss 1.663743, disc_loss 0.644622\n",
      "batch 90, gen_loss 1.620543, disc_loss 0.625105\n",
      "batch 91, gen_loss 1.638589, disc_loss 0.580798\n",
      "batch 92, gen_loss 1.813352, disc_loss 0.592385\n",
      "batch 93, gen_loss 1.896069, disc_loss 0.625788\n",
      "batch 94, gen_loss 1.898134, disc_loss 0.610823\n",
      "batch 95, gen_loss 1.889036, disc_loss 0.604299\n",
      "batch 96, gen_loss 1.921010, disc_loss 0.545432\n",
      "batch 97, gen_loss 1.813981, disc_loss 0.595608\n",
      "batch 98, gen_loss 1.639246, disc_loss 0.645787\n",
      "batch 99, gen_loss 1.659631, disc_loss 0.591170\n",
      "batch 100, gen_loss 1.680255, disc_loss 0.563550\n",
      "batch 101, gen_loss 1.758562, disc_loss 0.635291\n",
      "batch 102, gen_loss 1.913580, disc_loss 0.602638\n",
      "batch 103, gen_loss 1.828306, disc_loss 0.623348\n",
      "batch 104, gen_loss 1.849541, disc_loss 0.597278\n",
      "batch 105, gen_loss 1.914812, disc_loss 0.584345\n",
      "batch 106, gen_loss 1.731416, disc_loss 0.582276\n",
      "batch 107, gen_loss 1.706563, disc_loss 0.634726\n",
      "batch 108, gen_loss 1.767669, disc_loss 0.613149\n",
      "batch 109, gen_loss 1.863562, disc_loss 0.579970\n",
      "batch 110, gen_loss 1.840274, disc_loss 0.629661\n",
      "batch 111, gen_loss 1.860226, disc_loss 0.549579\n",
      "batch 112, gen_loss 1.866276, disc_loss 0.670152\n",
      "batch 113, gen_loss 1.828953, disc_loss 0.617448\n",
      "batch 114, gen_loss 1.663262, disc_loss 0.630459\n",
      "batch 115, gen_loss 1.661222, disc_loss 0.654942\n",
      "batch 116, gen_loss 1.681745, disc_loss 0.605278\n",
      "batch 117, gen_loss 1.690850, disc_loss 0.627655\n",
      "batch 118, gen_loss 1.794082, disc_loss 0.646265\n",
      "batch 119, gen_loss 1.758554, disc_loss 0.641362\n",
      "batch 120, gen_loss 1.747126, disc_loss 0.656713\n",
      "batch 121, gen_loss 1.714686, disc_loss 0.673542\n",
      "batch 122, gen_loss 1.641834, disc_loss 0.665713\n",
      "batch 123, gen_loss 1.707029, disc_loss 0.642023\n",
      "batch 124, gen_loss 1.586397, disc_loss 0.679117\n",
      "batch 125, gen_loss 1.652940, disc_loss 0.625873\n",
      "batch 126, gen_loss 1.798377, disc_loss 0.615872\n",
      "batch 127, gen_loss 1.736793, disc_loss 0.677166\n",
      "batch 128, gen_loss 1.668287, disc_loss 0.696490\n",
      "batch 129, gen_loss 1.656406, disc_loss 0.686872\n",
      "batch 130, gen_loss 1.640927, disc_loss 0.706034\n",
      "batch 131, gen_loss 1.624211, disc_loss 0.671183\n",
      "batch 132, gen_loss 1.539256, disc_loss 0.823990\n",
      "batch 133, gen_loss 1.698107, disc_loss 0.717102\n",
      "batch 134, gen_loss 1.754533, disc_loss 0.698971\n",
      "batch 135, gen_loss 1.735811, disc_loss 0.839779\n",
      "batch 136, gen_loss 1.732084, disc_loss 0.726081\n",
      "batch 137, gen_loss 1.690071, disc_loss 0.749854\n",
      "batch 138, gen_loss 1.746910, disc_loss 0.777880\n",
      "batch 139, gen_loss 1.488922, disc_loss 0.772163\n",
      "batch 140, gen_loss 1.569870, disc_loss 0.779608\n",
      "batch 141, gen_loss 1.480127, disc_loss 0.844659\n",
      "batch 142, gen_loss 1.575203, disc_loss 0.823221\n",
      "batch 143, gen_loss 1.682346, disc_loss 0.837454\n",
      "batch 144, gen_loss 1.638177, disc_loss 0.780325\n",
      "batch 145, gen_loss 1.661004, disc_loss 0.771675\n",
      "batch 146, gen_loss 1.649942, disc_loss 0.790672\n",
      "batch 147, gen_loss 1.634177, disc_loss 0.833996\n",
      "batch 148, gen_loss 1.507119, disc_loss 0.856049\n",
      "batch 149, gen_loss 1.509996, disc_loss 0.891334\n",
      "batch 150, gen_loss 1.586277, disc_loss 0.845379\n",
      "batch 151, gen_loss 1.735374, disc_loss 0.783246\n",
      "batch 152, gen_loss 1.602595, disc_loss 0.914351\n",
      "batch 153, gen_loss 1.718343, disc_loss 0.798140\n",
      "batch 154, gen_loss 1.623060, disc_loss 0.847859\n",
      "batch 155, gen_loss 1.630671, disc_loss 0.807576\n",
      "batch 156, gen_loss 1.664449, disc_loss 0.867011\n",
      "batch 157, gen_loss 1.643052, disc_loss 0.787499\n",
      "batch 158, gen_loss 1.611483, disc_loss 0.800854\n",
      "batch 159, gen_loss 1.794300, disc_loss 0.793252\n",
      "batch 160, gen_loss 1.817451, disc_loss 0.760578\n",
      "batch 161, gen_loss 1.844078, disc_loss 0.761038\n",
      "batch 162, gen_loss 1.905586, disc_loss 0.700342\n",
      "batch 163, gen_loss 1.757825, disc_loss 0.748871\n",
      "batch 164, gen_loss 1.770638, disc_loss 0.677569\n",
      "batch 165, gen_loss 1.824009, disc_loss 0.673335\n",
      "batch 166, gen_loss 1.786385, disc_loss 0.719618\n",
      "batch 167, gen_loss 1.866979, disc_loss 0.639347\n",
      "batch 168, gen_loss 1.974251, disc_loss 0.642343\n",
      "batch 169, gen_loss 2.072490, disc_loss 0.611823\n",
      "batch 170, gen_loss 2.091286, disc_loss 0.665332\n",
      "batch 171, gen_loss 2.068822, disc_loss 0.617446\n",
      "batch 172, gen_loss 1.946887, disc_loss 0.626340\n",
      "batch 173, gen_loss 1.954106, disc_loss 0.587298\n",
      "batch 174, gen_loss 2.037416, disc_loss 0.590600\n",
      "batch 175, gen_loss 2.108925, disc_loss 0.568060\n",
      "batch 176, gen_loss 2.219567, disc_loss 0.621256\n",
      "batch 177, gen_loss 2.194825, disc_loss 0.501497\n",
      "batch 178, gen_loss 2.216882, disc_loss 0.493626\n",
      "batch 179, gen_loss 2.166930, disc_loss 0.540894\n",
      "batch 180, gen_loss 2.314434, disc_loss 0.507547\n",
      "batch 181, gen_loss 2.341302, disc_loss 0.540940\n",
      "batch 182, gen_loss 2.225493, disc_loss 0.503961\n",
      "batch 183, gen_loss 2.184617, disc_loss 0.623726\n",
      "batch 184, gen_loss 1.986498, disc_loss 0.566523\n",
      "batch 185, gen_loss 1.905103, disc_loss 0.524394\n",
      "batch 186, gen_loss 2.081331, disc_loss 0.537007\n",
      "batch 187, gen_loss 1.989951, disc_loss 0.555224\n",
      "batch 188, gen_loss 2.190731, disc_loss 0.495014\n",
      "batch 189, gen_loss 2.420361, disc_loss 0.502469\n",
      "batch 190, gen_loss 2.342250, disc_loss 0.558489\n",
      "batch 191, gen_loss 2.255168, disc_loss 0.518899\n",
      "batch 192, gen_loss 2.054277, disc_loss 0.547776\n",
      "batch 193, gen_loss 2.058111, disc_loss 0.522694\n",
      "batch 194, gen_loss 1.940134, disc_loss 0.571251\n",
      "batch 195, gen_loss 1.905930, disc_loss 0.599288\n",
      "batch 196, gen_loss 1.860959, disc_loss 0.598202\n",
      "batch 197, gen_loss 1.930242, disc_loss 0.649276\n",
      "batch 198, gen_loss 1.829774, disc_loss 0.594693\n",
      "batch 199, gen_loss 1.804863, disc_loss 0.683798\n",
      "batch 200, gen_loss 1.711793, disc_loss 0.746474\n",
      "batch 201, gen_loss 1.863370, disc_loss 0.655424\n",
      "batch 202, gen_loss 1.850356, disc_loss 0.635485\n",
      "batch 203, gen_loss 1.760960, disc_loss 0.759643\n",
      "batch 204, gen_loss 1.628505, disc_loss 0.765423\n",
      "batch 205, gen_loss 1.477943, disc_loss 0.777911\n",
      "batch 206, gen_loss 1.454179, disc_loss 0.705068\n",
      "batch 207, gen_loss 1.512148, disc_loss 0.833810\n",
      "batch 208, gen_loss 1.615964, disc_loss 0.794110\n",
      "batch 209, gen_loss 1.750357, disc_loss 0.786423\n",
      "batch 210, gen_loss 1.746343, disc_loss 0.857805\n",
      "batch 211, gen_loss 1.780111, disc_loss 0.769257\n",
      "batch 212, gen_loss 1.638477, disc_loss 0.793710\n",
      "batch 213, gen_loss 1.549143, disc_loss 0.814219\n",
      "batch 214, gen_loss 1.708851, disc_loss 0.855968\n",
      "batch 215, gen_loss 1.658114, disc_loss 0.900142\n",
      "batch 216, gen_loss 1.562931, disc_loss 0.843130\n",
      "batch 217, gen_loss 1.531416, disc_loss 0.944250\n",
      "batch 218, gen_loss 1.630375, disc_loss 0.871084\n",
      "batch 219, gen_loss 1.622978, disc_loss 0.910160\n",
      "batch 220, gen_loss 1.548558, disc_loss 0.976474\n",
      "batch 221, gen_loss 1.549053, disc_loss 0.985922\n",
      "batch 222, gen_loss 1.465631, disc_loss 0.975464\n",
      "batch 223, gen_loss 1.359173, disc_loss 1.055264\n",
      "batch 224, gen_loss 1.388693, disc_loss 0.993884\n",
      "batch 225, gen_loss 1.359578, disc_loss 1.012483\n",
      "batch 226, gen_loss 1.359383, disc_loss 1.070438\n",
      "batch 227, gen_loss 1.320370, disc_loss 1.014444\n",
      "batch 228, gen_loss 1.244374, disc_loss 1.070899\n",
      "batch 229, gen_loss 1.519826, disc_loss 0.999288\n",
      "batch 230, gen_loss 1.431318, disc_loss 1.068011\n",
      "batch 231, gen_loss 1.393893, disc_loss 1.064362\n",
      "batch 232, gen_loss 1.268941, disc_loss 1.025394\n",
      "batch 233, gen_loss 1.127016, disc_loss 1.094690\n",
      "batch 234, gen_loss 1.215959, disc_loss 1.165796\n",
      "Time for epoch22is 7.6097023487091064 sec\n",
      "batch 0, gen_loss 1.345162, disc_loss 1.086616\n",
      "batch 1, gen_loss 1.377853, disc_loss 1.064267\n",
      "batch 2, gen_loss 1.327892, disc_loss 1.141492\n",
      "batch 3, gen_loss 1.367145, disc_loss 1.195532\n",
      "batch 4, gen_loss 1.234890, disc_loss 1.063380\n",
      "batch 5, gen_loss 1.247893, disc_loss 1.134380\n",
      "batch 6, gen_loss 1.189918, disc_loss 1.085454\n",
      "batch 7, gen_loss 1.258339, disc_loss 1.205786\n",
      "batch 8, gen_loss 1.230856, disc_loss 1.155201\n",
      "batch 9, gen_loss 1.209241, disc_loss 1.225889\n",
      "batch 10, gen_loss 1.308582, disc_loss 1.092704\n",
      "batch 11, gen_loss 1.325926, disc_loss 1.152406\n",
      "batch 12, gen_loss 1.309353, disc_loss 1.056917\n",
      "batch 13, gen_loss 1.391852, disc_loss 1.059550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 14, gen_loss 1.389669, disc_loss 1.146237\n",
      "batch 15, gen_loss 1.388692, disc_loss 1.048190\n",
      "batch 16, gen_loss 1.249208, disc_loss 1.073779\n",
      "batch 17, gen_loss 1.291850, disc_loss 0.999094\n",
      "batch 18, gen_loss 1.318599, disc_loss 0.981592\n",
      "batch 19, gen_loss 1.350513, disc_loss 0.959740\n",
      "batch 20, gen_loss 1.465324, disc_loss 1.017717\n",
      "batch 21, gen_loss 1.425126, disc_loss 1.046584\n",
      "batch 22, gen_loss 1.446026, disc_loss 0.924910\n",
      "batch 23, gen_loss 1.343559, disc_loss 0.986859\n",
      "batch 24, gen_loss 1.308729, disc_loss 0.989542\n",
      "batch 25, gen_loss 1.265286, disc_loss 0.957704\n",
      "batch 26, gen_loss 1.309263, disc_loss 0.984591\n",
      "batch 27, gen_loss 1.296531, disc_loss 1.001961\n",
      "batch 28, gen_loss 1.515098, disc_loss 0.864254\n",
      "batch 29, gen_loss 1.714398, disc_loss 0.946082\n",
      "batch 30, gen_loss 1.658390, disc_loss 0.929741\n",
      "batch 31, gen_loss 1.360977, disc_loss 0.952753\n",
      "batch 32, gen_loss 1.254080, disc_loss 0.869151\n",
      "batch 33, gen_loss 1.254346, disc_loss 0.899750\n",
      "batch 34, gen_loss 1.422972, disc_loss 0.794643\n",
      "batch 35, gen_loss 1.581866, disc_loss 0.866705\n",
      "batch 36, gen_loss 1.759438, disc_loss 0.834031\n",
      "batch 37, gen_loss 1.756607, disc_loss 0.807563\n",
      "batch 38, gen_loss 1.633475, disc_loss 0.797272\n",
      "batch 39, gen_loss 1.490203, disc_loss 0.811486\n",
      "batch 40, gen_loss 1.377812, disc_loss 0.824928\n",
      "batch 41, gen_loss 1.425810, disc_loss 0.755523\n",
      "batch 42, gen_loss 1.537197, disc_loss 0.799739\n",
      "batch 43, gen_loss 1.730934, disc_loss 0.743017\n",
      "batch 44, gen_loss 1.917854, disc_loss 0.776667\n",
      "batch 45, gen_loss 1.869535, disc_loss 0.739873\n",
      "batch 46, gen_loss 1.598557, disc_loss 0.767368\n",
      "batch 47, gen_loss 1.492069, disc_loss 0.729655\n",
      "batch 48, gen_loss 1.567583, disc_loss 0.693960\n",
      "batch 49, gen_loss 1.490113, disc_loss 0.729504\n",
      "batch 50, gen_loss 1.583330, disc_loss 0.662307\n",
      "batch 51, gen_loss 1.781224, disc_loss 0.714534\n",
      "batch 52, gen_loss 1.818953, disc_loss 0.649901\n",
      "batch 53, gen_loss 1.835155, disc_loss 0.684661\n",
      "batch 54, gen_loss 1.795048, disc_loss 0.658894\n",
      "batch 55, gen_loss 1.622123, disc_loss 0.703669\n",
      "batch 56, gen_loss 1.682290, disc_loss 0.653697\n",
      "batch 57, gen_loss 1.650429, disc_loss 0.635008\n",
      "batch 58, gen_loss 1.683049, disc_loss 0.656893\n",
      "batch 59, gen_loss 1.681424, disc_loss 0.672467\n",
      "batch 60, gen_loss 1.657917, disc_loss 0.670988\n",
      "batch 61, gen_loss 1.719933, disc_loss 0.700132\n",
      "batch 62, gen_loss 1.663204, disc_loss 0.702323\n",
      "batch 63, gen_loss 1.649829, disc_loss 0.706111\n",
      "batch 64, gen_loss 1.667474, disc_loss 0.705664\n",
      "batch 65, gen_loss 1.699204, disc_loss 0.703302\n",
      "batch 66, gen_loss 1.600673, disc_loss 0.766021\n",
      "batch 67, gen_loss 1.517542, disc_loss 0.740244\n",
      "batch 68, gen_loss 1.635317, disc_loss 0.705864\n",
      "batch 69, gen_loss 1.671824, disc_loss 0.745988\n",
      "batch 70, gen_loss 1.678539, disc_loss 0.727035\n",
      "batch 71, gen_loss 1.676010, disc_loss 0.702572\n",
      "batch 72, gen_loss 1.585804, disc_loss 0.748856\n",
      "batch 73, gen_loss 1.414068, disc_loss 0.799273\n",
      "batch 74, gen_loss 1.457789, disc_loss 0.758556\n",
      "batch 75, gen_loss 1.438750, disc_loss 0.782048\n",
      "batch 76, gen_loss 1.508751, disc_loss 0.686939\n",
      "batch 77, gen_loss 1.617173, disc_loss 0.729983\n",
      "batch 78, gen_loss 1.673163, disc_loss 0.783880\n",
      "batch 79, gen_loss 1.604413, disc_loss 0.752159\n",
      "batch 80, gen_loss 1.568820, disc_loss 0.716604\n",
      "batch 81, gen_loss 1.588606, disc_loss 0.768071\n",
      "batch 82, gen_loss 1.555745, disc_loss 0.760629\n",
      "batch 83, gen_loss 1.466069, disc_loss 0.808739\n",
      "batch 84, gen_loss 1.390665, disc_loss 0.745078\n",
      "batch 85, gen_loss 1.504171, disc_loss 0.807893\n",
      "batch 86, gen_loss 1.513938, disc_loss 0.838320\n",
      "batch 87, gen_loss 1.523749, disc_loss 0.782597\n",
      "batch 88, gen_loss 1.597739, disc_loss 0.795085\n",
      "batch 89, gen_loss 1.473109, disc_loss 0.791385\n",
      "batch 90, gen_loss 1.395275, disc_loss 0.863097\n",
      "batch 91, gen_loss 1.390535, disc_loss 0.794042\n",
      "batch 92, gen_loss 1.351536, disc_loss 0.833060\n",
      "batch 93, gen_loss 1.355892, disc_loss 0.930340\n",
      "batch 94, gen_loss 1.383387, disc_loss 0.821625\n",
      "batch 95, gen_loss 1.463494, disc_loss 0.881968\n",
      "batch 96, gen_loss 1.600386, disc_loss 0.797113\n",
      "batch 97, gen_loss 1.608676, disc_loss 0.949573\n",
      "batch 98, gen_loss 1.552424, disc_loss 0.925365\n",
      "batch 99, gen_loss 1.410885, disc_loss 0.815633\n",
      "batch 100, gen_loss 1.469681, disc_loss 0.798785\n",
      "batch 101, gen_loss 1.360901, disc_loss 0.902088\n",
      "batch 102, gen_loss 1.392559, disc_loss 0.902365\n",
      "batch 103, gen_loss 1.425675, disc_loss 0.891430\n",
      "batch 104, gen_loss 1.509201, disc_loss 0.973847\n",
      "batch 105, gen_loss 1.385684, disc_loss 0.926748\n",
      "batch 106, gen_loss 1.436865, disc_loss 0.905717\n",
      "batch 107, gen_loss 1.376618, disc_loss 0.893059\n",
      "batch 108, gen_loss 1.367894, disc_loss 0.862910\n",
      "batch 109, gen_loss 1.354534, disc_loss 0.907047\n",
      "batch 110, gen_loss 1.449483, disc_loss 0.846017\n",
      "batch 111, gen_loss 1.423723, disc_loss 1.006411\n",
      "batch 112, gen_loss 1.489068, disc_loss 0.906402\n",
      "batch 113, gen_loss 1.414991, disc_loss 1.026178\n",
      "batch 114, gen_loss 1.377272, disc_loss 0.938549\n",
      "batch 115, gen_loss 1.388270, disc_loss 0.915233\n",
      "batch 116, gen_loss 1.364490, disc_loss 0.940353\n",
      "batch 117, gen_loss 1.473568, disc_loss 0.858716\n",
      "batch 118, gen_loss 1.431783, disc_loss 0.947626\n",
      "batch 119, gen_loss 1.445357, disc_loss 0.884351\n",
      "batch 120, gen_loss 1.520998, disc_loss 0.919062\n",
      "batch 121, gen_loss 1.528696, disc_loss 0.993576\n",
      "batch 122, gen_loss 1.445793, disc_loss 0.986208\n",
      "batch 123, gen_loss 1.357181, disc_loss 1.030912\n",
      "batch 124, gen_loss 1.328924, disc_loss 0.884834\n",
      "batch 125, gen_loss 1.277903, disc_loss 0.867053\n",
      "batch 126, gen_loss 1.433977, disc_loss 0.924399\n",
      "batch 127, gen_loss 1.547197, disc_loss 0.889617\n",
      "batch 128, gen_loss 1.628762, disc_loss 0.795502\n",
      "batch 129, gen_loss 1.705878, disc_loss 0.847244\n",
      "batch 130, gen_loss 1.658075, disc_loss 0.803788\n",
      "batch 131, gen_loss 1.632558, disc_loss 0.825354\n",
      "batch 132, gen_loss 1.603067, disc_loss 0.799442\n",
      "batch 133, gen_loss 1.548979, disc_loss 0.780435\n",
      "batch 134, gen_loss 1.470235, disc_loss 0.782198\n",
      "batch 135, gen_loss 1.500263, disc_loss 0.723297\n",
      "batch 136, gen_loss 1.614210, disc_loss 0.771769\n",
      "batch 137, gen_loss 1.742378, disc_loss 0.664257\n",
      "batch 138, gen_loss 1.806289, disc_loss 0.670610\n",
      "batch 139, gen_loss 1.957411, disc_loss 0.679949\n",
      "batch 140, gen_loss 1.791917, disc_loss 0.650413\n",
      "batch 141, gen_loss 1.867452, disc_loss 0.590991\n",
      "batch 142, gen_loss 1.809190, disc_loss 0.565199\n",
      "batch 143, gen_loss 1.837662, disc_loss 0.605890\n",
      "batch 144, gen_loss 1.828634, disc_loss 0.720825\n",
      "batch 145, gen_loss 1.607068, disc_loss 0.641598\n",
      "batch 146, gen_loss 1.669243, disc_loss 0.600103\n",
      "batch 147, gen_loss 1.633309, disc_loss 0.651478\n",
      "batch 148, gen_loss 1.717049, disc_loss 0.604062\n",
      "batch 149, gen_loss 1.791476, disc_loss 0.560129\n",
      "batch 150, gen_loss 1.932610, disc_loss 0.597165\n",
      "batch 151, gen_loss 1.956323, disc_loss 0.626636\n",
      "batch 152, gen_loss 1.840419, disc_loss 0.623653\n",
      "batch 153, gen_loss 1.763890, disc_loss 0.613414\n",
      "batch 154, gen_loss 1.628447, disc_loss 0.629048\n",
      "batch 155, gen_loss 1.512366, disc_loss 0.649449\n",
      "batch 156, gen_loss 1.614234, disc_loss 0.620794\n",
      "batch 157, gen_loss 1.668593, disc_loss 0.667972\n",
      "batch 158, gen_loss 1.744425, disc_loss 0.698511\n",
      "batch 159, gen_loss 1.801839, disc_loss 0.720616\n",
      "batch 160, gen_loss 1.836572, disc_loss 0.689448\n",
      "batch 161, gen_loss 1.732081, disc_loss 0.693577\n",
      "batch 162, gen_loss 1.529609, disc_loss 0.630886\n",
      "batch 163, gen_loss 1.536421, disc_loss 0.709904\n",
      "batch 164, gen_loss 1.604363, disc_loss 0.731376\n",
      "batch 165, gen_loss 1.660707, disc_loss 0.678035\n",
      "batch 166, gen_loss 1.711933, disc_loss 0.698226\n",
      "batch 167, gen_loss 1.776236, disc_loss 0.659273\n",
      "batch 168, gen_loss 1.744445, disc_loss 0.671362\n",
      "batch 169, gen_loss 1.761361, disc_loss 0.701698\n",
      "batch 170, gen_loss 1.679969, disc_loss 0.804924\n",
      "batch 171, gen_loss 1.617144, disc_loss 0.720141\n",
      "batch 172, gen_loss 1.486020, disc_loss 0.797063\n",
      "batch 173, gen_loss 1.390336, disc_loss 0.725344\n",
      "batch 174, gen_loss 1.468471, disc_loss 0.756984\n",
      "batch 175, gen_loss 1.646086, disc_loss 0.723931\n",
      "batch 176, gen_loss 1.738659, disc_loss 0.777665\n",
      "batch 177, gen_loss 1.760205, disc_loss 0.689996\n",
      "batch 178, gen_loss 1.760926, disc_loss 0.828646\n",
      "batch 179, gen_loss 1.677192, disc_loss 0.721670\n",
      "batch 180, gen_loss 1.551325, disc_loss 0.806217\n",
      "batch 181, gen_loss 1.387584, disc_loss 0.763639\n",
      "batch 182, gen_loss 1.432324, disc_loss 0.759029\n",
      "batch 183, gen_loss 1.501841, disc_loss 0.764401\n",
      "batch 184, gen_loss 1.708870, disc_loss 0.797469\n",
      "batch 185, gen_loss 1.672113, disc_loss 0.823971\n",
      "batch 186, gen_loss 1.812752, disc_loss 0.733497\n",
      "batch 187, gen_loss 1.618402, disc_loss 0.702929\n",
      "batch 188, gen_loss 1.609536, disc_loss 0.732926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 189, gen_loss 1.545518, disc_loss 0.762383\n",
      "batch 190, gen_loss 1.723302, disc_loss 0.701387\n",
      "batch 191, gen_loss 1.647191, disc_loss 0.744142\n",
      "batch 192, gen_loss 1.701824, disc_loss 0.739846\n",
      "batch 193, gen_loss 1.621047, disc_loss 0.781905\n",
      "batch 194, gen_loss 1.673543, disc_loss 0.725181\n",
      "batch 195, gen_loss 1.482309, disc_loss 0.769642\n",
      "batch 196, gen_loss 1.513532, disc_loss 0.862719\n",
      "batch 197, gen_loss 1.556038, disc_loss 0.843431\n",
      "batch 198, gen_loss 1.535189, disc_loss 0.874303\n",
      "batch 199, gen_loss 1.614158, disc_loss 0.800700\n",
      "batch 200, gen_loss 1.454871, disc_loss 0.791239\n",
      "batch 201, gen_loss 1.742232, disc_loss 0.748943\n",
      "batch 202, gen_loss 1.650812, disc_loss 0.789304\n",
      "batch 203, gen_loss 1.840842, disc_loss 0.684735\n",
      "batch 204, gen_loss 1.823596, disc_loss 0.748898\n",
      "batch 205, gen_loss 1.634527, disc_loss 0.705574\n",
      "batch 206, gen_loss 1.505300, disc_loss 0.729672\n",
      "batch 207, gen_loss 1.734529, disc_loss 0.739872\n",
      "batch 208, gen_loss 1.751642, disc_loss 0.752171\n",
      "batch 209, gen_loss 1.732313, disc_loss 0.757643\n",
      "batch 210, gen_loss 1.824714, disc_loss 0.652283\n",
      "batch 211, gen_loss 1.770832, disc_loss 0.772969\n",
      "batch 212, gen_loss 1.710682, disc_loss 0.657122\n",
      "batch 213, gen_loss 1.668764, disc_loss 0.726351\n",
      "batch 214, gen_loss 1.751686, disc_loss 0.702537\n",
      "batch 215, gen_loss 1.830145, disc_loss 0.687176\n",
      "batch 216, gen_loss 1.840888, disc_loss 0.648712\n",
      "batch 217, gen_loss 1.937590, disc_loss 0.670090\n",
      "batch 218, gen_loss 1.846192, disc_loss 0.760675\n",
      "batch 219, gen_loss 1.731932, disc_loss 0.627888\n",
      "batch 220, gen_loss 1.722891, disc_loss 0.667906\n",
      "batch 221, gen_loss 1.776432, disc_loss 0.586644\n",
      "batch 222, gen_loss 1.935073, disc_loss 0.630410\n",
      "batch 223, gen_loss 1.895082, disc_loss 0.631251\n",
      "batch 224, gen_loss 1.925069, disc_loss 0.584488\n",
      "batch 225, gen_loss 1.921638, disc_loss 0.569787\n",
      "batch 226, gen_loss 1.883768, disc_loss 0.592244\n",
      "batch 227, gen_loss 1.919502, disc_loss 0.551531\n",
      "batch 228, gen_loss 1.857287, disc_loss 0.571104\n",
      "batch 229, gen_loss 1.929499, disc_loss 0.590554\n",
      "batch 230, gen_loss 1.993961, disc_loss 0.538690\n",
      "batch 231, gen_loss 1.981930, disc_loss 0.587177\n",
      "batch 232, gen_loss 1.963972, disc_loss 0.553125\n",
      "batch 233, gen_loss 1.894635, disc_loss 0.558746\n",
      "batch 234, gen_loss 1.838406, disc_loss 0.641924\n",
      "Time for epoch23is 7.597678184509277 sec\n",
      "batch 0, gen_loss 1.825962, disc_loss 0.637198\n",
      "batch 1, gen_loss 1.875238, disc_loss 0.553527\n",
      "batch 2, gen_loss 1.882990, disc_loss 0.587678\n",
      "batch 3, gen_loss 1.951270, disc_loss 0.604450\n",
      "batch 4, gen_loss 1.943173, disc_loss 0.596198\n",
      "batch 5, gen_loss 2.003087, disc_loss 0.598234\n",
      "batch 6, gen_loss 1.945950, disc_loss 0.529912\n",
      "batch 7, gen_loss 1.871056, disc_loss 0.563044\n",
      "batch 8, gen_loss 1.815285, disc_loss 0.561875\n",
      "batch 9, gen_loss 1.773956, disc_loss 0.638145\n",
      "batch 10, gen_loss 1.927838, disc_loss 0.588424\n",
      "batch 11, gen_loss 1.854401, disc_loss 0.636250\n",
      "batch 12, gen_loss 1.827369, disc_loss 0.645711\n",
      "batch 13, gen_loss 1.842353, disc_loss 0.638582\n",
      "batch 14, gen_loss 1.767176, disc_loss 0.681823\n",
      "batch 15, gen_loss 1.774024, disc_loss 0.599725\n",
      "batch 16, gen_loss 1.866466, disc_loss 0.601176\n",
      "batch 17, gen_loss 1.792510, disc_loss 0.720276\n",
      "batch 18, gen_loss 1.774251, disc_loss 0.669698\n",
      "batch 19, gen_loss 1.711332, disc_loss 0.789178\n",
      "batch 20, gen_loss 1.590374, disc_loss 0.715963\n",
      "batch 21, gen_loss 1.564666, disc_loss 0.780872\n",
      "batch 22, gen_loss 1.626294, disc_loss 0.772036\n",
      "batch 23, gen_loss 1.736870, disc_loss 0.912545\n",
      "batch 24, gen_loss 1.643877, disc_loss 0.893529\n",
      "batch 25, gen_loss 1.672225, disc_loss 0.861072\n",
      "batch 26, gen_loss 1.495843, disc_loss 0.834960\n",
      "batch 27, gen_loss 1.510977, disc_loss 0.950047\n",
      "batch 28, gen_loss 1.659240, disc_loss 0.754431\n",
      "batch 29, gen_loss 1.642940, disc_loss 0.942527\n",
      "batch 30, gen_loss 1.676718, disc_loss 0.919439\n",
      "batch 31, gen_loss 1.605536, disc_loss 0.908037\n",
      "batch 32, gen_loss 1.622997, disc_loss 1.076472\n",
      "batch 33, gen_loss 1.519099, disc_loss 0.931201\n",
      "batch 34, gen_loss 1.573977, disc_loss 1.024133\n",
      "batch 35, gen_loss 1.500839, disc_loss 0.927265\n",
      "batch 36, gen_loss 1.526597, disc_loss 0.976134\n",
      "batch 37, gen_loss 1.594454, disc_loss 1.025706\n",
      "batch 38, gen_loss 1.717263, disc_loss 0.890088\n",
      "batch 39, gen_loss 1.591277, disc_loss 1.057801\n",
      "batch 40, gen_loss 1.527062, disc_loss 1.015599\n",
      "batch 41, gen_loss 1.415204, disc_loss 0.962739\n",
      "batch 42, gen_loss 1.591379, disc_loss 0.899966\n",
      "batch 43, gen_loss 1.517648, disc_loss 0.865608\n",
      "batch 44, gen_loss 1.588543, disc_loss 0.937485\n",
      "batch 45, gen_loss 1.709147, disc_loss 0.896205\n",
      "batch 46, gen_loss 1.704536, disc_loss 0.932130\n",
      "batch 47, gen_loss 1.631600, disc_loss 0.791129\n",
      "batch 48, gen_loss 1.655703, disc_loss 0.947918\n",
      "batch 49, gen_loss 1.595943, disc_loss 0.852288\n",
      "batch 50, gen_loss 1.534132, disc_loss 0.843734\n",
      "batch 51, gen_loss 1.564194, disc_loss 0.899482\n",
      "batch 52, gen_loss 1.760975, disc_loss 0.999657\n",
      "batch 53, gen_loss 1.630011, disc_loss 0.891326\n",
      "batch 54, gen_loss 1.661864, disc_loss 0.953253\n",
      "batch 55, gen_loss 1.498075, disc_loss 0.796893\n",
      "batch 56, gen_loss 1.586578, disc_loss 0.816554\n",
      "batch 57, gen_loss 1.772781, disc_loss 0.821385\n",
      "batch 58, gen_loss 1.719377, disc_loss 0.794230\n",
      "batch 59, gen_loss 1.707675, disc_loss 0.761777\n",
      "batch 60, gen_loss 1.813592, disc_loss 0.747492\n",
      "batch 61, gen_loss 1.739575, disc_loss 0.743167\n",
      "batch 62, gen_loss 1.540385, disc_loss 0.781929\n",
      "batch 63, gen_loss 1.650651, disc_loss 0.857169\n",
      "batch 64, gen_loss 1.549613, disc_loss 0.768160\n",
      "batch 65, gen_loss 1.694254, disc_loss 0.745480\n",
      "batch 66, gen_loss 1.794977, disc_loss 0.745990\n",
      "batch 67, gen_loss 1.798957, disc_loss 0.678397\n",
      "batch 68, gen_loss 1.900592, disc_loss 0.674470\n",
      "batch 69, gen_loss 1.740051, disc_loss 0.632738\n",
      "batch 70, gen_loss 1.775401, disc_loss 0.672566\n",
      "batch 71, gen_loss 1.901620, disc_loss 0.744023\n",
      "batch 72, gen_loss 1.851810, disc_loss 0.611032\n",
      "batch 73, gen_loss 1.677042, disc_loss 0.746869\n",
      "batch 74, gen_loss 1.675155, disc_loss 0.687188\n",
      "batch 75, gen_loss 1.750843, disc_loss 0.651115\n",
      "batch 76, gen_loss 1.801904, disc_loss 0.655075\n",
      "batch 77, gen_loss 1.925435, disc_loss 0.601535\n",
      "batch 78, gen_loss 1.856236, disc_loss 0.634295\n",
      "batch 79, gen_loss 1.948725, disc_loss 0.587803\n",
      "batch 80, gen_loss 1.881209, disc_loss 0.575546\n",
      "batch 81, gen_loss 1.796886, disc_loss 0.580894\n",
      "batch 82, gen_loss 1.751573, disc_loss 0.596229\n",
      "batch 83, gen_loss 1.754983, disc_loss 0.562176\n",
      "batch 84, gen_loss 1.831915, disc_loss 0.625388\n",
      "batch 85, gen_loss 1.963308, disc_loss 0.603751\n",
      "batch 86, gen_loss 1.905217, disc_loss 0.615843\n",
      "batch 87, gen_loss 2.023317, disc_loss 0.583379\n",
      "batch 88, gen_loss 1.950380, disc_loss 0.604775\n",
      "batch 89, gen_loss 1.831795, disc_loss 0.614064\n",
      "batch 90, gen_loss 1.747545, disc_loss 0.629545\n",
      "batch 91, gen_loss 1.768001, disc_loss 0.621757\n",
      "batch 92, gen_loss 1.860308, disc_loss 0.541266\n",
      "batch 93, gen_loss 2.000219, disc_loss 0.559593\n",
      "batch 94, gen_loss 2.111660, disc_loss 0.588061\n",
      "batch 95, gen_loss 2.093196, disc_loss 0.570834\n",
      "batch 96, gen_loss 1.979311, disc_loss 0.577925\n",
      "batch 97, gen_loss 1.905630, disc_loss 0.623684\n",
      "batch 98, gen_loss 1.746941, disc_loss 0.647300\n",
      "batch 99, gen_loss 1.706765, disc_loss 0.612726\n",
      "batch 100, gen_loss 1.776750, disc_loss 0.537059\n",
      "batch 101, gen_loss 1.907878, disc_loss 0.633029\n",
      "batch 102, gen_loss 1.937431, disc_loss 0.679515\n",
      "batch 103, gen_loss 1.911978, disc_loss 0.652985\n",
      "batch 104, gen_loss 1.834962, disc_loss 0.628896\n",
      "batch 105, gen_loss 1.772800, disc_loss 0.751611\n",
      "batch 106, gen_loss 1.765673, disc_loss 0.604410\n",
      "batch 107, gen_loss 1.790359, disc_loss 0.654004\n",
      "batch 108, gen_loss 1.894673, disc_loss 0.663912\n",
      "batch 109, gen_loss 1.898936, disc_loss 0.626311\n",
      "batch 110, gen_loss 1.903371, disc_loss 0.608750\n",
      "batch 111, gen_loss 1.996461, disc_loss 0.596033\n",
      "batch 112, gen_loss 1.881164, disc_loss 0.633969\n",
      "batch 113, gen_loss 1.863815, disc_loss 0.671995\n",
      "batch 114, gen_loss 1.770677, disc_loss 0.633583\n",
      "batch 115, gen_loss 1.789816, disc_loss 0.634552\n",
      "batch 116, gen_loss 1.798654, disc_loss 0.749481\n",
      "batch 117, gen_loss 1.854993, disc_loss 0.681508\n",
      "batch 118, gen_loss 1.785479, disc_loss 0.687609\n",
      "batch 119, gen_loss 1.733045, disc_loss 0.694464\n",
      "batch 120, gen_loss 1.875821, disc_loss 0.619819\n",
      "batch 121, gen_loss 1.832303, disc_loss 0.685536\n",
      "batch 122, gen_loss 1.845717, disc_loss 0.612860\n",
      "batch 123, gen_loss 1.822677, disc_loss 0.622398\n",
      "batch 124, gen_loss 1.730946, disc_loss 0.789638\n",
      "batch 125, gen_loss 1.755733, disc_loss 0.707523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 126, gen_loss 1.782759, disc_loss 0.671618\n",
      "batch 127, gen_loss 1.839721, disc_loss 0.704598\n",
      "batch 128, gen_loss 1.877356, disc_loss 0.655282\n",
      "batch 129, gen_loss 1.934845, disc_loss 0.681559\n",
      "batch 130, gen_loss 1.698333, disc_loss 0.651429\n",
      "batch 131, gen_loss 1.728117, disc_loss 0.656109\n",
      "batch 132, gen_loss 1.915908, disc_loss 0.637393\n",
      "batch 133, gen_loss 1.861457, disc_loss 0.662409\n",
      "batch 134, gen_loss 1.817222, disc_loss 0.650269\n",
      "batch 135, gen_loss 1.757667, disc_loss 0.736201\n",
      "batch 136, gen_loss 1.706994, disc_loss 0.742909\n",
      "batch 137, gen_loss 1.831791, disc_loss 0.686443\n",
      "batch 138, gen_loss 1.699994, disc_loss 0.684437\n",
      "batch 139, gen_loss 1.836054, disc_loss 0.595279\n",
      "batch 140, gen_loss 1.852470, disc_loss 0.761465\n",
      "batch 141, gen_loss 1.765588, disc_loss 0.686138\n",
      "batch 142, gen_loss 1.786420, disc_loss 0.742894\n",
      "batch 143, gen_loss 1.735211, disc_loss 0.689340\n",
      "batch 144, gen_loss 1.841694, disc_loss 0.748002\n",
      "batch 145, gen_loss 1.814430, disc_loss 0.720978\n",
      "batch 146, gen_loss 1.820242, disc_loss 0.718904\n",
      "batch 147, gen_loss 1.581525, disc_loss 0.716420\n",
      "batch 148, gen_loss 1.639634, disc_loss 0.666687\n",
      "batch 149, gen_loss 1.779848, disc_loss 0.699319\n",
      "batch 150, gen_loss 1.735037, disc_loss 0.780646\n",
      "batch 151, gen_loss 1.837736, disc_loss 0.643294\n",
      "batch 152, gen_loss 1.873013, disc_loss 0.693274\n",
      "batch 153, gen_loss 1.701947, disc_loss 0.704099\n",
      "batch 154, gen_loss 1.633173, disc_loss 0.683058\n",
      "batch 155, gen_loss 1.581704, disc_loss 0.780073\n",
      "batch 156, gen_loss 1.665937, disc_loss 0.739169\n",
      "batch 157, gen_loss 1.676412, disc_loss 0.723905\n",
      "batch 158, gen_loss 1.850209, disc_loss 0.695881\n",
      "batch 159, gen_loss 1.746456, disc_loss 0.745118\n",
      "batch 160, gen_loss 1.683008, disc_loss 0.713291\n",
      "batch 161, gen_loss 1.558944, disc_loss 0.764316\n",
      "batch 162, gen_loss 1.600170, disc_loss 0.763380\n",
      "batch 163, gen_loss 1.695255, disc_loss 0.721516\n",
      "batch 164, gen_loss 1.737014, disc_loss 0.788091\n",
      "batch 165, gen_loss 1.605319, disc_loss 0.832325\n",
      "batch 166, gen_loss 1.455607, disc_loss 0.820009\n",
      "batch 167, gen_loss 1.631386, disc_loss 0.660704\n",
      "batch 168, gen_loss 1.567189, disc_loss 0.744539\n",
      "batch 169, gen_loss 1.652424, disc_loss 0.756931\n",
      "batch 170, gen_loss 1.663812, disc_loss 0.823122\n",
      "batch 171, gen_loss 1.611422, disc_loss 0.814987\n",
      "batch 172, gen_loss 1.584206, disc_loss 0.778455\n",
      "batch 173, gen_loss 1.428804, disc_loss 0.819929\n",
      "batch 174, gen_loss 1.445851, disc_loss 0.800857\n",
      "batch 175, gen_loss 1.467599, disc_loss 0.805193\n",
      "batch 176, gen_loss 1.578154, disc_loss 0.843049\n",
      "batch 177, gen_loss 1.643568, disc_loss 0.814180\n",
      "batch 178, gen_loss 1.684929, disc_loss 0.862376\n",
      "batch 179, gen_loss 1.532758, disc_loss 0.865908\n",
      "batch 180, gen_loss 1.634618, disc_loss 0.750964\n",
      "batch 181, gen_loss 1.616822, disc_loss 0.881058\n",
      "batch 182, gen_loss 1.493826, disc_loss 0.898313\n",
      "batch 183, gen_loss 1.544692, disc_loss 0.873213\n",
      "batch 184, gen_loss 1.509186, disc_loss 0.854136\n",
      "batch 185, gen_loss 1.337197, disc_loss 0.921665\n",
      "batch 186, gen_loss 1.541967, disc_loss 0.909496\n",
      "batch 187, gen_loss 1.580181, disc_loss 0.989150\n",
      "batch 188, gen_loss 1.555106, disc_loss 0.919246\n",
      "batch 189, gen_loss 1.438907, disc_loss 0.952293\n",
      "batch 190, gen_loss 1.480812, disc_loss 0.873104\n",
      "batch 191, gen_loss 1.377783, disc_loss 0.947062\n",
      "batch 192, gen_loss 1.325491, disc_loss 0.929365\n",
      "batch 193, gen_loss 1.387792, disc_loss 0.980099\n",
      "batch 194, gen_loss 1.522893, disc_loss 1.028167\n",
      "batch 195, gen_loss 1.536991, disc_loss 1.006465\n",
      "batch 196, gen_loss 1.432766, disc_loss 1.117993\n",
      "batch 197, gen_loss 1.371462, disc_loss 0.953635\n",
      "batch 198, gen_loss 1.286468, disc_loss 1.035233\n",
      "batch 199, gen_loss 1.383408, disc_loss 0.958384\n",
      "batch 200, gen_loss 1.432429, disc_loss 0.967893\n",
      "batch 201, gen_loss 1.512911, disc_loss 1.004524\n",
      "batch 202, gen_loss 1.446406, disc_loss 1.048966\n",
      "batch 203, gen_loss 1.524218, disc_loss 0.999066\n",
      "batch 204, gen_loss 1.432601, disc_loss 0.992375\n",
      "batch 205, gen_loss 1.353076, disc_loss 0.933791\n",
      "batch 206, gen_loss 1.429539, disc_loss 1.117407\n",
      "batch 207, gen_loss 1.420575, disc_loss 0.974131\n",
      "batch 208, gen_loss 1.362972, disc_loss 1.052130\n",
      "batch 209, gen_loss 1.447998, disc_loss 0.989234\n",
      "batch 210, gen_loss 1.453286, disc_loss 0.918322\n",
      "batch 211, gen_loss 1.414184, disc_loss 1.048822\n",
      "batch 212, gen_loss 1.387460, disc_loss 1.058514\n",
      "batch 213, gen_loss 1.259208, disc_loss 1.011350\n",
      "batch 214, gen_loss 1.249111, disc_loss 0.995280\n",
      "batch 215, gen_loss 1.391313, disc_loss 1.093326\n",
      "batch 216, gen_loss 1.413975, disc_loss 1.120154\n",
      "batch 217, gen_loss 1.641414, disc_loss 0.865524\n",
      "batch 218, gen_loss 1.638773, disc_loss 0.968281\n",
      "batch 219, gen_loss 1.484915, disc_loss 0.895790\n",
      "batch 220, gen_loss 1.418600, disc_loss 0.980010\n",
      "batch 221, gen_loss 1.385337, disc_loss 0.930513\n",
      "batch 222, gen_loss 1.443365, disc_loss 0.890536\n",
      "batch 223, gen_loss 1.403418, disc_loss 0.919380\n",
      "batch 224, gen_loss 1.545510, disc_loss 0.943069\n",
      "batch 225, gen_loss 1.583391, disc_loss 0.878249\n",
      "batch 226, gen_loss 1.613959, disc_loss 0.978989\n",
      "batch 227, gen_loss 1.374008, disc_loss 0.887354\n",
      "batch 228, gen_loss 1.315287, disc_loss 0.878529\n",
      "batch 229, gen_loss 1.366928, disc_loss 0.833934\n",
      "batch 230, gen_loss 1.448972, disc_loss 0.893777\n",
      "batch 231, gen_loss 1.676061, disc_loss 0.849023\n",
      "batch 232, gen_loss 1.722021, disc_loss 0.873979\n",
      "batch 233, gen_loss 1.615926, disc_loss 0.921482\n",
      "batch 234, gen_loss 1.285197, disc_loss 0.869862\n",
      "Time for epoch24is 7.608003377914429 sec\n",
      "batch 0, gen_loss 1.248998, disc_loss 0.824678\n",
      "batch 1, gen_loss 1.507413, disc_loss 0.874032\n",
      "batch 2, gen_loss 1.502871, disc_loss 0.935223\n",
      "batch 3, gen_loss 1.611533, disc_loss 0.892640\n",
      "batch 4, gen_loss 1.703550, disc_loss 0.795298\n",
      "batch 5, gen_loss 1.601404, disc_loss 0.867087\n",
      "batch 6, gen_loss 1.408720, disc_loss 0.870765\n",
      "batch 7, gen_loss 1.448993, disc_loss 0.854047\n",
      "batch 8, gen_loss 1.461652, disc_loss 0.855763\n",
      "batch 9, gen_loss 1.402365, disc_loss 0.867573\n",
      "batch 10, gen_loss 1.658030, disc_loss 0.766263\n",
      "batch 11, gen_loss 1.677395, disc_loss 0.852998\n",
      "batch 12, gen_loss 1.708082, disc_loss 0.813173\n",
      "batch 13, gen_loss 1.560297, disc_loss 0.843802\n",
      "batch 14, gen_loss 1.470636, disc_loss 0.788799\n",
      "batch 15, gen_loss 1.416139, disc_loss 0.893651\n",
      "batch 16, gen_loss 1.397214, disc_loss 0.873001\n",
      "batch 17, gen_loss 1.446931, disc_loss 0.909964\n",
      "batch 18, gen_loss 1.563310, disc_loss 0.820723\n",
      "batch 19, gen_loss 1.532214, disc_loss 0.849765\n",
      "batch 20, gen_loss 1.644247, disc_loss 0.815714\n",
      "batch 21, gen_loss 1.499308, disc_loss 0.827637\n",
      "batch 22, gen_loss 1.534995, disc_loss 0.839633\n",
      "batch 23, gen_loss 1.589708, disc_loss 0.747397\n",
      "batch 24, gen_loss 1.582449, disc_loss 0.841985\n",
      "batch 25, gen_loss 1.726577, disc_loss 0.819631\n",
      "batch 26, gen_loss 1.602839, disc_loss 0.784612\n",
      "batch 27, gen_loss 1.646372, disc_loss 0.693896\n",
      "batch 28, gen_loss 1.649126, disc_loss 0.759523\n",
      "batch 29, gen_loss 1.703598, disc_loss 0.757549\n",
      "batch 30, gen_loss 1.541923, disc_loss 0.725893\n",
      "batch 31, gen_loss 1.759751, disc_loss 0.700740\n",
      "batch 32, gen_loss 1.723191, disc_loss 0.652612\n",
      "batch 33, gen_loss 1.693260, disc_loss 0.672873\n",
      "batch 34, gen_loss 1.740319, disc_loss 0.699386\n",
      "batch 35, gen_loss 1.704054, disc_loss 0.786893\n",
      "batch 36, gen_loss 1.666240, disc_loss 0.690106\n",
      "batch 37, gen_loss 1.535557, disc_loss 0.730533\n",
      "batch 38, gen_loss 1.530076, disc_loss 0.702255\n",
      "batch 39, gen_loss 1.583128, disc_loss 0.720415\n",
      "batch 40, gen_loss 1.769518, disc_loss 0.671222\n",
      "batch 41, gen_loss 1.791815, disc_loss 0.679176\n",
      "batch 42, gen_loss 1.866789, disc_loss 0.791523\n",
      "batch 43, gen_loss 1.799529, disc_loss 0.658849\n",
      "batch 44, gen_loss 1.613341, disc_loss 0.679982\n",
      "batch 45, gen_loss 1.728886, disc_loss 0.660186\n",
      "batch 46, gen_loss 1.714799, disc_loss 0.707190\n",
      "batch 47, gen_loss 1.747162, disc_loss 0.706490\n",
      "batch 48, gen_loss 1.849872, disc_loss 0.640767\n",
      "batch 49, gen_loss 1.745815, disc_loss 0.618214\n",
      "batch 50, gen_loss 1.726772, disc_loss 0.723725\n",
      "batch 51, gen_loss 1.818653, disc_loss 0.710068\n",
      "batch 52, gen_loss 1.719754, disc_loss 0.603144\n",
      "batch 53, gen_loss 1.723125, disc_loss 0.666882\n",
      "batch 54, gen_loss 1.674222, disc_loss 0.676946\n",
      "batch 55, gen_loss 1.805858, disc_loss 0.616319\n",
      "batch 56, gen_loss 1.783939, disc_loss 0.722154\n",
      "batch 57, gen_loss 1.714035, disc_loss 0.622303\n",
      "batch 58, gen_loss 1.793989, disc_loss 0.713640\n",
      "batch 59, gen_loss 1.781614, disc_loss 0.672965\n",
      "batch 60, gen_loss 1.895702, disc_loss 0.614960\n",
      "batch 61, gen_loss 1.982573, disc_loss 0.586369\n",
      "batch 62, gen_loss 1.778835, disc_loss 0.748582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 63, gen_loss 1.708416, disc_loss 0.705339\n",
      "batch 64, gen_loss 1.852965, disc_loss 0.680510\n",
      "batch 65, gen_loss 1.870756, disc_loss 0.616930\n",
      "batch 66, gen_loss 1.833603, disc_loss 0.684254\n",
      "batch 67, gen_loss 1.828857, disc_loss 0.702567\n",
      "batch 68, gen_loss 1.777453, disc_loss 0.691269\n",
      "batch 69, gen_loss 1.792764, disc_loss 0.635887\n",
      "batch 70, gen_loss 1.881916, disc_loss 0.697094\n",
      "batch 71, gen_loss 1.780161, disc_loss 0.688916\n",
      "batch 72, gen_loss 1.851302, disc_loss 0.677069\n",
      "batch 73, gen_loss 1.815814, disc_loss 0.722756\n",
      "batch 74, gen_loss 1.697588, disc_loss 0.787267\n",
      "batch 75, gen_loss 1.716713, disc_loss 0.697439\n",
      "batch 76, gen_loss 1.740119, disc_loss 0.816475\n",
      "batch 77, gen_loss 1.786877, disc_loss 0.751267\n",
      "batch 78, gen_loss 1.857295, disc_loss 0.737968\n",
      "batch 79, gen_loss 1.815855, disc_loss 0.730940\n",
      "batch 80, gen_loss 1.817465, disc_loss 0.742160\n",
      "batch 81, gen_loss 1.581449, disc_loss 0.869443\n",
      "batch 82, gen_loss 1.578491, disc_loss 0.859103\n",
      "batch 83, gen_loss 1.612787, disc_loss 0.803313\n",
      "batch 84, gen_loss 1.694596, disc_loss 0.718289\n",
      "batch 85, gen_loss 1.814898, disc_loss 0.782975\n",
      "batch 86, gen_loss 1.873446, disc_loss 0.799600\n",
      "batch 87, gen_loss 1.816372, disc_loss 0.805822\n",
      "batch 88, gen_loss 1.603434, disc_loss 0.778529\n",
      "batch 89, gen_loss 1.512840, disc_loss 0.948136\n",
      "batch 90, gen_loss 1.554748, disc_loss 0.847051\n",
      "batch 91, gen_loss 1.648294, disc_loss 0.817262\n",
      "batch 92, gen_loss 1.678998, disc_loss 0.912610\n",
      "batch 93, gen_loss 1.779584, disc_loss 0.819715\n",
      "batch 94, gen_loss 1.893794, disc_loss 0.791779\n",
      "batch 95, gen_loss 1.761111, disc_loss 0.863603\n",
      "batch 96, gen_loss 1.646703, disc_loss 0.863679\n",
      "batch 97, gen_loss 1.539330, disc_loss 0.829751\n",
      "batch 98, gen_loss 1.510139, disc_loss 0.888371\n",
      "batch 99, gen_loss 1.689142, disc_loss 0.856833\n",
      "batch 100, gen_loss 1.732045, disc_loss 0.786883\n",
      "batch 101, gen_loss 1.836410, disc_loss 0.767017\n",
      "batch 102, gen_loss 1.759241, disc_loss 0.872157\n",
      "batch 103, gen_loss 1.487107, disc_loss 0.939681\n",
      "batch 104, gen_loss 1.678373, disc_loss 0.810556\n",
      "batch 105, gen_loss 1.665744, disc_loss 0.739685\n",
      "batch 106, gen_loss 1.937884, disc_loss 0.774920\n",
      "batch 107, gen_loss 1.912741, disc_loss 0.758666\n",
      "batch 108, gen_loss 1.846713, disc_loss 0.812110\n",
      "batch 109, gen_loss 1.693623, disc_loss 0.753826\n",
      "batch 110, gen_loss 1.540742, disc_loss 0.777133\n",
      "batch 111, gen_loss 1.571033, disc_loss 0.754369\n",
      "batch 112, gen_loss 1.675096, disc_loss 0.690202\n",
      "batch 113, gen_loss 1.753058, disc_loss 0.702762\n",
      "batch 114, gen_loss 1.836644, disc_loss 0.724932\n",
      "batch 115, gen_loss 1.816543, disc_loss 0.796274\n",
      "batch 116, gen_loss 1.953181, disc_loss 0.676051\n",
      "batch 117, gen_loss 1.800203, disc_loss 0.764036\n",
      "batch 118, gen_loss 1.746840, disc_loss 0.764304\n",
      "batch 119, gen_loss 1.598375, disc_loss 0.679130\n",
      "batch 120, gen_loss 1.542592, disc_loss 0.769175\n",
      "batch 121, gen_loss 1.722783, disc_loss 0.664139\n",
      "batch 122, gen_loss 1.908459, disc_loss 0.724415\n",
      "batch 123, gen_loss 1.972708, disc_loss 0.625738\n",
      "batch 124, gen_loss 2.118396, disc_loss 0.671911\n",
      "batch 125, gen_loss 1.953284, disc_loss 0.721325\n",
      "batch 126, gen_loss 1.745100, disc_loss 0.709011\n",
      "batch 127, gen_loss 1.681834, disc_loss 0.706696\n",
      "batch 128, gen_loss 1.606462, disc_loss 0.660198\n",
      "batch 129, gen_loss 1.777220, disc_loss 0.650776\n",
      "batch 130, gen_loss 1.883156, disc_loss 0.586638\n",
      "batch 131, gen_loss 1.857544, disc_loss 0.649563\n",
      "batch 132, gen_loss 2.058482, disc_loss 0.670997\n",
      "batch 133, gen_loss 1.945262, disc_loss 0.761051\n",
      "batch 134, gen_loss 1.800420, disc_loss 0.646502\n",
      "batch 135, gen_loss 1.636124, disc_loss 0.708076\n",
      "batch 136, gen_loss 1.732491, disc_loss 0.690590\n",
      "batch 137, gen_loss 1.667063, disc_loss 0.752188\n",
      "batch 138, gen_loss 1.766614, disc_loss 0.717180\n",
      "batch 139, gen_loss 1.785362, disc_loss 0.693544\n",
      "batch 140, gen_loss 1.863586, disc_loss 0.731060\n",
      "batch 141, gen_loss 1.841021, disc_loss 0.662436\n",
      "batch 142, gen_loss 1.938504, disc_loss 0.623441\n",
      "batch 143, gen_loss 1.877149, disc_loss 0.639018\n",
      "batch 144, gen_loss 1.803247, disc_loss 0.630853\n",
      "batch 145, gen_loss 1.706185, disc_loss 0.725823\n",
      "batch 146, gen_loss 1.714472, disc_loss 0.666958\n",
      "batch 147, gen_loss 1.683000, disc_loss 0.727681\n",
      "batch 148, gen_loss 1.902015, disc_loss 0.693721\n",
      "batch 149, gen_loss 1.808369, disc_loss 0.760635\n",
      "batch 150, gen_loss 1.745633, disc_loss 0.768200\n",
      "batch 151, gen_loss 1.780512, disc_loss 0.687430\n",
      "batch 152, gen_loss 1.576984, disc_loss 0.797233\n",
      "batch 153, gen_loss 1.704500, disc_loss 0.680924\n",
      "batch 154, gen_loss 1.734123, disc_loss 0.777272\n",
      "batch 155, gen_loss 1.720592, disc_loss 0.747865\n",
      "batch 156, gen_loss 1.684273, disc_loss 0.761851\n",
      "batch 157, gen_loss 1.611956, disc_loss 0.720698\n",
      "batch 158, gen_loss 1.711468, disc_loss 0.737631\n",
      "batch 159, gen_loss 1.738791, disc_loss 0.792846\n",
      "batch 160, gen_loss 1.666627, disc_loss 0.826764\n",
      "batch 161, gen_loss 1.637546, disc_loss 0.757114\n",
      "batch 162, gen_loss 1.637866, disc_loss 0.761132\n",
      "batch 163, gen_loss 1.616861, disc_loss 0.835676\n",
      "batch 164, gen_loss 1.540287, disc_loss 0.823099\n",
      "batch 165, gen_loss 1.717768, disc_loss 0.817406\n",
      "batch 166, gen_loss 1.664731, disc_loss 0.750083\n",
      "batch 167, gen_loss 1.761948, disc_loss 0.816635\n",
      "batch 168, gen_loss 1.754524, disc_loss 0.814146\n",
      "batch 169, gen_loss 1.636563, disc_loss 0.768078\n",
      "batch 170, gen_loss 1.551153, disc_loss 0.874916\n",
      "batch 171, gen_loss 1.577142, disc_loss 0.904218\n",
      "batch 172, gen_loss 1.495745, disc_loss 0.869831\n",
      "batch 173, gen_loss 1.598731, disc_loss 0.813349\n",
      "batch 174, gen_loss 1.616693, disc_loss 0.859530\n",
      "batch 175, gen_loss 1.666382, disc_loss 0.837099\n",
      "batch 176, gen_loss 1.522179, disc_loss 0.823797\n",
      "batch 177, gen_loss 1.604788, disc_loss 0.890631\n",
      "batch 178, gen_loss 1.478884, disc_loss 0.966461\n",
      "batch 179, gen_loss 1.534590, disc_loss 0.884353\n",
      "batch 180, gen_loss 1.542802, disc_loss 0.836696\n",
      "batch 181, gen_loss 1.436043, disc_loss 0.856117\n",
      "batch 182, gen_loss 1.546322, disc_loss 0.973205\n",
      "batch 183, gen_loss 1.501038, disc_loss 0.950715\n",
      "batch 184, gen_loss 1.353973, disc_loss 1.025764\n",
      "batch 185, gen_loss 1.485634, disc_loss 0.955274\n",
      "batch 186, gen_loss 1.426446, disc_loss 0.978065\n",
      "batch 187, gen_loss 1.382794, disc_loss 0.924157\n",
      "batch 188, gen_loss 1.401948, disc_loss 0.984462\n",
      "batch 189, gen_loss 1.452261, disc_loss 0.987368\n",
      "batch 190, gen_loss 1.478969, disc_loss 1.020949\n",
      "batch 191, gen_loss 1.452199, disc_loss 0.940084\n",
      "batch 192, gen_loss 1.352036, disc_loss 1.066476\n",
      "batch 193, gen_loss 1.428256, disc_loss 0.964766\n",
      "batch 194, gen_loss 1.408813, disc_loss 1.021284\n",
      "batch 195, gen_loss 1.451248, disc_loss 0.924412\n",
      "batch 196, gen_loss 1.497922, disc_loss 0.991997\n",
      "batch 197, gen_loss 1.349962, disc_loss 1.172031\n",
      "batch 198, gen_loss 1.384963, disc_loss 0.949176\n",
      "batch 199, gen_loss 1.328164, disc_loss 1.101223\n",
      "batch 200, gen_loss 1.355155, disc_loss 1.013271\n",
      "batch 201, gen_loss 1.402197, disc_loss 1.112234\n",
      "batch 202, gen_loss 1.410357, disc_loss 1.012620\n",
      "batch 203, gen_loss 1.521346, disc_loss 0.995470\n",
      "batch 204, gen_loss 1.477938, disc_loss 1.058497\n",
      "batch 205, gen_loss 1.441891, disc_loss 1.022337\n",
      "batch 206, gen_loss 1.202428, disc_loss 1.003699\n",
      "batch 207, gen_loss 1.398773, disc_loss 0.991636\n",
      "batch 208, gen_loss 1.299125, disc_loss 1.085474\n",
      "batch 209, gen_loss 1.409374, disc_loss 1.005586\n",
      "batch 210, gen_loss 1.618802, disc_loss 1.044449\n",
      "batch 211, gen_loss 1.582319, disc_loss 1.079258\n",
      "batch 212, gen_loss 1.513103, disc_loss 0.913858\n",
      "batch 213, gen_loss 1.490384, disc_loss 0.939824\n",
      "batch 214, gen_loss 1.258985, disc_loss 0.921280\n",
      "batch 215, gen_loss 1.254776, disc_loss 1.063475\n",
      "batch 216, gen_loss 1.429742, disc_loss 0.857322\n",
      "batch 217, gen_loss 1.699543, disc_loss 0.910970\n",
      "batch 218, gen_loss 1.668865, disc_loss 0.974683\n",
      "batch 219, gen_loss 1.574133, disc_loss 0.940306\n",
      "batch 220, gen_loss 1.539187, disc_loss 0.879757\n",
      "batch 221, gen_loss 1.373202, disc_loss 0.916121\n",
      "batch 222, gen_loss 1.393458, disc_loss 0.937354\n",
      "batch 223, gen_loss 1.487923, disc_loss 0.908844\n",
      "batch 224, gen_loss 1.605943, disc_loss 0.814719\n",
      "batch 225, gen_loss 1.666632, disc_loss 0.896881\n",
      "batch 226, gen_loss 1.695853, disc_loss 0.863827\n",
      "batch 227, gen_loss 1.678337, disc_loss 0.846303\n",
      "batch 228, gen_loss 1.560553, disc_loss 0.925133\n",
      "batch 229, gen_loss 1.502530, disc_loss 0.842690\n",
      "batch 230, gen_loss 1.426955, disc_loss 0.816700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 231, gen_loss 1.382598, disc_loss 0.854160\n",
      "batch 232, gen_loss 1.621457, disc_loss 0.780727\n",
      "batch 233, gen_loss 1.668365, disc_loss 0.776421\n",
      "batch 234, gen_loss 1.670920, disc_loss 0.865542\n",
      "Time for epoch25is 7.611479043960571 sec\n",
      "batch 0, gen_loss 1.541191, disc_loss 0.717004\n",
      "batch 1, gen_loss 1.530613, disc_loss 0.856405\n",
      "batch 2, gen_loss 1.561556, disc_loss 0.802960\n",
      "batch 3, gen_loss 1.596113, disc_loss 0.723474\n",
      "batch 4, gen_loss 1.568326, disc_loss 0.772852\n",
      "batch 5, gen_loss 1.620473, disc_loss 0.789237\n",
      "batch 6, gen_loss 1.796813, disc_loss 0.709592\n",
      "batch 7, gen_loss 1.720999, disc_loss 0.710846\n",
      "batch 8, gen_loss 1.655159, disc_loss 0.811230\n",
      "batch 9, gen_loss 1.801172, disc_loss 0.674005\n",
      "batch 10, gen_loss 1.714381, disc_loss 0.695348\n",
      "batch 11, gen_loss 1.701788, disc_loss 0.717043\n",
      "batch 12, gen_loss 1.597570, disc_loss 0.739431\n",
      "batch 13, gen_loss 1.668503, disc_loss 0.619889\n",
      "batch 14, gen_loss 1.565363, disc_loss 0.677542\n",
      "batch 15, gen_loss 1.649744, disc_loss 0.669303\n",
      "batch 16, gen_loss 1.753020, disc_loss 0.735186\n",
      "batch 17, gen_loss 1.827641, disc_loss 0.696643\n",
      "batch 18, gen_loss 1.878830, disc_loss 0.591783\n",
      "batch 19, gen_loss 1.779530, disc_loss 0.702477\n",
      "batch 20, gen_loss 1.724775, disc_loss 0.610048\n",
      "batch 21, gen_loss 1.777917, disc_loss 0.613109\n",
      "batch 22, gen_loss 1.700913, disc_loss 0.632887\n",
      "batch 23, gen_loss 1.663007, disc_loss 0.645307\n",
      "batch 24, gen_loss 1.812092, disc_loss 0.582024\n",
      "batch 25, gen_loss 1.792209, disc_loss 0.671245\n",
      "batch 26, gen_loss 1.955719, disc_loss 0.650680\n",
      "batch 27, gen_loss 1.968963, disc_loss 0.592795\n",
      "batch 28, gen_loss 1.850476, disc_loss 0.699432\n",
      "batch 29, gen_loss 1.725298, disc_loss 0.661738\n",
      "batch 30, gen_loss 1.646315, disc_loss 0.669190\n",
      "batch 31, gen_loss 1.641142, disc_loss 0.643175\n",
      "batch 32, gen_loss 1.638435, disc_loss 0.668380\n",
      "batch 33, gen_loss 1.834084, disc_loss 0.616827\n",
      "batch 34, gen_loss 1.887878, disc_loss 0.742520\n",
      "batch 35, gen_loss 1.828315, disc_loss 0.733315\n",
      "batch 36, gen_loss 1.699875, disc_loss 0.686509\n",
      "batch 37, gen_loss 1.577454, disc_loss 0.673565\n",
      "batch 38, gen_loss 1.630771, disc_loss 0.677938\n",
      "batch 39, gen_loss 1.680180, disc_loss 0.646444\n",
      "batch 40, gen_loss 1.676218, disc_loss 0.710559\n",
      "batch 41, gen_loss 1.811119, disc_loss 0.780579\n",
      "batch 42, gen_loss 1.883600, disc_loss 0.739269\n",
      "batch 43, gen_loss 1.808199, disc_loss 0.681739\n",
      "batch 44, gen_loss 1.685345, disc_loss 0.744387\n",
      "batch 45, gen_loss 1.645342, disc_loss 0.688356\n",
      "batch 46, gen_loss 1.640672, disc_loss 0.743970\n",
      "batch 47, gen_loss 1.608194, disc_loss 0.711580\n",
      "batch 48, gen_loss 1.741131, disc_loss 0.708146\n",
      "batch 49, gen_loss 1.854305, disc_loss 0.642133\n",
      "batch 50, gen_loss 1.950074, disc_loss 0.693092\n",
      "batch 51, gen_loss 1.876266, disc_loss 0.730663\n",
      "batch 52, gen_loss 1.789378, disc_loss 0.800464\n",
      "batch 53, gen_loss 1.644393, disc_loss 0.786837\n",
      "batch 54, gen_loss 1.478462, disc_loss 0.799949\n",
      "batch 55, gen_loss 1.414280, disc_loss 0.880254\n",
      "batch 56, gen_loss 1.388490, disc_loss 0.803228\n",
      "batch 57, gen_loss 1.607334, disc_loss 0.773859\n",
      "batch 58, gen_loss 1.606340, disc_loss 0.832081\n",
      "batch 59, gen_loss 1.800129, disc_loss 0.758915\n",
      "batch 60, gen_loss 1.782037, disc_loss 0.798706\n",
      "batch 61, gen_loss 1.747998, disc_loss 0.785738\n",
      "batch 62, gen_loss 1.598955, disc_loss 0.797318\n",
      "batch 63, gen_loss 1.631974, disc_loss 0.799875\n",
      "batch 64, gen_loss 1.546609, disc_loss 0.822314\n",
      "batch 65, gen_loss 1.441930, disc_loss 0.864358\n",
      "batch 66, gen_loss 1.364049, disc_loss 0.953665\n",
      "batch 67, gen_loss 1.639854, disc_loss 0.822859\n",
      "batch 68, gen_loss 1.505077, disc_loss 0.860406\n",
      "batch 69, gen_loss 1.609748, disc_loss 0.812266\n",
      "batch 70, gen_loss 1.692917, disc_loss 0.775561\n",
      "batch 71, gen_loss 1.633188, disc_loss 0.919138\n",
      "batch 72, gen_loss 1.429816, disc_loss 0.883767\n",
      "batch 73, gen_loss 1.423582, disc_loss 0.831195\n",
      "batch 74, gen_loss 1.356782, disc_loss 0.901763\n",
      "batch 75, gen_loss 1.450252, disc_loss 0.903372\n",
      "batch 76, gen_loss 1.488654, disc_loss 0.871633\n",
      "batch 77, gen_loss 1.489276, disc_loss 0.884916\n",
      "batch 78, gen_loss 1.589800, disc_loss 0.917480\n",
      "batch 79, gen_loss 1.569178, disc_loss 0.871969\n",
      "batch 80, gen_loss 1.537739, disc_loss 0.844608\n",
      "batch 81, gen_loss 1.383414, disc_loss 0.921334\n",
      "batch 82, gen_loss 1.277990, disc_loss 0.842022\n",
      "batch 83, gen_loss 1.367880, disc_loss 0.921974\n",
      "batch 84, gen_loss 1.441954, disc_loss 0.942411\n",
      "batch 85, gen_loss 1.576681, disc_loss 0.908498\n",
      "batch 86, gen_loss 1.593306, disc_loss 0.894465\n",
      "batch 87, gen_loss 1.431798, disc_loss 0.897555\n",
      "batch 88, gen_loss 1.317061, disc_loss 0.908865\n",
      "batch 89, gen_loss 1.376062, disc_loss 0.959782\n",
      "batch 90, gen_loss 1.322907, disc_loss 0.933773\n",
      "batch 91, gen_loss 1.424393, disc_loss 0.916552\n",
      "batch 92, gen_loss 1.639835, disc_loss 0.908435\n",
      "batch 93, gen_loss 1.645838, disc_loss 0.862652\n",
      "batch 94, gen_loss 1.714666, disc_loss 0.918269\n",
      "batch 95, gen_loss 1.468968, disc_loss 0.927018\n",
      "batch 96, gen_loss 1.357578, disc_loss 0.958044\n",
      "batch 97, gen_loss 1.179627, disc_loss 0.944345\n",
      "batch 98, gen_loss 1.361427, disc_loss 0.887528\n",
      "batch 99, gen_loss 1.539902, disc_loss 0.916121\n",
      "batch 100, gen_loss 1.742363, disc_loss 0.936709\n",
      "batch 101, gen_loss 1.750192, disc_loss 1.018591\n",
      "batch 102, gen_loss 1.487495, disc_loss 0.982909\n",
      "batch 103, gen_loss 1.201097, disc_loss 0.978399\n",
      "batch 104, gen_loss 1.204067, disc_loss 0.921582\n",
      "batch 105, gen_loss 1.335213, disc_loss 1.069125\n",
      "batch 106, gen_loss 1.611378, disc_loss 0.936473\n",
      "batch 107, gen_loss 1.669402, disc_loss 0.902758\n",
      "batch 108, gen_loss 1.641956, disc_loss 0.956165\n",
      "batch 109, gen_loss 1.586993, disc_loss 0.887766\n",
      "batch 110, gen_loss 1.347064, disc_loss 0.936336\n",
      "batch 111, gen_loss 1.335316, disc_loss 0.907201\n",
      "batch 112, gen_loss 1.473112, disc_loss 1.012008\n",
      "batch 113, gen_loss 1.559204, disc_loss 0.867787\n",
      "batch 114, gen_loss 1.673607, disc_loss 0.917801\n",
      "batch 115, gen_loss 1.766272, disc_loss 0.926214\n",
      "batch 116, gen_loss 1.544762, disc_loss 0.847214\n",
      "batch 117, gen_loss 1.511351, disc_loss 0.944012\n",
      "batch 118, gen_loss 1.466158, disc_loss 0.886410\n",
      "batch 119, gen_loss 1.376195, disc_loss 0.850329\n",
      "batch 120, gen_loss 1.509875, disc_loss 0.867004\n",
      "batch 121, gen_loss 1.702359, disc_loss 0.934519\n",
      "batch 122, gen_loss 1.737383, disc_loss 0.866006\n",
      "batch 123, gen_loss 1.596069, disc_loss 0.899154\n",
      "batch 124, gen_loss 1.550272, disc_loss 0.847903\n",
      "batch 125, gen_loss 1.618458, disc_loss 0.836949\n",
      "batch 126, gen_loss 1.542519, disc_loss 0.839575\n",
      "batch 127, gen_loss 1.551639, disc_loss 0.785415\n",
      "batch 128, gen_loss 1.625002, disc_loss 0.804891\n",
      "batch 129, gen_loss 1.726962, disc_loss 0.919967\n",
      "batch 130, gen_loss 1.720513, disc_loss 0.843036\n",
      "batch 131, gen_loss 1.494631, disc_loss 0.867122\n",
      "batch 132, gen_loss 1.525458, disc_loss 0.785984\n",
      "batch 133, gen_loss 1.467313, disc_loss 0.817562\n",
      "batch 134, gen_loss 1.578223, disc_loss 0.816248\n",
      "batch 135, gen_loss 1.755118, disc_loss 0.801716\n",
      "batch 136, gen_loss 1.718426, disc_loss 0.798449\n",
      "batch 137, gen_loss 1.699686, disc_loss 0.887784\n",
      "batch 138, gen_loss 1.683294, disc_loss 0.752507\n",
      "batch 139, gen_loss 1.630731, disc_loss 0.733985\n",
      "batch 140, gen_loss 1.550073, disc_loss 0.746097\n",
      "batch 141, gen_loss 1.612693, disc_loss 0.802963\n",
      "batch 142, gen_loss 1.660066, disc_loss 0.773690\n",
      "batch 143, gen_loss 1.686192, disc_loss 0.747177\n",
      "batch 144, gen_loss 1.716033, disc_loss 0.771360\n",
      "batch 145, gen_loss 1.816377, disc_loss 0.715943\n",
      "batch 146, gen_loss 1.764849, disc_loss 0.706493\n",
      "batch 147, gen_loss 1.623889, disc_loss 0.764638\n",
      "batch 148, gen_loss 1.702222, disc_loss 0.743042\n",
      "batch 149, gen_loss 1.548563, disc_loss 0.724151\n",
      "batch 150, gen_loss 1.781958, disc_loss 0.694757\n",
      "batch 151, gen_loss 1.757489, disc_loss 0.694274\n",
      "batch 152, gen_loss 1.860171, disc_loss 0.628344\n",
      "batch 153, gen_loss 1.856491, disc_loss 0.657760\n",
      "batch 154, gen_loss 1.771715, disc_loss 0.755170\n",
      "batch 155, gen_loss 1.765132, disc_loss 0.733114\n",
      "batch 156, gen_loss 1.588443, disc_loss 0.714219\n",
      "batch 157, gen_loss 1.574365, disc_loss 0.716246\n",
      "batch 158, gen_loss 1.626087, disc_loss 0.675398\n",
      "batch 159, gen_loss 1.769169, disc_loss 0.761302\n",
      "batch 160, gen_loss 1.803467, disc_loss 0.725364\n",
      "batch 161, gen_loss 1.929740, disc_loss 0.750049\n",
      "batch 162, gen_loss 1.663409, disc_loss 0.814168\n",
      "batch 163, gen_loss 1.689456, disc_loss 0.662583\n",
      "batch 164, gen_loss 1.633447, disc_loss 0.700358\n",
      "batch 165, gen_loss 1.615217, disc_loss 0.774125\n",
      "batch 166, gen_loss 1.593676, disc_loss 0.711717\n",
      "batch 167, gen_loss 1.677838, disc_loss 0.728043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 168, gen_loss 1.809365, disc_loss 0.787897\n",
      "batch 169, gen_loss 1.951698, disc_loss 0.826456\n",
      "batch 170, gen_loss 1.755131, disc_loss 0.768567\n",
      "batch 171, gen_loss 1.630438, disc_loss 0.737800\n",
      "batch 172, gen_loss 1.595960, disc_loss 0.763391\n",
      "batch 173, gen_loss 1.596117, disc_loss 0.798779\n",
      "batch 174, gen_loss 1.515964, disc_loss 0.858687\n",
      "batch 175, gen_loss 1.587139, disc_loss 0.839153\n",
      "batch 176, gen_loss 1.673390, disc_loss 0.843837\n",
      "batch 177, gen_loss 1.567929, disc_loss 0.809995\n",
      "batch 178, gen_loss 1.604146, disc_loss 0.826689\n",
      "batch 179, gen_loss 1.637313, disc_loss 0.751579\n",
      "batch 180, gen_loss 1.537094, disc_loss 0.918939\n",
      "batch 181, gen_loss 1.466707, disc_loss 0.877718\n",
      "batch 182, gen_loss 1.449316, disc_loss 0.827854\n",
      "batch 183, gen_loss 1.525715, disc_loss 0.828679\n",
      "batch 184, gen_loss 1.452353, disc_loss 0.809203\n",
      "batch 185, gen_loss 1.615879, disc_loss 0.881165\n",
      "batch 186, gen_loss 1.619307, disc_loss 0.841474\n",
      "batch 187, gen_loss 1.571014, disc_loss 0.933332\n",
      "batch 188, gen_loss 1.531498, disc_loss 0.908497\n",
      "batch 189, gen_loss 1.362055, disc_loss 0.967911\n",
      "batch 190, gen_loss 1.391857, disc_loss 0.872043\n",
      "batch 191, gen_loss 1.415188, disc_loss 0.883262\n",
      "batch 192, gen_loss 1.541006, disc_loss 0.957791\n",
      "batch 193, gen_loss 1.554119, disc_loss 0.915983\n",
      "batch 194, gen_loss 1.525426, disc_loss 0.914189\n",
      "batch 195, gen_loss 1.494600, disc_loss 0.928675\n",
      "batch 196, gen_loss 1.408271, disc_loss 0.869941\n",
      "batch 197, gen_loss 1.392713, disc_loss 0.970744\n",
      "batch 198, gen_loss 1.236599, disc_loss 0.997296\n",
      "batch 199, gen_loss 1.273042, disc_loss 0.956127\n",
      "batch 200, gen_loss 1.400678, disc_loss 1.008346\n",
      "batch 201, gen_loss 1.480103, disc_loss 0.926155\n",
      "batch 202, gen_loss 1.634629, disc_loss 0.918056\n",
      "batch 203, gen_loss 1.493469, disc_loss 0.916400\n",
      "batch 204, gen_loss 1.528857, disc_loss 0.825133\n",
      "batch 205, gen_loss 1.351355, disc_loss 0.950185\n",
      "batch 206, gen_loss 1.296335, disc_loss 0.949962\n",
      "batch 207, gen_loss 1.306282, disc_loss 0.904746\n",
      "batch 208, gen_loss 1.421810, disc_loss 0.901486\n",
      "batch 209, gen_loss 1.439789, disc_loss 0.938881\n",
      "batch 210, gen_loss 1.555801, disc_loss 0.877058\n",
      "batch 211, gen_loss 1.685091, disc_loss 0.866099\n",
      "batch 212, gen_loss 1.573039, disc_loss 0.920649\n",
      "batch 213, gen_loss 1.464607, disc_loss 0.896271\n",
      "batch 214, gen_loss 1.332218, disc_loss 0.899190\n",
      "batch 215, gen_loss 1.209081, disc_loss 0.907387\n",
      "batch 216, gen_loss 1.417140, disc_loss 0.900200\n",
      "batch 217, gen_loss 1.570152, disc_loss 0.850066\n",
      "batch 218, gen_loss 1.742817, disc_loss 0.782232\n",
      "batch 219, gen_loss 1.693819, disc_loss 0.884540\n",
      "batch 220, gen_loss 1.676457, disc_loss 0.842725\n",
      "batch 221, gen_loss 1.498772, disc_loss 0.816418\n",
      "batch 222, gen_loss 1.445885, disc_loss 0.774674\n",
      "batch 223, gen_loss 1.438358, disc_loss 0.774170\n",
      "batch 224, gen_loss 1.454107, disc_loss 0.841246\n",
      "batch 225, gen_loss 1.524152, disc_loss 0.803721\n",
      "batch 226, gen_loss 1.647894, disc_loss 0.779659\n",
      "batch 227, gen_loss 1.733649, disc_loss 0.726999\n",
      "batch 228, gen_loss 1.820793, disc_loss 0.730947\n",
      "batch 229, gen_loss 1.824410, disc_loss 0.726792\n",
      "batch 230, gen_loss 1.551134, disc_loss 0.707632\n",
      "batch 231, gen_loss 1.537357, disc_loss 0.764099\n",
      "batch 232, gen_loss 1.542596, disc_loss 0.715799\n",
      "batch 233, gen_loss 1.720879, disc_loss 0.700789\n",
      "batch 234, gen_loss 1.881459, disc_loss 0.623475\n",
      "Time for epoch26is 7.892776966094971 sec\n",
      "batch 0, gen_loss 1.863932, disc_loss 0.683516\n",
      "batch 1, gen_loss 1.908654, disc_loss 0.711046\n",
      "batch 2, gen_loss 1.848462, disc_loss 0.745087\n",
      "batch 3, gen_loss 1.654346, disc_loss 0.742388\n",
      "batch 4, gen_loss 1.426385, disc_loss 0.744788\n",
      "batch 5, gen_loss 1.524857, disc_loss 0.745305\n",
      "batch 6, gen_loss 1.557498, disc_loss 0.733257\n",
      "batch 7, gen_loss 1.724955, disc_loss 0.695816\n",
      "batch 8, gen_loss 1.858839, disc_loss 0.670182\n",
      "batch 9, gen_loss 1.922396, disc_loss 0.710868\n",
      "batch 10, gen_loss 2.032592, disc_loss 0.681588\n",
      "batch 11, gen_loss 1.709625, disc_loss 0.663546\n",
      "batch 12, gen_loss 1.576813, disc_loss 0.699488\n",
      "batch 13, gen_loss 1.635229, disc_loss 0.634588\n",
      "batch 14, gen_loss 1.683580, disc_loss 0.756969\n",
      "batch 15, gen_loss 1.720036, disc_loss 0.676766\n",
      "batch 16, gen_loss 1.765812, disc_loss 0.736267\n",
      "batch 17, gen_loss 1.858394, disc_loss 0.671161\n",
      "batch 18, gen_loss 1.862827, disc_loss 0.694030\n",
      "batch 19, gen_loss 1.701589, disc_loss 0.769585\n",
      "batch 20, gen_loss 1.757872, disc_loss 0.702025\n",
      "batch 21, gen_loss 1.691458, disc_loss 0.701777\n",
      "batch 22, gen_loss 1.580731, disc_loss 0.721813\n",
      "batch 23, gen_loss 1.644427, disc_loss 0.769763\n",
      "batch 24, gen_loss 1.755456, disc_loss 0.780838\n",
      "batch 25, gen_loss 1.951263, disc_loss 0.646598\n",
      "batch 26, gen_loss 1.795784, disc_loss 0.808535\n",
      "batch 27, gen_loss 1.627791, disc_loss 0.793911\n",
      "batch 28, gen_loss 1.551670, disc_loss 0.804933\n",
      "batch 29, gen_loss 1.521409, disc_loss 0.758024\n",
      "batch 30, gen_loss 1.546942, disc_loss 0.837593\n",
      "batch 31, gen_loss 1.633188, disc_loss 0.683619\n",
      "batch 32, gen_loss 1.661890, disc_loss 0.862704\n",
      "batch 33, gen_loss 1.644024, disc_loss 0.990708\n",
      "batch 34, gen_loss 1.645720, disc_loss 0.924890\n",
      "batch 35, gen_loss 1.547349, disc_loss 0.872079\n",
      "batch 36, gen_loss 1.461867, disc_loss 0.856800\n",
      "batch 37, gen_loss 1.451342, disc_loss 0.881575\n",
      "batch 38, gen_loss 1.572335, disc_loss 0.758951\n",
      "batch 39, gen_loss 1.622497, disc_loss 0.956217\n",
      "batch 40, gen_loss 1.733953, disc_loss 0.850119\n",
      "batch 41, gen_loss 1.777570, disc_loss 0.900639\n",
      "batch 42, gen_loss 1.651276, disc_loss 0.914397\n",
      "batch 43, gen_loss 1.493811, disc_loss 0.901872\n",
      "batch 44, gen_loss 1.434105, disc_loss 0.927322\n",
      "batch 45, gen_loss 1.404546, disc_loss 0.994452\n",
      "batch 46, gen_loss 1.498100, disc_loss 0.955394\n",
      "batch 47, gen_loss 1.646757, disc_loss 0.876602\n",
      "batch 48, gen_loss 1.583564, disc_loss 0.924453\n",
      "batch 49, gen_loss 1.647577, disc_loss 0.946768\n",
      "batch 50, gen_loss 1.640998, disc_loss 0.867400\n",
      "batch 51, gen_loss 1.564872, disc_loss 0.906149\n",
      "batch 52, gen_loss 1.519415, disc_loss 0.897153\n",
      "batch 53, gen_loss 1.486656, disc_loss 0.928180\n",
      "batch 54, gen_loss 1.295405, disc_loss 1.048558\n",
      "batch 55, gen_loss 1.557848, disc_loss 0.888616\n",
      "batch 56, gen_loss 1.475262, disc_loss 0.851470\n",
      "batch 57, gen_loss 1.636282, disc_loss 0.910361\n",
      "batch 58, gen_loss 1.748296, disc_loss 0.873912\n",
      "batch 59, gen_loss 1.751469, disc_loss 0.853517\n",
      "batch 60, gen_loss 1.569105, disc_loss 0.958404\n",
      "batch 61, gen_loss 1.363124, disc_loss 0.953887\n",
      "batch 62, gen_loss 1.319512, disc_loss 0.864033\n",
      "batch 63, gen_loss 1.489859, disc_loss 0.887654\n",
      "batch 64, gen_loss 1.509140, disc_loss 1.002411\n",
      "batch 65, gen_loss 1.526729, disc_loss 0.762888\n",
      "batch 66, gen_loss 1.640295, disc_loss 0.902239\n",
      "batch 67, gen_loss 1.619555, disc_loss 0.793437\n",
      "batch 68, gen_loss 1.722316, disc_loss 0.838233\n",
      "batch 69, gen_loss 1.639025, disc_loss 0.800460\n",
      "batch 70, gen_loss 1.647162, disc_loss 0.772519\n",
      "batch 71, gen_loss 1.556380, disc_loss 0.789263\n",
      "batch 72, gen_loss 1.639684, disc_loss 0.813138\n",
      "batch 73, gen_loss 1.524549, disc_loss 0.775989\n",
      "batch 74, gen_loss 1.707602, disc_loss 0.825850\n",
      "batch 75, gen_loss 1.671960, disc_loss 0.709542\n",
      "batch 76, gen_loss 1.674765, disc_loss 0.790750\n",
      "batch 77, gen_loss 1.741843, disc_loss 0.799737\n",
      "batch 78, gen_loss 1.606057, disc_loss 0.784866\n",
      "batch 79, gen_loss 1.579477, disc_loss 0.818048\n",
      "batch 80, gen_loss 1.543184, disc_loss 0.712982\n",
      "batch 81, gen_loss 1.629184, disc_loss 0.761222\n",
      "batch 82, gen_loss 1.739259, disc_loss 0.779449\n",
      "batch 83, gen_loss 1.868035, disc_loss 0.733035\n",
      "batch 84, gen_loss 1.750357, disc_loss 0.829469\n",
      "batch 85, gen_loss 1.537111, disc_loss 0.716697\n",
      "batch 86, gen_loss 1.592604, disc_loss 0.774361\n",
      "batch 87, gen_loss 1.658932, disc_loss 0.716300\n",
      "batch 88, gen_loss 1.622475, disc_loss 0.635287\n",
      "batch 89, gen_loss 1.600592, disc_loss 0.839685\n",
      "batch 90, gen_loss 1.763273, disc_loss 0.813850\n",
      "batch 91, gen_loss 1.764065, disc_loss 0.822404\n",
      "batch 92, gen_loss 1.826344, disc_loss 0.691070\n",
      "batch 93, gen_loss 1.691829, disc_loss 0.787546\n",
      "batch 94, gen_loss 1.601451, disc_loss 0.746475\n",
      "batch 95, gen_loss 1.546607, disc_loss 0.750049\n",
      "batch 96, gen_loss 1.538092, disc_loss 0.830330\n",
      "batch 97, gen_loss 1.607751, disc_loss 0.750617\n",
      "batch 98, gen_loss 1.690364, disc_loss 0.790482\n",
      "batch 99, gen_loss 1.838470, disc_loss 0.736277\n",
      "batch 100, gen_loss 1.834561, disc_loss 0.800274\n",
      "batch 101, gen_loss 1.854731, disc_loss 0.691071\n",
      "batch 102, gen_loss 1.756314, disc_loss 0.751756\n",
      "batch 103, gen_loss 1.594203, disc_loss 0.783795\n",
      "batch 104, gen_loss 1.561738, disc_loss 0.787006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 105, gen_loss 1.561457, disc_loss 0.756256\n",
      "batch 106, gen_loss 1.690585, disc_loss 0.679949\n",
      "batch 107, gen_loss 1.771728, disc_loss 0.843948\n",
      "batch 108, gen_loss 1.804997, disc_loss 0.749540\n",
      "batch 109, gen_loss 1.908331, disc_loss 0.711831\n",
      "batch 110, gen_loss 1.793463, disc_loss 0.730878\n",
      "batch 111, gen_loss 1.775897, disc_loss 0.776552\n",
      "batch 112, gen_loss 1.632760, disc_loss 0.653147\n",
      "batch 113, gen_loss 1.688502, disc_loss 0.702470\n",
      "batch 114, gen_loss 1.694914, disc_loss 0.733957\n",
      "batch 115, gen_loss 1.672551, disc_loss 0.698050\n",
      "batch 116, gen_loss 1.800040, disc_loss 0.652822\n",
      "batch 117, gen_loss 1.817826, disc_loss 0.690159\n",
      "batch 118, gen_loss 1.893779, disc_loss 0.686376\n",
      "batch 119, gen_loss 1.905205, disc_loss 0.675865\n",
      "batch 120, gen_loss 1.801536, disc_loss 0.723827\n",
      "batch 121, gen_loss 1.671212, disc_loss 0.684159\n",
      "batch 122, gen_loss 1.700513, disc_loss 0.703046\n",
      "batch 123, gen_loss 1.787497, disc_loss 0.732941\n",
      "batch 124, gen_loss 1.735480, disc_loss 0.663915\n",
      "batch 125, gen_loss 1.812501, disc_loss 0.678238\n",
      "batch 126, gen_loss 1.779895, disc_loss 0.632385\n",
      "batch 127, gen_loss 1.757834, disc_loss 0.640384\n",
      "batch 128, gen_loss 1.728064, disc_loss 0.706669\n",
      "batch 129, gen_loss 1.753575, disc_loss 0.677711\n",
      "batch 130, gen_loss 1.705748, disc_loss 0.610653\n",
      "batch 131, gen_loss 1.709130, disc_loss 0.616825\n",
      "batch 132, gen_loss 1.861582, disc_loss 0.728144\n",
      "batch 133, gen_loss 1.799216, disc_loss 0.619910\n",
      "batch 134, gen_loss 1.714197, disc_loss 0.600441\n",
      "batch 135, gen_loss 1.698284, disc_loss 0.614050\n",
      "batch 136, gen_loss 1.908494, disc_loss 0.609150\n",
      "batch 137, gen_loss 1.730470, disc_loss 0.683141\n",
      "batch 138, gen_loss 1.974776, disc_loss 0.567746\n",
      "batch 139, gen_loss 1.986388, disc_loss 0.556019\n",
      "batch 140, gen_loss 1.949322, disc_loss 0.607979\n",
      "batch 141, gen_loss 1.947793, disc_loss 0.581568\n",
      "batch 142, gen_loss 1.802014, disc_loss 0.632341\n",
      "batch 143, gen_loss 1.914392, disc_loss 0.550673\n",
      "batch 144, gen_loss 1.898097, disc_loss 0.597720\n",
      "batch 145, gen_loss 1.764234, disc_loss 0.608958\n",
      "batch 146, gen_loss 1.816031, disc_loss 0.573157\n",
      "batch 147, gen_loss 1.846418, disc_loss 0.523546\n",
      "batch 148, gen_loss 1.897448, disc_loss 0.617683\n",
      "batch 149, gen_loss 1.987101, disc_loss 0.581000\n",
      "batch 150, gen_loss 1.891728, disc_loss 0.672751\n",
      "batch 151, gen_loss 1.877721, disc_loss 0.648477\n",
      "batch 152, gen_loss 1.783186, disc_loss 0.617979\n",
      "batch 153, gen_loss 1.915900, disc_loss 0.582182\n",
      "batch 154, gen_loss 1.970107, disc_loss 0.534896\n",
      "batch 155, gen_loss 2.082735, disc_loss 0.616028\n",
      "batch 156, gen_loss 1.991626, disc_loss 0.554152\n",
      "batch 157, gen_loss 2.004881, disc_loss 0.603679\n",
      "batch 158, gen_loss 2.001643, disc_loss 0.527770\n",
      "batch 159, gen_loss 1.934695, disc_loss 0.623373\n",
      "batch 160, gen_loss 1.779654, disc_loss 0.586598\n",
      "batch 161, gen_loss 1.944638, disc_loss 0.644032\n",
      "batch 162, gen_loss 2.007704, disc_loss 0.591592\n",
      "batch 163, gen_loss 2.036260, disc_loss 0.559686\n",
      "batch 164, gen_loss 1.912312, disc_loss 0.629305\n",
      "batch 165, gen_loss 1.924717, disc_loss 0.655335\n",
      "batch 166, gen_loss 1.963911, disc_loss 0.596166\n",
      "batch 167, gen_loss 1.961313, disc_loss 0.710140\n",
      "batch 168, gen_loss 1.968406, disc_loss 0.671869\n",
      "batch 169, gen_loss 2.005208, disc_loss 0.661812\n",
      "batch 170, gen_loss 2.057068, disc_loss 0.641022\n",
      "batch 171, gen_loss 1.994584, disc_loss 0.656162\n",
      "batch 172, gen_loss 2.041800, disc_loss 0.666700\n",
      "batch 173, gen_loss 1.791788, disc_loss 0.689297\n",
      "batch 174, gen_loss 1.835125, disc_loss 0.721543\n",
      "batch 175, gen_loss 1.778287, disc_loss 0.708446\n",
      "batch 176, gen_loss 1.892401, disc_loss 0.817375\n",
      "batch 177, gen_loss 1.770889, disc_loss 0.765568\n",
      "batch 178, gen_loss 1.862749, disc_loss 0.752980\n",
      "batch 179, gen_loss 1.878291, disc_loss 0.765752\n",
      "batch 180, gen_loss 1.956622, disc_loss 0.769233\n",
      "batch 181, gen_loss 1.808211, disc_loss 0.759877\n",
      "batch 182, gen_loss 1.764119, disc_loss 0.810119\n",
      "batch 183, gen_loss 1.637476, disc_loss 0.823989\n",
      "batch 184, gen_loss 1.517260, disc_loss 0.780441\n",
      "batch 185, gen_loss 1.544954, disc_loss 0.856265\n",
      "batch 186, gen_loss 1.690474, disc_loss 0.807870\n",
      "batch 187, gen_loss 1.811683, disc_loss 0.807283\n",
      "batch 188, gen_loss 1.724618, disc_loss 1.023333\n",
      "batch 189, gen_loss 1.726170, disc_loss 0.949626\n",
      "batch 190, gen_loss 1.677747, disc_loss 0.892785\n",
      "batch 191, gen_loss 1.654675, disc_loss 0.888313\n",
      "batch 192, gen_loss 1.602316, disc_loss 0.939736\n",
      "batch 193, gen_loss 1.484810, disc_loss 0.953183\n",
      "batch 194, gen_loss 1.343535, disc_loss 1.074377\n",
      "batch 195, gen_loss 1.589705, disc_loss 0.984040\n",
      "batch 196, gen_loss 1.516907, disc_loss 0.947144\n",
      "batch 197, gen_loss 1.598584, disc_loss 0.878815\n",
      "batch 198, gen_loss 1.782793, disc_loss 0.981887\n",
      "batch 199, gen_loss 1.746925, disc_loss 0.884023\n",
      "batch 200, gen_loss 1.547122, disc_loss 1.012444\n",
      "batch 201, gen_loss 1.471887, disc_loss 0.965394\n",
      "batch 202, gen_loss 1.319285, disc_loss 1.038675\n",
      "batch 203, gen_loss 1.418595, disc_loss 1.027403\n",
      "batch 204, gen_loss 1.383662, disc_loss 1.088350\n",
      "batch 205, gen_loss 1.419426, disc_loss 1.070688\n",
      "batch 206, gen_loss 1.491454, disc_loss 1.200613\n",
      "batch 207, gen_loss 1.493277, disc_loss 1.017480\n",
      "batch 208, gen_loss 1.513366, disc_loss 1.068395\n",
      "batch 209, gen_loss 1.347664, disc_loss 1.071312\n",
      "batch 210, gen_loss 1.199353, disc_loss 1.166942\n",
      "batch 211, gen_loss 1.296760, disc_loss 1.059744\n",
      "batch 212, gen_loss 1.331726, disc_loss 1.148680\n",
      "batch 213, gen_loss 1.525821, disc_loss 1.080807\n",
      "batch 214, gen_loss 1.525572, disc_loss 1.165038\n",
      "batch 215, gen_loss 1.458046, disc_loss 1.059105\n",
      "batch 216, gen_loss 1.371638, disc_loss 1.121416\n",
      "batch 217, gen_loss 1.224432, disc_loss 1.015891\n",
      "batch 218, gen_loss 1.184120, disc_loss 1.166575\n",
      "batch 219, gen_loss 1.258857, disc_loss 1.109003\n",
      "batch 220, gen_loss 1.426261, disc_loss 1.061719\n",
      "batch 221, gen_loss 1.413977, disc_loss 1.093977\n",
      "batch 222, gen_loss 1.509172, disc_loss 1.150198\n",
      "batch 223, gen_loss 1.509838, disc_loss 1.012501\n",
      "batch 224, gen_loss 1.441566, disc_loss 0.924082\n",
      "batch 225, gen_loss 1.331047, disc_loss 1.066290\n",
      "batch 226, gen_loss 1.234443, disc_loss 1.139540\n",
      "batch 227, gen_loss 1.311206, disc_loss 0.970016\n",
      "batch 228, gen_loss 1.271230, disc_loss 1.115603\n",
      "batch 229, gen_loss 1.450453, disc_loss 1.015175\n",
      "batch 230, gen_loss 1.424263, disc_loss 0.957105\n",
      "batch 231, gen_loss 1.445778, disc_loss 1.128996\n",
      "batch 232, gen_loss 1.359405, disc_loss 1.026774\n",
      "batch 233, gen_loss 1.293044, disc_loss 1.035370\n",
      "batch 234, gen_loss 1.393692, disc_loss 0.936924\n",
      "Time for epoch27is 7.677850961685181 sec\n",
      "batch 0, gen_loss 1.375561, disc_loss 0.926073\n",
      "batch 1, gen_loss 1.360405, disc_loss 0.998315\n",
      "batch 2, gen_loss 1.454336, disc_loss 0.948333\n",
      "batch 3, gen_loss 1.413994, disc_loss 0.955438\n",
      "batch 4, gen_loss 1.449933, disc_loss 0.902671\n",
      "batch 5, gen_loss 1.501614, disc_loss 0.970535\n",
      "batch 6, gen_loss 1.586492, disc_loss 0.867935\n",
      "batch 7, gen_loss 1.487764, disc_loss 0.897859\n",
      "batch 8, gen_loss 1.445922, disc_loss 0.972195\n",
      "batch 9, gen_loss 1.267931, disc_loss 1.010229\n",
      "batch 10, gen_loss 1.351020, disc_loss 0.847653\n",
      "batch 11, gen_loss 1.427910, disc_loss 0.901386\n",
      "batch 12, gen_loss 1.472679, disc_loss 0.891315\n",
      "batch 13, gen_loss 1.532314, disc_loss 0.945808\n",
      "batch 14, gen_loss 1.668839, disc_loss 0.876709\n",
      "batch 15, gen_loss 1.492086, disc_loss 0.884488\n",
      "batch 16, gen_loss 1.400344, disc_loss 0.862116\n",
      "batch 17, gen_loss 1.345821, disc_loss 0.860613\n",
      "batch 18, gen_loss 1.379582, disc_loss 0.824535\n",
      "batch 19, gen_loss 1.536015, disc_loss 0.768229\n",
      "batch 20, gen_loss 1.654889, disc_loss 0.836731\n",
      "batch 21, gen_loss 1.716673, disc_loss 0.864932\n",
      "batch 22, gen_loss 1.641526, disc_loss 0.847054\n",
      "batch 23, gen_loss 1.403861, disc_loss 0.879224\n",
      "batch 24, gen_loss 1.404329, disc_loss 0.760421\n",
      "batch 25, gen_loss 1.440963, disc_loss 0.813856\n",
      "batch 26, gen_loss 1.433789, disc_loss 0.813033\n",
      "batch 27, gen_loss 1.478733, disc_loss 0.791354\n",
      "batch 28, gen_loss 1.621628, disc_loss 0.813071\n",
      "batch 29, gen_loss 1.685191, disc_loss 0.845046\n",
      "batch 30, gen_loss 1.794397, disc_loss 0.867149\n",
      "batch 31, gen_loss 1.721131, disc_loss 0.868846\n",
      "batch 32, gen_loss 1.594610, disc_loss 0.934995\n",
      "batch 33, gen_loss 1.491404, disc_loss 0.805003\n",
      "batch 34, gen_loss 1.312503, disc_loss 0.846426\n",
      "batch 35, gen_loss 1.430124, disc_loss 0.824261\n",
      "batch 36, gen_loss 1.523265, disc_loss 0.880933\n",
      "batch 37, gen_loss 1.758068, disc_loss 0.797386\n",
      "batch 38, gen_loss 1.782063, disc_loss 0.809522\n",
      "batch 39, gen_loss 1.734331, disc_loss 0.940686\n",
      "batch 40, gen_loss 1.713778, disc_loss 0.889376\n",
      "batch 41, gen_loss 1.449332, disc_loss 0.879136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 42, gen_loss 1.450490, disc_loss 0.847320\n",
      "batch 43, gen_loss 1.245214, disc_loss 0.938053\n",
      "batch 44, gen_loss 1.416660, disc_loss 0.888670\n",
      "batch 45, gen_loss 1.568894, disc_loss 0.839763\n",
      "batch 46, gen_loss 1.655870, disc_loss 0.878593\n",
      "batch 47, gen_loss 1.778952, disc_loss 0.900587\n",
      "batch 48, gen_loss 1.838034, disc_loss 0.884473\n",
      "batch 49, gen_loss 1.758623, disc_loss 0.872658\n",
      "batch 50, gen_loss 1.481134, disc_loss 0.987763\n",
      "batch 51, gen_loss 1.377828, disc_loss 0.867425\n",
      "batch 52, gen_loss 1.252614, disc_loss 0.923804\n",
      "batch 53, gen_loss 1.466862, disc_loss 0.878704\n",
      "batch 54, gen_loss 1.609453, disc_loss 1.031388\n",
      "batch 55, gen_loss 1.641982, disc_loss 0.886135\n",
      "batch 56, gen_loss 1.775960, disc_loss 0.828125\n",
      "batch 57, gen_loss 1.672708, disc_loss 0.839447\n",
      "batch 58, gen_loss 1.538024, disc_loss 0.855238\n",
      "batch 59, gen_loss 1.392810, disc_loss 0.883825\n",
      "batch 60, gen_loss 1.427410, disc_loss 0.877532\n",
      "batch 61, gen_loss 1.453671, disc_loss 0.850563\n",
      "batch 62, gen_loss 1.435834, disc_loss 0.907696\n",
      "batch 63, gen_loss 1.494742, disc_loss 0.922089\n",
      "batch 64, gen_loss 1.629211, disc_loss 0.911234\n",
      "batch 65, gen_loss 1.541974, disc_loss 0.829025\n",
      "batch 66, gen_loss 1.464218, disc_loss 0.901390\n",
      "batch 67, gen_loss 1.460690, disc_loss 0.899868\n",
      "batch 68, gen_loss 1.497007, disc_loss 0.857730\n",
      "batch 69, gen_loss 1.501001, disc_loss 0.934632\n",
      "batch 70, gen_loss 1.560447, disc_loss 0.912751\n",
      "batch 71, gen_loss 1.659202, disc_loss 0.777514\n",
      "batch 72, gen_loss 1.509742, disc_loss 0.953491\n",
      "batch 73, gen_loss 1.520618, disc_loss 0.878049\n",
      "batch 74, gen_loss 1.541207, disc_loss 0.868497\n",
      "batch 75, gen_loss 1.381734, disc_loss 0.933372\n",
      "batch 76, gen_loss 1.409173, disc_loss 0.796833\n",
      "batch 77, gen_loss 1.496837, disc_loss 0.818074\n",
      "batch 78, gen_loss 1.488857, disc_loss 0.822530\n",
      "batch 79, gen_loss 1.617797, disc_loss 0.835474\n",
      "batch 80, gen_loss 1.567794, disc_loss 0.901405\n",
      "batch 81, gen_loss 1.547149, disc_loss 0.755483\n",
      "batch 82, gen_loss 1.476194, disc_loss 0.871803\n",
      "batch 83, gen_loss 1.476929, disc_loss 0.863435\n",
      "batch 84, gen_loss 1.489276, disc_loss 0.816639\n",
      "batch 85, gen_loss 1.480358, disc_loss 0.867357\n",
      "batch 86, gen_loss 1.643050, disc_loss 0.769590\n",
      "batch 87, gen_loss 1.750266, disc_loss 0.785834\n",
      "batch 88, gen_loss 1.470141, disc_loss 0.793615\n",
      "batch 89, gen_loss 1.436326, disc_loss 0.764440\n",
      "batch 90, gen_loss 1.621444, disc_loss 0.779149\n",
      "batch 91, gen_loss 1.517166, disc_loss 0.823008\n",
      "batch 92, gen_loss 1.606105, disc_loss 0.793966\n",
      "batch 93, gen_loss 1.579824, disc_loss 0.765639\n",
      "batch 94, gen_loss 1.629052, disc_loss 0.743792\n",
      "batch 95, gen_loss 1.702990, disc_loss 0.695759\n",
      "batch 96, gen_loss 1.788317, disc_loss 0.772921\n",
      "batch 97, gen_loss 1.705284, disc_loss 0.781417\n",
      "batch 98, gen_loss 1.626022, disc_loss 0.694339\n",
      "batch 99, gen_loss 1.505352, disc_loss 0.737507\n",
      "batch 100, gen_loss 1.610448, disc_loss 0.798660\n",
      "batch 101, gen_loss 1.666991, disc_loss 0.738525\n",
      "batch 102, gen_loss 1.560465, disc_loss 0.819296\n",
      "batch 103, gen_loss 1.746251, disc_loss 0.736203\n",
      "batch 104, gen_loss 1.770669, disc_loss 0.691732\n",
      "batch 105, gen_loss 1.774987, disc_loss 0.661759\n",
      "batch 106, gen_loss 1.712934, disc_loss 0.702137\n",
      "batch 107, gen_loss 1.631402, disc_loss 0.733243\n",
      "batch 108, gen_loss 1.654521, disc_loss 0.714627\n",
      "batch 109, gen_loss 1.643065, disc_loss 0.711770\n",
      "batch 110, gen_loss 1.669646, disc_loss 0.735247\n",
      "batch 111, gen_loss 1.563420, disc_loss 0.775605\n",
      "batch 112, gen_loss 1.550995, disc_loss 0.660076\n",
      "batch 113, gen_loss 1.545961, disc_loss 0.699005\n",
      "batch 114, gen_loss 1.735454, disc_loss 0.741177\n",
      "batch 115, gen_loss 1.785915, disc_loss 0.694209\n",
      "batch 116, gen_loss 1.690037, disc_loss 0.748458\n",
      "batch 117, gen_loss 1.635948, disc_loss 0.693601\n",
      "batch 118, gen_loss 1.690121, disc_loss 0.655027\n",
      "batch 119, gen_loss 1.562082, disc_loss 0.723578\n",
      "batch 120, gen_loss 1.584077, disc_loss 0.744115\n",
      "batch 121, gen_loss 1.766803, disc_loss 0.742899\n",
      "batch 122, gen_loss 1.813464, disc_loss 0.695730\n",
      "batch 123, gen_loss 1.783500, disc_loss 0.727143\n",
      "batch 124, gen_loss 1.642618, disc_loss 0.651842\n",
      "batch 125, gen_loss 1.670315, disc_loss 0.627109\n",
      "batch 126, gen_loss 1.549364, disc_loss 0.729557\n",
      "batch 127, gen_loss 1.679621, disc_loss 0.669589\n",
      "batch 128, gen_loss 1.834465, disc_loss 0.637251\n",
      "batch 129, gen_loss 1.726407, disc_loss 0.773796\n",
      "batch 130, gen_loss 1.675984, disc_loss 0.711825\n",
      "batch 131, gen_loss 1.632596, disc_loss 0.727969\n",
      "batch 132, gen_loss 1.597152, disc_loss 0.688896\n",
      "batch 133, gen_loss 1.627780, disc_loss 0.748008\n",
      "batch 134, gen_loss 1.728894, disc_loss 0.691931\n",
      "batch 135, gen_loss 1.895887, disc_loss 0.675645\n",
      "batch 136, gen_loss 1.712170, disc_loss 0.754781\n",
      "batch 137, gen_loss 1.678379, disc_loss 0.710555\n",
      "batch 138, gen_loss 1.600257, disc_loss 0.739239\n",
      "batch 139, gen_loss 1.499212, disc_loss 0.850400\n",
      "batch 140, gen_loss 1.528620, disc_loss 0.785069\n",
      "batch 141, gen_loss 1.543259, disc_loss 0.811552\n",
      "batch 142, gen_loss 1.533846, disc_loss 0.769779\n",
      "batch 143, gen_loss 1.505961, disc_loss 0.778691\n",
      "batch 144, gen_loss 1.491124, disc_loss 0.836168\n",
      "batch 145, gen_loss 1.759933, disc_loss 0.781149\n",
      "batch 146, gen_loss 1.544638, disc_loss 0.851942\n",
      "batch 147, gen_loss 1.635336, disc_loss 0.736040\n",
      "batch 148, gen_loss 1.624941, disc_loss 0.771185\n",
      "batch 149, gen_loss 1.635112, disc_loss 0.792936\n",
      "batch 150, gen_loss 1.534955, disc_loss 0.791118\n",
      "batch 151, gen_loss 1.564608, disc_loss 0.715921\n",
      "batch 152, gen_loss 1.561083, disc_loss 0.790256\n",
      "batch 153, gen_loss 1.679360, disc_loss 0.766231\n",
      "batch 154, gen_loss 1.669589, disc_loss 0.747399\n",
      "batch 155, gen_loss 1.638423, disc_loss 0.723371\n",
      "batch 156, gen_loss 1.603756, disc_loss 0.829206\n",
      "batch 157, gen_loss 1.667080, disc_loss 0.849368\n",
      "batch 158, gen_loss 1.470812, disc_loss 0.816701\n",
      "batch 159, gen_loss 1.486165, disc_loss 0.728958\n",
      "batch 160, gen_loss 1.622639, disc_loss 0.764980\n",
      "batch 161, gen_loss 1.610372, disc_loss 0.913514\n",
      "batch 162, gen_loss 1.550143, disc_loss 0.890165\n",
      "batch 163, gen_loss 1.572802, disc_loss 0.850397\n",
      "batch 164, gen_loss 1.404608, disc_loss 0.814328\n",
      "batch 165, gen_loss 1.494391, disc_loss 0.868358\n",
      "batch 166, gen_loss 1.400692, disc_loss 0.853368\n",
      "batch 167, gen_loss 1.605059, disc_loss 0.849224\n",
      "batch 168, gen_loss 1.827123, disc_loss 0.833474\n",
      "batch 169, gen_loss 1.695614, disc_loss 0.769334\n",
      "batch 170, gen_loss 1.524413, disc_loss 0.863067\n",
      "batch 171, gen_loss 1.384082, disc_loss 0.879373\n",
      "batch 172, gen_loss 1.381125, disc_loss 0.866758\n",
      "batch 173, gen_loss 1.363294, disc_loss 0.882687\n",
      "batch 174, gen_loss 1.484712, disc_loss 0.874379\n",
      "batch 175, gen_loss 1.646755, disc_loss 0.861395\n",
      "batch 176, gen_loss 1.742492, disc_loss 0.843690\n",
      "batch 177, gen_loss 1.641372, disc_loss 0.824335\n",
      "batch 178, gen_loss 1.546041, disc_loss 0.860907\n",
      "batch 179, gen_loss 1.397211, disc_loss 0.834133\n",
      "batch 180, gen_loss 1.397140, disc_loss 0.830759\n",
      "batch 181, gen_loss 1.445583, disc_loss 0.835351\n",
      "batch 182, gen_loss 1.651824, disc_loss 0.912202\n",
      "batch 183, gen_loss 1.764053, disc_loss 0.807191\n",
      "batch 184, gen_loss 1.672924, disc_loss 0.894568\n",
      "batch 185, gen_loss 1.539887, disc_loss 0.836646\n",
      "batch 186, gen_loss 1.475250, disc_loss 0.897772\n",
      "batch 187, gen_loss 1.450622, disc_loss 0.866943\n",
      "batch 188, gen_loss 1.592299, disc_loss 0.792133\n",
      "batch 189, gen_loss 1.573331, disc_loss 0.831752\n",
      "batch 190, gen_loss 1.550496, disc_loss 0.875844\n",
      "batch 191, gen_loss 1.608898, disc_loss 0.772764\n",
      "batch 192, gen_loss 1.732644, disc_loss 0.771705\n",
      "batch 193, gen_loss 1.795852, disc_loss 0.843871\n",
      "batch 194, gen_loss 1.639584, disc_loss 0.824496\n",
      "batch 195, gen_loss 1.622009, disc_loss 0.838176\n",
      "batch 196, gen_loss 1.572828, disc_loss 0.794345\n",
      "batch 197, gen_loss 1.530187, disc_loss 0.818608\n",
      "batch 198, gen_loss 1.537348, disc_loss 0.809251\n",
      "batch 199, gen_loss 1.735691, disc_loss 0.758593\n",
      "batch 200, gen_loss 1.810303, disc_loss 0.741273\n",
      "batch 201, gen_loss 1.833978, disc_loss 0.744762\n",
      "batch 202, gen_loss 1.695193, disc_loss 0.680378\n",
      "batch 203, gen_loss 1.699491, disc_loss 0.778718\n",
      "batch 204, gen_loss 1.613352, disc_loss 0.798550\n",
      "batch 205, gen_loss 1.658352, disc_loss 0.768578\n",
      "batch 206, gen_loss 1.473844, disc_loss 0.775740\n",
      "batch 207, gen_loss 1.735248, disc_loss 0.759924\n",
      "batch 208, gen_loss 1.792737, disc_loss 0.700874\n",
      "batch 209, gen_loss 1.801012, disc_loss 0.771033\n",
      "batch 210, gen_loss 1.853593, disc_loss 0.729931\n",
      "batch 211, gen_loss 1.762379, disc_loss 0.751392\n",
      "batch 212, gen_loss 1.613016, disc_loss 0.733590\n",
      "batch 213, gen_loss 1.580977, disc_loss 0.718625\n",
      "batch 214, gen_loss 1.550819, disc_loss 0.743846\n",
      "batch 215, gen_loss 1.673027, disc_loss 0.760119\n",
      "batch 216, gen_loss 1.822198, disc_loss 0.743894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 217, gen_loss 1.861315, disc_loss 0.688347\n",
      "batch 218, gen_loss 1.710743, disc_loss 0.711737\n",
      "batch 219, gen_loss 1.793501, disc_loss 0.740218\n",
      "batch 220, gen_loss 1.754269, disc_loss 0.672104\n",
      "batch 221, gen_loss 1.684079, disc_loss 0.711801\n",
      "batch 222, gen_loss 1.906494, disc_loss 0.756212\n",
      "batch 223, gen_loss 1.788853, disc_loss 0.769419\n",
      "batch 224, gen_loss 1.557125, disc_loss 0.845254\n",
      "batch 225, gen_loss 1.677296, disc_loss 0.686181\n",
      "batch 226, gen_loss 1.631709, disc_loss 0.742019\n",
      "batch 227, gen_loss 1.620969, disc_loss 0.744354\n",
      "batch 228, gen_loss 1.723747, disc_loss 0.742708\n",
      "batch 229, gen_loss 1.692924, disc_loss 0.784488\n",
      "batch 230, gen_loss 1.911427, disc_loss 0.837834\n",
      "batch 231, gen_loss 1.744161, disc_loss 0.693004\n",
      "batch 232, gen_loss 1.669463, disc_loss 0.717359\n",
      "batch 233, gen_loss 1.549777, disc_loss 0.762709\n",
      "batch 234, gen_loss 1.699018, disc_loss 0.839154\n",
      "Time for epoch28is 7.618254899978638 sec\n",
      "batch 0, gen_loss 1.680623, disc_loss 0.827776\n",
      "batch 1, gen_loss 1.733496, disc_loss 0.877047\n",
      "batch 2, gen_loss 1.735885, disc_loss 0.749472\n",
      "batch 3, gen_loss 1.682498, disc_loss 0.843915\n",
      "batch 4, gen_loss 1.649849, disc_loss 0.745838\n",
      "batch 5, gen_loss 1.740077, disc_loss 0.751949\n",
      "batch 6, gen_loss 1.717463, disc_loss 0.777342\n",
      "batch 7, gen_loss 1.741085, disc_loss 0.789652\n",
      "batch 8, gen_loss 1.721509, disc_loss 0.812771\n",
      "batch 9, gen_loss 1.711394, disc_loss 0.758618\n",
      "batch 10, gen_loss 1.709766, disc_loss 0.692769\n",
      "batch 11, gen_loss 1.549867, disc_loss 0.763097\n",
      "batch 12, gen_loss 1.585882, disc_loss 0.802304\n",
      "batch 13, gen_loss 1.622616, disc_loss 0.807880\n",
      "batch 14, gen_loss 1.731716, disc_loss 0.778960\n",
      "batch 15, gen_loss 1.898342, disc_loss 0.721750\n",
      "batch 16, gen_loss 1.949582, disc_loss 0.792062\n",
      "batch 17, gen_loss 1.726476, disc_loss 0.771146\n",
      "batch 18, gen_loss 1.681245, disc_loss 0.732192\n",
      "batch 19, gen_loss 1.641869, disc_loss 0.786541\n",
      "batch 20, gen_loss 1.765471, disc_loss 0.733925\n",
      "batch 21, gen_loss 1.699268, disc_loss 0.696460\n",
      "batch 22, gen_loss 1.833325, disc_loss 0.762297\n",
      "batch 23, gen_loss 1.879123, disc_loss 0.755484\n",
      "batch 24, gen_loss 1.899196, disc_loss 0.721356\n",
      "batch 25, gen_loss 1.808069, disc_loss 0.701588\n",
      "batch 26, gen_loss 1.747017, disc_loss 0.795719\n",
      "batch 27, gen_loss 1.843409, disc_loss 0.763173\n",
      "batch 28, gen_loss 1.700617, disc_loss 0.812939\n",
      "batch 29, gen_loss 1.755642, disc_loss 0.727405\n",
      "batch 30, gen_loss 1.600925, disc_loss 0.842761\n",
      "batch 31, gen_loss 1.803974, disc_loss 0.904726\n",
      "batch 32, gen_loss 1.646403, disc_loss 0.899401\n",
      "batch 33, gen_loss 1.715717, disc_loss 0.905374\n",
      "batch 34, gen_loss 1.724952, disc_loss 0.867097\n",
      "batch 35, gen_loss 1.781394, disc_loss 0.848834\n",
      "batch 36, gen_loss 1.717726, disc_loss 0.777021\n",
      "batch 37, gen_loss 1.686921, disc_loss 0.859431\n",
      "batch 38, gen_loss 1.776131, disc_loss 0.919842\n",
      "batch 39, gen_loss 1.610592, disc_loss 0.956279\n",
      "batch 40, gen_loss 1.666976, disc_loss 0.851550\n",
      "batch 41, gen_loss 1.590624, disc_loss 0.886940\n",
      "batch 42, gen_loss 1.698569, disc_loss 0.914464\n",
      "batch 43, gen_loss 1.650368, disc_loss 0.961954\n",
      "batch 44, gen_loss 1.678497, disc_loss 0.950186\n",
      "batch 45, gen_loss 1.647634, disc_loss 0.889628\n",
      "batch 46, gen_loss 1.590533, disc_loss 0.897653\n",
      "batch 47, gen_loss 1.673778, disc_loss 0.846485\n",
      "batch 48, gen_loss 1.731719, disc_loss 0.937357\n",
      "batch 49, gen_loss 1.778150, disc_loss 0.928052\n",
      "batch 50, gen_loss 1.596367, disc_loss 0.825839\n",
      "batch 51, gen_loss 1.463872, disc_loss 0.872728\n",
      "batch 52, gen_loss 1.666788, disc_loss 0.930327\n",
      "batch 53, gen_loss 1.505710, disc_loss 0.899622\n",
      "batch 54, gen_loss 1.595511, disc_loss 0.853241\n",
      "batch 55, gen_loss 1.543696, disc_loss 0.928059\n",
      "batch 56, gen_loss 1.590273, disc_loss 0.859207\n",
      "batch 57, gen_loss 1.611804, disc_loss 0.974173\n",
      "batch 58, gen_loss 1.624317, disc_loss 0.861895\n",
      "batch 59, gen_loss 1.530325, disc_loss 0.963036\n",
      "batch 60, gen_loss 1.434416, disc_loss 0.968532\n",
      "batch 61, gen_loss 1.595957, disc_loss 0.955177\n",
      "batch 62, gen_loss 1.492155, disc_loss 0.979612\n",
      "batch 63, gen_loss 1.556167, disc_loss 1.016249\n",
      "batch 64, gen_loss 1.593010, disc_loss 1.013685\n",
      "batch 65, gen_loss 1.464508, disc_loss 0.864529\n",
      "batch 66, gen_loss 1.551213, disc_loss 1.017302\n",
      "batch 67, gen_loss 1.720111, disc_loss 0.917448\n",
      "batch 68, gen_loss 1.554933, disc_loss 0.982026\n",
      "batch 69, gen_loss 1.489093, disc_loss 0.895964\n",
      "batch 70, gen_loss 1.385858, disc_loss 0.914639\n",
      "batch 71, gen_loss 1.379361, disc_loss 0.835767\n",
      "batch 72, gen_loss 1.501831, disc_loss 0.885509\n",
      "batch 73, gen_loss 1.618021, disc_loss 0.984291\n",
      "batch 74, gen_loss 1.661009, disc_loss 0.949369\n",
      "batch 75, gen_loss 1.483696, disc_loss 0.926527\n",
      "batch 76, gen_loss 1.461955, disc_loss 0.876167\n",
      "batch 77, gen_loss 1.341932, disc_loss 0.886837\n",
      "batch 78, gen_loss 1.493777, disc_loss 0.787384\n",
      "batch 79, gen_loss 1.630013, disc_loss 0.800572\n",
      "batch 80, gen_loss 1.725616, disc_loss 0.758372\n",
      "batch 81, gen_loss 1.571393, disc_loss 0.770429\n",
      "batch 82, gen_loss 1.612793, disc_loss 0.771954\n",
      "batch 83, gen_loss 1.664629, disc_loss 0.752569\n",
      "batch 84, gen_loss 1.575272, disc_loss 0.823143\n",
      "batch 85, gen_loss 1.690092, disc_loss 0.710465\n",
      "batch 86, gen_loss 1.603666, disc_loss 0.775168\n",
      "batch 87, gen_loss 1.639884, disc_loss 0.690041\n",
      "batch 88, gen_loss 1.702581, disc_loss 0.768223\n",
      "batch 89, gen_loss 1.648652, disc_loss 0.765029\n",
      "batch 90, gen_loss 1.632860, disc_loss 0.743672\n",
      "batch 91, gen_loss 1.662349, disc_loss 0.657519\n",
      "batch 92, gen_loss 1.737370, disc_loss 0.714548\n",
      "batch 93, gen_loss 1.787391, disc_loss 0.670996\n",
      "batch 94, gen_loss 1.740348, disc_loss 0.632015\n",
      "batch 95, gen_loss 1.722912, disc_loss 0.682163\n",
      "batch 96, gen_loss 1.781462, disc_loss 0.553364\n",
      "batch 97, gen_loss 1.819450, disc_loss 0.586520\n",
      "batch 98, gen_loss 1.807751, disc_loss 0.626939\n",
      "batch 99, gen_loss 1.925583, disc_loss 0.647398\n",
      "batch 100, gen_loss 1.939772, disc_loss 0.629852\n",
      "batch 101, gen_loss 1.757567, disc_loss 0.592350\n",
      "batch 102, gen_loss 1.690648, disc_loss 0.717681\n",
      "batch 103, gen_loss 1.709320, disc_loss 0.631646\n",
      "batch 104, gen_loss 1.780365, disc_loss 0.599264\n",
      "batch 105, gen_loss 1.804774, disc_loss 0.641001\n",
      "batch 106, gen_loss 1.944746, disc_loss 0.647834\n",
      "batch 107, gen_loss 1.997196, disc_loss 0.700093\n",
      "batch 108, gen_loss 1.824316, disc_loss 0.622307\n",
      "batch 109, gen_loss 1.690729, disc_loss 0.681423\n",
      "batch 110, gen_loss 1.603108, disc_loss 0.660521\n",
      "batch 111, gen_loss 1.603068, disc_loss 0.708072\n",
      "batch 112, gen_loss 1.693532, disc_loss 0.663724\n",
      "batch 113, gen_loss 1.910071, disc_loss 0.660080\n",
      "batch 114, gen_loss 1.905479, disc_loss 0.741084\n",
      "batch 115, gen_loss 1.880335, disc_loss 0.700302\n",
      "batch 116, gen_loss 1.637506, disc_loss 0.765014\n",
      "batch 117, gen_loss 1.556524, disc_loss 0.719038\n",
      "batch 118, gen_loss 1.393900, disc_loss 0.739377\n",
      "batch 119, gen_loss 1.699644, disc_loss 0.727268\n",
      "batch 120, gen_loss 1.949125, disc_loss 0.722332\n",
      "batch 121, gen_loss 1.976135, disc_loss 0.789895\n",
      "batch 122, gen_loss 1.921887, disc_loss 0.747097\n",
      "batch 123, gen_loss 1.656341, disc_loss 0.768597\n",
      "batch 124, gen_loss 1.495499, disc_loss 0.689456\n",
      "batch 125, gen_loss 1.599249, disc_loss 0.772700\n",
      "batch 126, gen_loss 1.641058, disc_loss 0.830092\n",
      "batch 127, gen_loss 1.878783, disc_loss 0.723478\n",
      "batch 128, gen_loss 1.912660, disc_loss 0.720018\n",
      "batch 129, gen_loss 1.772603, disc_loss 0.779713\n",
      "batch 130, gen_loss 1.739211, disc_loss 0.784006\n",
      "batch 131, gen_loss 1.629646, disc_loss 0.804257\n",
      "batch 132, gen_loss 1.449253, disc_loss 0.827357\n",
      "batch 133, gen_loss 1.422251, disc_loss 0.867979\n",
      "batch 134, gen_loss 1.572348, disc_loss 0.771060\n",
      "batch 135, gen_loss 1.670994, disc_loss 0.793195\n",
      "batch 136, gen_loss 1.693397, disc_loss 0.821929\n",
      "batch 137, gen_loss 1.635419, disc_loss 0.810605\n",
      "batch 138, gen_loss 1.750096, disc_loss 0.822754\n",
      "batch 139, gen_loss 1.529479, disc_loss 0.784586\n",
      "batch 140, gen_loss 1.554881, disc_loss 0.856111\n",
      "batch 141, gen_loss 1.575122, disc_loss 0.869957\n",
      "batch 142, gen_loss 1.660350, disc_loss 0.797976\n",
      "batch 143, gen_loss 1.605648, disc_loss 0.810748\n",
      "batch 144, gen_loss 1.725742, disc_loss 0.681240\n",
      "batch 145, gen_loss 1.652216, disc_loss 0.796259\n",
      "batch 146, gen_loss 1.669756, disc_loss 0.771526\n",
      "batch 147, gen_loss 1.725382, disc_loss 0.774719\n",
      "batch 148, gen_loss 1.702909, disc_loss 0.789324\n",
      "batch 149, gen_loss 1.605888, disc_loss 0.682122\n",
      "batch 150, gen_loss 1.702806, disc_loss 0.762084\n",
      "batch 151, gen_loss 1.731320, disc_loss 0.654731\n",
      "batch 152, gen_loss 1.721664, disc_loss 0.792323\n",
      "batch 153, gen_loss 1.832098, disc_loss 0.667610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 154, gen_loss 1.601526, disc_loss 0.786642\n",
      "batch 155, gen_loss 1.522151, disc_loss 0.787133\n",
      "batch 156, gen_loss 1.623997, disc_loss 0.765229\n",
      "batch 157, gen_loss 1.600219, disc_loss 0.748438\n",
      "batch 158, gen_loss 1.867094, disc_loss 0.653931\n",
      "batch 159, gen_loss 1.985961, disc_loss 0.666873\n",
      "batch 160, gen_loss 1.832574, disc_loss 0.656779\n",
      "batch 161, gen_loss 1.771888, disc_loss 0.734714\n",
      "batch 162, gen_loss 1.676305, disc_loss 0.660535\n",
      "batch 163, gen_loss 1.690933, disc_loss 0.651129\n",
      "batch 164, gen_loss 1.700107, disc_loss 0.585912\n",
      "batch 165, gen_loss 1.876351, disc_loss 0.699175\n",
      "batch 166, gen_loss 1.964281, disc_loss 0.567793\n",
      "batch 167, gen_loss 1.827181, disc_loss 0.711444\n",
      "batch 168, gen_loss 1.868350, disc_loss 0.589877\n",
      "batch 169, gen_loss 1.762527, disc_loss 0.621732\n",
      "batch 170, gen_loss 1.901297, disc_loss 0.607555\n",
      "batch 171, gen_loss 1.856410, disc_loss 0.647536\n",
      "batch 172, gen_loss 1.784772, disc_loss 0.658137\n",
      "batch 173, gen_loss 1.690909, disc_loss 0.635850\n",
      "batch 174, gen_loss 1.881893, disc_loss 0.647606\n",
      "batch 175, gen_loss 1.859187, disc_loss 0.668082\n",
      "batch 176, gen_loss 1.848675, disc_loss 0.613065\n",
      "batch 177, gen_loss 1.785758, disc_loss 0.694353\n",
      "batch 178, gen_loss 1.757507, disc_loss 0.728689\n",
      "batch 179, gen_loss 1.856331, disc_loss 0.645272\n",
      "batch 180, gen_loss 1.822238, disc_loss 0.631881\n",
      "batch 181, gen_loss 1.792777, disc_loss 0.593022\n",
      "batch 182, gen_loss 1.861722, disc_loss 0.698983\n",
      "batch 183, gen_loss 1.743353, disc_loss 0.741384\n",
      "batch 184, gen_loss 1.833447, disc_loss 0.761880\n",
      "batch 185, gen_loss 1.632831, disc_loss 0.634815\n",
      "batch 186, gen_loss 1.488708, disc_loss 0.726470\n",
      "batch 187, gen_loss 1.596543, disc_loss 0.824404\n",
      "batch 188, gen_loss 1.881108, disc_loss 0.680563\n",
      "batch 189, gen_loss 1.900486, disc_loss 0.749831\n",
      "batch 190, gen_loss 1.999543, disc_loss 0.734933\n",
      "batch 191, gen_loss 1.765794, disc_loss 0.893593\n",
      "batch 192, gen_loss 1.607176, disc_loss 0.746302\n",
      "batch 193, gen_loss 1.491729, disc_loss 0.853881\n",
      "batch 194, gen_loss 1.414516, disc_loss 0.784469\n",
      "batch 195, gen_loss 1.619506, disc_loss 0.811761\n",
      "batch 196, gen_loss 1.696278, disc_loss 0.777271\n",
      "batch 197, gen_loss 1.896969, disc_loss 0.849959\n",
      "batch 198, gen_loss 1.827683, disc_loss 0.727203\n",
      "batch 199, gen_loss 1.664743, disc_loss 0.909602\n",
      "batch 200, gen_loss 1.508062, disc_loss 0.795787\n",
      "batch 201, gen_loss 1.508151, disc_loss 0.744731\n",
      "batch 202, gen_loss 1.710327, disc_loss 0.767538\n",
      "batch 203, gen_loss 1.739636, disc_loss 0.781355\n",
      "batch 204, gen_loss 1.776076, disc_loss 0.882415\n",
      "batch 205, gen_loss 1.716386, disc_loss 0.725736\n",
      "batch 206, gen_loss 1.730663, disc_loss 0.701895\n",
      "batch 207, gen_loss 1.715191, disc_loss 0.784000\n",
      "batch 208, gen_loss 1.697613, disc_loss 0.702792\n",
      "batch 209, gen_loss 1.693637, disc_loss 0.901208\n",
      "batch 210, gen_loss 1.771443, disc_loss 0.717141\n",
      "batch 211, gen_loss 1.789250, disc_loss 0.789237\n",
      "batch 212, gen_loss 1.939793, disc_loss 0.692938\n",
      "batch 213, gen_loss 1.910852, disc_loss 0.811581\n",
      "batch 214, gen_loss 1.808921, disc_loss 0.736105\n",
      "batch 215, gen_loss 1.834200, disc_loss 0.711341\n",
      "batch 216, gen_loss 1.737994, disc_loss 0.717852\n",
      "batch 217, gen_loss 1.893659, disc_loss 0.716165\n",
      "batch 218, gen_loss 1.944273, disc_loss 0.705515\n",
      "batch 219, gen_loss 1.810113, disc_loss 0.721674\n",
      "batch 220, gen_loss 1.898750, disc_loss 0.701368\n",
      "batch 221, gen_loss 2.037254, disc_loss 0.680647\n",
      "batch 222, gen_loss 1.913830, disc_loss 0.653086\n",
      "batch 223, gen_loss 2.006407, disc_loss 0.692532\n",
      "batch 224, gen_loss 1.997149, disc_loss 0.705406\n",
      "batch 225, gen_loss 1.933814, disc_loss 0.670086\n",
      "batch 226, gen_loss 1.793268, disc_loss 0.690808\n",
      "batch 227, gen_loss 2.032270, disc_loss 0.631419\n",
      "batch 228, gen_loss 1.941329, disc_loss 0.811389\n",
      "batch 229, gen_loss 1.877914, disc_loss 0.727648\n",
      "batch 230, gen_loss 1.944321, disc_loss 0.683636\n",
      "batch 231, gen_loss 2.112489, disc_loss 0.671130\n",
      "batch 232, gen_loss 2.094166, disc_loss 0.656411\n",
      "batch 233, gen_loss 2.069843, disc_loss 0.649951\n",
      "batch 234, gen_loss 1.922527, disc_loss 0.654139\n",
      "Time for epoch29is 7.6375627517700195 sec\n",
      "batch 0, gen_loss 1.986312, disc_loss 0.616209\n",
      "batch 1, gen_loss 2.275035, disc_loss 0.550003\n",
      "batch 2, gen_loss 2.243772, disc_loss 0.681332\n",
      "batch 3, gen_loss 2.311465, disc_loss 0.656528\n",
      "batch 4, gen_loss 2.019886, disc_loss 0.603162\n",
      "batch 5, gen_loss 1.960471, disc_loss 0.531723\n",
      "batch 6, gen_loss 2.064371, disc_loss 0.584406\n",
      "batch 7, gen_loss 2.249036, disc_loss 0.548779\n",
      "batch 8, gen_loss 2.484934, disc_loss 0.531129\n",
      "batch 9, gen_loss 2.677954, disc_loss 0.582778\n",
      "batch 10, gen_loss 2.395495, disc_loss 0.639323\n",
      "batch 11, gen_loss 2.051609, disc_loss 0.552197\n",
      "batch 12, gen_loss 1.931086, disc_loss 0.596683\n",
      "batch 13, gen_loss 2.119026, disc_loss 0.641726\n",
      "batch 14, gen_loss 2.339510, disc_loss 0.602777\n",
      "batch 15, gen_loss 2.499184, disc_loss 0.585061\n",
      "batch 16, gen_loss 2.450194, disc_loss 0.678349\n",
      "batch 17, gen_loss 2.329635, disc_loss 0.690577\n",
      "batch 18, gen_loss 2.047783, disc_loss 0.639167\n",
      "batch 19, gen_loss 1.919793, disc_loss 0.611470\n",
      "batch 20, gen_loss 1.796470, disc_loss 0.689976\n",
      "batch 21, gen_loss 1.891172, disc_loss 0.668862\n",
      "batch 22, gen_loss 1.977309, disc_loss 0.740726\n",
      "batch 23, gen_loss 2.096108, disc_loss 0.748006\n",
      "batch 24, gen_loss 2.050999, disc_loss 0.673337\n",
      "batch 25, gen_loss 2.075189, disc_loss 0.761271\n",
      "batch 26, gen_loss 2.079479, disc_loss 0.706505\n",
      "batch 27, gen_loss 1.893829, disc_loss 0.812132\n",
      "batch 28, gen_loss 1.768635, disc_loss 0.843835\n",
      "batch 29, gen_loss 1.748783, disc_loss 0.765949\n",
      "batch 30, gen_loss 1.837248, disc_loss 0.749977\n",
      "batch 31, gen_loss 1.855049, disc_loss 0.796161\n",
      "batch 32, gen_loss 2.188368, disc_loss 0.771796\n",
      "batch 33, gen_loss 1.895320, disc_loss 0.939261\n",
      "batch 34, gen_loss 1.800822, disc_loss 0.736032\n",
      "batch 35, gen_loss 1.769475, disc_loss 0.855269\n",
      "batch 36, gen_loss 1.767182, disc_loss 0.759614\n",
      "batch 37, gen_loss 1.730580, disc_loss 0.855010\n",
      "batch 38, gen_loss 1.722077, disc_loss 0.923455\n",
      "batch 39, gen_loss 1.773130, disc_loss 0.788564\n",
      "batch 40, gen_loss 1.774793, disc_loss 0.847970\n",
      "batch 41, gen_loss 1.821388, disc_loss 0.928478\n",
      "batch 42, gen_loss 1.623041, disc_loss 0.842890\n",
      "batch 43, gen_loss 1.598052, disc_loss 0.766806\n",
      "batch 44, gen_loss 1.578039, disc_loss 0.982980\n",
      "batch 45, gen_loss 1.664742, disc_loss 0.806065\n",
      "batch 46, gen_loss 1.661760, disc_loss 0.806410\n",
      "batch 47, gen_loss 1.727150, disc_loss 0.967314\n",
      "batch 48, gen_loss 1.793852, disc_loss 0.884450\n",
      "batch 49, gen_loss 1.574965, disc_loss 0.862177\n",
      "batch 50, gen_loss 1.780400, disc_loss 0.807212\n",
      "batch 51, gen_loss 1.812945, disc_loss 0.890058\n",
      "batch 52, gen_loss 1.768977, disc_loss 0.741495\n",
      "batch 53, gen_loss 1.659995, disc_loss 0.822653\n",
      "batch 54, gen_loss 1.795846, disc_loss 0.836752\n",
      "batch 55, gen_loss 1.634171, disc_loss 0.971688\n",
      "batch 56, gen_loss 1.697435, disc_loss 0.770465\n",
      "batch 57, gen_loss 1.618266, disc_loss 0.874851\n",
      "batch 58, gen_loss 1.660045, disc_loss 0.874357\n",
      "batch 59, gen_loss 1.688766, disc_loss 0.871655\n",
      "batch 60, gen_loss 1.695110, disc_loss 0.834102\n",
      "batch 61, gen_loss 1.907655, disc_loss 0.750166\n",
      "batch 62, gen_loss 1.669340, disc_loss 0.798647\n",
      "batch 63, gen_loss 1.771991, disc_loss 0.727300\n",
      "batch 64, gen_loss 1.831757, disc_loss 0.835455\n",
      "batch 65, gen_loss 1.747749, disc_loss 0.779490\n",
      "batch 66, gen_loss 1.758469, disc_loss 0.823060\n",
      "batch 67, gen_loss 1.677995, disc_loss 0.795779\n",
      "batch 68, gen_loss 1.731236, disc_loss 0.678850\n",
      "batch 69, gen_loss 1.795725, disc_loss 0.857616\n",
      "batch 70, gen_loss 1.842277, disc_loss 0.746721\n",
      "batch 71, gen_loss 1.932837, disc_loss 0.629290\n",
      "batch 72, gen_loss 1.865070, disc_loss 0.646243\n",
      "batch 73, gen_loss 1.972738, disc_loss 0.685197\n",
      "batch 74, gen_loss 1.915092, disc_loss 0.795811\n",
      "batch 75, gen_loss 1.910536, disc_loss 0.735900\n",
      "batch 76, gen_loss 1.846150, disc_loss 0.712791\n",
      "batch 77, gen_loss 1.905814, disc_loss 0.696775\n",
      "batch 78, gen_loss 1.958369, disc_loss 0.698614\n",
      "batch 79, gen_loss 2.134320, disc_loss 0.688182\n",
      "batch 80, gen_loss 1.987467, disc_loss 0.765937\n",
      "batch 81, gen_loss 1.952107, disc_loss 0.714113\n",
      "batch 82, gen_loss 1.918730, disc_loss 0.745224\n",
      "batch 83, gen_loss 1.933128, disc_loss 0.678122\n",
      "batch 84, gen_loss 1.954737, disc_loss 0.657514\n",
      "batch 85, gen_loss 1.897427, disc_loss 0.766489\n",
      "batch 86, gen_loss 2.080408, disc_loss 0.599507\n",
      "batch 87, gen_loss 2.025533, disc_loss 0.721036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 88, gen_loss 1.884246, disc_loss 0.729976\n",
      "batch 89, gen_loss 2.029625, disc_loss 0.722712\n",
      "batch 90, gen_loss 1.978204, disc_loss 0.662537\n",
      "batch 91, gen_loss 2.008450, disc_loss 0.746868\n",
      "batch 92, gen_loss 1.909202, disc_loss 0.707821\n",
      "batch 93, gen_loss 1.985868, disc_loss 0.758487\n",
      "batch 94, gen_loss 1.791069, disc_loss 0.692904\n",
      "batch 95, gen_loss 1.911642, disc_loss 0.677022\n",
      "batch 96, gen_loss 2.093590, disc_loss 0.709536\n",
      "batch 97, gen_loss 2.072197, disc_loss 0.662112\n",
      "batch 98, gen_loss 2.045273, disc_loss 0.670956\n",
      "batch 99, gen_loss 2.077709, disc_loss 0.693673\n",
      "batch 100, gen_loss 1.946603, disc_loss 0.738567\n",
      "batch 101, gen_loss 1.930932, disc_loss 0.684619\n",
      "batch 102, gen_loss 1.715956, disc_loss 0.780394\n",
      "batch 103, gen_loss 1.966126, disc_loss 0.681229\n",
      "batch 104, gen_loss 1.890703, disc_loss 0.767341\n",
      "batch 105, gen_loss 1.970923, disc_loss 0.841128\n",
      "batch 106, gen_loss 1.990154, disc_loss 0.745628\n",
      "batch 107, gen_loss 1.973945, disc_loss 0.790351\n",
      "batch 108, gen_loss 1.918457, disc_loss 0.760339\n",
      "batch 109, gen_loss 1.874959, disc_loss 0.776810\n",
      "batch 110, gen_loss 1.808476, disc_loss 0.796955\n",
      "batch 111, gen_loss 1.983841, disc_loss 0.742140\n",
      "batch 112, gen_loss 1.908888, disc_loss 0.786979\n",
      "batch 113, gen_loss 1.958708, disc_loss 0.782237\n",
      "batch 114, gen_loss 2.101557, disc_loss 0.726821\n",
      "batch 115, gen_loss 1.811853, disc_loss 0.672718\n",
      "batch 116, gen_loss 1.768566, disc_loss 0.807209\n",
      "batch 117, gen_loss 1.801907, disc_loss 0.808945\n",
      "batch 118, gen_loss 1.855480, disc_loss 0.721839\n",
      "batch 119, gen_loss 1.917212, disc_loss 0.845024\n",
      "batch 120, gen_loss 1.945094, disc_loss 0.746181\n",
      "batch 121, gen_loss 1.881632, disc_loss 0.835862\n",
      "batch 122, gen_loss 1.608652, disc_loss 0.882860\n",
      "batch 123, gen_loss 1.708320, disc_loss 0.869352\n",
      "batch 124, gen_loss 1.884003, disc_loss 0.810530\n",
      "batch 125, gen_loss 1.744555, disc_loss 0.885845\n",
      "batch 126, gen_loss 1.700016, disc_loss 0.976030\n",
      "batch 127, gen_loss 1.679609, disc_loss 0.937285\n",
      "batch 128, gen_loss 1.705950, disc_loss 0.853857\n",
      "batch 129, gen_loss 1.569657, disc_loss 0.890331\n",
      "batch 130, gen_loss 1.703018, disc_loss 0.836681\n",
      "batch 131, gen_loss 1.776092, disc_loss 0.980309\n",
      "batch 132, gen_loss 1.721645, disc_loss 0.936865\n",
      "batch 133, gen_loss 1.821932, disc_loss 0.822188\n",
      "batch 134, gen_loss 1.717949, disc_loss 0.960494\n",
      "batch 135, gen_loss 1.517341, disc_loss 1.097906\n",
      "batch 136, gen_loss 1.403384, disc_loss 0.954351\n",
      "batch 137, gen_loss 1.477980, disc_loss 0.986737\n",
      "batch 138, gen_loss 1.497813, disc_loss 1.005146\n",
      "batch 139, gen_loss 1.495359, disc_loss 0.987139\n",
      "batch 140, gen_loss 1.456165, disc_loss 1.048656\n",
      "batch 141, gen_loss 1.475796, disc_loss 1.036101\n",
      "batch 142, gen_loss 1.483610, disc_loss 1.032581\n",
      "batch 143, gen_loss 1.579947, disc_loss 0.956354\n",
      "batch 144, gen_loss 1.532695, disc_loss 1.065653\n",
      "batch 145, gen_loss 1.449049, disc_loss 1.069949\n",
      "batch 146, gen_loss 1.375334, disc_loss 1.083652\n",
      "batch 147, gen_loss 1.230655, disc_loss 1.099146\n",
      "batch 148, gen_loss 1.282198, disc_loss 1.088284\n",
      "batch 149, gen_loss 1.336048, disc_loss 1.090219\n",
      "batch 150, gen_loss 1.431292, disc_loss 1.205212\n",
      "batch 151, gen_loss 1.604963, disc_loss 1.123084\n",
      "batch 152, gen_loss 1.555394, disc_loss 1.139664\n",
      "batch 153, gen_loss 1.478352, disc_loss 1.149570\n",
      "batch 154, gen_loss 1.379156, disc_loss 0.971929\n",
      "batch 155, gen_loss 1.369675, disc_loss 1.095370\n",
      "batch 156, gen_loss 1.452910, disc_loss 1.043878\n",
      "batch 157, gen_loss 1.537377, disc_loss 1.127200\n",
      "batch 158, gen_loss 1.503953, disc_loss 1.155044\n",
      "batch 159, gen_loss 1.511137, disc_loss 1.129231\n",
      "batch 160, gen_loss 1.413291, disc_loss 1.036906\n",
      "batch 161, gen_loss 1.468470, disc_loss 1.105573\n",
      "batch 162, gen_loss 1.363055, disc_loss 1.107339\n",
      "batch 163, gen_loss 1.498147, disc_loss 1.041754\n",
      "batch 164, gen_loss 1.363047, disc_loss 1.027232\n",
      "batch 165, gen_loss 1.419602, disc_loss 0.996002\n",
      "batch 166, gen_loss 1.629643, disc_loss 0.967332\n",
      "batch 167, gen_loss 1.603994, disc_loss 1.107307\n",
      "batch 168, gen_loss 1.766565, disc_loss 0.920906\n",
      "batch 169, gen_loss 1.548033, disc_loss 1.011222\n",
      "batch 170, gen_loss 1.450849, disc_loss 0.966833\n",
      "batch 171, gen_loss 1.440581, disc_loss 0.897986\n",
      "batch 172, gen_loss 1.397234, disc_loss 0.922125\n",
      "batch 173, gen_loss 1.553636, disc_loss 0.908828\n",
      "batch 174, gen_loss 1.584035, disc_loss 0.891080\n",
      "batch 175, gen_loss 1.510442, disc_loss 0.926526\n",
      "batch 176, gen_loss 1.567476, disc_loss 0.836573\n",
      "batch 177, gen_loss 1.659299, disc_loss 0.886092\n",
      "batch 178, gen_loss 1.591667, disc_loss 0.869475\n",
      "batch 179, gen_loss 1.633699, disc_loss 0.867869\n",
      "batch 180, gen_loss 1.587096, disc_loss 0.822100\n",
      "batch 181, gen_loss 1.570120, disc_loss 0.939404\n",
      "batch 182, gen_loss 1.521264, disc_loss 0.904305\n",
      "batch 183, gen_loss 1.666322, disc_loss 0.823797\n",
      "batch 184, gen_loss 1.559993, disc_loss 0.811369\n",
      "batch 185, gen_loss 1.533207, disc_loss 0.798972\n",
      "batch 186, gen_loss 1.508854, disc_loss 0.809664\n",
      "batch 187, gen_loss 1.604427, disc_loss 0.826906\n",
      "batch 188, gen_loss 1.623123, disc_loss 0.776109\n",
      "batch 189, gen_loss 1.664035, disc_loss 0.852882\n",
      "batch 190, gen_loss 1.648749, disc_loss 0.832012\n",
      "batch 191, gen_loss 1.507323, disc_loss 0.816376\n",
      "batch 192, gen_loss 1.489847, disc_loss 0.856225\n",
      "batch 193, gen_loss 1.466269, disc_loss 0.835433\n",
      "batch 194, gen_loss 1.559843, disc_loss 0.781940\n",
      "batch 195, gen_loss 1.667805, disc_loss 0.806727\n",
      "batch 196, gen_loss 1.771317, disc_loss 0.735403\n",
      "batch 197, gen_loss 1.800014, disc_loss 0.825892\n",
      "batch 198, gen_loss 1.557667, disc_loss 0.840304\n",
      "batch 199, gen_loss 1.426498, disc_loss 0.838979\n",
      "batch 200, gen_loss 1.522213, disc_loss 0.819216\n",
      "batch 201, gen_loss 1.548956, disc_loss 0.899933\n",
      "batch 202, gen_loss 1.751699, disc_loss 0.803138\n",
      "batch 203, gen_loss 1.840270, disc_loss 0.871322\n",
      "batch 204, gen_loss 1.596466, disc_loss 0.800638\n",
      "batch 205, gen_loss 1.467247, disc_loss 0.816340\n",
      "batch 206, gen_loss 1.396190, disc_loss 0.856537\n",
      "batch 207, gen_loss 1.429728, disc_loss 0.881822\n",
      "batch 208, gen_loss 1.661525, disc_loss 0.842480\n",
      "batch 209, gen_loss 1.767448, disc_loss 0.805553\n",
      "batch 210, gen_loss 1.741037, disc_loss 0.815072\n",
      "batch 211, gen_loss 1.805515, disc_loss 0.891069\n",
      "batch 212, gen_loss 1.565201, disc_loss 0.815620\n",
      "batch 213, gen_loss 1.420550, disc_loss 0.828682\n",
      "batch 214, gen_loss 1.350960, disc_loss 0.854570\n",
      "batch 215, gen_loss 1.614332, disc_loss 0.784570\n",
      "batch 216, gen_loss 1.699294, disc_loss 0.806792\n",
      "batch 217, gen_loss 1.776528, disc_loss 0.781277\n",
      "batch 218, gen_loss 1.725292, disc_loss 0.829614\n",
      "batch 219, gen_loss 1.605106, disc_loss 0.785464\n",
      "batch 220, gen_loss 1.439056, disc_loss 0.874248\n",
      "batch 221, gen_loss 1.412249, disc_loss 0.824346\n",
      "batch 222, gen_loss 1.558161, disc_loss 0.790614\n",
      "batch 223, gen_loss 1.778093, disc_loss 0.889792\n",
      "batch 224, gen_loss 1.731393, disc_loss 0.796249\n",
      "batch 225, gen_loss 1.722512, disc_loss 0.811444\n",
      "batch 226, gen_loss 1.555522, disc_loss 0.795843\n",
      "batch 227, gen_loss 1.597912, disc_loss 0.754432\n",
      "batch 228, gen_loss 1.487522, disc_loss 0.804414\n",
      "batch 229, gen_loss 1.623863, disc_loss 0.720387\n",
      "batch 230, gen_loss 1.734372, disc_loss 0.683331\n",
      "batch 231, gen_loss 1.788471, disc_loss 0.729465\n",
      "batch 232, gen_loss 1.692804, disc_loss 0.810033\n",
      "batch 233, gen_loss 1.717015, disc_loss 0.693049\n",
      "batch 234, gen_loss 1.708920, disc_loss 0.757963\n",
      "Time for epoch30is 7.836078405380249 sec\n",
      "batch 0, gen_loss 1.672636, disc_loss 0.707140\n",
      "batch 1, gen_loss 1.589045, disc_loss 0.726652\n",
      "batch 2, gen_loss 1.593494, disc_loss 0.787030\n",
      "batch 3, gen_loss 1.704768, disc_loss 0.765870\n",
      "batch 4, gen_loss 1.860366, disc_loss 0.683544\n",
      "batch 5, gen_loss 1.906132, disc_loss 0.636155\n",
      "batch 6, gen_loss 1.714227, disc_loss 0.737722\n",
      "batch 7, gen_loss 1.635509, disc_loss 0.674174\n",
      "batch 8, gen_loss 1.613725, disc_loss 0.742990\n",
      "batch 9, gen_loss 1.700981, disc_loss 0.732126\n",
      "batch 10, gen_loss 1.894876, disc_loss 0.636974\n",
      "batch 11, gen_loss 1.871623, disc_loss 0.710833\n",
      "batch 12, gen_loss 1.885905, disc_loss 0.656577\n",
      "batch 13, gen_loss 1.793391, disc_loss 0.690505\n",
      "batch 14, gen_loss 1.849128, disc_loss 0.626685\n",
      "batch 15, gen_loss 1.832905, disc_loss 0.648812\n",
      "batch 16, gen_loss 1.895456, disc_loss 0.620072\n",
      "batch 17, gen_loss 1.778456, disc_loss 0.865798\n",
      "batch 18, gen_loss 1.849519, disc_loss 0.688332\n",
      "batch 19, gen_loss 1.864360, disc_loss 0.712127\n",
      "batch 20, gen_loss 1.777428, disc_loss 0.691916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 21, gen_loss 1.769396, disc_loss 0.774153\n",
      "batch 22, gen_loss 1.798806, disc_loss 0.668144\n",
      "batch 23, gen_loss 1.616345, disc_loss 0.750403\n",
      "batch 24, gen_loss 1.719567, disc_loss 0.768209\n",
      "batch 25, gen_loss 1.696366, disc_loss 0.766411\n",
      "batch 26, gen_loss 1.800984, disc_loss 0.673584\n",
      "batch 27, gen_loss 1.915386, disc_loss 0.819031\n",
      "batch 28, gen_loss 2.015755, disc_loss 0.733472\n",
      "batch 29, gen_loss 1.980588, disc_loss 0.757645\n",
      "batch 30, gen_loss 1.799296, disc_loss 0.747833\n",
      "batch 31, gen_loss 1.836304, disc_loss 0.718994\n",
      "batch 32, gen_loss 1.618756, disc_loss 0.752667\n",
      "batch 33, gen_loss 1.829738, disc_loss 0.756506\n",
      "batch 34, gen_loss 1.783371, disc_loss 0.797553\n",
      "batch 35, gen_loss 1.982721, disc_loss 0.751942\n",
      "batch 36, gen_loss 2.070590, disc_loss 0.756550\n",
      "batch 37, gen_loss 1.890789, disc_loss 0.852965\n",
      "batch 38, gen_loss 1.709816, disc_loss 0.890424\n",
      "batch 39, gen_loss 1.652258, disc_loss 0.822770\n",
      "batch 40, gen_loss 1.700551, disc_loss 0.801191\n",
      "batch 41, gen_loss 1.917886, disc_loss 0.901674\n",
      "batch 42, gen_loss 1.898939, disc_loss 0.935215\n",
      "batch 43, gen_loss 1.885307, disc_loss 0.797727\n",
      "batch 44, gen_loss 1.876820, disc_loss 0.789646\n",
      "batch 45, gen_loss 1.797040, disc_loss 0.870436\n",
      "batch 46, gen_loss 1.850882, disc_loss 0.863383\n",
      "batch 47, gen_loss 1.772389, disc_loss 0.800228\n",
      "batch 48, gen_loss 1.783579, disc_loss 0.858128\n",
      "batch 49, gen_loss 1.949752, disc_loss 0.943645\n",
      "batch 50, gen_loss 2.069516, disc_loss 0.853722\n",
      "batch 51, gen_loss 2.017034, disc_loss 0.835257\n",
      "batch 52, gen_loss 1.938920, disc_loss 0.795838\n",
      "batch 53, gen_loss 1.764429, disc_loss 0.788676\n",
      "batch 54, gen_loss 1.759833, disc_loss 0.911924\n",
      "batch 55, gen_loss 1.671757, disc_loss 0.867682\n",
      "batch 56, gen_loss 1.948145, disc_loss 0.834141\n",
      "batch 57, gen_loss 1.819387, disc_loss 0.823528\n",
      "batch 58, gen_loss 1.676745, disc_loss 0.893033\n",
      "batch 59, gen_loss 1.786325, disc_loss 0.806579\n",
      "batch 60, gen_loss 1.796117, disc_loss 0.800856\n",
      "batch 61, gen_loss 1.862660, disc_loss 0.857385\n",
      "batch 62, gen_loss 1.762329, disc_loss 0.920125\n",
      "batch 63, gen_loss 1.852151, disc_loss 0.859106\n",
      "batch 64, gen_loss 1.757904, disc_loss 0.955812\n",
      "batch 65, gen_loss 1.676481, disc_loss 0.866964\n",
      "batch 66, gen_loss 1.615408, disc_loss 0.853423\n",
      "batch 67, gen_loss 1.690771, disc_loss 0.870049\n",
      "batch 68, gen_loss 1.607890, disc_loss 0.888244\n",
      "batch 69, gen_loss 1.756888, disc_loss 0.887739\n",
      "batch 70, gen_loss 1.749353, disc_loss 0.854589\n",
      "batch 71, gen_loss 1.633427, disc_loss 0.855310\n",
      "batch 72, gen_loss 1.757417, disc_loss 0.870645\n",
      "batch 73, gen_loss 1.671518, disc_loss 0.889137\n",
      "batch 74, gen_loss 1.590459, disc_loss 0.795236\n",
      "batch 75, gen_loss 1.682378, disc_loss 0.784654\n",
      "batch 76, gen_loss 1.776343, disc_loss 0.869357\n",
      "batch 77, gen_loss 1.696376, disc_loss 0.882438\n",
      "batch 78, gen_loss 1.813422, disc_loss 0.867589\n",
      "batch 79, gen_loss 1.815131, disc_loss 0.833499\n",
      "batch 80, gen_loss 1.672315, disc_loss 0.872497\n",
      "batch 81, gen_loss 1.577686, disc_loss 0.839347\n",
      "batch 82, gen_loss 1.676816, disc_loss 0.710036\n",
      "batch 83, gen_loss 1.799195, disc_loss 0.764884\n",
      "batch 84, gen_loss 1.766924, disc_loss 0.791537\n",
      "batch 85, gen_loss 1.710781, disc_loss 0.853947\n",
      "batch 86, gen_loss 1.723080, disc_loss 0.769556\n",
      "batch 87, gen_loss 1.761816, disc_loss 0.733589\n",
      "batch 88, gen_loss 1.761880, disc_loss 0.787525\n",
      "batch 89, gen_loss 1.881141, disc_loss 0.797983\n",
      "batch 90, gen_loss 1.783388, disc_loss 0.743704\n",
      "batch 91, gen_loss 1.810000, disc_loss 0.646790\n",
      "batch 92, gen_loss 1.916388, disc_loss 0.721087\n",
      "batch 93, gen_loss 1.872148, disc_loss 0.770226\n",
      "batch 94, gen_loss 1.946743, disc_loss 0.659496\n",
      "batch 95, gen_loss 1.827304, disc_loss 0.722296\n",
      "batch 96, gen_loss 1.895674, disc_loss 0.688128\n",
      "batch 97, gen_loss 1.763333, disc_loss 0.731536\n",
      "batch 98, gen_loss 1.831848, disc_loss 0.662089\n",
      "batch 99, gen_loss 1.998133, disc_loss 0.650773\n",
      "batch 100, gen_loss 2.025601, disc_loss 0.582029\n",
      "batch 101, gen_loss 2.127720, disc_loss 0.595205\n",
      "batch 102, gen_loss 2.205453, disc_loss 0.730742\n",
      "batch 103, gen_loss 2.249933, disc_loss 0.638994\n",
      "batch 104, gen_loss 1.959197, disc_loss 0.643107\n",
      "batch 105, gen_loss 1.822855, disc_loss 0.606663\n",
      "batch 106, gen_loss 1.893936, disc_loss 0.662489\n",
      "batch 107, gen_loss 2.061373, disc_loss 0.583239\n",
      "batch 108, gen_loss 2.152732, disc_loss 0.675254\n",
      "batch 109, gen_loss 2.377389, disc_loss 0.609856\n",
      "batch 110, gen_loss 2.229236, disc_loss 0.564251\n",
      "batch 111, gen_loss 2.115288, disc_loss 0.546652\n",
      "batch 112, gen_loss 2.097028, disc_loss 0.559217\n",
      "batch 113, gen_loss 2.040331, disc_loss 0.639716\n",
      "batch 114, gen_loss 2.012985, disc_loss 0.541317\n",
      "batch 115, gen_loss 2.082806, disc_loss 0.589471\n",
      "batch 116, gen_loss 2.170953, disc_loss 0.635624\n",
      "batch 117, gen_loss 2.017344, disc_loss 0.666719\n",
      "batch 118, gen_loss 2.155497, disc_loss 0.635844\n",
      "batch 119, gen_loss 2.081107, disc_loss 0.552314\n",
      "batch 120, gen_loss 1.881236, disc_loss 0.576349\n",
      "batch 121, gen_loss 2.085523, disc_loss 0.648095\n",
      "batch 122, gen_loss 1.979069, disc_loss 0.605853\n",
      "batch 123, gen_loss 2.051017, disc_loss 0.635014\n",
      "batch 124, gen_loss 1.885708, disc_loss 0.696373\n",
      "batch 125, gen_loss 1.827377, disc_loss 0.674445\n",
      "batch 126, gen_loss 1.700364, disc_loss 0.658464\n",
      "batch 127, gen_loss 1.822922, disc_loss 0.704840\n",
      "batch 128, gen_loss 2.010359, disc_loss 0.702491\n",
      "batch 129, gen_loss 1.922156, disc_loss 0.716173\n",
      "batch 130, gen_loss 2.114851, disc_loss 0.808539\n",
      "batch 131, gen_loss 1.838736, disc_loss 0.807267\n",
      "batch 132, gen_loss 1.617043, disc_loss 0.870556\n",
      "batch 133, gen_loss 1.589656, disc_loss 0.833161\n",
      "batch 134, gen_loss 1.719173, disc_loss 0.881991\n",
      "batch 135, gen_loss 1.836044, disc_loss 0.814440\n",
      "batch 136, gen_loss 1.954498, disc_loss 0.799545\n",
      "batch 137, gen_loss 1.958696, disc_loss 0.874237\n",
      "batch 138, gen_loss 1.845307, disc_loss 0.947450\n",
      "batch 139, gen_loss 1.795738, disc_loss 0.761043\n",
      "batch 140, gen_loss 1.761319, disc_loss 0.911176\n",
      "batch 141, gen_loss 1.807174, disc_loss 0.823807\n",
      "batch 142, gen_loss 1.853397, disc_loss 0.976392\n",
      "batch 143, gen_loss 1.800843, disc_loss 0.823529\n",
      "batch 144, gen_loss 1.773219, disc_loss 0.913883\n",
      "batch 145, gen_loss 1.856956, disc_loss 0.958983\n",
      "batch 146, gen_loss 1.676065, disc_loss 0.869339\n",
      "batch 147, gen_loss 1.572516, disc_loss 0.860242\n",
      "batch 148, gen_loss 1.681376, disc_loss 0.802163\n",
      "batch 149, gen_loss 1.646293, disc_loss 0.842087\n",
      "batch 150, gen_loss 1.638650, disc_loss 0.997530\n",
      "batch 151, gen_loss 1.728261, disc_loss 0.860282\n",
      "batch 152, gen_loss 1.572677, disc_loss 0.817483\n",
      "batch 153, gen_loss 1.533610, disc_loss 0.786763\n",
      "batch 154, gen_loss 1.515429, disc_loss 0.889908\n",
      "batch 155, gen_loss 1.479264, disc_loss 0.814746\n",
      "batch 156, gen_loss 1.664248, disc_loss 0.786669\n",
      "batch 157, gen_loss 1.690682, disc_loss 0.833206\n",
      "batch 158, gen_loss 1.821721, disc_loss 0.795546\n",
      "batch 159, gen_loss 1.785604, disc_loss 0.897247\n",
      "batch 160, gen_loss 1.538426, disc_loss 0.810432\n",
      "batch 161, gen_loss 1.600623, disc_loss 0.928964\n",
      "batch 162, gen_loss 1.469718, disc_loss 0.882399\n",
      "batch 163, gen_loss 1.652942, disc_loss 0.918569\n",
      "batch 164, gen_loss 1.780687, disc_loss 0.861590\n",
      "batch 165, gen_loss 1.770756, disc_loss 0.818827\n",
      "batch 166, gen_loss 1.817205, disc_loss 0.923456\n",
      "batch 167, gen_loss 1.896949, disc_loss 0.850006\n",
      "batch 168, gen_loss 1.619605, disc_loss 0.921879\n",
      "batch 169, gen_loss 1.412087, disc_loss 0.910445\n",
      "batch 170, gen_loss 1.393217, disc_loss 0.891568\n",
      "batch 171, gen_loss 1.650221, disc_loss 0.820066\n",
      "batch 172, gen_loss 1.589533, disc_loss 0.815452\n",
      "batch 173, gen_loss 1.758227, disc_loss 0.862326\n",
      "batch 174, gen_loss 1.750042, disc_loss 0.923426\n",
      "batch 175, gen_loss 1.725047, disc_loss 0.930030\n",
      "batch 176, gen_loss 1.637259, disc_loss 0.826605\n",
      "batch 177, gen_loss 1.504376, disc_loss 0.835718\n",
      "batch 178, gen_loss 1.519722, disc_loss 0.880431\n",
      "batch 179, gen_loss 1.614473, disc_loss 0.772391\n",
      "batch 180, gen_loss 1.824198, disc_loss 0.916599\n",
      "batch 181, gen_loss 1.907381, disc_loss 0.815286\n",
      "batch 182, gen_loss 1.788107, disc_loss 0.802360\n",
      "batch 183, gen_loss 1.749778, disc_loss 0.774618\n",
      "batch 184, gen_loss 1.615155, disc_loss 0.851043\n",
      "batch 185, gen_loss 1.628741, disc_loss 0.818399\n",
      "batch 186, gen_loss 1.557891, disc_loss 0.817414\n",
      "batch 187, gen_loss 1.644828, disc_loss 0.831115\n",
      "batch 188, gen_loss 1.712438, disc_loss 0.795944\n",
      "batch 189, gen_loss 1.930551, disc_loss 0.774976\n",
      "batch 190, gen_loss 2.001860, disc_loss 0.750602\n",
      "batch 191, gen_loss 1.760680, disc_loss 0.755932\n",
      "batch 192, gen_loss 1.593874, disc_loss 0.733222\n",
      "batch 193, gen_loss 1.552237, disc_loss 0.784104\n",
      "batch 194, gen_loss 1.585990, disc_loss 0.752631\n",
      "batch 195, gen_loss 1.675854, disc_loss 0.757168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 196, gen_loss 1.784917, disc_loss 0.724116\n",
      "batch 197, gen_loss 1.851414, disc_loss 0.767152\n",
      "batch 198, gen_loss 1.840495, disc_loss 0.670135\n",
      "batch 199, gen_loss 1.735296, disc_loss 0.662380\n",
      "batch 200, gen_loss 1.608228, disc_loss 0.731873\n",
      "batch 201, gen_loss 1.786902, disc_loss 0.651029\n",
      "batch 202, gen_loss 1.671006, disc_loss 0.808740\n",
      "batch 203, gen_loss 1.783506, disc_loss 0.727000\n",
      "batch 204, gen_loss 1.904243, disc_loss 0.610977\n",
      "batch 205, gen_loss 1.779059, disc_loss 0.752102\n",
      "batch 206, gen_loss 1.726296, disc_loss 0.710186\n",
      "batch 207, gen_loss 1.758837, disc_loss 0.660708\n",
      "batch 208, gen_loss 1.756171, disc_loss 0.608917\n",
      "batch 209, gen_loss 1.689337, disc_loss 0.694350\n",
      "batch 210, gen_loss 1.835677, disc_loss 0.576406\n",
      "batch 211, gen_loss 2.004678, disc_loss 0.692939\n",
      "batch 212, gen_loss 1.871313, disc_loss 0.690162\n",
      "batch 213, gen_loss 1.868277, disc_loss 0.621015\n",
      "batch 214, gen_loss 1.756965, disc_loss 0.643025\n",
      "batch 215, gen_loss 1.730246, disc_loss 0.691094\n",
      "batch 216, gen_loss 1.681696, disc_loss 0.681316\n",
      "batch 217, gen_loss 1.650550, disc_loss 0.653618\n",
      "batch 218, gen_loss 1.852659, disc_loss 0.669790\n",
      "batch 219, gen_loss 1.918336, disc_loss 0.675656\n",
      "batch 220, gen_loss 1.964331, disc_loss 0.579992\n",
      "batch 221, gen_loss 1.960378, disc_loss 0.681991\n",
      "batch 222, gen_loss 1.704605, disc_loss 0.629837\n",
      "batch 223, gen_loss 1.634822, disc_loss 0.653220\n",
      "batch 224, gen_loss 1.638637, disc_loss 0.668393\n",
      "batch 225, gen_loss 1.820283, disc_loss 0.640136\n",
      "batch 226, gen_loss 1.802337, disc_loss 0.641677\n",
      "batch 227, gen_loss 1.903344, disc_loss 0.626343\n",
      "batch 228, gen_loss 1.855937, disc_loss 0.634819\n",
      "batch 229, gen_loss 1.825375, disc_loss 0.749846\n",
      "batch 230, gen_loss 1.739544, disc_loss 0.669058\n",
      "batch 231, gen_loss 1.584827, disc_loss 0.713234\n",
      "batch 232, gen_loss 1.652160, disc_loss 0.695968\n",
      "batch 233, gen_loss 1.739537, disc_loss 0.666230\n",
      "batch 234, gen_loss 1.776402, disc_loss 0.628692\n",
      "Time for epoch31is 7.584543228149414 sec\n",
      "batch 0, gen_loss 1.926220, disc_loss 0.695397\n",
      "batch 1, gen_loss 1.867365, disc_loss 0.723872\n",
      "batch 2, gen_loss 1.874914, disc_loss 0.691452\n",
      "batch 3, gen_loss 1.623963, disc_loss 0.712296\n",
      "batch 4, gen_loss 1.590469, disc_loss 0.604550\n",
      "batch 5, gen_loss 1.639261, disc_loss 0.616461\n",
      "batch 6, gen_loss 1.822259, disc_loss 0.662205\n",
      "batch 7, gen_loss 1.894335, disc_loss 0.624264\n",
      "batch 8, gen_loss 1.991860, disc_loss 0.715669\n",
      "batch 9, gen_loss 1.814578, disc_loss 0.720035\n",
      "batch 10, gen_loss 1.703974, disc_loss 0.681543\n",
      "batch 11, gen_loss 1.531796, disc_loss 0.607790\n",
      "batch 12, gen_loss 1.702273, disc_loss 0.701005\n",
      "batch 13, gen_loss 1.722453, disc_loss 0.705236\n",
      "batch 14, gen_loss 1.806433, disc_loss 0.595864\n",
      "batch 15, gen_loss 1.779015, disc_loss 0.682982\n",
      "batch 16, gen_loss 1.670102, disc_loss 0.678210\n",
      "batch 17, gen_loss 1.752665, disc_loss 0.654454\n",
      "batch 18, gen_loss 1.720383, disc_loss 0.744458\n",
      "batch 19, gen_loss 1.794913, disc_loss 0.645560\n",
      "batch 20, gen_loss 1.772501, disc_loss 0.662082\n",
      "batch 21, gen_loss 1.739827, disc_loss 0.692080\n",
      "batch 22, gen_loss 1.733930, disc_loss 0.664880\n",
      "batch 23, gen_loss 1.616939, disc_loss 0.665996\n",
      "batch 24, gen_loss 1.741447, disc_loss 0.653835\n",
      "batch 25, gen_loss 1.727760, disc_loss 0.657080\n",
      "batch 26, gen_loss 1.742090, disc_loss 0.636975\n",
      "batch 27, gen_loss 1.838277, disc_loss 0.665123\n",
      "batch 28, gen_loss 1.799215, disc_loss 0.681078\n",
      "batch 29, gen_loss 1.778215, disc_loss 0.719318\n",
      "batch 30, gen_loss 1.658724, disc_loss 0.638954\n",
      "batch 31, gen_loss 1.597405, disc_loss 0.648081\n",
      "batch 32, gen_loss 1.638351, disc_loss 0.623008\n",
      "batch 33, gen_loss 1.843983, disc_loss 0.655772\n",
      "batch 34, gen_loss 1.785995, disc_loss 0.658558\n",
      "batch 35, gen_loss 1.936352, disc_loss 0.675161\n",
      "batch 36, gen_loss 1.850046, disc_loss 0.671190\n",
      "batch 37, gen_loss 1.669828, disc_loss 0.693268\n",
      "batch 38, gen_loss 1.606729, disc_loss 0.689877\n",
      "batch 39, gen_loss 1.703642, disc_loss 0.696695\n",
      "batch 40, gen_loss 1.709588, disc_loss 0.597161\n",
      "batch 41, gen_loss 1.890811, disc_loss 0.594973\n",
      "batch 42, gen_loss 1.998907, disc_loss 0.628835\n",
      "batch 43, gen_loss 1.969808, disc_loss 0.671845\n",
      "batch 44, gen_loss 1.852366, disc_loss 0.652955\n",
      "batch 45, gen_loss 1.609797, disc_loss 0.641318\n",
      "batch 46, gen_loss 1.573718, disc_loss 0.678858\n",
      "batch 47, gen_loss 1.628775, disc_loss 0.636370\n",
      "batch 48, gen_loss 1.851490, disc_loss 0.736752\n",
      "batch 49, gen_loss 1.706266, disc_loss 0.683452\n",
      "batch 50, gen_loss 1.584698, disc_loss 0.764148\n",
      "batch 51, gen_loss 1.657160, disc_loss 0.731398\n",
      "batch 52, gen_loss 1.671601, disc_loss 0.762515\n",
      "batch 53, gen_loss 1.767388, disc_loss 0.719832\n",
      "batch 54, gen_loss 1.644532, disc_loss 0.637104\n",
      "batch 55, gen_loss 1.781326, disc_loss 0.713173\n",
      "batch 56, gen_loss 1.845466, disc_loss 0.710951\n",
      "batch 57, gen_loss 1.834957, disc_loss 0.771099\n",
      "batch 58, gen_loss 1.783221, disc_loss 0.685420\n",
      "batch 59, gen_loss 1.686281, disc_loss 0.728335\n",
      "batch 60, gen_loss 1.491004, disc_loss 0.820297\n",
      "batch 61, gen_loss 1.545677, disc_loss 0.732421\n",
      "batch 62, gen_loss 1.613656, disc_loss 0.839722\n",
      "batch 63, gen_loss 1.708392, disc_loss 0.699577\n",
      "batch 64, gen_loss 1.684156, disc_loss 0.776657\n",
      "batch 65, gen_loss 1.832407, disc_loss 0.756279\n",
      "batch 66, gen_loss 1.667483, disc_loss 0.781396\n",
      "batch 67, gen_loss 1.526868, disc_loss 0.825710\n",
      "batch 68, gen_loss 1.455866, disc_loss 0.927492\n",
      "batch 69, gen_loss 1.612372, disc_loss 0.806577\n",
      "batch 70, gen_loss 1.487601, disc_loss 0.960295\n",
      "batch 71, gen_loss 1.555141, disc_loss 0.876822\n",
      "batch 72, gen_loss 1.642916, disc_loss 0.834997\n",
      "batch 73, gen_loss 1.747715, disc_loss 0.883427\n",
      "batch 74, gen_loss 1.637948, disc_loss 0.934870\n",
      "batch 75, gen_loss 1.466251, disc_loss 0.894137\n",
      "batch 76, gen_loss 1.403399, disc_loss 0.887125\n",
      "batch 77, gen_loss 1.445089, disc_loss 0.908638\n",
      "batch 78, gen_loss 1.611196, disc_loss 0.976793\n",
      "batch 79, gen_loss 1.591418, disc_loss 0.914890\n",
      "batch 80, gen_loss 1.547715, disc_loss 0.982912\n",
      "batch 81, gen_loss 1.540328, disc_loss 0.830057\n",
      "batch 82, gen_loss 1.407223, disc_loss 0.896274\n",
      "batch 83, gen_loss 1.574236, disc_loss 0.918118\n",
      "batch 84, gen_loss 1.550778, disc_loss 0.911422\n",
      "batch 85, gen_loss 1.665266, disc_loss 0.917280\n",
      "batch 86, gen_loss 1.568996, disc_loss 0.941476\n",
      "batch 87, gen_loss 1.569467, disc_loss 0.911897\n",
      "batch 88, gen_loss 1.466766, disc_loss 0.822452\n",
      "batch 89, gen_loss 1.475803, disc_loss 1.032598\n",
      "batch 90, gen_loss 1.339830, disc_loss 1.002981\n",
      "batch 91, gen_loss 1.451938, disc_loss 0.938682\n",
      "batch 92, gen_loss 1.442190, disc_loss 1.000415\n",
      "batch 93, gen_loss 1.386143, disc_loss 1.049731\n",
      "batch 94, gen_loss 1.438148, disc_loss 1.037256\n",
      "batch 95, gen_loss 1.375514, disc_loss 1.003247\n",
      "batch 96, gen_loss 1.583753, disc_loss 0.895692\n",
      "batch 97, gen_loss 1.541095, disc_loss 0.905732\n",
      "batch 98, gen_loss 1.423861, disc_loss 0.885497\n",
      "batch 99, gen_loss 1.665885, disc_loss 0.978138\n",
      "batch 100, gen_loss 1.753913, disc_loss 1.017519\n",
      "batch 101, gen_loss 1.493196, disc_loss 0.877676\n",
      "batch 102, gen_loss 1.302905, disc_loss 0.888105\n",
      "batch 103, gen_loss 1.258604, disc_loss 0.897063\n",
      "batch 104, gen_loss 1.379767, disc_loss 0.912432\n",
      "batch 105, gen_loss 1.492219, disc_loss 0.970517\n",
      "batch 106, gen_loss 1.754336, disc_loss 0.999261\n",
      "batch 107, gen_loss 1.674328, disc_loss 0.907850\n",
      "batch 108, gen_loss 1.545189, disc_loss 0.865894\n",
      "batch 109, gen_loss 1.337007, disc_loss 0.895786\n",
      "batch 110, gen_loss 1.355234, disc_loss 0.831303\n",
      "batch 111, gen_loss 1.543477, disc_loss 0.824756\n",
      "batch 112, gen_loss 1.616763, disc_loss 0.887625\n",
      "batch 113, gen_loss 1.658182, disc_loss 0.903287\n",
      "batch 114, gen_loss 1.770900, disc_loss 0.819733\n",
      "batch 115, gen_loss 1.532710, disc_loss 0.907329\n",
      "batch 116, gen_loss 1.485562, disc_loss 0.854381\n",
      "batch 117, gen_loss 1.484292, disc_loss 0.822759\n",
      "batch 118, gen_loss 1.484185, disc_loss 0.887078\n",
      "batch 119, gen_loss 1.471104, disc_loss 0.875727\n",
      "batch 120, gen_loss 1.604629, disc_loss 0.901572\n",
      "batch 121, gen_loss 1.596372, disc_loss 0.838797\n",
      "batch 122, gen_loss 1.600142, disc_loss 0.851231\n",
      "batch 123, gen_loss 1.569477, disc_loss 0.899935\n",
      "batch 124, gen_loss 1.646745, disc_loss 0.853090\n",
      "batch 125, gen_loss 1.591818, disc_loss 0.777512\n",
      "batch 126, gen_loss 1.525223, disc_loss 0.840909\n",
      "batch 127, gen_loss 1.548183, disc_loss 0.788590\n",
      "batch 128, gen_loss 1.599212, disc_loss 0.788887\n",
      "batch 129, gen_loss 1.664630, disc_loss 0.793818\n",
      "batch 130, gen_loss 1.524383, disc_loss 0.886227\n",
      "batch 131, gen_loss 1.495707, disc_loss 0.771070\n",
      "batch 132, gen_loss 1.556342, disc_loss 0.736405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 133, gen_loss 1.612385, disc_loss 0.821518\n",
      "batch 134, gen_loss 1.655653, disc_loss 0.729616\n",
      "batch 135, gen_loss 1.698396, disc_loss 0.831058\n",
      "batch 136, gen_loss 1.652467, disc_loss 0.801062\n",
      "batch 137, gen_loss 1.495716, disc_loss 0.825572\n",
      "batch 138, gen_loss 1.603990, disc_loss 0.749988\n",
      "batch 139, gen_loss 1.541966, disc_loss 0.794799\n",
      "batch 140, gen_loss 1.608601, disc_loss 0.727790\n",
      "batch 141, gen_loss 1.767025, disc_loss 0.791696\n",
      "batch 142, gen_loss 1.795653, disc_loss 0.783309\n",
      "batch 143, gen_loss 1.684976, disc_loss 0.828829\n",
      "batch 144, gen_loss 1.409269, disc_loss 0.819414\n",
      "batch 145, gen_loss 1.525235, disc_loss 0.773904\n",
      "batch 146, gen_loss 1.397350, disc_loss 0.855102\n",
      "batch 147, gen_loss 1.609599, disc_loss 0.791942\n",
      "batch 148, gen_loss 1.770345, disc_loss 0.828414\n",
      "batch 149, gen_loss 1.849786, disc_loss 0.878314\n",
      "batch 150, gen_loss 1.647474, disc_loss 0.793409\n",
      "batch 151, gen_loss 1.488846, disc_loss 0.789786\n",
      "batch 152, gen_loss 1.324276, disc_loss 0.828772\n",
      "batch 153, gen_loss 1.260633, disc_loss 0.856549\n",
      "batch 154, gen_loss 1.649308, disc_loss 0.797511\n",
      "batch 155, gen_loss 1.813096, disc_loss 0.851055\n",
      "batch 156, gen_loss 1.891674, disc_loss 1.015740\n",
      "batch 157, gen_loss 1.674987, disc_loss 0.849495\n",
      "batch 158, gen_loss 1.239444, disc_loss 0.900292\n",
      "batch 159, gen_loss 1.228797, disc_loss 0.937306\n",
      "batch 160, gen_loss 1.354777, disc_loss 0.963855\n",
      "batch 161, gen_loss 1.625012, disc_loss 0.889432\n",
      "batch 162, gen_loss 1.746979, disc_loss 0.925612\n",
      "batch 163, gen_loss 1.770595, disc_loss 0.872500\n",
      "batch 164, gen_loss 1.598177, disc_loss 0.864769\n",
      "batch 165, gen_loss 1.563289, disc_loss 0.896635\n",
      "batch 166, gen_loss 1.380431, disc_loss 0.875198\n",
      "batch 167, gen_loss 1.230904, disc_loss 0.991607\n",
      "batch 168, gen_loss 1.287061, disc_loss 1.008187\n",
      "batch 169, gen_loss 1.550806, disc_loss 0.894493\n",
      "batch 170, gen_loss 1.727547, disc_loss 0.944964\n",
      "batch 171, gen_loss 1.887726, disc_loss 0.943213\n",
      "batch 172, gen_loss 1.683484, disc_loss 0.951790\n",
      "batch 173, gen_loss 1.366890, disc_loss 0.903797\n",
      "batch 174, gen_loss 1.251051, disc_loss 0.864246\n",
      "batch 175, gen_loss 1.407496, disc_loss 0.888241\n",
      "batch 176, gen_loss 1.572345, disc_loss 0.884790\n",
      "batch 177, gen_loss 1.748526, disc_loss 0.976875\n",
      "batch 178, gen_loss 1.770730, disc_loss 0.940605\n",
      "batch 179, gen_loss 1.774739, disc_loss 0.913533\n",
      "batch 180, gen_loss 1.357808, disc_loss 0.922600\n",
      "batch 181, gen_loss 1.329925, disc_loss 0.895504\n",
      "batch 182, gen_loss 1.418756, disc_loss 0.856211\n",
      "batch 183, gen_loss 1.655497, disc_loss 0.922320\n",
      "batch 184, gen_loss 1.858393, disc_loss 0.791415\n",
      "batch 185, gen_loss 1.866477, disc_loss 0.746732\n",
      "batch 186, gen_loss 1.669282, disc_loss 0.833695\n",
      "batch 187, gen_loss 1.559097, disc_loss 0.811931\n",
      "batch 188, gen_loss 1.531015, disc_loss 0.781941\n",
      "batch 189, gen_loss 1.683426, disc_loss 0.791528\n",
      "batch 190, gen_loss 1.712551, disc_loss 0.699147\n",
      "batch 191, gen_loss 1.781189, disc_loss 0.868074\n",
      "batch 192, gen_loss 1.938446, disc_loss 0.696424\n",
      "batch 193, gen_loss 1.869853, disc_loss 0.671651\n",
      "batch 194, gen_loss 1.590509, disc_loss 0.675890\n",
      "batch 195, gen_loss 1.761888, disc_loss 0.724911\n",
      "batch 196, gen_loss 1.751329, disc_loss 0.719269\n",
      "batch 197, gen_loss 1.832333, disc_loss 0.695589\n",
      "batch 198, gen_loss 1.895900, disc_loss 0.686423\n",
      "batch 199, gen_loss 1.821715, disc_loss 0.668050\n",
      "batch 200, gen_loss 1.921505, disc_loss 0.670261\n",
      "batch 201, gen_loss 1.753466, disc_loss 0.679255\n",
      "batch 202, gen_loss 1.775309, disc_loss 0.649625\n",
      "batch 203, gen_loss 1.787142, disc_loss 0.617097\n",
      "batch 204, gen_loss 1.825452, disc_loss 0.728341\n",
      "batch 205, gen_loss 1.869753, disc_loss 0.663333\n",
      "batch 206, gen_loss 1.849675, disc_loss 0.637600\n",
      "batch 207, gen_loss 1.854869, disc_loss 0.639684\n",
      "batch 208, gen_loss 1.737472, disc_loss 0.708320\n",
      "batch 209, gen_loss 1.793777, disc_loss 0.650429\n",
      "batch 210, gen_loss 1.836721, disc_loss 0.604399\n",
      "batch 211, gen_loss 1.694215, disc_loss 0.683054\n",
      "batch 212, gen_loss 1.790381, disc_loss 0.716435\n",
      "batch 213, gen_loss 1.910768, disc_loss 0.719352\n",
      "batch 214, gen_loss 1.944627, disc_loss 0.624438\n",
      "batch 215, gen_loss 1.834565, disc_loss 0.604208\n",
      "batch 216, gen_loss 1.800010, disc_loss 0.717316\n",
      "batch 217, gen_loss 1.702593, disc_loss 0.694754\n",
      "batch 218, gen_loss 1.734887, disc_loss 0.652089\n",
      "batch 219, gen_loss 1.767995, disc_loss 0.656514\n",
      "batch 220, gen_loss 1.663653, disc_loss 0.743208\n",
      "batch 221, gen_loss 1.789689, disc_loss 0.660289\n",
      "batch 222, gen_loss 1.813942, disc_loss 0.721737\n",
      "batch 223, gen_loss 1.811851, disc_loss 0.768746\n",
      "batch 224, gen_loss 1.723086, disc_loss 0.667568\n",
      "batch 225, gen_loss 1.680223, disc_loss 0.798702\n",
      "batch 226, gen_loss 1.751066, disc_loss 0.702380\n",
      "batch 227, gen_loss 1.623534, disc_loss 0.804629\n",
      "batch 228, gen_loss 1.789039, disc_loss 0.787624\n",
      "batch 229, gen_loss 1.605989, disc_loss 0.736064\n",
      "batch 230, gen_loss 1.610297, disc_loss 0.830512\n",
      "batch 231, gen_loss 1.689969, disc_loss 0.749993\n",
      "batch 232, gen_loss 1.745121, disc_loss 0.781945\n",
      "batch 233, gen_loss 1.701272, disc_loss 0.744443\n",
      "batch 234, gen_loss 1.835422, disc_loss 0.921025\n",
      "Time for epoch32is 7.606937646865845 sec\n",
      "batch 0, gen_loss 1.670516, disc_loss 0.824868\n",
      "batch 1, gen_loss 1.553041, disc_loss 0.754835\n",
      "batch 2, gen_loss 1.491611, disc_loss 0.830249\n",
      "batch 3, gen_loss 1.538739, disc_loss 0.877551\n",
      "batch 4, gen_loss 1.544393, disc_loss 0.825065\n",
      "batch 5, gen_loss 1.648906, disc_loss 0.760563\n",
      "batch 6, gen_loss 1.570179, disc_loss 0.826199\n",
      "batch 7, gen_loss 1.671503, disc_loss 0.894465\n",
      "batch 8, gen_loss 1.832598, disc_loss 0.716830\n",
      "batch 9, gen_loss 1.733034, disc_loss 0.922954\n",
      "batch 10, gen_loss 1.566189, disc_loss 0.791304\n",
      "batch 11, gen_loss 1.568531, disc_loss 0.893724\n",
      "batch 12, gen_loss 1.463236, disc_loss 0.833484\n",
      "batch 13, gen_loss 1.509143, disc_loss 0.864740\n",
      "batch 14, gen_loss 1.573897, disc_loss 0.900281\n",
      "batch 15, gen_loss 1.721292, disc_loss 0.808436\n",
      "batch 16, gen_loss 1.818508, disc_loss 0.792492\n",
      "batch 17, gen_loss 1.804031, disc_loss 0.866330\n",
      "batch 18, gen_loss 1.582431, disc_loss 0.858652\n",
      "batch 19, gen_loss 1.439687, disc_loss 0.842297\n",
      "batch 20, gen_loss 1.609519, disc_loss 0.864347\n",
      "batch 21, gen_loss 1.585117, disc_loss 0.823358\n",
      "batch 22, gen_loss 1.601340, disc_loss 0.812490\n",
      "batch 23, gen_loss 1.612357, disc_loss 0.889183\n",
      "batch 24, gen_loss 1.543059, disc_loss 0.802731\n",
      "batch 25, gen_loss 1.636449, disc_loss 0.781799\n",
      "batch 26, gen_loss 1.520834, disc_loss 0.853866\n",
      "batch 27, gen_loss 1.605973, disc_loss 0.909573\n",
      "batch 28, gen_loss 1.662712, disc_loss 0.763363\n",
      "batch 29, gen_loss 1.766972, disc_loss 0.841704\n",
      "batch 30, gen_loss 1.804429, disc_loss 0.872552\n",
      "batch 31, gen_loss 1.695530, disc_loss 0.851659\n",
      "batch 32, gen_loss 1.522587, disc_loss 0.821425\n",
      "batch 33, gen_loss 1.533515, disc_loss 0.737335\n",
      "batch 34, gen_loss 1.616111, disc_loss 0.836518\n",
      "batch 35, gen_loss 1.738279, disc_loss 0.851460\n",
      "batch 36, gen_loss 1.920887, disc_loss 0.753116\n",
      "batch 37, gen_loss 1.876533, disc_loss 0.810909\n",
      "batch 38, gen_loss 1.721388, disc_loss 0.743063\n",
      "batch 39, gen_loss 1.673190, disc_loss 0.801017\n",
      "batch 40, gen_loss 1.666231, disc_loss 0.831327\n",
      "batch 41, gen_loss 1.645460, disc_loss 0.797494\n",
      "batch 42, gen_loss 1.554365, disc_loss 0.815291\n",
      "batch 43, gen_loss 1.749545, disc_loss 0.796458\n",
      "batch 44, gen_loss 1.850223, disc_loss 0.808301\n",
      "batch 45, gen_loss 1.929036, disc_loss 0.793433\n",
      "batch 46, gen_loss 1.694724, disc_loss 0.772199\n",
      "batch 47, gen_loss 1.711920, disc_loss 0.854420\n",
      "batch 48, gen_loss 1.561823, disc_loss 0.775845\n",
      "batch 49, gen_loss 1.781693, disc_loss 0.678782\n",
      "batch 50, gen_loss 1.736347, disc_loss 0.765711\n",
      "batch 51, gen_loss 1.834746, disc_loss 0.722684\n",
      "batch 52, gen_loss 1.887234, disc_loss 0.831700\n",
      "batch 53, gen_loss 1.902902, disc_loss 0.785086\n",
      "batch 54, gen_loss 1.739669, disc_loss 0.743142\n",
      "batch 55, gen_loss 1.633854, disc_loss 0.796478\n",
      "batch 56, gen_loss 1.727920, disc_loss 0.702987\n",
      "batch 57, gen_loss 1.594825, disc_loss 0.773142\n",
      "batch 58, gen_loss 1.692153, disc_loss 0.773064\n",
      "batch 59, gen_loss 1.748482, disc_loss 0.689410\n",
      "batch 60, gen_loss 1.783098, disc_loss 0.837638\n",
      "batch 61, gen_loss 1.822832, disc_loss 0.769773\n",
      "batch 62, gen_loss 1.735278, disc_loss 0.745431\n",
      "batch 63, gen_loss 1.840253, disc_loss 0.710215\n",
      "batch 64, gen_loss 1.783275, disc_loss 0.770265\n",
      "batch 65, gen_loss 1.668537, disc_loss 0.736589\n",
      "batch 66, gen_loss 1.608539, disc_loss 0.763298\n",
      "batch 67, gen_loss 1.761985, disc_loss 0.668227\n",
      "batch 68, gen_loss 1.719085, disc_loss 0.802166\n",
      "batch 69, gen_loss 1.782162, disc_loss 0.765859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 70, gen_loss 1.785887, disc_loss 0.736363\n",
      "batch 71, gen_loss 1.712292, disc_loss 0.732588\n",
      "batch 72, gen_loss 1.635740, disc_loss 0.791261\n",
      "batch 73, gen_loss 1.655996, disc_loss 0.846560\n",
      "batch 74, gen_loss 1.627855, disc_loss 0.786849\n",
      "batch 75, gen_loss 1.678796, disc_loss 0.866799\n",
      "batch 76, gen_loss 1.592683, disc_loss 0.774614\n",
      "batch 77, gen_loss 1.561200, disc_loss 0.811154\n",
      "batch 78, gen_loss 1.605926, disc_loss 0.743360\n",
      "batch 79, gen_loss 1.667951, disc_loss 0.787649\n",
      "batch 80, gen_loss 1.713567, disc_loss 0.836208\n",
      "batch 81, gen_loss 1.651394, disc_loss 0.773499\n",
      "batch 82, gen_loss 1.674595, disc_loss 0.814371\n",
      "batch 83, gen_loss 1.744091, disc_loss 0.826749\n",
      "batch 84, gen_loss 1.582123, disc_loss 0.959894\n",
      "batch 85, gen_loss 1.491254, disc_loss 0.819461\n",
      "batch 86, gen_loss 1.394747, disc_loss 0.798645\n",
      "batch 87, gen_loss 1.511744, disc_loss 0.889511\n",
      "batch 88, gen_loss 1.588783, disc_loss 0.856170\n",
      "batch 89, gen_loss 1.571804, disc_loss 0.995254\n",
      "batch 90, gen_loss 1.705326, disc_loss 0.890549\n",
      "batch 91, gen_loss 1.634794, disc_loss 0.835917\n",
      "batch 92, gen_loss 1.508777, disc_loss 0.863241\n",
      "batch 93, gen_loss 1.347707, disc_loss 0.845954\n",
      "batch 94, gen_loss 1.430644, disc_loss 0.911720\n",
      "batch 95, gen_loss 1.573546, disc_loss 0.875728\n",
      "batch 96, gen_loss 1.710627, disc_loss 0.893747\n",
      "batch 97, gen_loss 1.650436, disc_loss 0.860108\n",
      "batch 98, gen_loss 1.537314, disc_loss 0.873217\n",
      "batch 99, gen_loss 1.534971, disc_loss 0.934388\n",
      "batch 100, gen_loss 1.512837, disc_loss 0.868531\n",
      "batch 101, gen_loss 1.468079, disc_loss 0.853559\n",
      "batch 102, gen_loss 1.403948, disc_loss 0.889009\n",
      "batch 103, gen_loss 1.556128, disc_loss 0.786810\n",
      "batch 104, gen_loss 1.547755, disc_loss 0.832049\n",
      "batch 105, gen_loss 1.613251, disc_loss 0.915234\n",
      "batch 106, gen_loss 1.457433, disc_loss 0.951128\n",
      "batch 107, gen_loss 1.570344, disc_loss 0.807506\n",
      "batch 108, gen_loss 1.521753, disc_loss 0.891124\n",
      "batch 109, gen_loss 1.424982, disc_loss 0.884251\n",
      "batch 110, gen_loss 1.535431, disc_loss 0.765977\n",
      "batch 111, gen_loss 1.648152, disc_loss 0.829221\n",
      "batch 112, gen_loss 1.716223, disc_loss 0.793819\n",
      "batch 113, gen_loss 1.669304, disc_loss 0.903251\n",
      "batch 114, gen_loss 1.562181, disc_loss 0.774788\n",
      "batch 115, gen_loss 1.447712, disc_loss 0.870789\n",
      "batch 116, gen_loss 1.415383, disc_loss 0.786798\n",
      "batch 117, gen_loss 1.442776, disc_loss 0.756444\n",
      "batch 118, gen_loss 1.594703, disc_loss 0.855398\n",
      "batch 119, gen_loss 1.792076, disc_loss 0.699204\n",
      "batch 120, gen_loss 1.696533, disc_loss 0.795408\n",
      "batch 121, gen_loss 1.707703, disc_loss 0.692585\n",
      "batch 122, gen_loss 1.638507, disc_loss 0.696865\n",
      "batch 123, gen_loss 1.479141, disc_loss 0.718386\n",
      "batch 124, gen_loss 1.534630, disc_loss 0.687173\n",
      "batch 125, gen_loss 1.773291, disc_loss 0.669420\n",
      "batch 126, gen_loss 1.928118, disc_loss 0.696708\n",
      "batch 127, gen_loss 1.757220, disc_loss 0.669004\n",
      "batch 128, gen_loss 1.660671, disc_loss 0.731206\n",
      "batch 129, gen_loss 1.567449, disc_loss 0.708743\n",
      "batch 130, gen_loss 1.474369, disc_loss 0.700523\n",
      "batch 131, gen_loss 1.563232, disc_loss 0.734719\n",
      "batch 132, gen_loss 1.703990, disc_loss 0.634914\n",
      "batch 133, gen_loss 1.746688, disc_loss 0.698524\n",
      "batch 134, gen_loss 1.791637, disc_loss 0.721888\n",
      "batch 135, gen_loss 1.608327, disc_loss 0.705913\n",
      "batch 136, gen_loss 1.552962, disc_loss 0.739727\n",
      "batch 137, gen_loss 1.580855, disc_loss 0.681870\n",
      "batch 138, gen_loss 1.646718, disc_loss 0.661472\n",
      "batch 139, gen_loss 1.709988, disc_loss 0.652967\n",
      "batch 140, gen_loss 1.749769, disc_loss 0.735939\n",
      "batch 141, gen_loss 1.808646, disc_loss 0.722047\n",
      "batch 142, gen_loss 1.888816, disc_loss 0.631910\n",
      "batch 143, gen_loss 1.814340, disc_loss 0.611073\n",
      "batch 144, gen_loss 1.787124, disc_loss 0.621624\n",
      "batch 145, gen_loss 1.565753, disc_loss 0.668679\n",
      "batch 146, gen_loss 1.762533, disc_loss 0.666517\n",
      "batch 147, gen_loss 1.726470, disc_loss 0.644450\n",
      "batch 148, gen_loss 1.720948, disc_loss 0.704357\n",
      "batch 149, gen_loss 1.802295, disc_loss 0.633314\n",
      "batch 150, gen_loss 1.842579, disc_loss 0.724704\n",
      "batch 151, gen_loss 1.806610, disc_loss 0.740847\n",
      "batch 152, gen_loss 1.696975, disc_loss 0.578846\n",
      "batch 153, gen_loss 1.716158, disc_loss 0.668366\n",
      "batch 154, gen_loss 1.754996, disc_loss 0.636133\n",
      "batch 155, gen_loss 1.862406, disc_loss 0.710544\n",
      "batch 156, gen_loss 1.743304, disc_loss 0.598171\n",
      "batch 157, gen_loss 1.749056, disc_loss 0.611286\n",
      "batch 158, gen_loss 1.696639, disc_loss 0.653407\n",
      "batch 159, gen_loss 1.804551, disc_loss 0.645275\n",
      "batch 160, gen_loss 1.708505, disc_loss 0.685938\n",
      "batch 161, gen_loss 1.852522, disc_loss 0.666784\n",
      "batch 162, gen_loss 1.833609, disc_loss 0.652970\n",
      "batch 163, gen_loss 1.753001, disc_loss 0.647180\n",
      "batch 164, gen_loss 1.752636, disc_loss 0.635516\n",
      "batch 165, gen_loss 1.771373, disc_loss 0.621008\n",
      "batch 166, gen_loss 1.854218, disc_loss 0.597154\n",
      "batch 167, gen_loss 1.834259, disc_loss 0.633896\n",
      "batch 168, gen_loss 1.960839, disc_loss 0.677725\n",
      "batch 169, gen_loss 1.949402, disc_loss 0.650003\n",
      "batch 170, gen_loss 1.917931, disc_loss 0.706873\n",
      "batch 171, gen_loss 1.767424, disc_loss 0.630525\n",
      "batch 172, gen_loss 1.713372, disc_loss 0.740618\n",
      "batch 173, gen_loss 1.751106, disc_loss 0.599143\n",
      "batch 174, gen_loss 1.706583, disc_loss 0.723078\n",
      "batch 175, gen_loss 1.847414, disc_loss 0.720522\n",
      "batch 176, gen_loss 1.769912, disc_loss 0.666477\n",
      "batch 177, gen_loss 1.729232, disc_loss 0.690414\n",
      "batch 178, gen_loss 1.792957, disc_loss 0.658634\n",
      "batch 179, gen_loss 1.622849, disc_loss 0.657476\n",
      "batch 180, gen_loss 1.659340, disc_loss 0.689566\n",
      "batch 181, gen_loss 1.757620, disc_loss 0.682302\n",
      "batch 182, gen_loss 2.040880, disc_loss 0.630868\n",
      "batch 183, gen_loss 1.781970, disc_loss 0.660556\n",
      "batch 184, gen_loss 1.802084, disc_loss 0.680415\n",
      "batch 185, gen_loss 1.730521, disc_loss 0.674829\n",
      "batch 186, gen_loss 1.620115, disc_loss 0.645216\n",
      "batch 187, gen_loss 1.593028, disc_loss 0.629194\n",
      "batch 188, gen_loss 1.772901, disc_loss 0.656822\n",
      "batch 189, gen_loss 1.846135, disc_loss 0.683692\n",
      "batch 190, gen_loss 1.930829, disc_loss 0.681942\n",
      "batch 191, gen_loss 1.900324, disc_loss 0.688506\n",
      "batch 192, gen_loss 1.735747, disc_loss 0.739433\n",
      "batch 193, gen_loss 1.464257, disc_loss 0.817853\n",
      "batch 194, gen_loss 1.541231, disc_loss 0.704418\n",
      "batch 195, gen_loss 1.678413, disc_loss 0.731739\n",
      "batch 196, gen_loss 1.764395, disc_loss 0.726269\n",
      "batch 197, gen_loss 1.741871, disc_loss 0.772120\n",
      "batch 198, gen_loss 1.767544, disc_loss 0.704020\n",
      "batch 199, gen_loss 1.633166, disc_loss 0.751206\n",
      "batch 200, gen_loss 1.454204, disc_loss 0.795144\n",
      "batch 201, gen_loss 1.578550, disc_loss 0.742109\n",
      "batch 202, gen_loss 1.570816, disc_loss 0.789905\n",
      "batch 203, gen_loss 1.572560, disc_loss 0.759830\n",
      "batch 204, gen_loss 1.808509, disc_loss 0.706939\n",
      "batch 205, gen_loss 1.904532, disc_loss 0.739182\n",
      "batch 206, gen_loss 1.654703, disc_loss 0.806890\n",
      "batch 207, gen_loss 1.508093, disc_loss 0.723909\n",
      "batch 208, gen_loss 1.470823, disc_loss 0.739992\n",
      "batch 209, gen_loss 1.570474, disc_loss 0.700093\n",
      "batch 210, gen_loss 1.720623, disc_loss 0.791774\n",
      "batch 211, gen_loss 1.886151, disc_loss 0.824799\n",
      "batch 212, gen_loss 1.852363, disc_loss 0.711124\n",
      "batch 213, gen_loss 1.689876, disc_loss 0.774188\n",
      "batch 214, gen_loss 1.501948, disc_loss 0.742588\n",
      "batch 215, gen_loss 1.458366, disc_loss 0.825314\n",
      "batch 216, gen_loss 1.706770, disc_loss 0.732414\n",
      "batch 217, gen_loss 1.835012, disc_loss 0.800085\n",
      "batch 218, gen_loss 1.791674, disc_loss 0.761683\n",
      "batch 219, gen_loss 1.819335, disc_loss 0.796986\n",
      "batch 220, gen_loss 1.805029, disc_loss 0.824449\n",
      "batch 221, gen_loss 1.471190, disc_loss 0.814269\n",
      "batch 222, gen_loss 1.259559, disc_loss 0.949697\n",
      "batch 223, gen_loss 1.403782, disc_loss 0.891007\n",
      "batch 224, gen_loss 1.535187, disc_loss 0.864008\n",
      "batch 225, gen_loss 1.625167, disc_loss 0.935609\n",
      "batch 226, gen_loss 1.590945, disc_loss 0.865250\n",
      "batch 227, gen_loss 1.600781, disc_loss 0.834172\n",
      "batch 228, gen_loss 1.458685, disc_loss 0.810549\n",
      "batch 229, gen_loss 1.434520, disc_loss 0.864094\n",
      "batch 230, gen_loss 1.297926, disc_loss 0.987077\n",
      "batch 231, gen_loss 1.451936, disc_loss 0.906376\n",
      "batch 232, gen_loss 1.556031, disc_loss 0.895308\n",
      "batch 233, gen_loss 1.666288, disc_loss 0.915559\n",
      "batch 234, gen_loss 1.579607, disc_loss 0.902891\n",
      "Time for epoch33is 7.590665102005005 sec\n",
      "batch 0, gen_loss 1.427527, disc_loss 0.887047\n",
      "batch 1, gen_loss 1.408416, disc_loss 0.941948\n",
      "batch 2, gen_loss 1.360382, disc_loss 0.885491\n",
      "batch 3, gen_loss 1.391865, disc_loss 0.960099\n",
      "batch 4, gen_loss 1.589808, disc_loss 0.943995\n",
      "batch 5, gen_loss 1.706783, disc_loss 0.932171\n",
      "batch 6, gen_loss 1.517336, disc_loss 0.908401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 7, gen_loss 1.417832, disc_loss 0.982177\n",
      "batch 8, gen_loss 1.397235, disc_loss 0.977782\n",
      "batch 9, gen_loss 1.436612, disc_loss 0.911209\n",
      "batch 10, gen_loss 1.375731, disc_loss 0.948430\n",
      "batch 11, gen_loss 1.472801, disc_loss 0.889110\n",
      "batch 12, gen_loss 1.684532, disc_loss 0.924529\n",
      "batch 13, gen_loss 1.789024, disc_loss 0.881726\n",
      "batch 14, gen_loss 1.735843, disc_loss 0.939266\n",
      "batch 15, gen_loss 1.622582, disc_loss 0.922521\n",
      "batch 16, gen_loss 1.481454, disc_loss 0.939228\n",
      "batch 17, gen_loss 1.287887, disc_loss 0.952421\n",
      "batch 18, gen_loss 1.344925, disc_loss 0.942046\n",
      "batch 19, gen_loss 1.508147, disc_loss 0.875965\n",
      "batch 20, gen_loss 1.610581, disc_loss 0.976704\n",
      "batch 21, gen_loss 1.758361, disc_loss 0.918171\n",
      "batch 22, gen_loss 1.720749, disc_loss 0.960825\n",
      "batch 23, gen_loss 1.537765, disc_loss 0.867847\n",
      "batch 24, gen_loss 1.470041, disc_loss 0.876516\n",
      "batch 25, gen_loss 1.410605, disc_loss 0.973629\n",
      "batch 26, gen_loss 1.514325, disc_loss 0.787594\n",
      "batch 27, gen_loss 1.569832, disc_loss 0.776076\n",
      "batch 28, gen_loss 1.748486, disc_loss 0.848125\n",
      "batch 29, gen_loss 1.821904, disc_loss 0.912933\n",
      "batch 30, gen_loss 1.745506, disc_loss 0.805486\n",
      "batch 31, gen_loss 1.746771, disc_loss 0.823284\n",
      "batch 32, gen_loss 1.450157, disc_loss 0.908026\n",
      "batch 33, gen_loss 1.377092, disc_loss 0.864376\n",
      "batch 34, gen_loss 1.463302, disc_loss 0.841886\n",
      "batch 35, gen_loss 1.541734, disc_loss 0.899077\n",
      "batch 36, gen_loss 1.576087, disc_loss 0.841457\n",
      "batch 37, gen_loss 1.549024, disc_loss 0.919322\n",
      "batch 38, gen_loss 1.779810, disc_loss 0.874634\n",
      "batch 39, gen_loss 1.626618, disc_loss 0.876753\n",
      "batch 40, gen_loss 1.468178, disc_loss 0.871529\n",
      "batch 41, gen_loss 1.387148, disc_loss 0.889229\n",
      "batch 42, gen_loss 1.507289, disc_loss 0.847705\n",
      "batch 43, gen_loss 1.619141, disc_loss 0.945295\n",
      "batch 44, gen_loss 1.608187, disc_loss 0.893729\n",
      "batch 45, gen_loss 1.613720, disc_loss 0.832989\n",
      "batch 46, gen_loss 1.555018, disc_loss 0.906757\n",
      "batch 47, gen_loss 1.538706, disc_loss 0.930594\n",
      "batch 48, gen_loss 1.400925, disc_loss 0.983394\n",
      "batch 49, gen_loss 1.344224, disc_loss 0.899274\n",
      "batch 50, gen_loss 1.440900, disc_loss 0.964654\n",
      "batch 51, gen_loss 1.461314, disc_loss 0.914522\n",
      "batch 52, gen_loss 1.556715, disc_loss 0.923167\n",
      "batch 53, gen_loss 1.628484, disc_loss 0.855370\n",
      "batch 54, gen_loss 1.611566, disc_loss 0.866818\n",
      "batch 55, gen_loss 1.577688, disc_loss 0.845252\n",
      "batch 56, gen_loss 1.557168, disc_loss 0.839115\n",
      "batch 57, gen_loss 1.530973, disc_loss 0.821979\n",
      "batch 58, gen_loss 1.535200, disc_loss 0.819103\n",
      "batch 59, gen_loss 1.486333, disc_loss 0.824634\n",
      "batch 60, gen_loss 1.675493, disc_loss 0.854844\n",
      "batch 61, gen_loss 1.708681, disc_loss 0.827772\n",
      "batch 62, gen_loss 1.646327, disc_loss 0.810092\n",
      "batch 63, gen_loss 1.694725, disc_loss 0.793994\n",
      "batch 64, gen_loss 1.676138, disc_loss 0.736900\n",
      "batch 65, gen_loss 1.570891, disc_loss 0.692745\n",
      "batch 66, gen_loss 1.581888, disc_loss 0.773835\n",
      "batch 67, gen_loss 1.605586, disc_loss 0.875755\n",
      "batch 68, gen_loss 1.618061, disc_loss 0.833671\n",
      "batch 69, gen_loss 1.611697, disc_loss 0.812951\n",
      "batch 70, gen_loss 1.562207, disc_loss 0.810170\n",
      "batch 71, gen_loss 1.654745, disc_loss 0.735589\n",
      "batch 72, gen_loss 1.603704, disc_loss 0.769442\n",
      "batch 73, gen_loss 1.572655, disc_loss 0.831083\n",
      "batch 74, gen_loss 1.651379, disc_loss 0.792096\n",
      "batch 75, gen_loss 1.644389, disc_loss 0.682749\n",
      "batch 76, gen_loss 1.609104, disc_loss 0.804965\n",
      "batch 77, gen_loss 1.653165, disc_loss 0.817021\n",
      "batch 78, gen_loss 1.617161, disc_loss 0.801619\n",
      "batch 79, gen_loss 1.508487, disc_loss 0.865689\n",
      "batch 80, gen_loss 1.569014, disc_loss 0.713209\n",
      "batch 81, gen_loss 1.619326, disc_loss 0.792345\n",
      "batch 82, gen_loss 1.611190, disc_loss 0.777812\n",
      "batch 83, gen_loss 1.439760, disc_loss 0.787969\n",
      "batch 84, gen_loss 1.562227, disc_loss 0.808703\n",
      "batch 85, gen_loss 1.537367, disc_loss 0.762197\n",
      "batch 86, gen_loss 1.583233, disc_loss 0.876549\n",
      "batch 87, gen_loss 1.656381, disc_loss 0.800023\n",
      "batch 88, gen_loss 1.494355, disc_loss 0.821702\n",
      "batch 89, gen_loss 1.540486, disc_loss 0.786201\n",
      "batch 90, gen_loss 1.578064, disc_loss 0.799161\n",
      "batch 91, gen_loss 1.639036, disc_loss 0.833729\n",
      "batch 92, gen_loss 1.667331, disc_loss 0.851803\n",
      "batch 93, gen_loss 1.528005, disc_loss 0.885085\n",
      "batch 94, gen_loss 1.499840, disc_loss 0.804776\n",
      "batch 95, gen_loss 1.495107, disc_loss 0.863972\n",
      "batch 96, gen_loss 1.507025, disc_loss 0.802587\n",
      "batch 97, gen_loss 1.618003, disc_loss 0.762977\n",
      "batch 98, gen_loss 1.536460, disc_loss 0.848565\n",
      "batch 99, gen_loss 1.615664, disc_loss 0.854997\n",
      "batch 100, gen_loss 1.529456, disc_loss 0.931266\n",
      "batch 101, gen_loss 1.483556, disc_loss 0.871136\n",
      "batch 102, gen_loss 1.402507, disc_loss 0.837510\n",
      "batch 103, gen_loss 1.392392, disc_loss 0.820535\n",
      "batch 104, gen_loss 1.439041, disc_loss 0.819355\n",
      "batch 105, gen_loss 1.488453, disc_loss 0.788223\n",
      "batch 106, gen_loss 1.729425, disc_loss 0.781343\n",
      "batch 107, gen_loss 1.720533, disc_loss 0.812802\n",
      "batch 108, gen_loss 1.671762, disc_loss 0.796294\n",
      "batch 109, gen_loss 1.711650, disc_loss 0.823325\n",
      "batch 110, gen_loss 1.631013, disc_loss 0.773145\n",
      "batch 111, gen_loss 1.501963, disc_loss 0.792047\n",
      "batch 112, gen_loss 1.482230, disc_loss 0.805098\n",
      "batch 113, gen_loss 1.609242, disc_loss 0.699096\n",
      "batch 114, gen_loss 1.681075, disc_loss 0.787879\n",
      "batch 115, gen_loss 1.622239, disc_loss 0.754456\n",
      "batch 116, gen_loss 1.725353, disc_loss 0.791453\n",
      "batch 117, gen_loss 1.637192, disc_loss 0.721726\n",
      "batch 118, gen_loss 1.642180, disc_loss 0.793674\n",
      "batch 119, gen_loss 1.603753, disc_loss 0.728613\n",
      "batch 120, gen_loss 1.416648, disc_loss 0.744772\n",
      "batch 121, gen_loss 1.558549, disc_loss 0.707171\n",
      "batch 122, gen_loss 1.420290, disc_loss 0.760961\n",
      "batch 123, gen_loss 1.511133, disc_loss 0.856067\n",
      "batch 124, gen_loss 1.671332, disc_loss 0.785392\n",
      "batch 125, gen_loss 1.707084, disc_loss 0.763987\n",
      "batch 126, gen_loss 1.723132, disc_loss 0.731188\n",
      "batch 127, gen_loss 1.612074, disc_loss 0.753712\n",
      "batch 128, gen_loss 1.717475, disc_loss 0.706344\n",
      "batch 129, gen_loss 1.669567, disc_loss 0.817049\n",
      "batch 130, gen_loss 1.742062, disc_loss 0.825829\n",
      "batch 131, gen_loss 1.625617, disc_loss 0.807201\n",
      "batch 132, gen_loss 1.547382, disc_loss 0.739294\n",
      "batch 133, gen_loss 1.654464, disc_loss 0.739542\n",
      "batch 134, gen_loss 1.566676, disc_loss 0.750440\n",
      "batch 135, gen_loss 1.782580, disc_loss 0.753425\n",
      "batch 136, gen_loss 1.752029, disc_loss 0.727922\n",
      "batch 137, gen_loss 1.709729, disc_loss 0.754118\n",
      "batch 138, gen_loss 1.612582, disc_loss 0.767315\n",
      "batch 139, gen_loss 1.665643, disc_loss 0.673090\n",
      "batch 140, gen_loss 1.562620, disc_loss 0.710592\n",
      "batch 141, gen_loss 1.701400, disc_loss 0.718637\n",
      "batch 142, gen_loss 1.705234, disc_loss 0.638934\n",
      "batch 143, gen_loss 1.881262, disc_loss 0.662691\n",
      "batch 144, gen_loss 1.910460, disc_loss 0.678895\n",
      "batch 145, gen_loss 1.885231, disc_loss 0.622779\n",
      "batch 146, gen_loss 1.798164, disc_loss 0.736424\n",
      "batch 147, gen_loss 1.853022, disc_loss 0.648667\n",
      "batch 148, gen_loss 1.715614, disc_loss 0.600582\n",
      "batch 149, gen_loss 1.760227, disc_loss 0.644486\n",
      "batch 150, gen_loss 1.848629, disc_loss 0.626165\n",
      "batch 151, gen_loss 1.802548, disc_loss 0.670897\n",
      "batch 152, gen_loss 1.845109, disc_loss 0.723554\n",
      "batch 153, gen_loss 1.897760, disc_loss 0.633116\n",
      "batch 154, gen_loss 1.837320, disc_loss 0.645458\n",
      "batch 155, gen_loss 1.843723, disc_loss 0.615957\n",
      "batch 156, gen_loss 1.846150, disc_loss 0.654146\n",
      "batch 157, gen_loss 1.801076, disc_loss 0.589233\n",
      "batch 158, gen_loss 1.803354, disc_loss 0.575655\n",
      "batch 159, gen_loss 1.908585, disc_loss 0.633111\n",
      "batch 160, gen_loss 1.944373, disc_loss 0.669358\n",
      "batch 161, gen_loss 1.798657, disc_loss 0.676562\n",
      "batch 162, gen_loss 1.886071, disc_loss 0.576924\n",
      "batch 163, gen_loss 1.743336, disc_loss 0.615852\n",
      "batch 164, gen_loss 1.717945, disc_loss 0.658043\n",
      "batch 165, gen_loss 1.777386, disc_loss 0.678362\n",
      "batch 166, gen_loss 1.747027, disc_loss 0.696907\n",
      "batch 167, gen_loss 1.692166, disc_loss 0.734053\n",
      "batch 168, gen_loss 1.861848, disc_loss 0.679480\n",
      "batch 169, gen_loss 1.802785, disc_loss 0.660395\n",
      "batch 170, gen_loss 1.859220, disc_loss 0.674960\n",
      "batch 171, gen_loss 1.860350, disc_loss 0.709674\n",
      "batch 172, gen_loss 1.793054, disc_loss 0.661462\n",
      "batch 173, gen_loss 1.717388, disc_loss 0.697195\n",
      "batch 174, gen_loss 1.746230, disc_loss 0.696736\n",
      "batch 175, gen_loss 1.626360, disc_loss 0.786718\n",
      "batch 176, gen_loss 1.699758, disc_loss 0.751340\n",
      "batch 177, gen_loss 1.721216, disc_loss 0.818027\n",
      "batch 178, gen_loss 1.739356, disc_loss 0.854186\n",
      "batch 179, gen_loss 1.721686, disc_loss 0.731235\n",
      "batch 180, gen_loss 1.609599, disc_loss 0.823031\n",
      "batch 181, gen_loss 1.529171, disc_loss 0.909242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 182, gen_loss 1.535673, disc_loss 0.959856\n",
      "batch 183, gen_loss 1.639013, disc_loss 0.864913\n",
      "batch 184, gen_loss 1.485224, disc_loss 1.071993\n",
      "batch 185, gen_loss 1.511185, disc_loss 1.047322\n",
      "batch 186, gen_loss 1.631845, disc_loss 1.012699\n",
      "batch 187, gen_loss 1.534140, disc_loss 1.095541\n",
      "batch 188, gen_loss 1.615553, disc_loss 0.930308\n",
      "batch 189, gen_loss 1.471642, disc_loss 1.062526\n",
      "batch 190, gen_loss 1.353141, disc_loss 1.044134\n",
      "batch 191, gen_loss 1.493371, disc_loss 1.105400\n",
      "batch 192, gen_loss 1.717040, disc_loss 0.988044\n",
      "batch 193, gen_loss 1.554494, disc_loss 1.151038\n",
      "batch 194, gen_loss 1.629950, disc_loss 1.096155\n",
      "batch 195, gen_loss 1.602175, disc_loss 1.063511\n",
      "batch 196, gen_loss 1.485785, disc_loss 1.194711\n",
      "batch 197, gen_loss 1.500311, disc_loss 1.140916\n",
      "batch 198, gen_loss 1.494752, disc_loss 1.190600\n",
      "batch 199, gen_loss 1.538802, disc_loss 1.085649\n",
      "batch 200, gen_loss 1.627530, disc_loss 1.047838\n",
      "batch 201, gen_loss 1.634998, disc_loss 1.122176\n",
      "batch 202, gen_loss 1.592157, disc_loss 1.172784\n",
      "batch 203, gen_loss 1.517827, disc_loss 1.073379\n",
      "batch 204, gen_loss 1.493816, disc_loss 1.050689\n",
      "batch 205, gen_loss 1.477538, disc_loss 1.076595\n",
      "batch 206, gen_loss 1.534644, disc_loss 1.041050\n",
      "batch 207, gen_loss 1.717248, disc_loss 1.038756\n",
      "batch 208, gen_loss 1.678790, disc_loss 1.042606\n",
      "batch 209, gen_loss 1.569628, disc_loss 0.978034\n",
      "batch 210, gen_loss 1.557118, disc_loss 1.012809\n",
      "batch 211, gen_loss 1.501450, disc_loss 0.967663\n",
      "batch 212, gen_loss 1.522442, disc_loss 0.926925\n",
      "batch 213, gen_loss 1.600801, disc_loss 0.982793\n",
      "batch 214, gen_loss 1.459041, disc_loss 0.982498\n",
      "batch 215, gen_loss 1.629368, disc_loss 0.828434\n",
      "batch 216, gen_loss 1.670632, disc_loss 0.825403\n",
      "batch 217, gen_loss 1.665777, disc_loss 0.844899\n",
      "batch 218, gen_loss 1.621031, disc_loss 0.904315\n",
      "batch 219, gen_loss 1.675499, disc_loss 0.817391\n",
      "batch 220, gen_loss 1.593413, disc_loss 0.800664\n",
      "batch 221, gen_loss 1.563932, disc_loss 0.780590\n",
      "batch 222, gen_loss 1.830421, disc_loss 0.742280\n",
      "batch 223, gen_loss 1.696615, disc_loss 0.785904\n",
      "batch 224, gen_loss 1.814401, disc_loss 0.806367\n",
      "batch 225, gen_loss 1.695226, disc_loss 0.690501\n",
      "batch 226, gen_loss 1.811929, disc_loss 0.794364\n",
      "batch 227, gen_loss 1.597872, disc_loss 0.689026\n",
      "batch 228, gen_loss 1.621795, disc_loss 0.757998\n",
      "batch 229, gen_loss 1.707282, disc_loss 0.754157\n",
      "batch 230, gen_loss 1.806312, disc_loss 0.686598\n",
      "batch 231, gen_loss 1.963841, disc_loss 0.665110\n",
      "batch 232, gen_loss 1.931481, disc_loss 0.654565\n",
      "batch 233, gen_loss 1.769174, disc_loss 0.693349\n",
      "batch 234, gen_loss 1.735107, disc_loss 0.679494\n",
      "Time for epoch34is 7.613238573074341 sec\n",
      "batch 0, gen_loss 1.797923, disc_loss 0.621206\n",
      "batch 1, gen_loss 1.858485, disc_loss 0.555800\n",
      "batch 2, gen_loss 1.916774, disc_loss 0.603661\n",
      "batch 3, gen_loss 1.998204, disc_loss 0.624511\n",
      "batch 4, gen_loss 1.941064, disc_loss 0.598081\n",
      "batch 5, gen_loss 1.931970, disc_loss 0.572784\n",
      "batch 6, gen_loss 1.957363, disc_loss 0.545572\n",
      "batch 7, gen_loss 1.900985, disc_loss 0.645962\n",
      "batch 8, gen_loss 2.013437, disc_loss 0.551768\n",
      "batch 9, gen_loss 2.090922, disc_loss 0.610429\n",
      "batch 10, gen_loss 2.049476, disc_loss 0.549115\n",
      "batch 11, gen_loss 2.012969, disc_loss 0.573639\n",
      "batch 12, gen_loss 1.912302, disc_loss 0.576986\n",
      "batch 13, gen_loss 1.893213, disc_loss 0.499721\n",
      "batch 14, gen_loss 1.895484, disc_loss 0.568474\n",
      "batch 15, gen_loss 2.036249, disc_loss 0.576236\n",
      "batch 16, gen_loss 2.099665, disc_loss 0.527263\n",
      "batch 17, gen_loss 2.068472, disc_loss 0.575628\n",
      "batch 18, gen_loss 2.032060, disc_loss 0.510057\n",
      "batch 19, gen_loss 2.056350, disc_loss 0.532778\n",
      "batch 20, gen_loss 2.063384, disc_loss 0.587006\n",
      "batch 21, gen_loss 2.048349, disc_loss 0.620636\n",
      "batch 22, gen_loss 2.073127, disc_loss 0.535179\n",
      "batch 23, gen_loss 1.989688, disc_loss 0.527000\n",
      "batch 24, gen_loss 1.832947, disc_loss 0.532726\n",
      "batch 25, gen_loss 1.937513, disc_loss 0.555486\n",
      "batch 26, gen_loss 1.936443, disc_loss 0.582615\n",
      "batch 27, gen_loss 2.070876, disc_loss 0.600337\n",
      "batch 28, gen_loss 1.906837, disc_loss 0.554084\n",
      "batch 29, gen_loss 2.008124, disc_loss 0.619141\n",
      "batch 30, gen_loss 1.855222, disc_loss 0.587532\n",
      "batch 31, gen_loss 1.882820, disc_loss 0.636711\n",
      "batch 32, gen_loss 1.975721, disc_loss 0.579946\n",
      "batch 33, gen_loss 2.065934, disc_loss 0.534769\n",
      "batch 34, gen_loss 2.018036, disc_loss 0.617004\n",
      "batch 35, gen_loss 2.012544, disc_loss 0.605967\n",
      "batch 36, gen_loss 1.840455, disc_loss 0.651337\n",
      "batch 37, gen_loss 1.776433, disc_loss 0.657147\n",
      "batch 38, gen_loss 1.904025, disc_loss 0.637575\n",
      "batch 39, gen_loss 2.046953, disc_loss 0.686415\n",
      "batch 40, gen_loss 2.075469, disc_loss 0.630629\n",
      "batch 41, gen_loss 1.756266, disc_loss 0.684331\n",
      "batch 42, gen_loss 1.738670, disc_loss 0.639310\n",
      "batch 43, gen_loss 1.761742, disc_loss 0.691078\n",
      "batch 44, gen_loss 1.831875, disc_loss 0.748000\n",
      "batch 45, gen_loss 1.997731, disc_loss 0.604727\n",
      "batch 46, gen_loss 1.797910, disc_loss 0.697372\n",
      "batch 47, gen_loss 2.101820, disc_loss 0.687029\n",
      "batch 48, gen_loss 1.819986, disc_loss 0.619112\n",
      "batch 49, gen_loss 1.935765, disc_loss 0.628911\n",
      "batch 50, gen_loss 1.896147, disc_loss 0.625956\n",
      "batch 51, gen_loss 1.865393, disc_loss 0.647228\n",
      "batch 52, gen_loss 1.892857, disc_loss 0.735276\n",
      "batch 53, gen_loss 2.001417, disc_loss 0.653335\n",
      "batch 54, gen_loss 1.964688, disc_loss 0.706238\n",
      "batch 55, gen_loss 1.881171, disc_loss 0.710674\n",
      "batch 56, gen_loss 1.995840, disc_loss 0.640600\n",
      "batch 57, gen_loss 1.858711, disc_loss 0.696797\n",
      "batch 58, gen_loss 1.995810, disc_loss 0.625141\n",
      "batch 59, gen_loss 1.755149, disc_loss 0.649605\n",
      "batch 60, gen_loss 1.843780, disc_loss 0.686342\n",
      "batch 61, gen_loss 1.878428, disc_loss 0.676196\n",
      "batch 62, gen_loss 2.125697, disc_loss 0.692441\n",
      "batch 63, gen_loss 2.227900, disc_loss 0.673072\n",
      "batch 64, gen_loss 2.221451, disc_loss 0.689649\n",
      "batch 65, gen_loss 1.935674, disc_loss 0.756118\n",
      "batch 66, gen_loss 1.504998, disc_loss 0.753956\n",
      "batch 67, gen_loss 1.543855, disc_loss 0.789527\n",
      "batch 68, gen_loss 1.767748, disc_loss 0.781175\n",
      "batch 69, gen_loss 2.117190, disc_loss 0.794963\n",
      "batch 70, gen_loss 2.054820, disc_loss 0.763713\n",
      "batch 71, gen_loss 1.896140, disc_loss 0.788352\n",
      "batch 72, gen_loss 1.787283, disc_loss 0.781403\n",
      "batch 73, gen_loss 1.744651, disc_loss 0.821836\n",
      "batch 74, gen_loss 1.651377, disc_loss 0.757622\n",
      "batch 75, gen_loss 1.742025, disc_loss 0.836811\n",
      "batch 76, gen_loss 1.909848, disc_loss 0.808824\n",
      "batch 77, gen_loss 1.933808, disc_loss 0.744137\n",
      "batch 78, gen_loss 1.931692, disc_loss 0.866853\n",
      "batch 79, gen_loss 1.741937, disc_loss 0.848384\n",
      "batch 80, gen_loss 1.781932, disc_loss 0.875192\n",
      "batch 81, gen_loss 1.661814, disc_loss 0.852213\n",
      "batch 82, gen_loss 1.601407, disc_loss 0.807425\n",
      "batch 83, gen_loss 1.774013, disc_loss 0.933796\n",
      "batch 84, gen_loss 1.726930, disc_loss 0.930444\n",
      "batch 85, gen_loss 1.822551, disc_loss 0.971293\n",
      "batch 86, gen_loss 1.753507, disc_loss 1.015794\n",
      "batch 87, gen_loss 1.589032, disc_loss 1.021292\n",
      "batch 88, gen_loss 1.341331, disc_loss 1.062923\n",
      "batch 89, gen_loss 1.436252, disc_loss 0.917995\n",
      "batch 90, gen_loss 1.638786, disc_loss 0.959784\n",
      "batch 91, gen_loss 1.810822, disc_loss 1.061231\n",
      "batch 92, gen_loss 1.893153, disc_loss 1.056410\n",
      "batch 93, gen_loss 1.642698, disc_loss 1.051928\n",
      "batch 94, gen_loss 1.485638, disc_loss 1.080461\n",
      "batch 95, gen_loss 1.343920, disc_loss 1.047269\n",
      "batch 96, gen_loss 1.439289, disc_loss 1.076522\n",
      "batch 97, gen_loss 1.512621, disc_loss 0.982791\n",
      "batch 98, gen_loss 1.779675, disc_loss 0.950752\n",
      "batch 99, gen_loss 1.877380, disc_loss 1.050680\n",
      "batch 100, gen_loss 1.661079, disc_loss 1.017433\n",
      "batch 101, gen_loss 1.490890, disc_loss 1.056022\n",
      "batch 102, gen_loss 1.616212, disc_loss 0.919575\n",
      "batch 103, gen_loss 1.613758, disc_loss 1.006098\n",
      "batch 104, gen_loss 1.642781, disc_loss 1.004189\n",
      "batch 105, gen_loss 1.754150, disc_loss 0.938531\n",
      "batch 106, gen_loss 1.749391, disc_loss 0.834307\n",
      "batch 107, gen_loss 1.745026, disc_loss 0.918918\n",
      "batch 108, gen_loss 1.652428, disc_loss 0.887803\n",
      "batch 109, gen_loss 1.598297, disc_loss 0.809793\n",
      "batch 110, gen_loss 1.747755, disc_loss 0.816343\n",
      "batch 111, gen_loss 1.807642, disc_loss 0.830701\n",
      "batch 112, gen_loss 1.883817, disc_loss 0.806337\n",
      "batch 113, gen_loss 1.876489, disc_loss 0.894700\n",
      "batch 114, gen_loss 1.781910, disc_loss 0.909600\n",
      "batch 115, gen_loss 1.690356, disc_loss 0.813076\n",
      "batch 116, gen_loss 1.596259, disc_loss 0.814662\n",
      "batch 117, gen_loss 1.632149, disc_loss 0.788407\n",
      "batch 118, gen_loss 1.782796, disc_loss 0.730895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 119, gen_loss 2.066196, disc_loss 0.745245\n",
      "batch 120, gen_loss 2.154258, disc_loss 0.789023\n",
      "batch 121, gen_loss 1.996091, disc_loss 0.728341\n",
      "batch 122, gen_loss 2.013221, disc_loss 0.621748\n",
      "batch 123, gen_loss 1.989397, disc_loss 0.715780\n",
      "batch 124, gen_loss 1.984710, disc_loss 0.675446\n",
      "batch 125, gen_loss 2.043734, disc_loss 0.676546\n",
      "batch 126, gen_loss 2.009389, disc_loss 0.683380\n",
      "batch 127, gen_loss 2.019274, disc_loss 0.763360\n",
      "batch 128, gen_loss 2.116620, disc_loss 0.762613\n",
      "batch 129, gen_loss 2.268011, disc_loss 0.606593\n",
      "batch 130, gen_loss 2.074723, disc_loss 0.779234\n",
      "batch 131, gen_loss 2.038176, disc_loss 0.714249\n",
      "batch 132, gen_loss 2.041267, disc_loss 0.741412\n",
      "batch 133, gen_loss 2.109530, disc_loss 0.602162\n",
      "batch 134, gen_loss 2.161051, disc_loss 0.766740\n",
      "batch 135, gen_loss 2.141065, disc_loss 0.695591\n",
      "batch 136, gen_loss 2.142735, disc_loss 0.690420\n",
      "batch 137, gen_loss 2.044311, disc_loss 0.668612\n",
      "batch 138, gen_loss 2.055845, disc_loss 0.748001\n",
      "batch 139, gen_loss 1.938690, disc_loss 0.803781\n",
      "batch 140, gen_loss 2.200443, disc_loss 0.624574\n",
      "batch 141, gen_loss 2.065383, disc_loss 0.710476\n",
      "batch 142, gen_loss 2.044105, disc_loss 0.751224\n",
      "batch 143, gen_loss 2.118646, disc_loss 0.727499\n",
      "batch 144, gen_loss 2.174819, disc_loss 0.698164\n",
      "batch 145, gen_loss 1.957013, disc_loss 0.813316\n",
      "batch 146, gen_loss 2.019592, disc_loss 0.686868\n",
      "batch 147, gen_loss 1.798322, disc_loss 0.765725\n",
      "batch 148, gen_loss 1.942596, disc_loss 0.738691\n",
      "batch 149, gen_loss 1.938256, disc_loss 0.822917\n",
      "batch 150, gen_loss 1.953566, disc_loss 0.722255\n",
      "batch 151, gen_loss 2.049359, disc_loss 0.809942\n",
      "batch 152, gen_loss 2.064740, disc_loss 0.810025\n",
      "batch 153, gen_loss 2.128891, disc_loss 0.878183\n",
      "batch 154, gen_loss 1.950589, disc_loss 0.848787\n",
      "batch 155, gen_loss 1.924942, disc_loss 0.935907\n",
      "batch 156, gen_loss 1.938955, disc_loss 0.957624\n",
      "batch 157, gen_loss 1.759913, disc_loss 0.840639\n",
      "batch 158, gen_loss 1.680701, disc_loss 0.796963\n",
      "batch 159, gen_loss 1.831839, disc_loss 0.782583\n",
      "batch 160, gen_loss 1.903580, disc_loss 0.966246\n",
      "batch 161, gen_loss 1.986325, disc_loss 0.965069\n",
      "batch 162, gen_loss 1.956107, disc_loss 0.818804\n",
      "batch 163, gen_loss 1.788899, disc_loss 0.926127\n",
      "batch 164, gen_loss 1.774427, disc_loss 0.913175\n",
      "batch 165, gen_loss 1.581307, disc_loss 0.931443\n",
      "batch 166, gen_loss 1.625530, disc_loss 0.838790\n",
      "batch 167, gen_loss 1.667708, disc_loss 0.862275\n",
      "batch 168, gen_loss 1.835423, disc_loss 0.974278\n",
      "batch 169, gen_loss 1.952488, disc_loss 0.949916\n",
      "batch 170, gen_loss 1.923537, disc_loss 0.827222\n",
      "batch 171, gen_loss 1.947688, disc_loss 0.918764\n",
      "batch 172, gen_loss 1.677973, disc_loss 0.847853\n",
      "batch 173, gen_loss 1.754057, disc_loss 0.938132\n",
      "batch 174, gen_loss 1.644592, disc_loss 0.818238\n",
      "batch 175, gen_loss 1.622628, disc_loss 0.885117\n",
      "batch 176, gen_loss 1.782883, disc_loss 0.800887\n",
      "batch 177, gen_loss 1.830739, disc_loss 0.827378\n",
      "batch 178, gen_loss 1.884073, disc_loss 0.892981\n",
      "batch 179, gen_loss 1.670625, disc_loss 0.883977\n",
      "batch 180, gen_loss 1.785445, disc_loss 0.865805\n",
      "batch 181, gen_loss 1.576425, disc_loss 0.830585\n",
      "batch 182, gen_loss 1.592945, disc_loss 0.904652\n",
      "batch 183, gen_loss 1.626664, disc_loss 0.779863\n",
      "batch 184, gen_loss 1.651161, disc_loss 0.753721\n",
      "batch 185, gen_loss 1.654393, disc_loss 0.792654\n",
      "batch 186, gen_loss 1.901559, disc_loss 0.836247\n",
      "batch 187, gen_loss 1.825029, disc_loss 0.791955\n",
      "batch 188, gen_loss 1.652218, disc_loss 0.785048\n",
      "batch 189, gen_loss 1.592550, disc_loss 0.787107\n",
      "batch 190, gen_loss 1.604207, disc_loss 0.784405\n",
      "batch 191, gen_loss 1.522720, disc_loss 0.770012\n",
      "batch 192, gen_loss 1.758288, disc_loss 0.775140\n",
      "batch 193, gen_loss 1.698561, disc_loss 0.796367\n",
      "batch 194, gen_loss 1.703684, disc_loss 0.722551\n",
      "batch 195, gen_loss 1.843595, disc_loss 0.711803\n",
      "batch 196, gen_loss 1.706271, disc_loss 0.664108\n",
      "batch 197, gen_loss 1.650526, disc_loss 0.787653\n",
      "batch 198, gen_loss 1.759922, disc_loss 0.713365\n",
      "batch 199, gen_loss 1.829483, disc_loss 0.672065\n",
      "batch 200, gen_loss 1.749644, disc_loss 0.737602\n",
      "batch 201, gen_loss 1.633712, disc_loss 0.734104\n",
      "batch 202, gen_loss 1.639007, disc_loss 0.638661\n",
      "batch 203, gen_loss 1.846542, disc_loss 0.761368\n",
      "batch 204, gen_loss 1.815004, disc_loss 0.726686\n",
      "batch 205, gen_loss 1.864491, disc_loss 0.708861\n",
      "batch 206, gen_loss 1.835473, disc_loss 0.774536\n",
      "batch 207, gen_loss 1.819921, disc_loss 0.710312\n",
      "batch 208, gen_loss 1.644145, disc_loss 0.769234\n",
      "batch 209, gen_loss 1.609042, disc_loss 0.672861\n",
      "batch 210, gen_loss 1.768192, disc_loss 0.751542\n",
      "batch 211, gen_loss 1.846353, disc_loss 0.644662\n",
      "batch 212, gen_loss 1.850095, disc_loss 0.736958\n",
      "batch 213, gen_loss 1.736782, disc_loss 0.763511\n",
      "batch 214, gen_loss 1.816387, disc_loss 0.726136\n",
      "batch 215, gen_loss 1.859166, disc_loss 0.776947\n",
      "batch 216, gen_loss 1.738994, disc_loss 0.733619\n",
      "batch 217, gen_loss 1.694711, disc_loss 0.752167\n",
      "batch 218, gen_loss 1.594501, disc_loss 0.848055\n",
      "batch 219, gen_loss 1.562914, disc_loss 0.746058\n",
      "batch 220, gen_loss 1.787723, disc_loss 0.756312\n",
      "batch 221, gen_loss 1.833406, disc_loss 0.725383\n",
      "batch 222, gen_loss 1.885655, disc_loss 0.821475\n",
      "batch 223, gen_loss 1.795199, disc_loss 0.814640\n",
      "batch 224, gen_loss 1.788990, disc_loss 0.765417\n",
      "batch 225, gen_loss 1.638233, disc_loss 0.746673\n",
      "batch 226, gen_loss 1.645069, disc_loss 0.783905\n",
      "batch 227, gen_loss 1.628056, disc_loss 0.860723\n",
      "batch 228, gen_loss 1.727779, disc_loss 0.841401\n",
      "batch 229, gen_loss 1.752419, disc_loss 0.805777\n",
      "batch 230, gen_loss 1.847944, disc_loss 0.815240\n",
      "batch 231, gen_loss 2.003027, disc_loss 0.842192\n",
      "batch 232, gen_loss 1.822292, disc_loss 0.896510\n",
      "batch 233, gen_loss 1.658128, disc_loss 0.779580\n",
      "batch 234, gen_loss 1.581610, disc_loss 0.700784\n",
      "Time for epoch35is 7.621652364730835 sec\n",
      "batch 0, gen_loss 1.668597, disc_loss 0.849872\n",
      "batch 1, gen_loss 1.679548, disc_loss 0.812582\n",
      "batch 2, gen_loss 1.590927, disc_loss 0.782600\n",
      "batch 3, gen_loss 1.579263, disc_loss 0.875255\n",
      "batch 4, gen_loss 1.741573, disc_loss 0.790272\n",
      "batch 5, gen_loss 1.655607, disc_loss 0.817865\n",
      "batch 6, gen_loss 1.749041, disc_loss 0.802025\n",
      "batch 7, gen_loss 1.878154, disc_loss 0.770541\n",
      "batch 8, gen_loss 1.853233, disc_loss 0.773024\n",
      "batch 9, gen_loss 1.729441, disc_loss 0.735311\n",
      "batch 10, gen_loss 1.696687, disc_loss 0.761490\n",
      "batch 11, gen_loss 1.615160, disc_loss 0.844104\n",
      "batch 12, gen_loss 1.760549, disc_loss 0.710677\n",
      "batch 13, gen_loss 1.785711, disc_loss 0.665454\n",
      "batch 14, gen_loss 1.920663, disc_loss 0.706858\n",
      "batch 15, gen_loss 1.885808, disc_loss 0.788599\n",
      "batch 16, gen_loss 1.895457, disc_loss 0.811860\n",
      "batch 17, gen_loss 1.823074, disc_loss 0.825048\n",
      "batch 18, gen_loss 1.673716, disc_loss 0.823179\n",
      "batch 19, gen_loss 1.532505, disc_loss 0.747815\n",
      "batch 20, gen_loss 1.643460, disc_loss 0.740529\n",
      "batch 21, gen_loss 1.782796, disc_loss 0.715715\n",
      "batch 22, gen_loss 1.904717, disc_loss 0.767752\n",
      "batch 23, gen_loss 1.937123, disc_loss 0.746160\n",
      "batch 24, gen_loss 1.912350, disc_loss 0.849756\n",
      "batch 25, gen_loss 1.780766, disc_loss 0.730047\n",
      "batch 26, gen_loss 1.824817, disc_loss 0.636654\n",
      "batch 27, gen_loss 1.754866, disc_loss 0.682606\n",
      "batch 28, gen_loss 1.803626, disc_loss 0.599023\n",
      "batch 29, gen_loss 1.854185, disc_loss 0.678235\n",
      "batch 30, gen_loss 1.790284, disc_loss 0.768326\n",
      "batch 31, gen_loss 2.023122, disc_loss 0.635528\n",
      "batch 32, gen_loss 1.959647, disc_loss 0.700870\n",
      "batch 33, gen_loss 1.846127, disc_loss 0.709185\n",
      "batch 34, gen_loss 1.764528, disc_loss 0.800425\n",
      "batch 35, gen_loss 1.631938, disc_loss 0.728137\n",
      "batch 36, gen_loss 1.800844, disc_loss 0.662754\n",
      "batch 37, gen_loss 1.720900, disc_loss 0.628363\n",
      "batch 38, gen_loss 1.841162, disc_loss 0.667216\n",
      "batch 39, gen_loss 2.062552, disc_loss 0.695021\n",
      "batch 40, gen_loss 2.144350, disc_loss 0.672353\n",
      "batch 41, gen_loss 2.089657, disc_loss 0.756953\n",
      "batch 42, gen_loss 1.944786, disc_loss 0.727294\n",
      "batch 43, gen_loss 1.665237, disc_loss 0.749875\n",
      "batch 44, gen_loss 1.583517, disc_loss 0.748496\n",
      "batch 45, gen_loss 1.530418, disc_loss 0.762597\n",
      "batch 46, gen_loss 1.599753, disc_loss 0.809024\n",
      "batch 47, gen_loss 1.779752, disc_loss 0.721293\n",
      "batch 48, gen_loss 2.048816, disc_loss 0.750123\n",
      "batch 49, gen_loss 1.932226, disc_loss 0.851850\n",
      "batch 50, gen_loss 1.799833, disc_loss 0.819204\n",
      "batch 51, gen_loss 1.731799, disc_loss 0.779259\n",
      "batch 52, gen_loss 1.691410, disc_loss 0.773753\n",
      "batch 53, gen_loss 1.638821, disc_loss 0.786502\n",
      "batch 54, gen_loss 1.677835, disc_loss 0.796359\n",
      "batch 55, gen_loss 1.789739, disc_loss 0.796946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 56, gen_loss 1.786565, disc_loss 0.816177\n",
      "batch 57, gen_loss 1.745975, disc_loss 0.854184\n",
      "batch 58, gen_loss 1.792515, disc_loss 0.852386\n",
      "batch 59, gen_loss 1.685007, disc_loss 0.948031\n",
      "batch 60, gen_loss 1.740893, disc_loss 0.873273\n",
      "batch 61, gen_loss 1.562339, disc_loss 1.032306\n",
      "batch 62, gen_loss 1.520273, disc_loss 0.943608\n",
      "batch 63, gen_loss 1.509841, disc_loss 0.946286\n",
      "batch 64, gen_loss 1.469987, disc_loss 0.918635\n",
      "batch 65, gen_loss 1.732727, disc_loss 0.957646\n",
      "batch 66, gen_loss 1.758108, disc_loss 0.899930\n",
      "batch 67, gen_loss 1.800149, disc_loss 0.940822\n",
      "batch 68, gen_loss 1.723025, disc_loss 0.942078\n",
      "batch 69, gen_loss 1.447506, disc_loss 0.955812\n",
      "batch 70, gen_loss 1.354999, disc_loss 0.983685\n",
      "batch 71, gen_loss 1.418784, disc_loss 1.018200\n",
      "batch 72, gen_loss 1.463633, disc_loss 0.957471\n",
      "batch 73, gen_loss 1.576702, disc_loss 1.028805\n",
      "batch 74, gen_loss 1.718875, disc_loss 1.019488\n",
      "batch 75, gen_loss 1.539658, disc_loss 1.025389\n",
      "batch 76, gen_loss 1.431793, disc_loss 1.116917\n",
      "batch 77, gen_loss 1.430803, disc_loss 1.069456\n",
      "batch 78, gen_loss 1.324993, disc_loss 1.017787\n",
      "batch 79, gen_loss 1.438472, disc_loss 1.038142\n",
      "batch 80, gen_loss 1.621745, disc_loss 0.977943\n",
      "batch 81, gen_loss 1.629400, disc_loss 1.014897\n",
      "batch 82, gen_loss 1.522164, disc_loss 1.026489\n",
      "batch 83, gen_loss 1.372710, disc_loss 0.985101\n",
      "batch 84, gen_loss 1.389118, disc_loss 0.876830\n",
      "batch 85, gen_loss 1.406784, disc_loss 1.031836\n",
      "batch 86, gen_loss 1.487606, disc_loss 0.991226\n",
      "batch 87, gen_loss 1.663707, disc_loss 1.028494\n",
      "batch 88, gen_loss 1.561394, disc_loss 0.896343\n",
      "batch 89, gen_loss 1.505249, disc_loss 0.906402\n",
      "batch 90, gen_loss 1.379393, disc_loss 0.970645\n",
      "batch 91, gen_loss 1.557970, disc_loss 0.961244\n",
      "batch 92, gen_loss 1.467947, disc_loss 0.920950\n",
      "batch 93, gen_loss 1.431277, disc_loss 0.962211\n",
      "batch 94, gen_loss 1.715214, disc_loss 0.948555\n",
      "batch 95, gen_loss 1.659767, disc_loss 0.874414\n",
      "batch 96, gen_loss 1.483211, disc_loss 0.965926\n",
      "batch 97, gen_loss 1.529787, disc_loss 0.939288\n",
      "batch 98, gen_loss 1.353032, disc_loss 0.944824\n",
      "batch 99, gen_loss 1.473394, disc_loss 0.943863\n",
      "batch 100, gen_loss 1.686863, disc_loss 0.790407\n",
      "batch 101, gen_loss 1.791283, disc_loss 0.822997\n",
      "batch 102, gen_loss 1.712743, disc_loss 0.820223\n",
      "batch 103, gen_loss 1.672189, disc_loss 0.783536\n",
      "batch 104, gen_loss 1.626678, disc_loss 0.789620\n",
      "batch 105, gen_loss 1.628976, disc_loss 0.740563\n",
      "batch 106, gen_loss 1.638650, disc_loss 0.660554\n",
      "batch 107, gen_loss 1.815673, disc_loss 0.740521\n",
      "batch 108, gen_loss 1.724088, disc_loss 0.819031\n",
      "batch 109, gen_loss 1.880767, disc_loss 0.765582\n",
      "batch 110, gen_loss 1.717432, disc_loss 0.720290\n",
      "batch 111, gen_loss 1.796941, disc_loss 0.698719\n",
      "batch 112, gen_loss 1.496253, disc_loss 0.764729\n",
      "batch 113, gen_loss 1.476883, disc_loss 0.772059\n",
      "batch 114, gen_loss 1.696981, disc_loss 0.654191\n",
      "batch 115, gen_loss 1.976237, disc_loss 0.750334\n",
      "batch 116, gen_loss 2.179094, disc_loss 0.721886\n",
      "batch 117, gen_loss 1.966222, disc_loss 0.704453\n",
      "batch 118, gen_loss 1.754783, disc_loss 0.700605\n",
      "batch 119, gen_loss 1.515534, disc_loss 0.718878\n",
      "batch 120, gen_loss 1.485608, disc_loss 0.757082\n",
      "batch 121, gen_loss 1.666919, disc_loss 0.649609\n",
      "batch 122, gen_loss 1.824039, disc_loss 0.711692\n",
      "batch 123, gen_loss 1.907644, disc_loss 0.694532\n",
      "batch 124, gen_loss 1.983123, disc_loss 0.762557\n",
      "batch 125, gen_loss 1.717478, disc_loss 0.710969\n",
      "batch 126, gen_loss 1.714543, disc_loss 0.614263\n",
      "batch 127, gen_loss 1.674136, disc_loss 0.680771\n",
      "batch 128, gen_loss 1.724420, disc_loss 0.677056\n",
      "batch 129, gen_loss 1.844398, disc_loss 0.727524\n",
      "batch 130, gen_loss 1.852598, disc_loss 0.716250\n",
      "batch 131, gen_loss 1.728219, disc_loss 0.761153\n",
      "batch 132, gen_loss 1.760938, disc_loss 0.708806\n",
      "batch 133, gen_loss 1.671972, disc_loss 0.653308\n",
      "batch 134, gen_loss 1.652484, disc_loss 0.728203\n",
      "batch 135, gen_loss 1.645092, disc_loss 0.759399\n",
      "batch 136, gen_loss 1.599766, disc_loss 0.746288\n",
      "batch 137, gen_loss 1.591614, disc_loss 0.823587\n",
      "batch 138, gen_loss 1.746273, disc_loss 0.779396\n",
      "batch 139, gen_loss 1.720684, disc_loss 0.714833\n",
      "batch 140, gen_loss 1.731359, disc_loss 0.788291\n",
      "batch 141, gen_loss 1.699580, disc_loss 0.783788\n",
      "batch 142, gen_loss 1.560867, disc_loss 0.790833\n",
      "batch 143, gen_loss 1.402333, disc_loss 0.857390\n",
      "batch 144, gen_loss 1.594994, disc_loss 0.800034\n",
      "batch 145, gen_loss 1.692900, disc_loss 0.915070\n",
      "batch 146, gen_loss 1.673242, disc_loss 0.862953\n",
      "batch 147, gen_loss 1.541861, disc_loss 0.831241\n",
      "batch 148, gen_loss 1.569427, disc_loss 0.778302\n",
      "batch 149, gen_loss 1.592180, disc_loss 0.828308\n",
      "batch 150, gen_loss 1.651624, disc_loss 0.885952\n",
      "batch 151, gen_loss 1.609371, disc_loss 0.866677\n",
      "batch 152, gen_loss 1.527297, disc_loss 0.997241\n",
      "batch 153, gen_loss 1.489192, disc_loss 0.778316\n",
      "batch 154, gen_loss 1.457225, disc_loss 0.862935\n",
      "batch 155, gen_loss 1.606851, disc_loss 0.893995\n",
      "batch 156, gen_loss 1.712661, disc_loss 0.936207\n",
      "batch 157, gen_loss 1.625840, disc_loss 0.817664\n",
      "batch 158, gen_loss 1.578339, disc_loss 0.887910\n",
      "batch 159, gen_loss 1.388071, disc_loss 0.857057\n",
      "batch 160, gen_loss 1.457473, disc_loss 0.943922\n",
      "batch 161, gen_loss 1.693694, disc_loss 0.892819\n",
      "batch 162, gen_loss 1.579120, disc_loss 0.851542\n",
      "batch 163, gen_loss 1.634983, disc_loss 0.981412\n",
      "batch 164, gen_loss 1.504824, disc_loss 0.919783\n",
      "batch 165, gen_loss 1.322256, disc_loss 0.925751\n",
      "batch 166, gen_loss 1.349301, disc_loss 1.029629\n",
      "batch 167, gen_loss 1.426627, disc_loss 1.000783\n",
      "batch 168, gen_loss 1.432096, disc_loss 1.000917\n",
      "batch 169, gen_loss 1.550672, disc_loss 0.975460\n",
      "batch 170, gen_loss 1.527774, disc_loss 1.060302\n",
      "batch 171, gen_loss 1.564098, disc_loss 0.996056\n",
      "batch 172, gen_loss 1.430395, disc_loss 1.015540\n",
      "batch 173, gen_loss 1.454272, disc_loss 0.998734\n",
      "batch 174, gen_loss 1.242945, disc_loss 1.052598\n",
      "batch 175, gen_loss 1.403067, disc_loss 0.970393\n",
      "batch 176, gen_loss 1.522343, disc_loss 0.975191\n",
      "batch 177, gen_loss 1.596475, disc_loss 1.053139\n",
      "batch 178, gen_loss 1.627619, disc_loss 1.102190\n",
      "batch 179, gen_loss 1.529913, disc_loss 0.966584\n",
      "batch 180, gen_loss 1.466424, disc_loss 1.040443\n",
      "batch 181, gen_loss 1.440956, disc_loss 0.971516\n",
      "batch 182, gen_loss 1.429562, disc_loss 1.012673\n",
      "batch 183, gen_loss 1.325670, disc_loss 1.056542\n",
      "batch 184, gen_loss 1.367240, disc_loss 0.990687\n",
      "batch 185, gen_loss 1.522499, disc_loss 1.022840\n",
      "batch 186, gen_loss 1.677296, disc_loss 1.014649\n",
      "batch 187, gen_loss 1.652943, disc_loss 0.958403\n",
      "batch 188, gen_loss 1.629628, disc_loss 0.982915\n",
      "batch 189, gen_loss 1.415946, disc_loss 0.972801\n",
      "batch 190, gen_loss 1.417998, disc_loss 0.914132\n",
      "batch 191, gen_loss 1.430173, disc_loss 0.952202\n",
      "batch 192, gen_loss 1.572584, disc_loss 0.974402\n",
      "batch 193, gen_loss 1.569465, disc_loss 0.961892\n",
      "batch 194, gen_loss 1.682026, disc_loss 0.932034\n",
      "batch 195, gen_loss 1.733365, disc_loss 0.918709\n",
      "batch 196, gen_loss 1.606856, disc_loss 0.865003\n",
      "batch 197, gen_loss 1.441583, disc_loss 0.950346\n",
      "batch 198, gen_loss 1.340268, disc_loss 0.860251\n",
      "batch 199, gen_loss 1.604035, disc_loss 0.774577\n",
      "batch 200, gen_loss 1.748082, disc_loss 0.842642\n",
      "batch 201, gen_loss 1.864975, disc_loss 0.905126\n",
      "batch 202, gen_loss 1.828001, disc_loss 0.836410\n",
      "batch 203, gen_loss 1.787465, disc_loss 0.686251\n",
      "batch 204, gen_loss 1.645392, disc_loss 0.661640\n",
      "batch 205, gen_loss 1.635924, disc_loss 0.711253\n",
      "batch 206, gen_loss 1.725703, disc_loss 0.824814\n",
      "batch 207, gen_loss 1.756036, disc_loss 0.691984\n",
      "batch 208, gen_loss 1.729282, disc_loss 0.711155\n",
      "batch 209, gen_loss 1.981578, disc_loss 0.682471\n",
      "batch 210, gen_loss 1.877585, disc_loss 0.815125\n",
      "batch 211, gen_loss 1.795032, disc_loss 0.665008\n",
      "batch 212, gen_loss 1.837899, disc_loss 0.679496\n",
      "batch 213, gen_loss 1.773684, disc_loss 0.663274\n",
      "batch 214, gen_loss 1.842954, disc_loss 0.668913\n",
      "batch 215, gen_loss 1.810193, disc_loss 0.674654\n",
      "batch 216, gen_loss 1.879978, disc_loss 0.605590\n",
      "batch 217, gen_loss 1.971406, disc_loss 0.580350\n",
      "batch 218, gen_loss 2.017288, disc_loss 0.542795\n",
      "batch 219, gen_loss 2.056373, disc_loss 0.557564\n",
      "batch 220, gen_loss 2.010050, disc_loss 0.623357\n",
      "batch 221, gen_loss 1.914745, disc_loss 0.583148\n",
      "batch 222, gen_loss 1.898905, disc_loss 0.558954\n",
      "batch 223, gen_loss 1.961287, disc_loss 0.627222\n",
      "batch 224, gen_loss 2.029366, disc_loss 0.540493\n",
      "batch 225, gen_loss 2.121167, disc_loss 0.522383\n",
      "batch 226, gen_loss 2.197261, disc_loss 0.608889\n",
      "batch 227, gen_loss 2.163167, disc_loss 0.553008\n",
      "batch 228, gen_loss 1.898339, disc_loss 0.577113\n",
      "batch 229, gen_loss 1.911027, disc_loss 0.601126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 230, gen_loss 1.836005, disc_loss 0.602373\n",
      "batch 231, gen_loss 1.839378, disc_loss 0.581927\n",
      "batch 232, gen_loss 2.110402, disc_loss 0.526529\n",
      "batch 233, gen_loss 2.156343, disc_loss 0.602046\n",
      "batch 234, gen_loss 2.124528, disc_loss 0.507906\n",
      "Time for epoch36is 7.671003580093384 sec\n",
      "batch 0, gen_loss 1.961965, disc_loss 0.598862\n",
      "batch 1, gen_loss 2.080818, disc_loss 0.556246\n",
      "batch 2, gen_loss 1.937959, disc_loss 0.557988\n",
      "batch 3, gen_loss 2.022247, disc_loss 0.553993\n",
      "batch 4, gen_loss 1.975150, disc_loss 0.469046\n",
      "batch 5, gen_loss 2.051693, disc_loss 0.482057\n",
      "batch 6, gen_loss 1.972308, disc_loss 0.582594\n",
      "batch 7, gen_loss 2.202536, disc_loss 0.574546\n",
      "batch 8, gen_loss 2.015664, disc_loss 0.590470\n",
      "batch 9, gen_loss 2.140675, disc_loss 0.545325\n",
      "batch 10, gen_loss 1.991636, disc_loss 0.526465\n",
      "batch 11, gen_loss 1.988319, disc_loss 0.578108\n",
      "batch 12, gen_loss 1.931489, disc_loss 0.592632\n",
      "batch 13, gen_loss 1.825145, disc_loss 0.573404\n",
      "batch 14, gen_loss 1.816093, disc_loss 0.557604\n",
      "batch 15, gen_loss 2.010258, disc_loss 0.547169\n",
      "batch 16, gen_loss 1.980080, disc_loss 0.682417\n",
      "batch 17, gen_loss 2.013751, disc_loss 0.657178\n",
      "batch 18, gen_loss 2.049471, disc_loss 0.669911\n",
      "batch 19, gen_loss 1.899675, disc_loss 0.721921\n",
      "batch 20, gen_loss 1.581532, disc_loss 0.677714\n",
      "batch 21, gen_loss 1.669198, disc_loss 0.697856\n",
      "batch 22, gen_loss 1.710334, disc_loss 0.712366\n",
      "batch 23, gen_loss 1.798802, disc_loss 0.745755\n",
      "batch 24, gen_loss 1.872921, disc_loss 0.666908\n",
      "batch 25, gen_loss 1.863228, disc_loss 0.683687\n",
      "batch 26, gen_loss 2.035962, disc_loss 0.661479\n",
      "batch 27, gen_loss 1.784078, disc_loss 0.708877\n",
      "batch 28, gen_loss 1.611219, disc_loss 0.816672\n",
      "batch 29, gen_loss 1.576691, disc_loss 0.720679\n",
      "batch 30, gen_loss 1.498559, disc_loss 0.767796\n",
      "batch 31, gen_loss 1.706767, disc_loss 0.797046\n",
      "batch 32, gen_loss 1.838055, disc_loss 0.671171\n",
      "batch 33, gen_loss 1.825249, disc_loss 0.746444\n",
      "batch 34, gen_loss 1.910111, disc_loss 0.871776\n",
      "batch 35, gen_loss 1.678976, disc_loss 0.757755\n",
      "batch 36, gen_loss 1.536872, disc_loss 0.754318\n",
      "batch 37, gen_loss 1.496862, disc_loss 0.783420\n",
      "batch 38, gen_loss 1.552446, disc_loss 0.786075\n",
      "batch 39, gen_loss 1.652136, disc_loss 0.795616\n",
      "batch 40, gen_loss 1.782878, disc_loss 0.884047\n",
      "batch 41, gen_loss 1.643513, disc_loss 0.815350\n",
      "batch 42, gen_loss 1.664745, disc_loss 0.779000\n",
      "batch 43, gen_loss 1.702313, disc_loss 0.829657\n",
      "batch 44, gen_loss 1.683334, disc_loss 0.783380\n",
      "batch 45, gen_loss 1.559012, disc_loss 0.897773\n",
      "batch 46, gen_loss 1.420400, disc_loss 0.822077\n",
      "batch 47, gen_loss 1.599620, disc_loss 0.852077\n",
      "batch 48, gen_loss 1.497816, disc_loss 0.837385\n",
      "batch 49, gen_loss 1.708881, disc_loss 0.788610\n",
      "batch 50, gen_loss 1.756255, disc_loss 0.880981\n",
      "batch 51, gen_loss 1.759969, disc_loss 0.897554\n",
      "batch 52, gen_loss 1.752264, disc_loss 0.787473\n",
      "batch 53, gen_loss 1.614815, disc_loss 0.795916\n",
      "batch 54, gen_loss 1.441746, disc_loss 0.835578\n",
      "batch 55, gen_loss 1.526423, disc_loss 0.895996\n",
      "batch 56, gen_loss 1.577552, disc_loss 0.810309\n",
      "batch 57, gen_loss 1.778978, disc_loss 0.814239\n",
      "batch 58, gen_loss 1.704826, disc_loss 0.855340\n",
      "batch 59, gen_loss 1.741133, disc_loss 0.822937\n",
      "batch 60, gen_loss 1.705075, disc_loss 0.830035\n",
      "batch 61, gen_loss 1.549799, disc_loss 0.960473\n",
      "batch 62, gen_loss 1.394421, disc_loss 0.862226\n",
      "batch 63, gen_loss 1.443217, disc_loss 0.894258\n",
      "batch 64, gen_loss 1.508727, disc_loss 0.863685\n",
      "batch 65, gen_loss 1.685010, disc_loss 0.855910\n",
      "batch 66, gen_loss 1.810507, disc_loss 0.763068\n",
      "batch 67, gen_loss 1.794395, disc_loss 0.855237\n",
      "batch 68, gen_loss 1.770234, disc_loss 0.860744\n",
      "batch 69, gen_loss 1.668170, disc_loss 0.743756\n",
      "batch 70, gen_loss 1.689456, disc_loss 0.872751\n",
      "batch 71, gen_loss 1.501608, disc_loss 0.874430\n",
      "batch 72, gen_loss 1.606690, disc_loss 0.765638\n",
      "batch 73, gen_loss 1.672414, disc_loss 0.824353\n",
      "batch 74, gen_loss 1.844192, disc_loss 0.806021\n",
      "batch 75, gen_loss 1.749035, disc_loss 0.841090\n",
      "batch 76, gen_loss 1.735070, disc_loss 0.854198\n",
      "batch 77, gen_loss 1.718040, disc_loss 0.822785\n",
      "batch 78, gen_loss 1.637454, disc_loss 0.743996\n",
      "batch 79, gen_loss 1.546473, disc_loss 0.802777\n",
      "batch 80, gen_loss 1.546048, disc_loss 0.813719\n",
      "batch 81, gen_loss 1.621720, disc_loss 0.760815\n",
      "batch 82, gen_loss 1.676060, disc_loss 0.762060\n",
      "batch 83, gen_loss 1.892249, disc_loss 0.699582\n",
      "batch 84, gen_loss 1.953497, disc_loss 0.808804\n",
      "batch 85, gen_loss 2.005319, disc_loss 0.728358\n",
      "batch 86, gen_loss 1.781319, disc_loss 0.670452\n",
      "batch 87, gen_loss 1.537065, disc_loss 0.713988\n",
      "batch 88, gen_loss 1.547213, disc_loss 0.693728\n",
      "batch 89, gen_loss 1.566332, disc_loss 0.761531\n",
      "batch 90, gen_loss 1.787843, disc_loss 0.693801\n",
      "batch 91, gen_loss 1.863128, disc_loss 0.806043\n",
      "batch 92, gen_loss 1.878788, disc_loss 0.752008\n",
      "batch 93, gen_loss 1.755478, disc_loss 0.713101\n",
      "batch 94, gen_loss 1.743160, disc_loss 0.752463\n",
      "batch 95, gen_loss 1.634226, disc_loss 0.731581\n",
      "batch 96, gen_loss 1.577756, disc_loss 0.747081\n",
      "batch 97, gen_loss 1.564421, disc_loss 0.813115\n",
      "batch 98, gen_loss 1.600893, disc_loss 0.684213\n",
      "batch 99, gen_loss 1.781642, disc_loss 0.705469\n",
      "batch 100, gen_loss 1.839532, disc_loss 0.734245\n",
      "batch 101, gen_loss 1.769710, disc_loss 0.762115\n",
      "batch 102, gen_loss 1.786837, disc_loss 0.704943\n",
      "batch 103, gen_loss 1.537554, disc_loss 0.797944\n",
      "batch 104, gen_loss 1.560155, disc_loss 0.772371\n",
      "batch 105, gen_loss 1.541053, disc_loss 0.761952\n",
      "batch 106, gen_loss 1.500980, disc_loss 0.757397\n",
      "batch 107, gen_loss 1.621544, disc_loss 0.840180\n",
      "batch 108, gen_loss 1.633331, disc_loss 0.761869\n",
      "batch 109, gen_loss 1.736875, disc_loss 0.710688\n",
      "batch 110, gen_loss 1.734216, disc_loss 0.783859\n",
      "batch 111, gen_loss 1.720630, disc_loss 0.774564\n",
      "batch 112, gen_loss 1.695587, disc_loss 0.837637\n",
      "batch 113, gen_loss 1.665506, disc_loss 0.821223\n",
      "batch 114, gen_loss 1.430091, disc_loss 0.761266\n",
      "batch 115, gen_loss 1.399013, disc_loss 0.843303\n",
      "batch 116, gen_loss 1.411106, disc_loss 0.854570\n",
      "batch 117, gen_loss 1.644164, disc_loss 0.900048\n",
      "batch 118, gen_loss 1.786108, disc_loss 0.881155\n",
      "batch 119, gen_loss 1.713026, disc_loss 0.813399\n",
      "batch 120, gen_loss 1.620928, disc_loss 0.861635\n",
      "batch 121, gen_loss 1.489693, disc_loss 0.844274\n",
      "batch 122, gen_loss 1.363731, disc_loss 0.824371\n",
      "batch 123, gen_loss 1.506261, disc_loss 0.862885\n",
      "batch 124, gen_loss 1.472999, disc_loss 0.930845\n",
      "batch 125, gen_loss 1.759109, disc_loss 0.873786\n",
      "batch 126, gen_loss 1.728341, disc_loss 0.813421\n",
      "batch 127, gen_loss 1.579608, disc_loss 1.030082\n",
      "batch 128, gen_loss 1.532238, disc_loss 0.948845\n",
      "batch 129, gen_loss 1.540526, disc_loss 0.866489\n",
      "batch 130, gen_loss 1.413373, disc_loss 0.987480\n",
      "batch 131, gen_loss 1.459912, disc_loss 0.930283\n",
      "batch 132, gen_loss 1.557552, disc_loss 0.892937\n",
      "batch 133, gen_loss 1.470014, disc_loss 0.897860\n",
      "batch 134, gen_loss 1.672435, disc_loss 0.955702\n",
      "batch 135, gen_loss 1.628177, disc_loss 0.992991\n",
      "batch 136, gen_loss 1.611636, disc_loss 1.009493\n",
      "batch 137, gen_loss 1.519757, disc_loss 0.924925\n",
      "batch 138, gen_loss 1.272931, disc_loss 0.942051\n",
      "batch 139, gen_loss 1.362208, disc_loss 0.952470\n",
      "batch 140, gen_loss 1.510168, disc_loss 0.964716\n",
      "batch 141, gen_loss 1.668524, disc_loss 0.866805\n",
      "batch 142, gen_loss 1.757065, disc_loss 0.880273\n",
      "batch 143, gen_loss 1.635396, disc_loss 0.933790\n",
      "batch 144, gen_loss 1.637811, disc_loss 0.914760\n",
      "batch 145, gen_loss 1.563140, disc_loss 1.000805\n",
      "batch 146, gen_loss 1.375751, disc_loss 0.913298\n",
      "batch 147, gen_loss 1.413179, disc_loss 0.963299\n",
      "batch 148, gen_loss 1.443538, disc_loss 0.995660\n",
      "batch 149, gen_loss 1.424480, disc_loss 0.996384\n",
      "batch 150, gen_loss 1.508228, disc_loss 0.903581\n",
      "batch 151, gen_loss 1.772495, disc_loss 0.830324\n",
      "batch 152, gen_loss 1.872797, disc_loss 0.872428\n",
      "batch 153, gen_loss 1.661302, disc_loss 0.954717\n",
      "batch 154, gen_loss 1.585671, disc_loss 0.908171\n",
      "batch 155, gen_loss 1.272448, disc_loss 1.009060\n",
      "batch 156, gen_loss 1.315269, disc_loss 0.949751\n",
      "batch 157, gen_loss 1.395236, disc_loss 0.950908\n",
      "batch 158, gen_loss 1.630511, disc_loss 0.871603\n",
      "batch 159, gen_loss 1.716259, disc_loss 0.867692\n",
      "batch 160, gen_loss 1.782302, disc_loss 0.966902\n",
      "batch 161, gen_loss 1.747003, disc_loss 0.910165\n",
      "batch 162, gen_loss 1.584858, disc_loss 0.861081\n",
      "batch 163, gen_loss 1.403531, disc_loss 0.922976\n",
      "batch 164, gen_loss 1.421321, disc_loss 0.809347\n",
      "batch 165, gen_loss 1.485085, disc_loss 0.921671\n",
      "batch 166, gen_loss 1.743313, disc_loss 0.891130\n",
      "batch 167, gen_loss 1.602724, disc_loss 0.837781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 168, gen_loss 1.639167, disc_loss 0.849362\n",
      "batch 169, gen_loss 1.694825, disc_loss 0.812811\n",
      "batch 170, gen_loss 1.633831, disc_loss 0.870314\n",
      "batch 171, gen_loss 1.527211, disc_loss 0.807749\n",
      "batch 172, gen_loss 1.556468, disc_loss 0.815264\n",
      "batch 173, gen_loss 1.554967, disc_loss 0.863010\n",
      "batch 174, gen_loss 1.583770, disc_loss 0.799951\n",
      "batch 175, gen_loss 1.509652, disc_loss 0.807099\n",
      "batch 176, gen_loss 1.706283, disc_loss 0.710203\n",
      "batch 177, gen_loss 1.756871, disc_loss 0.851865\n",
      "batch 178, gen_loss 1.841710, disc_loss 0.693287\n",
      "batch 179, gen_loss 1.792654, disc_loss 0.699216\n",
      "batch 180, gen_loss 1.701629, disc_loss 0.790898\n",
      "batch 181, gen_loss 1.646478, disc_loss 0.733466\n",
      "batch 182, gen_loss 1.511280, disc_loss 0.742931\n",
      "batch 183, gen_loss 1.587959, disc_loss 0.732592\n",
      "batch 184, gen_loss 1.598945, disc_loss 0.777638\n",
      "batch 185, gen_loss 1.653201, disc_loss 0.813662\n",
      "batch 186, gen_loss 1.759459, disc_loss 0.784487\n",
      "batch 187, gen_loss 1.712369, disc_loss 0.698948\n",
      "batch 188, gen_loss 1.542399, disc_loss 0.838649\n",
      "batch 189, gen_loss 1.687986, disc_loss 0.735434\n",
      "batch 190, gen_loss 1.605561, disc_loss 0.891815\n",
      "batch 191, gen_loss 1.594126, disc_loss 0.909293\n",
      "batch 192, gen_loss 1.601465, disc_loss 0.818061\n",
      "batch 193, gen_loss 1.443075, disc_loss 0.858671\n",
      "batch 194, gen_loss 1.551792, disc_loss 0.857859\n",
      "batch 195, gen_loss 1.638785, disc_loss 0.776614\n",
      "batch 196, gen_loss 1.580464, disc_loss 0.837718\n",
      "batch 197, gen_loss 1.625169, disc_loss 0.807885\n",
      "batch 198, gen_loss 1.641302, disc_loss 0.754822\n",
      "batch 199, gen_loss 1.599527, disc_loss 0.755501\n",
      "batch 200, gen_loss 1.757278, disc_loss 0.829998\n",
      "batch 201, gen_loss 1.781660, disc_loss 0.782315\n",
      "batch 202, gen_loss 1.537846, disc_loss 0.818578\n",
      "batch 203, gen_loss 1.552999, disc_loss 0.861129\n",
      "batch 204, gen_loss 1.499419, disc_loss 0.897761\n",
      "batch 205, gen_loss 1.456620, disc_loss 0.914222\n",
      "batch 206, gen_loss 1.563995, disc_loss 0.823591\n",
      "batch 207, gen_loss 1.609273, disc_loss 0.938322\n",
      "batch 208, gen_loss 1.663138, disc_loss 0.837612\n",
      "batch 209, gen_loss 1.494677, disc_loss 0.835171\n",
      "batch 210, gen_loss 1.552278, disc_loss 0.856791\n",
      "batch 211, gen_loss 1.516809, disc_loss 0.883479\n",
      "batch 212, gen_loss 1.476792, disc_loss 0.931883\n",
      "batch 213, gen_loss 1.604404, disc_loss 0.828520\n",
      "batch 214, gen_loss 1.596950, disc_loss 0.826730\n",
      "batch 215, gen_loss 1.561725, disc_loss 0.931097\n",
      "batch 216, gen_loss 1.585370, disc_loss 0.911965\n",
      "batch 217, gen_loss 1.417780, disc_loss 0.946582\n",
      "batch 218, gen_loss 1.497744, disc_loss 0.873555\n",
      "batch 219, gen_loss 1.564530, disc_loss 0.935287\n",
      "batch 220, gen_loss 1.497379, disc_loss 0.892634\n",
      "batch 221, gen_loss 1.527099, disc_loss 0.845909\n",
      "batch 222, gen_loss 1.652216, disc_loss 0.855442\n",
      "batch 223, gen_loss 1.637145, disc_loss 0.883543\n",
      "batch 224, gen_loss 1.641991, disc_loss 0.782043\n",
      "batch 225, gen_loss 1.485291, disc_loss 0.888698\n",
      "batch 226, gen_loss 1.553369, disc_loss 0.858325\n",
      "batch 227, gen_loss 1.659828, disc_loss 0.949400\n",
      "batch 228, gen_loss 1.594985, disc_loss 0.896374\n",
      "batch 229, gen_loss 1.484299, disc_loss 0.912253\n",
      "batch 230, gen_loss 1.420089, disc_loss 0.828139\n",
      "batch 231, gen_loss 1.553368, disc_loss 0.923866\n",
      "batch 232, gen_loss 1.666506, disc_loss 0.897115\n",
      "batch 233, gen_loss 1.563376, disc_loss 0.831305\n",
      "batch 234, gen_loss 1.615444, disc_loss 0.885389\n",
      "Time for epoch37is 7.610297679901123 sec\n",
      "batch 0, gen_loss 1.511164, disc_loss 0.867674\n",
      "batch 1, gen_loss 1.481278, disc_loss 0.798242\n",
      "batch 2, gen_loss 1.526612, disc_loss 0.846689\n",
      "batch 3, gen_loss 1.760130, disc_loss 0.811707\n",
      "batch 4, gen_loss 1.634378, disc_loss 0.850003\n",
      "batch 5, gen_loss 1.415855, disc_loss 0.813668\n",
      "batch 6, gen_loss 1.509501, disc_loss 0.867213\n",
      "batch 7, gen_loss 1.475638, disc_loss 0.811045\n",
      "batch 8, gen_loss 1.579547, disc_loss 0.843832\n",
      "batch 9, gen_loss 1.709839, disc_loss 0.775050\n",
      "batch 10, gen_loss 1.839303, disc_loss 0.747642\n",
      "batch 11, gen_loss 1.551598, disc_loss 0.741479\n",
      "batch 12, gen_loss 1.537258, disc_loss 0.742977\n",
      "batch 13, gen_loss 1.389519, disc_loss 0.790496\n",
      "batch 14, gen_loss 1.627151, disc_loss 0.733466\n",
      "batch 15, gen_loss 1.720132, disc_loss 0.710519\n",
      "batch 16, gen_loss 1.841426, disc_loss 0.808396\n",
      "batch 17, gen_loss 1.582330, disc_loss 0.745209\n",
      "batch 18, gen_loss 1.511800, disc_loss 0.810673\n",
      "batch 19, gen_loss 1.520532, disc_loss 0.727979\n",
      "batch 20, gen_loss 1.504091, disc_loss 0.789647\n",
      "batch 21, gen_loss 1.654782, disc_loss 0.722658\n",
      "batch 22, gen_loss 1.782705, disc_loss 0.734406\n",
      "batch 23, gen_loss 1.767463, disc_loss 0.717910\n",
      "batch 24, gen_loss 1.727249, disc_loss 0.676114\n",
      "batch 25, gen_loss 1.708310, disc_loss 0.655231\n",
      "batch 26, gen_loss 1.539571, disc_loss 0.768046\n",
      "batch 27, gen_loss 1.619116, disc_loss 0.709818\n",
      "batch 28, gen_loss 1.643241, disc_loss 0.698304\n",
      "batch 29, gen_loss 1.892682, disc_loss 0.666485\n",
      "batch 30, gen_loss 1.858513, disc_loss 0.733700\n",
      "batch 31, gen_loss 1.833389, disc_loss 0.719944\n",
      "batch 32, gen_loss 1.547088, disc_loss 0.726325\n",
      "batch 33, gen_loss 1.456848, disc_loss 0.668102\n",
      "batch 34, gen_loss 1.622205, disc_loss 0.729149\n",
      "batch 35, gen_loss 1.901378, disc_loss 0.613383\n",
      "batch 36, gen_loss 1.890715, disc_loss 0.686983\n",
      "batch 37, gen_loss 1.861825, disc_loss 0.692201\n",
      "batch 38, gen_loss 1.845181, disc_loss 0.716554\n",
      "batch 39, gen_loss 1.908378, disc_loss 0.691363\n",
      "batch 40, gen_loss 1.746475, disc_loss 0.688285\n",
      "batch 41, gen_loss 1.483479, disc_loss 0.707831\n",
      "batch 42, gen_loss 1.535337, disc_loss 0.717990\n",
      "batch 43, gen_loss 1.658272, disc_loss 0.785503\n",
      "batch 44, gen_loss 1.870654, disc_loss 0.706833\n",
      "batch 45, gen_loss 1.967296, disc_loss 0.646072\n",
      "batch 46, gen_loss 1.953218, disc_loss 0.720321\n",
      "batch 47, gen_loss 1.740239, disc_loss 0.736152\n",
      "batch 48, gen_loss 1.522205, disc_loss 0.695143\n",
      "batch 49, gen_loss 1.575767, disc_loss 0.701355\n",
      "batch 50, gen_loss 1.490491, disc_loss 0.739591\n",
      "batch 51, gen_loss 1.649567, disc_loss 0.720997\n",
      "batch 52, gen_loss 1.906384, disc_loss 0.697391\n",
      "batch 53, gen_loss 2.033300, disc_loss 0.767322\n",
      "batch 54, gen_loss 2.031502, disc_loss 0.690089\n",
      "batch 55, gen_loss 1.671432, disc_loss 0.747010\n",
      "batch 56, gen_loss 1.647868, disc_loss 0.696852\n",
      "batch 57, gen_loss 1.495791, disc_loss 0.769196\n",
      "batch 58, gen_loss 1.547495, disc_loss 0.691724\n",
      "batch 59, gen_loss 1.685309, disc_loss 0.792276\n",
      "batch 60, gen_loss 1.947396, disc_loss 0.825653\n",
      "batch 61, gen_loss 1.870126, disc_loss 0.757219\n",
      "batch 62, gen_loss 1.657501, disc_loss 0.794148\n",
      "batch 63, gen_loss 1.499378, disc_loss 0.765242\n",
      "batch 64, gen_loss 1.448257, disc_loss 0.831009\n",
      "batch 65, gen_loss 1.508031, disc_loss 0.804268\n",
      "batch 66, gen_loss 1.635927, disc_loss 0.760736\n",
      "batch 67, gen_loss 1.796327, disc_loss 0.823173\n",
      "batch 68, gen_loss 1.830340, disc_loss 0.733620\n",
      "batch 69, gen_loss 1.783788, disc_loss 0.847364\n",
      "batch 70, gen_loss 1.585400, disc_loss 0.821200\n",
      "batch 71, gen_loss 1.535973, disc_loss 0.767750\n",
      "batch 72, gen_loss 1.448875, disc_loss 0.815652\n",
      "batch 73, gen_loss 1.503314, disc_loss 0.799867\n",
      "batch 74, gen_loss 1.597999, disc_loss 0.772296\n",
      "batch 75, gen_loss 1.695593, disc_loss 0.878814\n",
      "batch 76, gen_loss 1.731403, disc_loss 0.835497\n",
      "batch 77, gen_loss 1.596173, disc_loss 0.945053\n",
      "batch 78, gen_loss 1.484412, disc_loss 0.870385\n",
      "batch 79, gen_loss 1.463362, disc_loss 0.801291\n",
      "batch 80, gen_loss 1.417700, disc_loss 0.853734\n",
      "batch 81, gen_loss 1.488514, disc_loss 0.871290\n",
      "batch 82, gen_loss 1.605885, disc_loss 0.904977\n",
      "batch 83, gen_loss 1.627095, disc_loss 0.808895\n",
      "batch 84, gen_loss 1.638406, disc_loss 0.923196\n",
      "batch 85, gen_loss 1.516562, disc_loss 1.016734\n",
      "batch 86, gen_loss 1.488414, disc_loss 0.847741\n",
      "batch 87, gen_loss 1.396468, disc_loss 0.944441\n",
      "batch 88, gen_loss 1.301184, disc_loss 1.000444\n",
      "batch 89, gen_loss 1.439255, disc_loss 0.880038\n",
      "batch 90, gen_loss 1.581947, disc_loss 0.922802\n",
      "batch 91, gen_loss 1.654029, disc_loss 0.885720\n",
      "batch 92, gen_loss 1.457234, disc_loss 0.957338\n",
      "batch 93, gen_loss 1.518866, disc_loss 0.903314\n",
      "batch 94, gen_loss 1.446625, disc_loss 0.954983\n",
      "batch 95, gen_loss 1.441743, disc_loss 0.918298\n",
      "batch 96, gen_loss 1.449394, disc_loss 0.859045\n",
      "batch 97, gen_loss 1.473441, disc_loss 0.908482\n",
      "batch 98, gen_loss 1.488713, disc_loss 0.999804\n",
      "batch 99, gen_loss 1.621669, disc_loss 0.888356\n",
      "batch 100, gen_loss 1.565284, disc_loss 0.970133\n",
      "batch 101, gen_loss 1.456954, disc_loss 0.956795\n",
      "batch 102, gen_loss 1.394834, disc_loss 0.989296\n",
      "batch 103, gen_loss 1.310988, disc_loss 1.027459\n",
      "batch 104, gen_loss 1.294599, disc_loss 1.045074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 105, gen_loss 1.315687, disc_loss 1.030827\n",
      "batch 106, gen_loss 1.614284, disc_loss 0.826620\n",
      "batch 107, gen_loss 1.559675, disc_loss 1.009682\n",
      "batch 108, gen_loss 1.531147, disc_loss 0.974273\n",
      "batch 109, gen_loss 1.518770, disc_loss 0.989126\n",
      "batch 110, gen_loss 1.426905, disc_loss 0.966553\n",
      "batch 111, gen_loss 1.461503, disc_loss 0.839580\n",
      "batch 112, gen_loss 1.361921, disc_loss 1.020030\n",
      "batch 113, gen_loss 1.369498, disc_loss 1.038583\n",
      "batch 114, gen_loss 1.389721, disc_loss 1.009378\n",
      "batch 115, gen_loss 1.488663, disc_loss 0.966423\n",
      "batch 116, gen_loss 1.542332, disc_loss 1.007084\n",
      "batch 117, gen_loss 1.333165, disc_loss 1.000730\n",
      "batch 118, gen_loss 1.388489, disc_loss 1.040651\n",
      "batch 119, gen_loss 1.341887, disc_loss 1.044769\n",
      "batch 120, gen_loss 1.373141, disc_loss 0.907389\n",
      "batch 121, gen_loss 1.339664, disc_loss 1.034347\n",
      "batch 122, gen_loss 1.446041, disc_loss 0.919924\n",
      "batch 123, gen_loss 1.480847, disc_loss 0.955512\n",
      "batch 124, gen_loss 1.425568, disc_loss 1.054589\n",
      "batch 125, gen_loss 1.389769, disc_loss 0.971270\n",
      "batch 126, gen_loss 1.376670, disc_loss 0.941673\n",
      "batch 127, gen_loss 1.327486, disc_loss 1.009939\n",
      "batch 128, gen_loss 1.290797, disc_loss 1.015261\n",
      "batch 129, gen_loss 1.301431, disc_loss 0.964946\n",
      "batch 130, gen_loss 1.365168, disc_loss 0.925965\n",
      "batch 131, gen_loss 1.487188, disc_loss 0.892423\n",
      "batch 132, gen_loss 1.558720, disc_loss 0.963980\n",
      "batch 133, gen_loss 1.559790, disc_loss 0.873866\n",
      "batch 134, gen_loss 1.611302, disc_loss 0.912434\n",
      "batch 135, gen_loss 1.456113, disc_loss 0.902405\n",
      "batch 136, gen_loss 1.356059, disc_loss 0.974978\n",
      "batch 137, gen_loss 1.362447, disc_loss 0.938369\n",
      "batch 138, gen_loss 1.407176, disc_loss 0.950861\n",
      "batch 139, gen_loss 1.512312, disc_loss 0.937575\n",
      "batch 140, gen_loss 1.611868, disc_loss 0.879018\n",
      "batch 141, gen_loss 1.525234, disc_loss 0.967817\n",
      "batch 142, gen_loss 1.481790, disc_loss 0.908938\n",
      "batch 143, gen_loss 1.374633, disc_loss 0.969293\n",
      "batch 144, gen_loss 1.352149, disc_loss 0.908976\n",
      "batch 145, gen_loss 1.440458, disc_loss 0.880085\n",
      "batch 146, gen_loss 1.454329, disc_loss 0.911784\n",
      "batch 147, gen_loss 1.485576, disc_loss 0.948211\n",
      "batch 148, gen_loss 1.525787, disc_loss 0.955945\n",
      "batch 149, gen_loss 1.358333, disc_loss 0.931480\n",
      "batch 150, gen_loss 1.416793, disc_loss 0.981484\n",
      "batch 151, gen_loss 1.364530, disc_loss 1.017655\n",
      "batch 152, gen_loss 1.413555, disc_loss 0.899639\n",
      "batch 153, gen_loss 1.366297, disc_loss 1.033777\n",
      "batch 154, gen_loss 1.403871, disc_loss 1.004914\n",
      "batch 155, gen_loss 1.585334, disc_loss 0.989032\n",
      "batch 156, gen_loss 1.532121, disc_loss 0.870403\n",
      "batch 157, gen_loss 1.425395, disc_loss 0.930796\n",
      "batch 158, gen_loss 1.485702, disc_loss 0.893960\n",
      "batch 159, gen_loss 1.527959, disc_loss 0.883273\n",
      "batch 160, gen_loss 1.505398, disc_loss 0.969689\n",
      "batch 161, gen_loss 1.430277, disc_loss 0.953739\n",
      "batch 162, gen_loss 1.457900, disc_loss 0.912387\n",
      "batch 163, gen_loss 1.457909, disc_loss 0.855726\n",
      "batch 164, gen_loss 1.431062, disc_loss 0.873913\n",
      "batch 165, gen_loss 1.468962, disc_loss 0.915536\n",
      "batch 166, gen_loss 1.477540, disc_loss 0.928349\n",
      "batch 167, gen_loss 1.541679, disc_loss 0.909709\n",
      "batch 168, gen_loss 1.458837, disc_loss 0.958890\n",
      "batch 169, gen_loss 1.322392, disc_loss 1.000854\n",
      "batch 170, gen_loss 1.252540, disc_loss 0.981848\n",
      "batch 171, gen_loss 1.332600, disc_loss 0.939560\n",
      "batch 172, gen_loss 1.557763, disc_loss 0.897070\n",
      "batch 173, gen_loss 1.674237, disc_loss 0.771387\n",
      "batch 174, gen_loss 1.628278, disc_loss 0.880096\n",
      "batch 175, gen_loss 1.475842, disc_loss 0.877371\n",
      "batch 176, gen_loss 1.499632, disc_loss 0.959516\n",
      "batch 177, gen_loss 1.350315, disc_loss 0.948907\n",
      "batch 178, gen_loss 1.457831, disc_loss 0.852545\n",
      "batch 179, gen_loss 1.418558, disc_loss 0.900292\n",
      "batch 180, gen_loss 1.469859, disc_loss 0.892427\n",
      "batch 181, gen_loss 1.421509, disc_loss 0.879544\n",
      "batch 182, gen_loss 1.424780, disc_loss 0.874925\n",
      "batch 183, gen_loss 1.576609, disc_loss 0.880505\n",
      "batch 184, gen_loss 1.529286, disc_loss 0.958689\n",
      "batch 185, gen_loss 1.436367, disc_loss 0.847423\n",
      "batch 186, gen_loss 1.378005, disc_loss 0.830349\n",
      "batch 187, gen_loss 1.286211, disc_loss 0.897033\n",
      "batch 188, gen_loss 1.544304, disc_loss 0.855275\n",
      "batch 189, gen_loss 1.542719, disc_loss 0.927494\n",
      "batch 190, gen_loss 1.675369, disc_loss 0.812343\n",
      "batch 191, gen_loss 1.516967, disc_loss 0.945742\n",
      "batch 192, gen_loss 1.453456, disc_loss 0.874591\n",
      "batch 193, gen_loss 1.386356, disc_loss 0.908135\n",
      "batch 194, gen_loss 1.379550, disc_loss 0.904073\n",
      "batch 195, gen_loss 1.464599, disc_loss 0.899095\n",
      "batch 196, gen_loss 1.464208, disc_loss 1.024371\n",
      "batch 197, gen_loss 1.472905, disc_loss 0.934264\n",
      "batch 198, gen_loss 1.515232, disc_loss 0.832063\n",
      "batch 199, gen_loss 1.406353, disc_loss 0.927296\n",
      "batch 200, gen_loss 1.513017, disc_loss 0.886878\n",
      "batch 201, gen_loss 1.405140, disc_loss 0.897772\n",
      "batch 202, gen_loss 1.425634, disc_loss 0.888289\n",
      "batch 203, gen_loss 1.382831, disc_loss 0.950332\n",
      "batch 204, gen_loss 1.411514, disc_loss 0.868022\n",
      "batch 205, gen_loss 1.393960, disc_loss 0.896731\n",
      "batch 206, gen_loss 1.495614, disc_loss 0.981431\n",
      "batch 207, gen_loss 1.551679, disc_loss 0.961541\n",
      "batch 208, gen_loss 1.463894, disc_loss 0.907612\n",
      "batch 209, gen_loss 1.437960, disc_loss 0.920211\n",
      "batch 210, gen_loss 1.274227, disc_loss 0.906793\n",
      "batch 211, gen_loss 1.352083, disc_loss 0.975831\n",
      "batch 212, gen_loss 1.409358, disc_loss 0.871195\n",
      "batch 213, gen_loss 1.585552, disc_loss 0.924303\n",
      "batch 214, gen_loss 1.497602, disc_loss 0.882265\n",
      "batch 215, gen_loss 1.489343, disc_loss 0.952685\n",
      "batch 216, gen_loss 1.497456, disc_loss 0.878951\n",
      "batch 217, gen_loss 1.407141, disc_loss 0.911889\n",
      "batch 218, gen_loss 1.451289, disc_loss 0.987158\n",
      "batch 219, gen_loss 1.432752, disc_loss 0.935281\n",
      "batch 220, gen_loss 1.467444, disc_loss 1.012105\n",
      "batch 221, gen_loss 1.446439, disc_loss 0.926537\n",
      "batch 222, gen_loss 1.468654, disc_loss 0.875115\n",
      "batch 223, gen_loss 1.316358, disc_loss 0.987950\n",
      "batch 224, gen_loss 1.370579, disc_loss 1.028239\n",
      "batch 225, gen_loss 1.489211, disc_loss 0.873146\n",
      "batch 226, gen_loss 1.621396, disc_loss 0.950919\n",
      "batch 227, gen_loss 1.489980, disc_loss 0.938861\n",
      "batch 228, gen_loss 1.459207, disc_loss 0.890279\n",
      "batch 229, gen_loss 1.308390, disc_loss 1.007193\n",
      "batch 230, gen_loss 1.391411, disc_loss 0.954137\n",
      "batch 231, gen_loss 1.384341, disc_loss 0.909435\n",
      "batch 232, gen_loss 1.398635, disc_loss 0.896889\n",
      "batch 233, gen_loss 1.578433, disc_loss 0.919288\n",
      "batch 234, gen_loss 1.600866, disc_loss 0.987118\n",
      "Time for epoch38is 8.269073724746704 sec\n",
      "batch 0, gen_loss 1.478196, disc_loss 0.984380\n",
      "batch 1, gen_loss 1.365243, disc_loss 0.890742\n",
      "batch 2, gen_loss 1.316009, disc_loss 0.875418\n",
      "batch 3, gen_loss 1.359664, disc_loss 0.942379\n",
      "batch 4, gen_loss 1.469663, disc_loss 0.911892\n",
      "batch 5, gen_loss 1.732656, disc_loss 0.949954\n",
      "batch 6, gen_loss 1.795668, disc_loss 0.899086\n",
      "batch 7, gen_loss 1.616917, disc_loss 0.905737\n",
      "batch 8, gen_loss 1.347398, disc_loss 0.894962\n",
      "batch 9, gen_loss 1.149816, disc_loss 0.925781\n",
      "batch 10, gen_loss 1.391331, disc_loss 0.887478\n",
      "batch 11, gen_loss 1.621550, disc_loss 0.942455\n",
      "batch 12, gen_loss 1.776532, disc_loss 0.835456\n",
      "batch 13, gen_loss 1.718888, disc_loss 0.865573\n",
      "batch 14, gen_loss 1.543551, disc_loss 0.842363\n",
      "batch 15, gen_loss 1.429950, disc_loss 0.877442\n",
      "batch 16, gen_loss 1.411359, disc_loss 0.819045\n",
      "batch 17, gen_loss 1.335479, disc_loss 0.838657\n",
      "batch 18, gen_loss 1.538600, disc_loss 0.818667\n",
      "batch 19, gen_loss 1.573924, disc_loss 0.847934\n",
      "batch 20, gen_loss 1.749500, disc_loss 0.894340\n",
      "batch 21, gen_loss 1.753005, disc_loss 0.850570\n",
      "batch 22, gen_loss 1.586544, disc_loss 0.840591\n",
      "batch 23, gen_loss 1.386875, disc_loss 0.881270\n",
      "batch 24, gen_loss 1.394960, disc_loss 0.822236\n",
      "batch 25, gen_loss 1.471165, disc_loss 0.913385\n",
      "batch 26, gen_loss 1.557135, disc_loss 0.831071\n",
      "batch 27, gen_loss 1.714394, disc_loss 0.884711\n",
      "batch 28, gen_loss 1.643670, disc_loss 0.825558\n",
      "batch 29, gen_loss 1.530011, disc_loss 0.834460\n",
      "batch 30, gen_loss 1.562411, disc_loss 0.848280\n",
      "batch 31, gen_loss 1.582787, disc_loss 0.734366\n",
      "batch 32, gen_loss 1.558901, disc_loss 0.708770\n",
      "batch 33, gen_loss 1.542356, disc_loss 0.817121\n",
      "batch 34, gen_loss 1.741163, disc_loss 0.820700\n",
      "batch 35, gen_loss 1.547484, disc_loss 0.855055\n",
      "batch 36, gen_loss 1.472812, disc_loss 0.871631\n",
      "batch 37, gen_loss 1.517111, disc_loss 0.880373\n",
      "batch 38, gen_loss 1.498281, disc_loss 0.776917\n",
      "batch 39, gen_loss 1.516350, disc_loss 0.820911\n",
      "batch 40, gen_loss 1.549958, disc_loss 0.864636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 41, gen_loss 1.499602, disc_loss 0.874967\n",
      "batch 42, gen_loss 1.636380, disc_loss 0.793221\n",
      "batch 43, gen_loss 1.488532, disc_loss 0.813480\n",
      "batch 44, gen_loss 1.493795, disc_loss 0.863993\n",
      "batch 45, gen_loss 1.578358, disc_loss 0.819864\n",
      "batch 46, gen_loss 1.537559, disc_loss 0.871044\n",
      "batch 47, gen_loss 1.437487, disc_loss 0.814665\n",
      "batch 48, gen_loss 1.432823, disc_loss 0.875403\n",
      "batch 49, gen_loss 1.612202, disc_loss 0.862036\n",
      "batch 50, gen_loss 1.555520, disc_loss 0.818708\n",
      "batch 51, gen_loss 1.623691, disc_loss 0.835159\n",
      "batch 52, gen_loss 1.593814, disc_loss 0.842673\n",
      "batch 53, gen_loss 1.658322, disc_loss 0.845973\n",
      "batch 54, gen_loss 1.534533, disc_loss 0.793368\n",
      "batch 55, gen_loss 1.465117, disc_loss 0.774528\n",
      "batch 56, gen_loss 1.512163, disc_loss 0.858990\n",
      "batch 57, gen_loss 1.406780, disc_loss 0.980805\n",
      "batch 58, gen_loss 1.578736, disc_loss 0.862862\n",
      "batch 59, gen_loss 1.583743, disc_loss 0.781266\n",
      "batch 60, gen_loss 1.607665, disc_loss 0.833353\n",
      "batch 61, gen_loss 1.565310, disc_loss 0.823323\n",
      "batch 62, gen_loss 1.485507, disc_loss 0.803895\n",
      "batch 63, gen_loss 1.563810, disc_loss 0.891502\n",
      "batch 64, gen_loss 1.484144, disc_loss 0.818443\n",
      "batch 65, gen_loss 1.479485, disc_loss 0.890216\n",
      "batch 66, gen_loss 1.541195, disc_loss 0.875156\n",
      "batch 67, gen_loss 1.557778, disc_loss 0.848184\n",
      "batch 68, gen_loss 1.559278, disc_loss 0.875138\n",
      "batch 69, gen_loss 1.588297, disc_loss 0.912848\n",
      "batch 70, gen_loss 1.517182, disc_loss 0.806572\n",
      "batch 71, gen_loss 1.474601, disc_loss 0.848727\n",
      "batch 72, gen_loss 1.500113, disc_loss 0.834824\n",
      "batch 73, gen_loss 1.495162, disc_loss 0.817768\n",
      "batch 74, gen_loss 1.559381, disc_loss 0.915643\n",
      "batch 75, gen_loss 1.507074, disc_loss 0.850134\n",
      "batch 76, gen_loss 1.470036, disc_loss 0.864134\n",
      "batch 77, gen_loss 1.558155, disc_loss 0.830633\n",
      "batch 78, gen_loss 1.609965, disc_loss 0.863065\n",
      "batch 79, gen_loss 1.576090, disc_loss 0.759460\n",
      "batch 80, gen_loss 1.448545, disc_loss 0.831146\n",
      "batch 81, gen_loss 1.470091, disc_loss 0.893168\n",
      "batch 82, gen_loss 1.626787, disc_loss 0.783083\n",
      "batch 83, gen_loss 1.678147, disc_loss 0.820699\n",
      "batch 84, gen_loss 1.683750, disc_loss 0.811926\n",
      "batch 85, gen_loss 1.556253, disc_loss 0.775951\n",
      "batch 86, gen_loss 1.622038, disc_loss 0.801620\n",
      "batch 87, gen_loss 1.653761, disc_loss 0.815989\n",
      "batch 88, gen_loss 1.545959, disc_loss 0.851052\n",
      "batch 89, gen_loss 1.506179, disc_loss 0.856019\n",
      "batch 90, gen_loss 1.383530, disc_loss 0.890607\n",
      "batch 91, gen_loss 1.384233, disc_loss 0.762386\n",
      "batch 92, gen_loss 1.471454, disc_loss 0.877421\n",
      "batch 93, gen_loss 1.598948, disc_loss 0.861192\n",
      "batch 94, gen_loss 1.711338, disc_loss 0.796450\n",
      "batch 95, gen_loss 1.601046, disc_loss 0.813391\n",
      "batch 96, gen_loss 1.537265, disc_loss 0.843271\n",
      "batch 97, gen_loss 1.461695, disc_loss 0.836743\n",
      "batch 98, gen_loss 1.457626, disc_loss 0.885063\n",
      "batch 99, gen_loss 1.363775, disc_loss 0.879207\n",
      "batch 100, gen_loss 1.387025, disc_loss 0.853186\n",
      "batch 101, gen_loss 1.485718, disc_loss 0.819411\n",
      "batch 102, gen_loss 1.727355, disc_loss 0.874668\n",
      "batch 103, gen_loss 1.789536, disc_loss 0.795060\n",
      "batch 104, gen_loss 1.629894, disc_loss 0.827229\n",
      "batch 105, gen_loss 1.483717, disc_loss 0.844628\n",
      "batch 106, gen_loss 1.431647, disc_loss 0.847142\n",
      "batch 107, gen_loss 1.367990, disc_loss 0.947594\n",
      "batch 108, gen_loss 1.382383, disc_loss 0.889568\n",
      "batch 109, gen_loss 1.392618, disc_loss 0.871233\n",
      "batch 110, gen_loss 1.415842, disc_loss 0.891540\n",
      "batch 111, gen_loss 1.544534, disc_loss 0.926597\n",
      "batch 112, gen_loss 1.566107, disc_loss 0.847290\n",
      "batch 113, gen_loss 1.548626, disc_loss 0.928838\n",
      "batch 114, gen_loss 1.455624, disc_loss 0.932208\n",
      "batch 115, gen_loss 1.386729, disc_loss 0.919751\n",
      "batch 116, gen_loss 1.311000, disc_loss 0.924273\n",
      "batch 117, gen_loss 1.479642, disc_loss 0.913072\n",
      "batch 118, gen_loss 1.441091, disc_loss 0.897947\n",
      "batch 119, gen_loss 1.404353, disc_loss 1.050326\n",
      "batch 120, gen_loss 1.463139, disc_loss 0.963999\n",
      "batch 121, gen_loss 1.511005, disc_loss 0.863692\n",
      "batch 122, gen_loss 1.461087, disc_loss 0.969871\n",
      "batch 123, gen_loss 1.438341, disc_loss 1.075929\n",
      "batch 124, gen_loss 1.373639, disc_loss 0.944866\n",
      "batch 125, gen_loss 1.413657, disc_loss 0.972096\n",
      "batch 126, gen_loss 1.308019, disc_loss 0.991670\n",
      "batch 127, gen_loss 1.366293, disc_loss 1.016206\n",
      "batch 128, gen_loss 1.404779, disc_loss 0.939609\n",
      "batch 129, gen_loss 1.589312, disc_loss 0.944046\n",
      "batch 130, gen_loss 1.458871, disc_loss 1.026948\n",
      "batch 131, gen_loss 1.575726, disc_loss 0.959772\n",
      "batch 132, gen_loss 1.494932, disc_loss 1.043385\n",
      "batch 133, gen_loss 1.379441, disc_loss 0.990509\n",
      "batch 134, gen_loss 1.382018, disc_loss 0.970935\n",
      "batch 135, gen_loss 1.360902, disc_loss 0.901277\n",
      "batch 136, gen_loss 1.343095, disc_loss 0.945546\n",
      "batch 137, gen_loss 1.532179, disc_loss 0.999023\n",
      "batch 138, gen_loss 1.878100, disc_loss 1.139897\n",
      "batch 139, gen_loss 1.542438, disc_loss 0.977508\n",
      "batch 140, gen_loss 1.226979, disc_loss 1.022900\n",
      "batch 141, gen_loss 1.180704, disc_loss 0.971108\n",
      "batch 142, gen_loss 1.266569, disc_loss 1.004712\n",
      "batch 143, gen_loss 1.431980, disc_loss 0.951147\n",
      "batch 144, gen_loss 1.552280, disc_loss 0.903370\n",
      "batch 145, gen_loss 1.651786, disc_loss 0.879618\n",
      "batch 146, gen_loss 1.666675, disc_loss 0.931230\n",
      "batch 147, gen_loss 1.579538, disc_loss 0.884066\n",
      "batch 148, gen_loss 1.515510, disc_loss 0.899666\n",
      "batch 149, gen_loss 1.544789, disc_loss 0.848372\n",
      "batch 150, gen_loss 1.366396, disc_loss 0.919110\n",
      "batch 151, gen_loss 1.438946, disc_loss 0.864397\n",
      "batch 152, gen_loss 1.526162, disc_loss 0.822056\n",
      "batch 153, gen_loss 1.583943, disc_loss 0.886751\n",
      "batch 154, gen_loss 1.647442, disc_loss 0.861624\n",
      "batch 155, gen_loss 1.671451, disc_loss 0.873647\n",
      "batch 156, gen_loss 1.523371, disc_loss 0.955065\n",
      "batch 157, gen_loss 1.375527, disc_loss 0.865868\n",
      "batch 158, gen_loss 1.292135, disc_loss 0.834654\n",
      "batch 159, gen_loss 1.335158, disc_loss 0.882569\n",
      "batch 160, gen_loss 1.618395, disc_loss 0.799664\n",
      "batch 161, gen_loss 1.680001, disc_loss 0.752245\n",
      "batch 162, gen_loss 1.812075, disc_loss 0.914016\n",
      "batch 163, gen_loss 1.893250, disc_loss 0.838517\n",
      "batch 164, gen_loss 1.527200, disc_loss 0.814477\n",
      "batch 165, gen_loss 1.374130, disc_loss 0.832133\n",
      "batch 166, gen_loss 1.275804, disc_loss 0.852228\n",
      "batch 167, gen_loss 1.426897, disc_loss 0.838950\n",
      "batch 168, gen_loss 1.490592, disc_loss 0.815893\n",
      "batch 169, gen_loss 1.606437, disc_loss 0.811143\n",
      "batch 170, gen_loss 1.676882, disc_loss 0.849884\n",
      "batch 171, gen_loss 1.855171, disc_loss 0.851645\n",
      "batch 172, gen_loss 1.689924, disc_loss 0.817147\n",
      "batch 173, gen_loss 1.548209, disc_loss 0.777619\n",
      "batch 174, gen_loss 1.354092, disc_loss 0.786977\n",
      "batch 175, gen_loss 1.426628, disc_loss 0.833011\n",
      "batch 176, gen_loss 1.448707, disc_loss 0.732459\n",
      "batch 177, gen_loss 1.603441, disc_loss 0.758363\n",
      "batch 178, gen_loss 1.668136, disc_loss 0.866233\n",
      "batch 179, gen_loss 1.860654, disc_loss 0.836941\n",
      "batch 180, gen_loss 1.764683, disc_loss 0.797197\n",
      "batch 181, gen_loss 1.544813, disc_loss 0.855840\n",
      "batch 182, gen_loss 1.361256, disc_loss 0.827396\n",
      "batch 183, gen_loss 1.226128, disc_loss 0.918778\n",
      "batch 184, gen_loss 1.516186, disc_loss 0.756783\n",
      "batch 185, gen_loss 1.664237, disc_loss 0.833215\n",
      "batch 186, gen_loss 1.725526, disc_loss 0.858965\n",
      "batch 187, gen_loss 1.700545, disc_loss 0.876405\n",
      "batch 188, gen_loss 1.649563, disc_loss 0.847005\n",
      "batch 189, gen_loss 1.505326, disc_loss 0.804818\n",
      "batch 190, gen_loss 1.377729, disc_loss 0.844521\n",
      "batch 191, gen_loss 1.324093, disc_loss 0.826223\n",
      "batch 192, gen_loss 1.531621, disc_loss 0.735600\n",
      "batch 193, gen_loss 1.658507, disc_loss 0.879681\n",
      "batch 194, gen_loss 1.696550, disc_loss 0.734667\n",
      "batch 195, gen_loss 1.669640, disc_loss 0.837263\n",
      "batch 196, gen_loss 1.623656, disc_loss 0.737208\n",
      "batch 197, gen_loss 1.516845, disc_loss 0.781841\n",
      "batch 198, gen_loss 1.461694, disc_loss 0.873966\n",
      "batch 199, gen_loss 1.411256, disc_loss 0.831904\n",
      "batch 200, gen_loss 1.504021, disc_loss 0.813725\n",
      "batch 201, gen_loss 1.609478, disc_loss 0.728719\n",
      "batch 202, gen_loss 1.575190, disc_loss 0.834753\n",
      "batch 203, gen_loss 1.717524, disc_loss 0.789092\n",
      "batch 204, gen_loss 1.658352, disc_loss 0.834514\n",
      "batch 205, gen_loss 1.509777, disc_loss 0.786328\n",
      "batch 206, gen_loss 1.543425, disc_loss 0.830131\n",
      "batch 207, gen_loss 1.506698, disc_loss 0.808102\n",
      "batch 208, gen_loss 1.423852, disc_loss 0.832057\n",
      "batch 209, gen_loss 1.546081, disc_loss 0.765008\n",
      "batch 210, gen_loss 1.525729, disc_loss 0.847130\n",
      "batch 211, gen_loss 1.554236, disc_loss 0.840645\n",
      "batch 212, gen_loss 1.559653, disc_loss 0.741665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 213, gen_loss 1.553667, disc_loss 0.792495\n",
      "batch 214, gen_loss 1.635216, disc_loss 0.789788\n",
      "batch 215, gen_loss 1.705424, disc_loss 0.760409\n",
      "batch 216, gen_loss 1.623400, disc_loss 0.789552\n",
      "batch 217, gen_loss 1.536502, disc_loss 0.797495\n",
      "batch 218, gen_loss 1.623099, disc_loss 0.766344\n",
      "batch 219, gen_loss 1.502677, disc_loss 0.848356\n",
      "batch 220, gen_loss 1.662059, disc_loss 0.779808\n",
      "batch 221, gen_loss 1.636044, disc_loss 0.698458\n",
      "batch 222, gen_loss 1.689000, disc_loss 0.728077\n",
      "batch 223, gen_loss 1.658389, disc_loss 0.801974\n",
      "batch 224, gen_loss 1.649473, disc_loss 0.712140\n",
      "batch 225, gen_loss 1.640608, disc_loss 0.856160\n",
      "batch 226, gen_loss 1.491310, disc_loss 0.838873\n",
      "batch 227, gen_loss 1.544325, disc_loss 0.768806\n",
      "batch 228, gen_loss 1.489504, disc_loss 0.720495\n",
      "batch 229, gen_loss 1.513184, disc_loss 0.753770\n",
      "batch 230, gen_loss 1.768285, disc_loss 0.770128\n",
      "batch 231, gen_loss 1.794135, disc_loss 0.767660\n",
      "batch 232, gen_loss 1.726514, disc_loss 0.738870\n",
      "batch 233, gen_loss 1.615712, disc_loss 0.765427\n",
      "batch 234, gen_loss 1.375229, disc_loss 0.830154\n",
      "Time for epoch39is 7.846745491027832 sec\n",
      "batch 0, gen_loss 1.444361, disc_loss 0.823357\n",
      "batch 1, gen_loss 1.528129, disc_loss 0.797577\n",
      "batch 2, gen_loss 1.682067, disc_loss 0.776352\n",
      "batch 3, gen_loss 1.662864, disc_loss 0.894900\n",
      "batch 4, gen_loss 1.662956, disc_loss 0.778194\n",
      "batch 5, gen_loss 1.518822, disc_loss 0.778134\n",
      "batch 6, gen_loss 1.400892, disc_loss 0.847385\n",
      "batch 7, gen_loss 1.550817, disc_loss 0.792632\n",
      "batch 8, gen_loss 1.652528, disc_loss 0.849812\n",
      "batch 9, gen_loss 1.569821, disc_loss 0.872884\n",
      "batch 10, gen_loss 1.542806, disc_loss 0.905786\n",
      "batch 11, gen_loss 1.531480, disc_loss 0.829692\n",
      "batch 12, gen_loss 1.449545, disc_loss 0.907938\n",
      "batch 13, gen_loss 1.513889, disc_loss 0.864647\n",
      "batch 14, gen_loss 1.529500, disc_loss 0.872470\n",
      "batch 15, gen_loss 1.666278, disc_loss 0.950638\n",
      "batch 16, gen_loss 1.615191, disc_loss 0.908611\n",
      "batch 17, gen_loss 1.493396, disc_loss 0.923823\n",
      "batch 18, gen_loss 1.432178, disc_loss 0.861604\n",
      "batch 19, gen_loss 1.477914, disc_loss 0.786428\n",
      "batch 20, gen_loss 1.418656, disc_loss 0.909769\n",
      "batch 21, gen_loss 1.570025, disc_loss 0.835905\n",
      "batch 22, gen_loss 1.752974, disc_loss 0.913746\n",
      "batch 23, gen_loss 1.512024, disc_loss 0.906840\n",
      "batch 24, gen_loss 1.536181, disc_loss 0.906439\n",
      "batch 25, gen_loss 1.534649, disc_loss 0.901216\n",
      "batch 26, gen_loss 1.434420, disc_loss 0.910996\n",
      "batch 27, gen_loss 1.455306, disc_loss 0.940821\n",
      "batch 28, gen_loss 1.394355, disc_loss 0.871255\n",
      "batch 29, gen_loss 1.440510, disc_loss 0.845706\n",
      "batch 30, gen_loss 1.546121, disc_loss 0.973898\n",
      "batch 31, gen_loss 1.631754, disc_loss 0.923169\n",
      "batch 32, gen_loss 1.700567, disc_loss 0.898069\n",
      "batch 33, gen_loss 1.639434, disc_loss 0.935474\n",
      "batch 34, gen_loss 1.608369, disc_loss 0.904965\n",
      "batch 35, gen_loss 1.489239, disc_loss 0.845979\n",
      "batch 36, gen_loss 1.423526, disc_loss 0.926355\n",
      "batch 37, gen_loss 1.426813, disc_loss 0.928598\n",
      "batch 38, gen_loss 1.574849, disc_loss 0.818238\n",
      "batch 39, gen_loss 1.699090, disc_loss 0.914722\n",
      "batch 40, gen_loss 1.709797, disc_loss 0.794850\n",
      "batch 41, gen_loss 1.581852, disc_loss 0.827163\n",
      "batch 42, gen_loss 1.604698, disc_loss 0.783583\n",
      "batch 43, gen_loss 1.625068, disc_loss 0.769164\n",
      "batch 44, gen_loss 1.544603, disc_loss 0.809575\n",
      "batch 45, gen_loss 1.568361, disc_loss 0.832784\n",
      "batch 46, gen_loss 1.572061, disc_loss 0.818445\n",
      "batch 47, gen_loss 1.640953, disc_loss 0.894082\n",
      "batch 48, gen_loss 1.594613, disc_loss 0.823151\n",
      "batch 49, gen_loss 1.594608, disc_loss 0.788008\n",
      "batch 50, gen_loss 1.528350, disc_loss 0.782518\n",
      "batch 51, gen_loss 1.638490, disc_loss 0.779742\n",
      "batch 52, gen_loss 1.709705, disc_loss 0.760894\n",
      "batch 53, gen_loss 1.597948, disc_loss 0.711515\n",
      "batch 54, gen_loss 1.722336, disc_loss 0.800829\n",
      "batch 55, gen_loss 1.611104, disc_loss 0.785376\n",
      "batch 56, gen_loss 1.610705, disc_loss 0.806662\n",
      "batch 57, gen_loss 1.622406, disc_loss 0.795216\n",
      "batch 58, gen_loss 1.674072, disc_loss 0.754465\n",
      "batch 59, gen_loss 1.559397, disc_loss 0.769938\n",
      "batch 60, gen_loss 1.722195, disc_loss 0.724091\n",
      "batch 61, gen_loss 1.747687, disc_loss 0.740483\n",
      "batch 62, gen_loss 1.684518, disc_loss 0.693951\n",
      "batch 63, gen_loss 1.564911, disc_loss 0.735729\n",
      "batch 64, gen_loss 1.616594, disc_loss 0.844768\n",
      "batch 65, gen_loss 1.623648, disc_loss 0.848729\n",
      "batch 66, gen_loss 1.491302, disc_loss 0.804041\n",
      "batch 67, gen_loss 1.562879, disc_loss 0.745646\n",
      "batch 68, gen_loss 1.579649, disc_loss 0.803887\n",
      "batch 69, gen_loss 1.607799, disc_loss 0.837632\n",
      "batch 70, gen_loss 1.578460, disc_loss 0.829063\n",
      "batch 71, gen_loss 1.707638, disc_loss 0.770799\n",
      "batch 72, gen_loss 1.666594, disc_loss 0.771716\n",
      "batch 73, gen_loss 1.619257, disc_loss 0.822199\n",
      "batch 74, gen_loss 1.487476, disc_loss 0.835958\n",
      "batch 75, gen_loss 1.570829, disc_loss 0.797284\n",
      "batch 76, gen_loss 1.622859, disc_loss 0.854326\n",
      "batch 77, gen_loss 1.400809, disc_loss 0.915025\n",
      "batch 78, gen_loss 1.483541, disc_loss 0.806721\n",
      "batch 79, gen_loss 1.520182, disc_loss 0.800115\n",
      "batch 80, gen_loss 1.533674, disc_loss 0.849923\n",
      "batch 81, gen_loss 1.514199, disc_loss 0.923725\n",
      "batch 82, gen_loss 1.445354, disc_loss 0.913965\n",
      "batch 83, gen_loss 1.500288, disc_loss 0.924503\n",
      "batch 84, gen_loss 1.328389, disc_loss 0.977550\n",
      "batch 85, gen_loss 1.472398, disc_loss 0.907239\n",
      "batch 86, gen_loss 1.458244, disc_loss 0.927245\n",
      "batch 87, gen_loss 1.542202, disc_loss 0.938192\n",
      "batch 88, gen_loss 1.542049, disc_loss 0.935055\n",
      "batch 89, gen_loss 1.574174, disc_loss 0.930572\n",
      "batch 90, gen_loss 1.461657, disc_loss 0.898095\n",
      "batch 91, gen_loss 1.416036, disc_loss 0.949299\n",
      "batch 92, gen_loss 1.362932, disc_loss 1.007774\n",
      "batch 93, gen_loss 1.410569, disc_loss 0.933070\n",
      "batch 94, gen_loss 1.414445, disc_loss 0.981225\n",
      "batch 95, gen_loss 1.218813, disc_loss 1.102258\n",
      "batch 96, gen_loss 1.291934, disc_loss 1.048413\n",
      "batch 97, gen_loss 1.476033, disc_loss 0.955388\n",
      "batch 98, gen_loss 1.460477, disc_loss 1.051885\n",
      "batch 99, gen_loss 1.327591, disc_loss 0.978578\n",
      "batch 100, gen_loss 1.354561, disc_loss 1.031477\n",
      "batch 101, gen_loss 1.427902, disc_loss 0.936419\n",
      "batch 102, gen_loss 1.398960, disc_loss 1.083153\n",
      "batch 103, gen_loss 1.394784, disc_loss 0.975666\n",
      "batch 104, gen_loss 1.423830, disc_loss 0.970912\n",
      "batch 105, gen_loss 1.266510, disc_loss 1.106938\n",
      "batch 106, gen_loss 1.248620, disc_loss 1.055233\n",
      "batch 107, gen_loss 1.437773, disc_loss 1.017311\n",
      "batch 108, gen_loss 1.430481, disc_loss 1.008241\n",
      "batch 109, gen_loss 1.401964, disc_loss 1.098601\n",
      "batch 110, gen_loss 1.264025, disc_loss 0.993124\n",
      "batch 111, gen_loss 1.380096, disc_loss 1.007293\n",
      "batch 112, gen_loss 1.292918, disc_loss 1.057087\n",
      "batch 113, gen_loss 1.325370, disc_loss 1.036271\n",
      "batch 114, gen_loss 1.345631, disc_loss 1.153623\n",
      "batch 115, gen_loss 1.501926, disc_loss 1.076985\n",
      "batch 116, gen_loss 1.499651, disc_loss 1.076311\n",
      "batch 117, gen_loss 1.488972, disc_loss 1.006334\n",
      "batch 118, gen_loss 1.336611, disc_loss 1.080497\n",
      "batch 119, gen_loss 1.290528, disc_loss 1.085796\n",
      "batch 120, gen_loss 1.227688, disc_loss 1.080505\n",
      "batch 121, gen_loss 1.394336, disc_loss 1.092887\n",
      "batch 122, gen_loss 1.505556, disc_loss 0.977631\n",
      "batch 123, gen_loss 1.455192, disc_loss 1.078606\n",
      "batch 124, gen_loss 1.485908, disc_loss 1.138024\n",
      "batch 125, gen_loss 1.404056, disc_loss 1.103761\n",
      "batch 126, gen_loss 1.306183, disc_loss 1.027235\n",
      "batch 127, gen_loss 1.276214, disc_loss 1.055326\n",
      "batch 128, gen_loss 1.297226, disc_loss 1.015905\n",
      "batch 129, gen_loss 1.323479, disc_loss 1.063776\n",
      "batch 130, gen_loss 1.431899, disc_loss 1.076431\n",
      "batch 131, gen_loss 1.516123, disc_loss 1.117376\n",
      "batch 132, gen_loss 1.432968, disc_loss 0.939784\n",
      "batch 133, gen_loss 1.364966, disc_loss 1.018569\n",
      "batch 134, gen_loss 1.328336, disc_loss 1.011976\n",
      "batch 135, gen_loss 1.415554, disc_loss 1.038472\n",
      "batch 136, gen_loss 1.575740, disc_loss 0.997449\n",
      "batch 137, gen_loss 1.434517, disc_loss 0.987659\n",
      "batch 138, gen_loss 1.405670, disc_loss 1.053723\n",
      "batch 139, gen_loss 1.462858, disc_loss 0.973922\n",
      "batch 140, gen_loss 1.425156, disc_loss 0.999030\n",
      "batch 141, gen_loss 1.647847, disc_loss 0.895801\n",
      "batch 142, gen_loss 1.274499, disc_loss 1.080782\n",
      "batch 143, gen_loss 1.442732, disc_loss 0.983603\n",
      "batch 144, gen_loss 1.373486, disc_loss 0.988552\n",
      "batch 145, gen_loss 1.486537, disc_loss 0.888409\n",
      "batch 146, gen_loss 1.478815, disc_loss 0.886696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 147, gen_loss 1.458584, disc_loss 0.991059\n",
      "batch 148, gen_loss 1.649620, disc_loss 0.981456\n",
      "batch 149, gen_loss 1.477844, disc_loss 0.898776\n",
      "batch 150, gen_loss 1.416254, disc_loss 0.922726\n",
      "batch 151, gen_loss 1.403105, disc_loss 0.895893\n",
      "batch 152, gen_loss 1.314600, disc_loss 0.985364\n",
      "batch 153, gen_loss 1.416915, disc_loss 0.933654\n",
      "batch 154, gen_loss 1.483297, disc_loss 0.952216\n",
      "batch 155, gen_loss 1.440757, disc_loss 1.000246\n",
      "batch 156, gen_loss 1.376519, disc_loss 0.955189\n",
      "batch 157, gen_loss 1.352297, disc_loss 0.927468\n",
      "batch 158, gen_loss 1.497306, disc_loss 0.896161\n",
      "batch 159, gen_loss 1.554817, disc_loss 0.895121\n",
      "batch 160, gen_loss 1.727230, disc_loss 0.962540\n",
      "batch 161, gen_loss 1.395719, disc_loss 0.946126\n",
      "batch 162, gen_loss 1.303758, disc_loss 0.960845\n",
      "batch 163, gen_loss 1.416911, disc_loss 0.841380\n",
      "batch 164, gen_loss 1.382439, disc_loss 0.842782\n",
      "batch 165, gen_loss 1.537227, disc_loss 0.926627\n",
      "batch 166, gen_loss 1.532591, disc_loss 0.926674\n",
      "batch 167, gen_loss 1.447556, disc_loss 0.868295\n",
      "batch 168, gen_loss 1.538316, disc_loss 0.894274\n",
      "batch 169, gen_loss 1.415441, disc_loss 0.911353\n",
      "batch 170, gen_loss 1.449901, disc_loss 0.938254\n",
      "batch 171, gen_loss 1.589723, disc_loss 0.878692\n",
      "batch 172, gen_loss 1.418684, disc_loss 0.998647\n",
      "batch 173, gen_loss 1.301198, disc_loss 0.963153\n",
      "batch 174, gen_loss 1.333185, disc_loss 0.942738\n",
      "batch 175, gen_loss 1.422571, disc_loss 0.953360\n",
      "batch 176, gen_loss 1.431852, disc_loss 0.986518\n",
      "batch 177, gen_loss 1.426367, disc_loss 0.925638\n",
      "batch 178, gen_loss 1.543139, disc_loss 0.921961\n",
      "batch 179, gen_loss 1.462933, disc_loss 0.915720\n",
      "batch 180, gen_loss 1.458400, disc_loss 0.944161\n",
      "batch 181, gen_loss 1.341319, disc_loss 0.870672\n",
      "batch 182, gen_loss 1.365205, disc_loss 0.942230\n",
      "batch 183, gen_loss 1.513423, disc_loss 0.941319\n",
      "batch 184, gen_loss 1.583244, disc_loss 0.923871\n",
      "batch 185, gen_loss 1.547633, disc_loss 0.982687\n",
      "batch 186, gen_loss 1.446477, disc_loss 0.899773\n",
      "batch 187, gen_loss 1.358654, disc_loss 0.881579\n",
      "batch 188, gen_loss 1.260644, disc_loss 0.914611\n",
      "batch 189, gen_loss 1.386913, disc_loss 0.931347\n",
      "batch 190, gen_loss 1.623453, disc_loss 0.882575\n",
      "batch 191, gen_loss 1.693832, disc_loss 0.867397\n",
      "batch 192, gen_loss 1.624887, disc_loss 0.868698\n",
      "batch 193, gen_loss 1.452300, disc_loss 0.886741\n",
      "batch 194, gen_loss 1.387703, disc_loss 0.823623\n",
      "batch 195, gen_loss 1.318003, disc_loss 0.892170\n",
      "batch 196, gen_loss 1.618052, disc_loss 0.855500\n",
      "batch 197, gen_loss 1.748318, disc_loss 0.799671\n",
      "batch 198, gen_loss 1.639241, disc_loss 0.831916\n",
      "batch 199, gen_loss 1.694019, disc_loss 0.797059\n",
      "batch 200, gen_loss 1.490489, disc_loss 0.854414\n",
      "batch 201, gen_loss 1.291715, disc_loss 0.860901\n",
      "batch 202, gen_loss 1.529165, disc_loss 0.777300\n",
      "batch 203, gen_loss 1.622812, disc_loss 0.776814\n",
      "batch 204, gen_loss 1.784482, disc_loss 0.877507\n",
      "batch 205, gen_loss 1.809451, disc_loss 0.785056\n",
      "batch 206, gen_loss 1.718589, disc_loss 0.831782\n",
      "batch 207, gen_loss 1.546511, disc_loss 0.835364\n",
      "batch 208, gen_loss 1.451158, disc_loss 0.762101\n",
      "batch 209, gen_loss 1.587841, disc_loss 0.796428\n",
      "batch 210, gen_loss 1.659772, disc_loss 0.700012\n",
      "batch 211, gen_loss 1.702036, disc_loss 0.711206\n",
      "batch 212, gen_loss 1.654423, disc_loss 0.781137\n",
      "batch 213, gen_loss 1.739356, disc_loss 0.758380\n",
      "batch 214, gen_loss 1.710175, disc_loss 0.720540\n",
      "batch 215, gen_loss 1.666661, disc_loss 0.704928\n",
      "batch 216, gen_loss 1.658935, disc_loss 0.692677\n",
      "batch 217, gen_loss 1.758014, disc_loss 0.794315\n",
      "batch 218, gen_loss 1.800399, disc_loss 0.656930\n",
      "batch 219, gen_loss 1.860943, disc_loss 0.741936\n",
      "batch 220, gen_loss 1.700548, disc_loss 0.725064\n",
      "batch 221, gen_loss 1.506092, disc_loss 0.723027\n",
      "batch 222, gen_loss 1.521497, disc_loss 0.719887\n",
      "batch 223, gen_loss 1.720882, disc_loss 0.754101\n",
      "batch 224, gen_loss 1.734207, disc_loss 0.747376\n",
      "batch 225, gen_loss 1.754611, disc_loss 0.744173\n",
      "batch 226, gen_loss 1.763426, disc_loss 0.656543\n",
      "batch 227, gen_loss 1.637554, disc_loss 0.685112\n",
      "batch 228, gen_loss 1.587528, disc_loss 0.675245\n",
      "batch 229, gen_loss 1.608269, disc_loss 0.741051\n",
      "batch 230, gen_loss 1.726964, disc_loss 0.679764\n",
      "batch 231, gen_loss 1.658184, disc_loss 0.792890\n",
      "batch 232, gen_loss 1.699923, disc_loss 0.727244\n",
      "batch 233, gen_loss 1.604089, disc_loss 0.687252\n",
      "batch 234, gen_loss 1.607664, disc_loss 0.744605\n",
      "Time for epoch40is 7.648228645324707 sec\n",
      "batch 0, gen_loss 1.462881, disc_loss 0.747384\n",
      "batch 1, gen_loss 1.461764, disc_loss 0.758494\n",
      "batch 2, gen_loss 1.581982, disc_loss 0.748116\n",
      "batch 3, gen_loss 1.741048, disc_loss 0.740792\n",
      "batch 4, gen_loss 1.783842, disc_loss 0.799261\n",
      "batch 5, gen_loss 1.722660, disc_loss 0.771803\n",
      "batch 6, gen_loss 1.584176, disc_loss 0.799047\n",
      "batch 7, gen_loss 1.440982, disc_loss 0.773871\n",
      "batch 8, gen_loss 1.406266, disc_loss 0.807763\n",
      "batch 9, gen_loss 1.405886, disc_loss 0.775375\n",
      "batch 10, gen_loss 1.732567, disc_loss 0.836726\n",
      "batch 11, gen_loss 1.936369, disc_loss 0.890179\n",
      "batch 12, gen_loss 1.799513, disc_loss 0.870264\n",
      "batch 13, gen_loss 1.671531, disc_loss 0.843160\n",
      "batch 14, gen_loss 1.308486, disc_loss 0.938513\n",
      "batch 15, gen_loss 1.236783, disc_loss 0.910497\n",
      "batch 16, gen_loss 1.403946, disc_loss 0.831736\n",
      "batch 17, gen_loss 1.479202, disc_loss 0.893906\n",
      "batch 18, gen_loss 1.652903, disc_loss 0.960793\n",
      "batch 19, gen_loss 1.779000, disc_loss 0.898812\n",
      "batch 20, gen_loss 1.588053, disc_loss 0.955489\n",
      "batch 21, gen_loss 1.540777, disc_loss 0.923006\n",
      "batch 22, gen_loss 1.354606, disc_loss 0.945832\n",
      "batch 23, gen_loss 1.263265, disc_loss 0.936003\n",
      "batch 24, gen_loss 1.342844, disc_loss 0.937881\n",
      "batch 25, gen_loss 1.519894, disc_loss 0.945866\n",
      "batch 26, gen_loss 1.553203, disc_loss 0.977337\n",
      "batch 27, gen_loss 1.629973, disc_loss 1.038513\n",
      "batch 28, gen_loss 1.454571, disc_loss 0.984104\n",
      "batch 29, gen_loss 1.469839, disc_loss 0.969655\n",
      "batch 30, gen_loss 1.371411, disc_loss 1.007843\n",
      "batch 31, gen_loss 1.431020, disc_loss 0.969991\n",
      "batch 32, gen_loss 1.404266, disc_loss 0.985359\n",
      "batch 33, gen_loss 1.573521, disc_loss 0.915926\n",
      "batch 34, gen_loss 1.517978, disc_loss 0.898951\n",
      "batch 35, gen_loss 1.591085, disc_loss 0.965155\n",
      "batch 36, gen_loss 1.498870, disc_loss 0.847632\n",
      "batch 37, gen_loss 1.552485, disc_loss 0.831562\n",
      "batch 38, gen_loss 1.568777, disc_loss 0.874299\n",
      "batch 39, gen_loss 1.511468, disc_loss 0.923795\n",
      "batch 40, gen_loss 1.559078, disc_loss 0.839731\n",
      "batch 41, gen_loss 1.534230, disc_loss 0.875518\n",
      "batch 42, gen_loss 1.557870, disc_loss 0.851112\n",
      "batch 43, gen_loss 1.561615, disc_loss 0.928605\n",
      "batch 44, gen_loss 1.520405, disc_loss 0.849185\n",
      "batch 45, gen_loss 1.685772, disc_loss 0.814569\n",
      "batch 46, gen_loss 1.534929, disc_loss 0.922324\n",
      "batch 47, gen_loss 1.410700, disc_loss 0.894091\n",
      "batch 48, gen_loss 1.435605, disc_loss 0.837196\n",
      "batch 49, gen_loss 1.436468, disc_loss 0.829617\n",
      "batch 50, gen_loss 1.688683, disc_loss 0.766312\n",
      "batch 51, gen_loss 1.839777, disc_loss 0.904295\n",
      "batch 52, gen_loss 1.750604, disc_loss 0.831187\n",
      "batch 53, gen_loss 1.576890, disc_loss 0.861223\n",
      "batch 54, gen_loss 1.478997, disc_loss 0.831787\n",
      "batch 55, gen_loss 1.400891, disc_loss 0.815843\n",
      "batch 56, gen_loss 1.491985, disc_loss 0.759046\n",
      "batch 57, gen_loss 1.624769, disc_loss 0.814723\n",
      "batch 58, gen_loss 1.710052, disc_loss 0.840979\n",
      "batch 59, gen_loss 1.803656, disc_loss 0.780507\n",
      "batch 60, gen_loss 1.719300, disc_loss 0.813022\n",
      "batch 61, gen_loss 1.606566, disc_loss 0.856514\n",
      "batch 62, gen_loss 1.549482, disc_loss 0.838302\n",
      "batch 63, gen_loss 1.442763, disc_loss 0.756676\n",
      "batch 64, gen_loss 1.432976, disc_loss 0.829922\n",
      "batch 65, gen_loss 1.443348, disc_loss 0.826993\n",
      "batch 66, gen_loss 1.632878, disc_loss 0.842284\n",
      "batch 67, gen_loss 1.764498, disc_loss 0.787933\n",
      "batch 68, gen_loss 1.753817, disc_loss 0.871993\n",
      "batch 69, gen_loss 1.664447, disc_loss 0.902128\n",
      "batch 70, gen_loss 1.531353, disc_loss 0.761928\n",
      "batch 71, gen_loss 1.479239, disc_loss 0.838567\n",
      "batch 72, gen_loss 1.421398, disc_loss 0.863625\n",
      "batch 73, gen_loss 1.567553, disc_loss 0.794750\n",
      "batch 74, gen_loss 1.613641, disc_loss 0.870813\n",
      "batch 75, gen_loss 1.821516, disc_loss 0.904448\n",
      "batch 76, gen_loss 1.655068, disc_loss 0.854431\n",
      "batch 77, gen_loss 1.487810, disc_loss 0.818947\n",
      "batch 78, gen_loss 1.425159, disc_loss 0.830348\n",
      "batch 79, gen_loss 1.482391, disc_loss 0.852966\n",
      "batch 80, gen_loss 1.476811, disc_loss 0.912878\n",
      "batch 81, gen_loss 1.535794, disc_loss 0.873463\n",
      "batch 82, gen_loss 1.621180, disc_loss 0.880477\n",
      "batch 83, gen_loss 1.588089, disc_loss 0.860507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 84, gen_loss 1.540269, disc_loss 0.884512\n",
      "batch 85, gen_loss 1.484543, disc_loss 0.818602\n",
      "batch 86, gen_loss 1.553579, disc_loss 0.854055\n",
      "batch 87, gen_loss 1.456259, disc_loss 0.886238\n",
      "batch 88, gen_loss 1.418357, disc_loss 1.019552\n",
      "batch 89, gen_loss 1.462381, disc_loss 0.936367\n",
      "batch 90, gen_loss 1.460772, disc_loss 0.842538\n",
      "batch 91, gen_loss 1.608560, disc_loss 0.975222\n",
      "batch 92, gen_loss 1.557989, disc_loss 0.858509\n",
      "batch 93, gen_loss 1.549793, disc_loss 0.862620\n",
      "batch 94, gen_loss 1.512056, disc_loss 0.834649\n",
      "batch 95, gen_loss 1.402137, disc_loss 0.838820\n",
      "batch 96, gen_loss 1.472934, disc_loss 0.859676\n",
      "batch 97, gen_loss 1.632169, disc_loss 0.939143\n",
      "batch 98, gen_loss 1.599327, disc_loss 0.866096\n",
      "batch 99, gen_loss 1.539982, disc_loss 0.813428\n",
      "batch 100, gen_loss 1.479143, disc_loss 0.815233\n",
      "batch 101, gen_loss 1.454692, disc_loss 0.788484\n",
      "batch 102, gen_loss 1.752244, disc_loss 0.777554\n",
      "batch 103, gen_loss 1.768312, disc_loss 0.843067\n",
      "batch 104, gen_loss 1.710767, disc_loss 0.795532\n",
      "batch 105, gen_loss 1.544639, disc_loss 0.823694\n",
      "batch 106, gen_loss 1.580171, disc_loss 0.742185\n",
      "batch 107, gen_loss 1.441043, disc_loss 0.833524\n",
      "batch 108, gen_loss 1.527984, disc_loss 0.751684\n",
      "batch 109, gen_loss 1.568455, disc_loss 0.719465\n",
      "batch 110, gen_loss 1.767856, disc_loss 0.741315\n",
      "batch 111, gen_loss 1.724778, disc_loss 0.761777\n",
      "batch 112, gen_loss 1.766206, disc_loss 0.776472\n",
      "batch 113, gen_loss 1.579375, disc_loss 0.768033\n",
      "batch 114, gen_loss 1.484532, disc_loss 0.794853\n",
      "batch 115, gen_loss 1.621907, disc_loss 0.730258\n",
      "batch 116, gen_loss 1.584145, disc_loss 0.742000\n",
      "batch 117, gen_loss 1.772214, disc_loss 0.675620\n",
      "batch 118, gen_loss 1.701580, disc_loss 0.703385\n",
      "batch 119, gen_loss 1.877368, disc_loss 0.693854\n",
      "batch 120, gen_loss 1.784525, disc_loss 0.703065\n",
      "batch 121, gen_loss 1.742066, disc_loss 0.778210\n",
      "batch 122, gen_loss 1.716122, disc_loss 0.773541\n",
      "batch 123, gen_loss 1.660309, disc_loss 0.665517\n",
      "batch 124, gen_loss 1.705016, disc_loss 0.614451\n",
      "batch 125, gen_loss 1.735972, disc_loss 0.663564\n",
      "batch 126, gen_loss 1.861756, disc_loss 0.733818\n",
      "batch 127, gen_loss 1.767995, disc_loss 0.741955\n",
      "batch 128, gen_loss 1.732542, disc_loss 0.689289\n",
      "batch 129, gen_loss 1.720978, disc_loss 0.752869\n",
      "batch 130, gen_loss 1.597251, disc_loss 0.771638\n",
      "batch 131, gen_loss 1.559942, disc_loss 0.787607\n",
      "batch 132, gen_loss 1.433789, disc_loss 0.756145\n",
      "batch 133, gen_loss 1.465816, disc_loss 0.756261\n",
      "batch 134, gen_loss 1.540417, disc_loss 0.738999\n",
      "batch 135, gen_loss 1.770576, disc_loss 0.802898\n",
      "batch 136, gen_loss 1.840537, disc_loss 0.737979\n",
      "batch 137, gen_loss 1.767926, disc_loss 0.750193\n",
      "batch 138, gen_loss 1.832908, disc_loss 0.707152\n",
      "batch 139, gen_loss 1.735286, disc_loss 0.854888\n",
      "batch 140, gen_loss 1.629238, disc_loss 0.770162\n",
      "batch 141, gen_loss 1.421830, disc_loss 0.864931\n",
      "batch 142, gen_loss 1.633077, disc_loss 0.767541\n",
      "batch 143, gen_loss 1.525821, disc_loss 0.865516\n",
      "batch 144, gen_loss 1.500773, disc_loss 0.823175\n",
      "batch 145, gen_loss 1.556834, disc_loss 0.837792\n",
      "batch 146, gen_loss 1.594402, disc_loss 0.806397\n",
      "batch 147, gen_loss 1.613161, disc_loss 0.857686\n",
      "batch 148, gen_loss 1.587070, disc_loss 0.893995\n",
      "batch 149, gen_loss 1.536908, disc_loss 0.879108\n",
      "batch 150, gen_loss 1.343510, disc_loss 0.866716\n",
      "batch 151, gen_loss 1.431235, disc_loss 0.885104\n",
      "batch 152, gen_loss 1.575929, disc_loss 0.913833\n",
      "batch 153, gen_loss 1.682171, disc_loss 0.749117\n",
      "batch 154, gen_loss 1.603389, disc_loss 0.857535\n",
      "batch 155, gen_loss 1.587461, disc_loss 0.907013\n",
      "batch 156, gen_loss 1.511688, disc_loss 0.960119\n",
      "batch 157, gen_loss 1.338874, disc_loss 0.944304\n",
      "batch 158, gen_loss 1.321563, disc_loss 0.915583\n",
      "batch 159, gen_loss 1.287507, disc_loss 1.003832\n",
      "batch 160, gen_loss 1.471638, disc_loss 0.867781\n",
      "batch 161, gen_loss 1.440033, disc_loss 0.979119\n",
      "batch 162, gen_loss 1.672168, disc_loss 1.059813\n",
      "batch 163, gen_loss 1.553002, disc_loss 0.971038\n",
      "batch 164, gen_loss 1.573332, disc_loss 0.954778\n",
      "batch 165, gen_loss 1.464501, disc_loss 1.066126\n",
      "batch 166, gen_loss 1.211303, disc_loss 0.986580\n",
      "batch 167, gen_loss 1.262080, disc_loss 0.974707\n",
      "batch 168, gen_loss 1.152604, disc_loss 1.025138\n",
      "batch 169, gen_loss 1.440514, disc_loss 0.881065\n",
      "batch 170, gen_loss 1.654894, disc_loss 1.059863\n",
      "batch 171, gen_loss 1.686754, disc_loss 1.054494\n",
      "batch 172, gen_loss 1.640538, disc_loss 0.908110\n",
      "batch 173, gen_loss 1.419938, disc_loss 0.907601\n",
      "batch 174, gen_loss 1.261512, disc_loss 0.895043\n",
      "batch 175, gen_loss 1.346864, disc_loss 0.962843\n",
      "batch 176, gen_loss 1.442955, disc_loss 0.920456\n",
      "batch 177, gen_loss 1.521620, disc_loss 0.890033\n",
      "batch 178, gen_loss 1.701004, disc_loss 0.895665\n",
      "batch 179, gen_loss 1.641779, disc_loss 0.880817\n",
      "batch 180, gen_loss 1.671945, disc_loss 0.864197\n",
      "batch 181, gen_loss 1.509944, disc_loss 0.874334\n",
      "batch 182, gen_loss 1.499814, disc_loss 0.937963\n",
      "batch 183, gen_loss 1.469986, disc_loss 0.871760\n",
      "batch 184, gen_loss 1.537642, disc_loss 0.804855\n",
      "batch 185, gen_loss 1.529160, disc_loss 0.809457\n",
      "batch 186, gen_loss 1.688547, disc_loss 0.812826\n",
      "batch 187, gen_loss 1.682028, disc_loss 0.847781\n",
      "batch 188, gen_loss 1.629603, disc_loss 0.812757\n",
      "batch 189, gen_loss 1.620519, disc_loss 0.749227\n",
      "batch 190, gen_loss 1.613300, disc_loss 0.764874\n",
      "batch 191, gen_loss 1.527616, disc_loss 0.797844\n",
      "batch 192, gen_loss 1.600521, disc_loss 0.775132\n",
      "batch 193, gen_loss 1.587388, disc_loss 0.810891\n",
      "batch 194, gen_loss 1.584877, disc_loss 0.830242\n",
      "batch 195, gen_loss 1.590299, disc_loss 0.788895\n",
      "batch 196, gen_loss 1.595953, disc_loss 0.893763\n",
      "batch 197, gen_loss 1.451725, disc_loss 0.804765\n",
      "batch 198, gen_loss 1.697515, disc_loss 0.812434\n",
      "batch 199, gen_loss 1.737608, disc_loss 0.819929\n",
      "batch 200, gen_loss 1.581854, disc_loss 0.796019\n",
      "batch 201, gen_loss 1.595175, disc_loss 0.801268\n",
      "batch 202, gen_loss 1.614585, disc_loss 0.724453\n",
      "batch 203, gen_loss 1.643403, disc_loss 0.745442\n",
      "batch 204, gen_loss 1.733473, disc_loss 0.800719\n",
      "batch 205, gen_loss 1.786481, disc_loss 0.835010\n",
      "batch 206, gen_loss 1.854140, disc_loss 0.810450\n",
      "batch 207, gen_loss 1.619647, disc_loss 0.829480\n",
      "batch 208, gen_loss 1.678613, disc_loss 0.766672\n",
      "batch 209, gen_loss 1.669237, disc_loss 0.750235\n",
      "batch 210, gen_loss 1.659032, disc_loss 0.706521\n",
      "batch 211, gen_loss 1.627508, disc_loss 0.810066\n",
      "batch 212, gen_loss 1.780850, disc_loss 0.724958\n",
      "batch 213, gen_loss 1.802239, disc_loss 0.816546\n",
      "batch 214, gen_loss 1.680007, disc_loss 0.824081\n",
      "batch 215, gen_loss 1.660246, disc_loss 0.822875\n",
      "batch 216, gen_loss 1.556462, disc_loss 0.803358\n",
      "batch 217, gen_loss 1.663071, disc_loss 0.723926\n",
      "batch 218, gen_loss 1.480883, disc_loss 0.801717\n",
      "batch 219, gen_loss 1.723928, disc_loss 0.868919\n",
      "batch 220, gen_loss 1.726457, disc_loss 0.804087\n",
      "batch 221, gen_loss 1.730537, disc_loss 0.806481\n",
      "batch 222, gen_loss 1.648407, disc_loss 0.811649\n",
      "batch 223, gen_loss 1.649993, disc_loss 0.842626\n",
      "batch 224, gen_loss 1.618531, disc_loss 0.863215\n",
      "batch 225, gen_loss 1.652373, disc_loss 0.849394\n",
      "batch 226, gen_loss 1.562830, disc_loss 0.752611\n",
      "batch 227, gen_loss 1.559399, disc_loss 0.808581\n",
      "batch 228, gen_loss 1.570350, disc_loss 0.883752\n",
      "batch 229, gen_loss 1.674180, disc_loss 0.861908\n",
      "batch 230, gen_loss 1.617563, disc_loss 0.860271\n",
      "batch 231, gen_loss 1.590396, disc_loss 0.931184\n",
      "batch 232, gen_loss 1.398178, disc_loss 0.898102\n",
      "batch 233, gen_loss 1.450785, disc_loss 0.804633\n",
      "batch 234, gen_loss 1.706459, disc_loss 0.899495\n",
      "Time for epoch41is 7.58870530128479 sec\n",
      "batch 0, gen_loss 1.667632, disc_loss 0.831719\n",
      "batch 1, gen_loss 1.551216, disc_loss 0.826584\n",
      "batch 2, gen_loss 1.612566, disc_loss 0.902358\n",
      "batch 3, gen_loss 1.677757, disc_loss 0.823951\n",
      "batch 4, gen_loss 1.554669, disc_loss 0.892271\n",
      "batch 5, gen_loss 1.601740, disc_loss 0.807216\n",
      "batch 6, gen_loss 1.731586, disc_loss 0.864895\n",
      "batch 7, gen_loss 1.658700, disc_loss 0.909687\n",
      "batch 8, gen_loss 1.586477, disc_loss 0.814239\n",
      "batch 9, gen_loss 1.543501, disc_loss 0.943265\n",
      "batch 10, gen_loss 1.503607, disc_loss 0.923805\n",
      "batch 11, gen_loss 1.489468, disc_loss 0.760581\n",
      "batch 12, gen_loss 1.620434, disc_loss 0.845548\n",
      "batch 13, gen_loss 1.769174, disc_loss 0.760040\n",
      "batch 14, gen_loss 1.813262, disc_loss 0.897522\n",
      "batch 15, gen_loss 1.771272, disc_loss 0.848765\n",
      "batch 16, gen_loss 1.612861, disc_loss 0.907707\n",
      "batch 17, gen_loss 1.529519, disc_loss 0.790863\n",
      "batch 18, gen_loss 1.403429, disc_loss 0.842264\n",
      "batch 19, gen_loss 1.595119, disc_loss 0.858346\n",
      "batch 20, gen_loss 1.742098, disc_loss 0.728829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 21, gen_loss 1.858736, disc_loss 0.801456\n",
      "batch 22, gen_loss 1.790882, disc_loss 0.898910\n",
      "batch 23, gen_loss 1.670038, disc_loss 0.783293\n",
      "batch 24, gen_loss 1.597600, disc_loss 0.724074\n",
      "batch 25, gen_loss 1.647286, disc_loss 0.900700\n",
      "batch 26, gen_loss 1.739945, disc_loss 0.725915\n",
      "batch 27, gen_loss 1.647948, disc_loss 0.832605\n",
      "batch 28, gen_loss 1.573228, disc_loss 0.830411\n",
      "batch 29, gen_loss 1.569522, disc_loss 0.759292\n",
      "batch 30, gen_loss 1.543408, disc_loss 0.825841\n",
      "batch 31, gen_loss 1.655492, disc_loss 0.799142\n",
      "batch 32, gen_loss 1.691163, disc_loss 0.742169\n",
      "batch 33, gen_loss 1.726715, disc_loss 0.803919\n",
      "batch 34, gen_loss 1.760343, disc_loss 0.769512\n",
      "batch 35, gen_loss 1.722382, disc_loss 0.798850\n",
      "batch 36, gen_loss 1.602867, disc_loss 0.731617\n",
      "batch 37, gen_loss 1.595693, disc_loss 0.819401\n",
      "batch 38, gen_loss 1.645280, disc_loss 0.788652\n",
      "batch 39, gen_loss 1.564973, disc_loss 0.798052\n",
      "batch 40, gen_loss 1.695314, disc_loss 0.766312\n",
      "batch 41, gen_loss 1.689326, disc_loss 0.715672\n",
      "batch 42, gen_loss 1.654437, disc_loss 0.792612\n",
      "batch 43, gen_loss 1.710386, disc_loss 0.693189\n",
      "batch 44, gen_loss 1.747706, disc_loss 0.714196\n",
      "batch 45, gen_loss 1.908333, disc_loss 0.717671\n",
      "batch 46, gen_loss 1.859019, disc_loss 0.795813\n",
      "batch 47, gen_loss 1.674637, disc_loss 0.748991\n",
      "batch 48, gen_loss 1.621173, disc_loss 0.716735\n",
      "batch 49, gen_loss 1.577138, disc_loss 0.730098\n",
      "batch 50, gen_loss 1.740752, disc_loss 0.696866\n",
      "batch 51, gen_loss 1.839357, disc_loss 0.669199\n",
      "batch 52, gen_loss 1.885388, disc_loss 0.760368\n",
      "batch 53, gen_loss 1.882820, disc_loss 0.733250\n",
      "batch 54, gen_loss 1.749982, disc_loss 0.723157\n",
      "batch 55, gen_loss 1.753252, disc_loss 0.732453\n",
      "batch 56, gen_loss 1.834324, disc_loss 0.683769\n",
      "batch 57, gen_loss 1.778908, disc_loss 0.775027\n",
      "batch 58, gen_loss 1.769065, disc_loss 0.645311\n",
      "batch 59, gen_loss 1.741956, disc_loss 0.703334\n",
      "batch 60, gen_loss 1.689445, disc_loss 0.714222\n",
      "batch 61, gen_loss 1.830581, disc_loss 0.708859\n",
      "batch 62, gen_loss 1.824902, disc_loss 0.733276\n",
      "batch 63, gen_loss 1.664883, disc_loss 0.762801\n",
      "batch 64, gen_loss 1.704887, disc_loss 0.715894\n",
      "batch 65, gen_loss 1.762205, disc_loss 0.660774\n",
      "batch 66, gen_loss 1.829068, disc_loss 0.739109\n",
      "batch 67, gen_loss 1.874510, disc_loss 0.668135\n",
      "batch 68, gen_loss 1.913781, disc_loss 0.665763\n",
      "batch 69, gen_loss 1.865392, disc_loss 0.707073\n",
      "batch 70, gen_loss 1.892420, disc_loss 0.662396\n",
      "batch 71, gen_loss 1.846292, disc_loss 0.696128\n",
      "batch 72, gen_loss 1.772263, disc_loss 0.692031\n",
      "batch 73, gen_loss 1.734727, disc_loss 0.736893\n",
      "batch 74, gen_loss 1.798675, disc_loss 0.684236\n",
      "batch 75, gen_loss 1.764668, disc_loss 0.724218\n",
      "batch 76, gen_loss 1.786175, disc_loss 0.651909\n",
      "batch 77, gen_loss 1.920608, disc_loss 0.587019\n",
      "batch 78, gen_loss 1.982246, disc_loss 0.829793\n",
      "batch 79, gen_loss 1.945240, disc_loss 0.694236\n",
      "batch 80, gen_loss 1.841669, disc_loss 0.700888\n",
      "batch 81, gen_loss 1.715514, disc_loss 0.717832\n",
      "batch 82, gen_loss 1.664865, disc_loss 0.762349\n",
      "batch 83, gen_loss 1.654619, disc_loss 0.724215\n",
      "batch 84, gen_loss 1.885460, disc_loss 0.679161\n",
      "batch 85, gen_loss 1.990966, disc_loss 0.760402\n",
      "batch 86, gen_loss 1.955635, disc_loss 0.733238\n",
      "batch 87, gen_loss 1.902496, disc_loss 0.719921\n",
      "batch 88, gen_loss 1.889040, disc_loss 0.758555\n",
      "batch 89, gen_loss 1.605334, disc_loss 0.792064\n",
      "batch 90, gen_loss 1.641716, disc_loss 0.725335\n",
      "batch 91, gen_loss 1.755915, disc_loss 0.761453\n",
      "batch 92, gen_loss 1.778241, disc_loss 0.736116\n",
      "batch 93, gen_loss 1.878456, disc_loss 0.712911\n",
      "batch 94, gen_loss 1.961815, disc_loss 0.720290\n",
      "batch 95, gen_loss 1.743738, disc_loss 0.778018\n",
      "batch 96, gen_loss 1.593571, disc_loss 0.818447\n",
      "batch 97, gen_loss 1.611208, disc_loss 0.810274\n",
      "batch 98, gen_loss 1.683871, disc_loss 0.798518\n",
      "batch 99, gen_loss 1.677438, disc_loss 0.687630\n",
      "batch 100, gen_loss 1.891906, disc_loss 0.796071\n",
      "batch 101, gen_loss 1.763708, disc_loss 0.799678\n",
      "batch 102, gen_loss 1.751150, disc_loss 0.697569\n",
      "batch 103, gen_loss 1.667074, disc_loss 0.840408\n",
      "batch 104, gen_loss 1.717246, disc_loss 0.780742\n",
      "batch 105, gen_loss 1.576892, disc_loss 0.810707\n",
      "batch 106, gen_loss 1.604404, disc_loss 0.738415\n",
      "batch 107, gen_loss 1.725850, disc_loss 0.856153\n",
      "batch 108, gen_loss 1.715428, disc_loss 0.825579\n",
      "batch 109, gen_loss 1.784535, disc_loss 0.775838\n",
      "batch 110, gen_loss 1.582962, disc_loss 0.939146\n",
      "batch 111, gen_loss 1.702932, disc_loss 0.876489\n",
      "batch 112, gen_loss 1.559868, disc_loss 0.887965\n",
      "batch 113, gen_loss 1.560374, disc_loss 0.943651\n",
      "batch 114, gen_loss 1.522754, disc_loss 0.860290\n",
      "batch 115, gen_loss 1.508049, disc_loss 0.966978\n",
      "batch 116, gen_loss 1.486291, disc_loss 0.913622\n",
      "batch 117, gen_loss 1.549141, disc_loss 0.888313\n",
      "batch 118, gen_loss 1.630406, disc_loss 1.017369\n",
      "batch 119, gen_loss 1.703602, disc_loss 0.883625\n",
      "batch 120, gen_loss 1.592043, disc_loss 0.909358\n",
      "batch 121, gen_loss 1.640471, disc_loss 1.041002\n",
      "batch 122, gen_loss 1.463356, disc_loss 1.033693\n",
      "batch 123, gen_loss 1.435349, disc_loss 0.925170\n",
      "batch 124, gen_loss 1.410820, disc_loss 1.008381\n",
      "batch 125, gen_loss 1.401866, disc_loss 1.058539\n",
      "batch 126, gen_loss 1.510390, disc_loss 1.004732\n",
      "batch 127, gen_loss 1.514668, disc_loss 1.085393\n",
      "batch 128, gen_loss 1.505001, disc_loss 0.959143\n",
      "batch 129, gen_loss 1.505401, disc_loss 1.016006\n",
      "batch 130, gen_loss 1.533777, disc_loss 0.974395\n",
      "batch 131, gen_loss 1.386233, disc_loss 0.989736\n",
      "batch 132, gen_loss 1.481905, disc_loss 0.967543\n",
      "batch 133, gen_loss 1.490675, disc_loss 0.928070\n",
      "batch 134, gen_loss 1.669330, disc_loss 0.864460\n",
      "batch 135, gen_loss 1.519184, disc_loss 0.947838\n",
      "batch 136, gen_loss 1.581310, disc_loss 0.843660\n",
      "batch 137, gen_loss 1.374830, disc_loss 0.934337\n",
      "batch 138, gen_loss 1.450138, disc_loss 0.924218\n",
      "batch 139, gen_loss 1.569959, disc_loss 0.814488\n",
      "batch 140, gen_loss 1.569923, disc_loss 0.820985\n",
      "batch 141, gen_loss 1.547244, disc_loss 0.870289\n",
      "batch 142, gen_loss 1.615839, disc_loss 0.859110\n",
      "batch 143, gen_loss 1.626138, disc_loss 0.794119\n",
      "batch 144, gen_loss 1.561226, disc_loss 0.844603\n",
      "batch 145, gen_loss 1.555423, disc_loss 0.799694\n",
      "batch 146, gen_loss 1.493810, disc_loss 0.743244\n",
      "batch 147, gen_loss 1.639270, disc_loss 0.851006\n",
      "batch 148, gen_loss 1.681048, disc_loss 0.781167\n",
      "batch 149, gen_loss 1.610767, disc_loss 0.794063\n",
      "batch 150, gen_loss 1.676283, disc_loss 0.751882\n",
      "batch 151, gen_loss 1.624165, disc_loss 0.758263\n",
      "batch 152, gen_loss 1.707389, disc_loss 0.765301\n",
      "batch 153, gen_loss 1.658267, disc_loss 0.859066\n",
      "batch 154, gen_loss 1.554401, disc_loss 0.816204\n",
      "batch 155, gen_loss 1.627062, disc_loss 0.701671\n",
      "batch 156, gen_loss 1.554685, disc_loss 0.804620\n",
      "batch 157, gen_loss 1.566347, disc_loss 0.669008\n",
      "batch 158, gen_loss 1.579359, disc_loss 0.846907\n",
      "batch 159, gen_loss 1.750328, disc_loss 0.790697\n",
      "batch 160, gen_loss 1.640654, disc_loss 0.852159\n",
      "batch 161, gen_loss 1.728347, disc_loss 0.852490\n",
      "batch 162, gen_loss 1.612017, disc_loss 0.838376\n",
      "batch 163, gen_loss 1.416664, disc_loss 0.775933\n",
      "batch 164, gen_loss 1.494931, disc_loss 0.884659\n",
      "batch 165, gen_loss 1.579069, disc_loss 0.851506\n",
      "batch 166, gen_loss 1.712333, disc_loss 0.819513\n",
      "batch 167, gen_loss 1.711908, disc_loss 0.823466\n",
      "batch 168, gen_loss 1.759063, disc_loss 0.744393\n",
      "batch 169, gen_loss 1.749675, disc_loss 0.932778\n",
      "batch 170, gen_loss 1.787519, disc_loss 0.792408\n",
      "batch 171, gen_loss 1.569859, disc_loss 0.846198\n",
      "batch 172, gen_loss 1.596659, disc_loss 0.905007\n",
      "batch 173, gen_loss 1.566359, disc_loss 0.961054\n",
      "batch 174, gen_loss 1.588108, disc_loss 0.957139\n",
      "batch 175, gen_loss 1.757406, disc_loss 0.934445\n",
      "batch 176, gen_loss 1.765778, disc_loss 0.969503\n",
      "batch 177, gen_loss 1.645465, disc_loss 0.974998\n",
      "batch 178, gen_loss 1.690847, disc_loss 1.028154\n",
      "batch 179, gen_loss 1.562652, disc_loss 0.968699\n",
      "batch 180, gen_loss 1.622158, disc_loss 0.933320\n",
      "batch 181, gen_loss 1.722254, disc_loss 0.967313\n",
      "batch 182, gen_loss 1.663458, disc_loss 0.981559\n",
      "batch 183, gen_loss 1.730147, disc_loss 0.917171\n",
      "batch 184, gen_loss 1.672280, disc_loss 0.901007\n",
      "batch 185, gen_loss 1.644550, disc_loss 0.886173\n",
      "batch 186, gen_loss 1.728081, disc_loss 0.866156\n",
      "batch 187, gen_loss 1.764886, disc_loss 0.919998\n",
      "batch 188, gen_loss 1.813475, disc_loss 1.085216\n",
      "batch 189, gen_loss 1.659086, disc_loss 1.051135\n",
      "batch 190, gen_loss 1.671624, disc_loss 0.933297\n",
      "batch 191, gen_loss 1.494104, disc_loss 0.999780\n",
      "batch 192, gen_loss 1.492125, disc_loss 1.038926\n",
      "batch 193, gen_loss 1.635319, disc_loss 0.972655\n",
      "batch 194, gen_loss 1.822885, disc_loss 1.007576\n",
      "batch 195, gen_loss 1.705154, disc_loss 1.084054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 196, gen_loss 1.650321, disc_loss 1.055720\n",
      "batch 197, gen_loss 1.375192, disc_loss 1.019491\n",
      "batch 198, gen_loss 1.356780, disc_loss 1.005920\n",
      "batch 199, gen_loss 1.421586, disc_loss 0.950805\n",
      "batch 200, gen_loss 1.481340, disc_loss 1.037166\n",
      "batch 201, gen_loss 1.608194, disc_loss 0.937992\n",
      "batch 202, gen_loss 1.730006, disc_loss 0.943518\n",
      "batch 203, gen_loss 1.683828, disc_loss 1.025106\n",
      "batch 204, gen_loss 1.498081, disc_loss 1.071392\n",
      "batch 205, gen_loss 1.302231, disc_loss 1.084343\n",
      "batch 206, gen_loss 1.225073, disc_loss 0.981020\n",
      "batch 207, gen_loss 1.333739, disc_loss 0.923983\n",
      "batch 208, gen_loss 1.548816, disc_loss 0.941374\n",
      "batch 209, gen_loss 1.588752, disc_loss 0.911860\n",
      "batch 210, gen_loss 1.642844, disc_loss 0.985651\n",
      "batch 211, gen_loss 1.596477, disc_loss 0.881426\n",
      "batch 212, gen_loss 1.532567, disc_loss 0.843455\n",
      "batch 213, gen_loss 1.433410, disc_loss 0.861170\n",
      "batch 214, gen_loss 1.507596, disc_loss 0.889804\n",
      "batch 215, gen_loss 1.487488, disc_loss 0.900621\n",
      "batch 216, gen_loss 1.703885, disc_loss 0.797957\n",
      "batch 217, gen_loss 1.709279, disc_loss 0.926006\n",
      "batch 218, gen_loss 1.718184, disc_loss 0.971317\n",
      "batch 219, gen_loss 1.524628, disc_loss 0.844098\n",
      "batch 220, gen_loss 1.263850, disc_loss 0.883047\n",
      "batch 221, gen_loss 1.324933, disc_loss 0.896415\n",
      "batch 222, gen_loss 1.496122, disc_loss 0.757788\n",
      "batch 223, gen_loss 1.703582, disc_loss 0.776267\n",
      "batch 224, gen_loss 1.872550, disc_loss 0.823311\n",
      "batch 225, gen_loss 1.871941, disc_loss 0.737215\n",
      "batch 226, gen_loss 1.689451, disc_loss 0.688637\n",
      "batch 227, gen_loss 1.602851, disc_loss 0.758986\n",
      "batch 228, gen_loss 1.566993, disc_loss 0.871725\n",
      "batch 229, gen_loss 1.510037, disc_loss 0.737748\n",
      "batch 230, gen_loss 1.450331, disc_loss 0.893947\n",
      "batch 231, gen_loss 1.540088, disc_loss 0.711674\n",
      "batch 232, gen_loss 1.487980, disc_loss 0.849487\n",
      "batch 233, gen_loss 1.688324, disc_loss 0.748889\n",
      "batch 234, gen_loss 1.659432, disc_loss 0.740271\n",
      "Time for epoch42is 7.658392429351807 sec\n",
      "batch 0, gen_loss 1.584502, disc_loss 0.826680\n",
      "batch 1, gen_loss 1.599540, disc_loss 0.740278\n",
      "batch 2, gen_loss 1.431887, disc_loss 0.842475\n",
      "batch 3, gen_loss 1.521624, disc_loss 0.675172\n",
      "batch 4, gen_loss 1.626102, disc_loss 0.798076\n",
      "batch 5, gen_loss 1.801237, disc_loss 0.659540\n",
      "batch 6, gen_loss 1.692236, disc_loss 0.702613\n",
      "batch 7, gen_loss 1.747300, disc_loss 0.731093\n",
      "batch 8, gen_loss 1.711393, disc_loss 0.786561\n",
      "batch 9, gen_loss 1.557817, disc_loss 0.795148\n",
      "batch 10, gen_loss 1.585067, disc_loss 0.782242\n",
      "batch 11, gen_loss 1.460784, disc_loss 0.842480\n",
      "batch 12, gen_loss 1.540417, disc_loss 0.835760\n",
      "batch 13, gen_loss 1.598584, disc_loss 0.800186\n",
      "batch 14, gen_loss 1.694241, disc_loss 0.784464\n",
      "batch 15, gen_loss 1.620956, disc_loss 0.873343\n",
      "batch 16, gen_loss 1.703390, disc_loss 0.729083\n",
      "batch 17, gen_loss 1.658862, disc_loss 0.836769\n",
      "batch 18, gen_loss 1.474247, disc_loss 0.790256\n",
      "batch 19, gen_loss 1.533234, disc_loss 0.811727\n",
      "batch 20, gen_loss 1.551126, disc_loss 0.849660\n",
      "batch 21, gen_loss 1.615579, disc_loss 0.925129\n",
      "batch 22, gen_loss 1.744068, disc_loss 0.978198\n",
      "batch 23, gen_loss 1.578482, disc_loss 0.879391\n",
      "batch 24, gen_loss 1.500730, disc_loss 0.972188\n",
      "batch 25, gen_loss 1.392735, disc_loss 0.893721\n",
      "batch 26, gen_loss 1.681170, disc_loss 0.811915\n",
      "batch 27, gen_loss 1.720865, disc_loss 0.845923\n",
      "batch 28, gen_loss 1.645605, disc_loss 0.886586\n",
      "batch 29, gen_loss 1.678731, disc_loss 0.882177\n",
      "batch 30, gen_loss 1.529637, disc_loss 0.970959\n",
      "batch 31, gen_loss 1.428526, disc_loss 0.884407\n",
      "batch 32, gen_loss 1.351449, disc_loss 0.839107\n",
      "batch 33, gen_loss 1.363807, disc_loss 0.877552\n",
      "batch 34, gen_loss 1.525249, disc_loss 0.887530\n",
      "batch 35, gen_loss 1.504197, disc_loss 0.858398\n",
      "batch 36, gen_loss 1.707803, disc_loss 0.883726\n",
      "batch 37, gen_loss 1.625108, disc_loss 0.856771\n",
      "batch 38, gen_loss 1.558623, disc_loss 0.923765\n",
      "batch 39, gen_loss 1.505611, disc_loss 0.829861\n",
      "batch 40, gen_loss 1.438232, disc_loss 0.943036\n",
      "batch 41, gen_loss 1.421949, disc_loss 0.865546\n",
      "batch 42, gen_loss 1.381183, disc_loss 0.953815\n",
      "batch 43, gen_loss 1.462167, disc_loss 0.872994\n",
      "batch 44, gen_loss 1.576964, disc_loss 0.947661\n",
      "batch 45, gen_loss 1.621907, disc_loss 0.835192\n",
      "batch 46, gen_loss 1.528282, disc_loss 0.880532\n",
      "batch 47, gen_loss 1.416737, disc_loss 0.952709\n",
      "batch 48, gen_loss 1.335287, disc_loss 0.890519\n",
      "batch 49, gen_loss 1.449475, disc_loss 0.850260\n",
      "batch 50, gen_loss 1.522742, disc_loss 0.959401\n",
      "batch 51, gen_loss 1.562579, disc_loss 0.944576\n",
      "batch 52, gen_loss 1.542844, disc_loss 0.894943\n",
      "batch 53, gen_loss 1.482595, disc_loss 0.965485\n",
      "batch 54, gen_loss 1.599622, disc_loss 0.919040\n",
      "batch 55, gen_loss 1.335908, disc_loss 0.927533\n",
      "batch 56, gen_loss 1.361021, disc_loss 0.937170\n",
      "batch 57, gen_loss 1.393455, disc_loss 0.916553\n",
      "batch 58, gen_loss 1.341900, disc_loss 0.943018\n",
      "batch 59, gen_loss 1.498549, disc_loss 0.913754\n",
      "batch 60, gen_loss 1.583147, disc_loss 0.849556\n",
      "batch 61, gen_loss 1.637207, disc_loss 0.889216\n",
      "batch 62, gen_loss 1.521380, disc_loss 0.915203\n",
      "batch 63, gen_loss 1.328470, disc_loss 0.981122\n",
      "batch 64, gen_loss 1.261736, disc_loss 0.897267\n",
      "batch 65, gen_loss 1.382300, disc_loss 0.966538\n",
      "batch 66, gen_loss 1.474547, disc_loss 1.036709\n",
      "batch 67, gen_loss 1.641941, disc_loss 1.000105\n",
      "batch 68, gen_loss 1.509085, disc_loss 0.875769\n",
      "batch 69, gen_loss 1.344972, disc_loss 0.942019\n",
      "batch 70, gen_loss 1.427878, disc_loss 0.976462\n",
      "batch 71, gen_loss 1.447368, disc_loss 1.008092\n",
      "batch 72, gen_loss 1.568690, disc_loss 0.846190\n",
      "batch 73, gen_loss 1.628345, disc_loss 1.000773\n",
      "batch 74, gen_loss 1.607255, disc_loss 0.969274\n",
      "batch 75, gen_loss 1.538179, disc_loss 0.986008\n",
      "batch 76, gen_loss 1.380888, disc_loss 0.948061\n",
      "batch 77, gen_loss 1.310981, disc_loss 0.992747\n",
      "batch 78, gen_loss 1.417997, disc_loss 0.953685\n",
      "batch 79, gen_loss 1.537014, disc_loss 0.940352\n",
      "batch 80, gen_loss 1.712054, disc_loss 0.957830\n",
      "batch 81, gen_loss 1.518049, disc_loss 1.009312\n",
      "batch 82, gen_loss 1.438094, disc_loss 0.912284\n",
      "batch 83, gen_loss 1.255599, disc_loss 0.921741\n",
      "batch 84, gen_loss 1.384665, disc_loss 0.920561\n",
      "batch 85, gen_loss 1.683780, disc_loss 0.808812\n",
      "batch 86, gen_loss 1.779201, disc_loss 0.794393\n",
      "batch 87, gen_loss 1.762059, disc_loss 0.941576\n",
      "batch 88, gen_loss 1.676808, disc_loss 0.818544\n",
      "batch 89, gen_loss 1.408836, disc_loss 0.872219\n",
      "batch 90, gen_loss 1.415739, disc_loss 0.865590\n",
      "batch 91, gen_loss 1.513179, disc_loss 0.833132\n",
      "batch 92, gen_loss 1.561653, disc_loss 0.870414\n",
      "batch 93, gen_loss 1.787262, disc_loss 0.855401\n",
      "batch 94, gen_loss 1.792574, disc_loss 0.818957\n",
      "batch 95, gen_loss 1.780317, disc_loss 0.785957\n",
      "batch 96, gen_loss 1.521406, disc_loss 0.934579\n",
      "batch 97, gen_loss 1.414914, disc_loss 0.876772\n",
      "batch 98, gen_loss 1.367249, disc_loss 0.902814\n",
      "batch 99, gen_loss 1.549989, disc_loss 0.854018\n",
      "batch 100, gen_loss 1.856810, disc_loss 0.768578\n",
      "batch 101, gen_loss 1.783228, disc_loss 0.842506\n",
      "batch 102, gen_loss 1.665538, disc_loss 0.797720\n",
      "batch 103, gen_loss 1.464777, disc_loss 0.861738\n",
      "batch 104, gen_loss 1.457548, disc_loss 0.955139\n",
      "batch 105, gen_loss 1.490681, disc_loss 0.786763\n",
      "batch 106, gen_loss 1.543527, disc_loss 0.744308\n",
      "batch 107, gen_loss 1.653345, disc_loss 0.863401\n",
      "batch 108, gen_loss 1.651335, disc_loss 0.725087\n",
      "batch 109, gen_loss 1.668519, disc_loss 0.744936\n",
      "batch 110, gen_loss 1.700545, disc_loss 0.883611\n",
      "batch 111, gen_loss 1.703901, disc_loss 0.843412\n",
      "batch 112, gen_loss 1.653930, disc_loss 0.727192\n",
      "batch 113, gen_loss 1.439333, disc_loss 0.866081\n",
      "batch 114, gen_loss 1.461316, disc_loss 0.897082\n",
      "batch 115, gen_loss 1.564555, disc_loss 0.832796\n",
      "batch 116, gen_loss 1.802716, disc_loss 0.730481\n",
      "batch 117, gen_loss 1.743428, disc_loss 0.782580\n",
      "batch 118, gen_loss 1.760795, disc_loss 0.800697\n",
      "batch 119, gen_loss 1.577508, disc_loss 0.829932\n",
      "batch 120, gen_loss 1.556802, disc_loss 0.869241\n",
      "batch 121, gen_loss 1.401373, disc_loss 0.819100\n",
      "batch 122, gen_loss 1.481027, disc_loss 0.838596\n",
      "batch 123, gen_loss 1.643757, disc_loss 0.877926\n",
      "batch 124, gen_loss 1.595682, disc_loss 0.811683\n",
      "batch 125, gen_loss 1.588518, disc_loss 0.801081\n",
      "batch 126, gen_loss 1.484323, disc_loss 0.815609\n",
      "batch 127, gen_loss 1.617353, disc_loss 0.828868\n",
      "batch 128, gen_loss 1.695109, disc_loss 0.776438\n",
      "batch 129, gen_loss 1.678681, disc_loss 0.752128\n",
      "batch 130, gen_loss 1.725375, disc_loss 0.821555\n",
      "batch 131, gen_loss 1.558231, disc_loss 0.825220\n",
      "batch 132, gen_loss 1.541758, disc_loss 0.832023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 133, gen_loss 1.458254, disc_loss 0.791339\n",
      "batch 134, gen_loss 1.626803, disc_loss 0.790039\n",
      "batch 135, gen_loss 1.734567, disc_loss 0.853064\n",
      "batch 136, gen_loss 1.727080, disc_loss 0.778208\n",
      "batch 137, gen_loss 1.671950, disc_loss 0.829000\n",
      "batch 138, gen_loss 1.583475, disc_loss 0.748511\n",
      "batch 139, gen_loss 1.635630, disc_loss 0.762399\n",
      "batch 140, gen_loss 1.559134, disc_loss 0.837559\n",
      "batch 141, gen_loss 1.651903, disc_loss 0.839229\n",
      "batch 142, gen_loss 1.543021, disc_loss 0.811660\n",
      "batch 143, gen_loss 1.731866, disc_loss 0.676082\n",
      "batch 144, gen_loss 1.860508, disc_loss 0.757327\n",
      "batch 145, gen_loss 1.619763, disc_loss 0.785998\n",
      "batch 146, gen_loss 1.608356, disc_loss 0.753939\n",
      "batch 147, gen_loss 1.672041, disc_loss 0.670640\n",
      "batch 148, gen_loss 1.731159, disc_loss 0.762926\n",
      "batch 149, gen_loss 1.836232, disc_loss 0.735072\n",
      "batch 150, gen_loss 1.761492, disc_loss 0.759924\n",
      "batch 151, gen_loss 1.637252, disc_loss 0.752728\n",
      "batch 152, gen_loss 1.670317, disc_loss 0.696789\n",
      "batch 153, gen_loss 1.567855, disc_loss 0.706382\n",
      "batch 154, gen_loss 1.883636, disc_loss 0.728360\n",
      "batch 155, gen_loss 2.008975, disc_loss 0.779045\n",
      "batch 156, gen_loss 1.944789, disc_loss 0.737729\n",
      "batch 157, gen_loss 1.953125, disc_loss 0.757330\n",
      "batch 158, gen_loss 1.778220, disc_loss 0.677408\n",
      "batch 159, gen_loss 1.710063, disc_loss 0.718293\n",
      "batch 160, gen_loss 1.580393, disc_loss 0.729537\n",
      "batch 161, gen_loss 1.632598, disc_loss 0.783791\n",
      "batch 162, gen_loss 1.726601, disc_loss 0.808001\n",
      "batch 163, gen_loss 1.724758, disc_loss 0.754641\n",
      "batch 164, gen_loss 1.911447, disc_loss 0.789801\n",
      "batch 165, gen_loss 1.865171, disc_loss 0.735508\n",
      "batch 166, gen_loss 1.747526, disc_loss 0.746376\n",
      "batch 167, gen_loss 1.694066, disc_loss 0.899748\n",
      "batch 168, gen_loss 1.633922, disc_loss 0.823260\n",
      "batch 169, gen_loss 1.695667, disc_loss 0.758894\n",
      "batch 170, gen_loss 1.747778, disc_loss 0.742834\n",
      "batch 171, gen_loss 1.957052, disc_loss 0.782315\n",
      "batch 172, gen_loss 1.906700, disc_loss 0.776861\n",
      "batch 173, gen_loss 1.888086, disc_loss 0.802147\n",
      "batch 174, gen_loss 1.720483, disc_loss 0.739188\n",
      "batch 175, gen_loss 1.553109, disc_loss 0.874373\n",
      "batch 176, gen_loss 1.728766, disc_loss 0.810858\n",
      "batch 177, gen_loss 1.860359, disc_loss 0.785235\n",
      "batch 178, gen_loss 2.002844, disc_loss 0.791848\n",
      "batch 179, gen_loss 1.954734, disc_loss 0.808212\n",
      "batch 180, gen_loss 1.817638, disc_loss 0.771027\n",
      "batch 181, gen_loss 1.724672, disc_loss 0.959114\n",
      "batch 182, gen_loss 1.657085, disc_loss 0.808061\n",
      "batch 183, gen_loss 1.646854, disc_loss 0.964407\n",
      "batch 184, gen_loss 1.386512, disc_loss 0.881312\n",
      "batch 185, gen_loss 1.461899, disc_loss 0.895810\n",
      "batch 186, gen_loss 1.843883, disc_loss 0.880303\n",
      "batch 187, gen_loss 2.078629, disc_loss 0.880994\n",
      "batch 188, gen_loss 2.208204, disc_loss 0.913136\n",
      "batch 189, gen_loss 2.060254, disc_loss 0.839347\n",
      "batch 190, gen_loss 1.603274, disc_loss 0.891255\n",
      "batch 191, gen_loss 1.454863, disc_loss 0.914522\n",
      "batch 192, gen_loss 1.598710, disc_loss 0.877565\n",
      "batch 193, gen_loss 1.840773, disc_loss 0.863086\n",
      "batch 194, gen_loss 1.900623, disc_loss 0.970424\n",
      "batch 195, gen_loss 1.820352, disc_loss 0.870538\n",
      "batch 196, gen_loss 1.695131, disc_loss 0.849464\n",
      "batch 197, gen_loss 1.643291, disc_loss 0.848835\n",
      "batch 198, gen_loss 1.813025, disc_loss 0.829954\n",
      "batch 199, gen_loss 1.948672, disc_loss 0.944945\n",
      "batch 200, gen_loss 1.752695, disc_loss 0.867288\n",
      "batch 201, gen_loss 1.706524, disc_loss 0.703243\n",
      "batch 202, gen_loss 1.805891, disc_loss 0.782071\n",
      "batch 203, gen_loss 1.771245, disc_loss 0.722066\n",
      "batch 204, gen_loss 1.825338, disc_loss 0.864405\n",
      "batch 205, gen_loss 1.855088, disc_loss 0.813639\n",
      "batch 206, gen_loss 1.876017, disc_loss 0.690191\n",
      "batch 207, gen_loss 1.657642, disc_loss 0.803907\n",
      "batch 208, gen_loss 1.750990, disc_loss 0.808407\n",
      "batch 209, gen_loss 1.766032, disc_loss 0.729949\n",
      "batch 210, gen_loss 1.921630, disc_loss 0.764301\n",
      "batch 211, gen_loss 2.045033, disc_loss 0.746913\n",
      "batch 212, gen_loss 1.885247, disc_loss 0.816450\n",
      "batch 213, gen_loss 1.690227, disc_loss 0.799605\n",
      "batch 214, gen_loss 1.444395, disc_loss 0.773522\n",
      "batch 215, gen_loss 1.635735, disc_loss 0.806528\n",
      "batch 216, gen_loss 1.880909, disc_loss 0.684800\n",
      "batch 217, gen_loss 2.025844, disc_loss 0.728168\n",
      "batch 218, gen_loss 1.982112, disc_loss 0.714596\n",
      "batch 219, gen_loss 2.040359, disc_loss 0.692793\n",
      "batch 220, gen_loss 1.961433, disc_loss 0.664327\n",
      "batch 221, gen_loss 1.704730, disc_loss 0.681549\n",
      "batch 222, gen_loss 1.757530, disc_loss 0.754473\n",
      "batch 223, gen_loss 1.727111, disc_loss 0.737872\n",
      "batch 224, gen_loss 1.777067, disc_loss 0.704376\n",
      "batch 225, gen_loss 1.964332, disc_loss 0.685352\n",
      "batch 226, gen_loss 2.004716, disc_loss 0.766626\n",
      "batch 227, gen_loss 1.810699, disc_loss 0.690207\n",
      "batch 228, gen_loss 1.922067, disc_loss 0.673444\n",
      "batch 229, gen_loss 1.878330, disc_loss 0.719269\n",
      "batch 230, gen_loss 1.956925, disc_loss 0.652188\n",
      "batch 231, gen_loss 1.705866, disc_loss 0.695667\n",
      "batch 232, gen_loss 1.816346, disc_loss 0.805802\n",
      "batch 233, gen_loss 1.863438, disc_loss 0.783230\n",
      "batch 234, gen_loss 2.090977, disc_loss 0.776439\n",
      "Time for epoch43is 7.629443168640137 sec\n",
      "batch 0, gen_loss 1.909787, disc_loss 0.760624\n",
      "batch 1, gen_loss 1.996669, disc_loss 0.688588\n",
      "batch 2, gen_loss 1.759556, disc_loss 0.796778\n",
      "batch 3, gen_loss 1.653786, disc_loss 0.816022\n",
      "batch 4, gen_loss 1.633643, disc_loss 0.687973\n",
      "batch 5, gen_loss 1.661471, disc_loss 0.863831\n",
      "batch 6, gen_loss 1.845750, disc_loss 0.721944\n",
      "batch 7, gen_loss 1.967610, disc_loss 0.816729\n",
      "batch 8, gen_loss 2.088073, disc_loss 0.719293\n",
      "batch 9, gen_loss 1.890368, disc_loss 0.751612\n",
      "batch 10, gen_loss 1.598813, disc_loss 0.903461\n",
      "batch 11, gen_loss 1.495632, disc_loss 0.804208\n",
      "batch 12, gen_loss 1.857141, disc_loss 0.697040\n",
      "batch 13, gen_loss 2.085347, disc_loss 0.772718\n",
      "batch 14, gen_loss 1.982626, disc_loss 0.752879\n",
      "batch 15, gen_loss 1.797621, disc_loss 0.857868\n",
      "batch 16, gen_loss 1.692386, disc_loss 0.816406\n",
      "batch 17, gen_loss 1.590551, disc_loss 0.841554\n",
      "batch 18, gen_loss 1.656888, disc_loss 0.855838\n",
      "batch 19, gen_loss 1.719562, disc_loss 0.820064\n",
      "batch 20, gen_loss 1.800079, disc_loss 0.773079\n",
      "batch 21, gen_loss 1.816962, disc_loss 0.877146\n",
      "batch 22, gen_loss 1.908513, disc_loss 0.787437\n",
      "batch 23, gen_loss 1.690608, disc_loss 0.814620\n",
      "batch 24, gen_loss 1.559540, disc_loss 0.894604\n",
      "batch 25, gen_loss 1.611805, disc_loss 0.824484\n",
      "batch 26, gen_loss 1.776329, disc_loss 0.766467\n",
      "batch 27, gen_loss 1.760277, disc_loss 0.829972\n",
      "batch 28, gen_loss 1.895246, disc_loss 0.823598\n",
      "batch 29, gen_loss 1.870205, disc_loss 0.801486\n",
      "batch 30, gen_loss 1.684838, disc_loss 0.887872\n",
      "batch 31, gen_loss 1.684653, disc_loss 0.836773\n",
      "batch 32, gen_loss 1.590748, disc_loss 0.870660\n",
      "batch 33, gen_loss 1.708477, disc_loss 0.793736\n",
      "batch 34, gen_loss 1.902720, disc_loss 0.823114\n",
      "batch 35, gen_loss 1.801594, disc_loss 0.923678\n",
      "batch 36, gen_loss 1.819046, disc_loss 0.806908\n",
      "batch 37, gen_loss 1.498319, disc_loss 0.866995\n",
      "batch 38, gen_loss 1.503664, disc_loss 0.957208\n",
      "batch 39, gen_loss 1.597266, disc_loss 0.886981\n",
      "batch 40, gen_loss 1.655398, disc_loss 1.001561\n",
      "batch 41, gen_loss 1.893213, disc_loss 0.909920\n",
      "batch 42, gen_loss 1.862661, disc_loss 0.921488\n",
      "batch 43, gen_loss 1.675298, disc_loss 0.815133\n",
      "batch 44, gen_loss 1.677920, disc_loss 0.818774\n",
      "batch 45, gen_loss 1.539760, disc_loss 0.954689\n",
      "batch 46, gen_loss 1.537271, disc_loss 0.847067\n",
      "batch 47, gen_loss 1.794100, disc_loss 0.748347\n",
      "batch 48, gen_loss 1.733868, disc_loss 0.885432\n",
      "batch 49, gen_loss 1.775675, disc_loss 0.865333\n",
      "batch 50, gen_loss 1.675976, disc_loss 0.993718\n",
      "batch 51, gen_loss 1.439316, disc_loss 0.952416\n",
      "batch 52, gen_loss 1.388781, disc_loss 0.853104\n",
      "batch 53, gen_loss 1.548317, disc_loss 0.835839\n",
      "batch 54, gen_loss 1.835544, disc_loss 0.799348\n",
      "batch 55, gen_loss 1.844988, disc_loss 0.838500\n",
      "batch 56, gen_loss 1.851977, disc_loss 0.717396\n",
      "batch 57, gen_loss 1.696511, disc_loss 0.756851\n",
      "batch 58, gen_loss 1.563184, disc_loss 0.748154\n",
      "batch 59, gen_loss 1.456666, disc_loss 0.780299\n",
      "batch 60, gen_loss 1.561924, disc_loss 0.830082\n",
      "batch 61, gen_loss 1.825796, disc_loss 0.748401\n",
      "batch 62, gen_loss 1.799865, disc_loss 0.848111\n",
      "batch 63, gen_loss 1.863126, disc_loss 0.774783\n",
      "batch 64, gen_loss 1.739863, disc_loss 0.751548\n",
      "batch 65, gen_loss 1.423705, disc_loss 0.863458\n",
      "batch 66, gen_loss 1.367532, disc_loss 0.904260\n",
      "batch 67, gen_loss 1.561627, disc_loss 0.803726\n",
      "batch 68, gen_loss 1.773892, disc_loss 0.724928\n",
      "batch 69, gen_loss 1.706218, disc_loss 0.902727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 70, gen_loss 1.816592, disc_loss 0.836634\n",
      "batch 71, gen_loss 1.622180, disc_loss 0.808496\n",
      "batch 72, gen_loss 1.442689, disc_loss 0.875803\n",
      "batch 73, gen_loss 1.465627, disc_loss 0.821264\n",
      "batch 74, gen_loss 1.536254, disc_loss 0.804624\n",
      "batch 75, gen_loss 1.555449, disc_loss 0.778540\n",
      "batch 76, gen_loss 1.691018, disc_loss 0.875554\n",
      "batch 77, gen_loss 1.681530, disc_loss 0.827916\n",
      "batch 78, gen_loss 1.634487, disc_loss 0.902514\n",
      "batch 79, gen_loss 1.527879, disc_loss 0.829818\n",
      "batch 80, gen_loss 1.345947, disc_loss 0.890257\n",
      "batch 81, gen_loss 1.426175, disc_loss 0.808654\n",
      "batch 82, gen_loss 1.524587, disc_loss 0.904013\n",
      "batch 83, gen_loss 1.739436, disc_loss 0.807744\n",
      "batch 84, gen_loss 1.707970, disc_loss 0.887505\n",
      "batch 85, gen_loss 1.683065, disc_loss 0.854629\n",
      "batch 86, gen_loss 1.549084, disc_loss 0.854700\n",
      "batch 87, gen_loss 1.472942, disc_loss 0.946988\n",
      "batch 88, gen_loss 1.486083, disc_loss 0.910373\n",
      "batch 89, gen_loss 1.380278, disc_loss 0.912687\n",
      "batch 90, gen_loss 1.524643, disc_loss 0.865166\n",
      "batch 91, gen_loss 1.671398, disc_loss 0.869295\n",
      "batch 92, gen_loss 1.572191, disc_loss 0.919572\n",
      "batch 93, gen_loss 1.548403, disc_loss 0.898904\n",
      "batch 94, gen_loss 1.564212, disc_loss 0.938602\n",
      "batch 95, gen_loss 1.509614, disc_loss 0.916614\n",
      "batch 96, gen_loss 1.453565, disc_loss 0.947394\n",
      "batch 97, gen_loss 1.510523, disc_loss 1.006909\n",
      "batch 98, gen_loss 1.631162, disc_loss 0.918646\n",
      "batch 99, gen_loss 1.629839, disc_loss 0.905237\n",
      "batch 100, gen_loss 1.528315, disc_loss 1.046423\n",
      "batch 101, gen_loss 1.626362, disc_loss 0.945439\n",
      "batch 102, gen_loss 1.516435, disc_loss 1.025436\n",
      "batch 103, gen_loss 1.388769, disc_loss 1.118801\n",
      "batch 104, gen_loss 1.336038, disc_loss 1.066108\n",
      "batch 105, gen_loss 1.297389, disc_loss 1.023792\n",
      "batch 106, gen_loss 1.402605, disc_loss 1.001316\n",
      "batch 107, gen_loss 1.598946, disc_loss 1.040020\n",
      "batch 108, gen_loss 1.529651, disc_loss 1.058816\n",
      "batch 109, gen_loss 1.484414, disc_loss 1.158509\n",
      "batch 110, gen_loss 1.355335, disc_loss 1.122337\n",
      "batch 111, gen_loss 1.377242, disc_loss 1.158119\n",
      "batch 112, gen_loss 1.307993, disc_loss 1.090226\n",
      "batch 113, gen_loss 1.345043, disc_loss 1.115592\n",
      "batch 114, gen_loss 1.404377, disc_loss 1.076446\n",
      "batch 115, gen_loss 1.415339, disc_loss 1.072141\n",
      "batch 116, gen_loss 1.655929, disc_loss 1.129189\n",
      "batch 117, gen_loss 1.450257, disc_loss 1.101681\n",
      "batch 118, gen_loss 1.381369, disc_loss 1.062341\n",
      "batch 119, gen_loss 1.328232, disc_loss 1.041231\n",
      "batch 120, gen_loss 1.452263, disc_loss 1.079779\n",
      "batch 121, gen_loss 1.337782, disc_loss 1.036100\n",
      "batch 122, gen_loss 1.456155, disc_loss 1.158715\n",
      "batch 123, gen_loss 1.452149, disc_loss 1.100390\n",
      "batch 124, gen_loss 1.518915, disc_loss 0.994007\n",
      "batch 125, gen_loss 1.635318, disc_loss 0.891610\n",
      "batch 126, gen_loss 1.707174, disc_loss 0.995275\n",
      "batch 127, gen_loss 1.298692, disc_loss 0.991857\n",
      "batch 128, gen_loss 1.400786, disc_loss 0.913731\n",
      "batch 129, gen_loss 1.455638, disc_loss 1.044625\n",
      "batch 130, gen_loss 1.566259, disc_loss 1.009965\n",
      "batch 131, gen_loss 1.440841, disc_loss 1.023560\n",
      "batch 132, gen_loss 1.346771, disc_loss 0.975805\n",
      "batch 133, gen_loss 1.393500, disc_loss 0.911477\n",
      "batch 134, gen_loss 1.419388, disc_loss 0.979679\n",
      "batch 135, gen_loss 1.506716, disc_loss 1.084335\n",
      "batch 136, gen_loss 1.429646, disc_loss 0.919912\n",
      "batch 137, gen_loss 1.575191, disc_loss 0.920860\n",
      "batch 138, gen_loss 1.625262, disc_loss 0.855734\n",
      "batch 139, gen_loss 1.541030, disc_loss 0.921278\n",
      "batch 140, gen_loss 1.490016, disc_loss 0.896400\n",
      "batch 141, gen_loss 1.342216, disc_loss 0.938627\n",
      "batch 142, gen_loss 1.298651, disc_loss 0.894695\n",
      "batch 143, gen_loss 1.630574, disc_loss 0.807612\n",
      "batch 144, gen_loss 1.937122, disc_loss 0.873069\n",
      "batch 145, gen_loss 1.797425, disc_loss 0.919525\n",
      "batch 146, gen_loss 1.634285, disc_loss 0.844752\n",
      "batch 147, gen_loss 1.373540, disc_loss 0.882694\n",
      "batch 148, gen_loss 1.410679, disc_loss 0.904940\n",
      "batch 149, gen_loss 1.510326, disc_loss 0.823736\n",
      "batch 150, gen_loss 1.618779, disc_loss 0.794581\n",
      "batch 151, gen_loss 1.767459, disc_loss 0.895704\n",
      "batch 152, gen_loss 1.838242, disc_loss 0.791292\n",
      "batch 153, gen_loss 1.812619, disc_loss 0.779619\n",
      "batch 154, gen_loss 1.572681, disc_loss 0.751030\n",
      "batch 155, gen_loss 1.580132, disc_loss 0.772171\n",
      "batch 156, gen_loss 1.716659, disc_loss 0.771439\n",
      "batch 157, gen_loss 1.716974, disc_loss 0.817181\n",
      "batch 158, gen_loss 1.797553, disc_loss 0.724693\n",
      "batch 159, gen_loss 1.696434, disc_loss 0.760885\n",
      "batch 160, gen_loss 1.657732, disc_loss 0.724412\n",
      "batch 161, gen_loss 1.721879, disc_loss 0.801798\n",
      "batch 162, gen_loss 1.630272, disc_loss 0.745190\n",
      "batch 163, gen_loss 1.823619, disc_loss 0.692068\n",
      "batch 164, gen_loss 1.895042, disc_loss 0.722639\n",
      "batch 165, gen_loss 1.725392, disc_loss 0.810266\n",
      "batch 166, gen_loss 1.590973, disc_loss 0.735201\n",
      "batch 167, gen_loss 1.566303, disc_loss 0.744809\n",
      "batch 168, gen_loss 1.717100, disc_loss 0.683420\n",
      "batch 169, gen_loss 1.783128, disc_loss 0.692274\n",
      "batch 170, gen_loss 1.892675, disc_loss 0.699847\n",
      "batch 171, gen_loss 1.828446, disc_loss 0.758210\n",
      "batch 172, gen_loss 1.752826, disc_loss 0.721900\n",
      "batch 173, gen_loss 1.666390, disc_loss 0.779536\n",
      "batch 174, gen_loss 1.532169, disc_loss 0.710405\n",
      "batch 175, gen_loss 1.673105, disc_loss 0.747262\n",
      "batch 176, gen_loss 1.879863, disc_loss 0.717658\n",
      "batch 177, gen_loss 1.929606, disc_loss 0.749178\n",
      "batch 178, gen_loss 1.801735, disc_loss 0.713863\n",
      "batch 179, gen_loss 1.763386, disc_loss 0.842237\n",
      "batch 180, gen_loss 1.451016, disc_loss 0.865145\n",
      "batch 181, gen_loss 1.504808, disc_loss 0.777148\n",
      "batch 182, gen_loss 1.666978, disc_loss 0.803613\n",
      "batch 183, gen_loss 1.625359, disc_loss 0.836228\n",
      "batch 184, gen_loss 1.774548, disc_loss 0.837003\n",
      "batch 185, gen_loss 1.713821, disc_loss 0.832575\n",
      "batch 186, gen_loss 1.611549, disc_loss 0.809226\n",
      "batch 187, gen_loss 1.558616, disc_loss 0.800907\n",
      "batch 188, gen_loss 1.359508, disc_loss 0.906485\n",
      "batch 189, gen_loss 1.583781, disc_loss 0.848882\n",
      "batch 190, gen_loss 1.442142, disc_loss 0.877114\n",
      "batch 191, gen_loss 1.579424, disc_loss 1.006676\n",
      "batch 192, gen_loss 1.651262, disc_loss 0.927206\n",
      "batch 193, gen_loss 1.495704, disc_loss 0.883922\n",
      "batch 194, gen_loss 1.500768, disc_loss 0.923384\n",
      "batch 195, gen_loss 1.485682, disc_loss 1.079920\n",
      "batch 196, gen_loss 1.381167, disc_loss 0.866236\n",
      "batch 197, gen_loss 1.540738, disc_loss 1.024165\n",
      "batch 198, gen_loss 1.494744, disc_loss 0.909664\n",
      "batch 199, gen_loss 1.588340, disc_loss 1.014678\n",
      "batch 200, gen_loss 1.411364, disc_loss 0.983705\n",
      "batch 201, gen_loss 1.440214, disc_loss 0.911022\n",
      "batch 202, gen_loss 1.414585, disc_loss 1.093971\n",
      "batch 203, gen_loss 1.488789, disc_loss 1.098005\n",
      "batch 204, gen_loss 1.414317, disc_loss 1.003770\n",
      "batch 205, gen_loss 1.467827, disc_loss 0.978816\n",
      "batch 206, gen_loss 1.408122, disc_loss 0.935665\n",
      "batch 207, gen_loss 1.415651, disc_loss 1.045418\n",
      "batch 208, gen_loss 1.590745, disc_loss 0.993804\n",
      "batch 209, gen_loss 1.460349, disc_loss 1.090570\n",
      "batch 210, gen_loss 1.463253, disc_loss 1.048211\n",
      "batch 211, gen_loss 1.358036, disc_loss 1.021285\n",
      "batch 212, gen_loss 1.386163, disc_loss 0.899399\n",
      "batch 213, gen_loss 1.530154, disc_loss 0.944888\n",
      "batch 214, gen_loss 1.582040, disc_loss 0.986686\n",
      "batch 215, gen_loss 1.565713, disc_loss 0.956787\n",
      "batch 216, gen_loss 1.584830, disc_loss 0.884725\n",
      "batch 217, gen_loss 1.555391, disc_loss 0.831887\n",
      "batch 218, gen_loss 1.525599, disc_loss 0.921422\n",
      "batch 219, gen_loss 1.577080, disc_loss 0.850236\n",
      "batch 220, gen_loss 1.588815, disc_loss 0.796275\n",
      "batch 221, gen_loss 1.516232, disc_loss 0.875402\n",
      "batch 222, gen_loss 1.494401, disc_loss 0.856272\n",
      "batch 223, gen_loss 1.567860, disc_loss 0.817349\n",
      "batch 224, gen_loss 1.674726, disc_loss 0.792495\n",
      "batch 225, gen_loss 1.682197, disc_loss 0.788195\n",
      "batch 226, gen_loss 1.715025, disc_loss 0.806150\n",
      "batch 227, gen_loss 1.684369, disc_loss 0.836126\n",
      "batch 228, gen_loss 1.617418, disc_loss 0.758124\n",
      "batch 229, gen_loss 1.589178, disc_loss 0.728165\n",
      "batch 230, gen_loss 1.674299, disc_loss 0.674570\n",
      "batch 231, gen_loss 1.680843, disc_loss 0.721027\n",
      "batch 232, gen_loss 1.640037, disc_loss 0.805121\n",
      "batch 233, gen_loss 1.735657, disc_loss 0.738226\n",
      "batch 234, gen_loss 1.751980, disc_loss 0.612856\n",
      "Time for epoch44is 7.624282121658325 sec\n",
      "batch 0, gen_loss 1.905731, disc_loss 0.698832\n",
      "batch 1, gen_loss 1.914552, disc_loss 0.681781\n",
      "batch 2, gen_loss 1.775105, disc_loss 0.673663\n",
      "batch 3, gen_loss 1.813378, disc_loss 0.738875\n",
      "batch 4, gen_loss 1.683915, disc_loss 0.707978\n",
      "batch 5, gen_loss 1.674820, disc_loss 0.673367\n",
      "batch 6, gen_loss 1.733731, disc_loss 0.706260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 7, gen_loss 1.799872, disc_loss 0.618609\n",
      "batch 8, gen_loss 1.647105, disc_loss 0.714983\n",
      "batch 9, gen_loss 1.728279, disc_loss 0.700926\n",
      "batch 10, gen_loss 1.737938, disc_loss 0.708103\n",
      "batch 11, gen_loss 1.785848, disc_loss 0.716641\n",
      "batch 12, gen_loss 1.730409, disc_loss 0.695546\n",
      "batch 13, gen_loss 1.782053, disc_loss 0.736009\n",
      "batch 14, gen_loss 1.816795, disc_loss 0.662259\n",
      "batch 15, gen_loss 1.646753, disc_loss 0.744897\n",
      "batch 16, gen_loss 1.659350, disc_loss 0.696660\n",
      "batch 17, gen_loss 1.739992, disc_loss 0.715116\n",
      "batch 18, gen_loss 1.633524, disc_loss 0.771718\n",
      "batch 19, gen_loss 1.719564, disc_loss 0.659078\n",
      "batch 20, gen_loss 1.625682, disc_loss 0.743200\n",
      "batch 21, gen_loss 1.671675, disc_loss 0.720420\n",
      "batch 22, gen_loss 1.730170, disc_loss 0.777130\n",
      "batch 23, gen_loss 1.714751, disc_loss 0.674978\n",
      "batch 24, gen_loss 1.643380, disc_loss 0.755453\n",
      "batch 25, gen_loss 1.789519, disc_loss 0.715421\n",
      "batch 26, gen_loss 1.703312, disc_loss 0.681059\n",
      "batch 27, gen_loss 1.681057, disc_loss 0.764132\n",
      "batch 28, gen_loss 1.671166, disc_loss 0.752540\n",
      "batch 29, gen_loss 1.654466, disc_loss 0.764476\n",
      "batch 30, gen_loss 1.551764, disc_loss 0.791510\n",
      "batch 31, gen_loss 1.669375, disc_loss 0.739045\n",
      "batch 32, gen_loss 1.607366, disc_loss 0.802687\n",
      "batch 33, gen_loss 1.572437, disc_loss 0.832091\n",
      "batch 34, gen_loss 1.566617, disc_loss 0.860950\n",
      "batch 35, gen_loss 1.693978, disc_loss 0.805905\n",
      "batch 36, gen_loss 1.578222, disc_loss 0.932842\n",
      "batch 37, gen_loss 1.657999, disc_loss 0.807562\n",
      "batch 38, gen_loss 1.716931, disc_loss 0.884450\n",
      "batch 39, gen_loss 1.780598, disc_loss 0.782770\n",
      "batch 40, gen_loss 1.654273, disc_loss 0.905289\n",
      "batch 41, gen_loss 1.767875, disc_loss 0.843076\n",
      "batch 42, gen_loss 1.502654, disc_loss 0.858049\n",
      "batch 43, gen_loss 1.537455, disc_loss 0.859142\n",
      "batch 44, gen_loss 1.629811, disc_loss 0.893566\n",
      "batch 45, gen_loss 1.569631, disc_loss 0.921866\n",
      "batch 46, gen_loss 1.612807, disc_loss 0.961456\n",
      "batch 47, gen_loss 1.607764, disc_loss 0.927974\n",
      "batch 48, gen_loss 1.804032, disc_loss 0.949608\n",
      "batch 49, gen_loss 1.715930, disc_loss 0.965145\n",
      "batch 50, gen_loss 1.418644, disc_loss 0.944845\n",
      "batch 51, gen_loss 1.369818, disc_loss 0.914141\n",
      "batch 52, gen_loss 1.464623, disc_loss 1.012014\n",
      "batch 53, gen_loss 1.609932, disc_loss 0.898016\n",
      "batch 54, gen_loss 1.878421, disc_loss 0.965838\n",
      "batch 55, gen_loss 1.704190, disc_loss 1.056114\n",
      "batch 56, gen_loss 1.518191, disc_loss 0.969382\n",
      "batch 57, gen_loss 1.348030, disc_loss 0.993216\n",
      "batch 58, gen_loss 1.404542, disc_loss 1.013614\n",
      "batch 59, gen_loss 1.571611, disc_loss 0.915725\n",
      "batch 60, gen_loss 1.729834, disc_loss 0.928021\n",
      "batch 61, gen_loss 1.671067, disc_loss 1.023875\n",
      "batch 62, gen_loss 1.815172, disc_loss 0.890753\n",
      "batch 63, gen_loss 1.459840, disc_loss 0.935184\n",
      "batch 64, gen_loss 1.455322, disc_loss 0.974461\n",
      "batch 65, gen_loss 1.499861, disc_loss 1.072019\n",
      "batch 66, gen_loss 1.604419, disc_loss 0.985895\n",
      "batch 67, gen_loss 1.798773, disc_loss 0.904138\n",
      "batch 68, gen_loss 1.701160, disc_loss 0.894480\n",
      "batch 69, gen_loss 1.641707, disc_loss 1.032866\n",
      "batch 70, gen_loss 1.537592, disc_loss 0.974945\n",
      "batch 71, gen_loss 1.492725, disc_loss 0.934489\n",
      "batch 72, gen_loss 1.458582, disc_loss 0.894854\n",
      "batch 73, gen_loss 1.467981, disc_loss 0.926581\n",
      "batch 74, gen_loss 1.597880, disc_loss 0.908533\n",
      "batch 75, gen_loss 1.621684, disc_loss 0.876523\n",
      "batch 76, gen_loss 1.756051, disc_loss 0.967367\n",
      "batch 77, gen_loss 1.728143, disc_loss 0.928993\n",
      "batch 78, gen_loss 1.548649, disc_loss 0.889169\n",
      "batch 79, gen_loss 1.416759, disc_loss 0.866060\n",
      "batch 80, gen_loss 1.561142, disc_loss 0.936938\n",
      "batch 81, gen_loss 1.571912, disc_loss 0.892868\n",
      "batch 82, gen_loss 1.624510, disc_loss 0.862550\n",
      "batch 83, gen_loss 1.626349, disc_loss 0.905549\n",
      "batch 84, gen_loss 1.550125, disc_loss 0.835099\n",
      "batch 85, gen_loss 1.559759, disc_loss 0.854539\n",
      "batch 86, gen_loss 1.553731, disc_loss 0.942954\n",
      "batch 87, gen_loss 1.628763, disc_loss 0.825330\n",
      "batch 88, gen_loss 1.516297, disc_loss 0.809083\n",
      "batch 89, gen_loss 1.551814, disc_loss 0.878839\n",
      "batch 90, gen_loss 1.691230, disc_loss 0.825369\n",
      "batch 91, gen_loss 1.595192, disc_loss 0.936785\n",
      "batch 92, gen_loss 1.677459, disc_loss 0.862451\n",
      "batch 93, gen_loss 1.424497, disc_loss 0.902372\n",
      "batch 94, gen_loss 1.540300, disc_loss 0.815780\n",
      "batch 95, gen_loss 1.468252, disc_loss 0.815707\n",
      "batch 96, gen_loss 1.414463, disc_loss 0.845764\n",
      "batch 97, gen_loss 1.523638, disc_loss 0.925880\n",
      "batch 98, gen_loss 1.585791, disc_loss 0.840328\n",
      "batch 99, gen_loss 1.641254, disc_loss 0.815304\n",
      "batch 100, gen_loss 1.666856, disc_loss 0.887533\n",
      "batch 101, gen_loss 1.490215, disc_loss 0.895092\n",
      "batch 102, gen_loss 1.366859, disc_loss 0.834455\n",
      "batch 103, gen_loss 1.412432, disc_loss 0.766424\n",
      "batch 104, gen_loss 1.424093, disc_loss 0.868413\n",
      "batch 105, gen_loss 1.752477, disc_loss 0.846664\n",
      "batch 106, gen_loss 1.765676, disc_loss 0.842392\n",
      "batch 107, gen_loss 1.651039, disc_loss 0.869650\n",
      "batch 108, gen_loss 1.355243, disc_loss 0.981007\n",
      "batch 109, gen_loss 1.335232, disc_loss 0.876151\n",
      "batch 110, gen_loss 1.374431, disc_loss 0.851226\n",
      "batch 111, gen_loss 1.437851, disc_loss 0.766547\n",
      "batch 112, gen_loss 1.619023, disc_loss 0.878153\n",
      "batch 113, gen_loss 1.670572, disc_loss 0.807772\n",
      "batch 114, gen_loss 1.598521, disc_loss 0.835516\n",
      "batch 115, gen_loss 1.563888, disc_loss 0.913673\n",
      "batch 116, gen_loss 1.454580, disc_loss 0.899817\n",
      "batch 117, gen_loss 1.495413, disc_loss 0.846874\n",
      "batch 118, gen_loss 1.516805, disc_loss 0.896878\n",
      "batch 119, gen_loss 1.527126, disc_loss 0.852910\n",
      "batch 120, gen_loss 1.397517, disc_loss 0.948278\n",
      "batch 121, gen_loss 1.453665, disc_loss 0.962252\n",
      "batch 122, gen_loss 1.471960, disc_loss 0.967358\n",
      "batch 123, gen_loss 1.568879, disc_loss 0.869839\n",
      "batch 124, gen_loss 1.493000, disc_loss 0.911202\n",
      "batch 125, gen_loss 1.571036, disc_loss 0.900423\n",
      "batch 126, gen_loss 1.423374, disc_loss 0.879422\n",
      "batch 127, gen_loss 1.592980, disc_loss 0.891642\n",
      "batch 128, gen_loss 1.550358, disc_loss 0.934023\n",
      "batch 129, gen_loss 1.428622, disc_loss 0.868338\n",
      "batch 130, gen_loss 1.431916, disc_loss 0.867694\n",
      "batch 131, gen_loss 1.416305, disc_loss 0.896107\n",
      "batch 132, gen_loss 1.359999, disc_loss 0.879126\n",
      "batch 133, gen_loss 1.440665, disc_loss 1.056407\n",
      "batch 134, gen_loss 1.632306, disc_loss 0.848145\n",
      "batch 135, gen_loss 1.645743, disc_loss 0.892226\n",
      "batch 136, gen_loss 1.591854, disc_loss 0.949282\n",
      "batch 137, gen_loss 1.364945, disc_loss 0.966785\n",
      "batch 138, gen_loss 1.257276, disc_loss 0.993106\n",
      "batch 139, gen_loss 1.317583, disc_loss 0.948990\n",
      "batch 140, gen_loss 1.430354, disc_loss 0.960770\n",
      "batch 141, gen_loss 1.590105, disc_loss 0.852919\n",
      "batch 142, gen_loss 1.616013, disc_loss 0.956946\n",
      "batch 143, gen_loss 1.571687, disc_loss 1.019491\n",
      "batch 144, gen_loss 1.447248, disc_loss 0.915810\n",
      "batch 145, gen_loss 1.257602, disc_loss 0.979742\n",
      "batch 146, gen_loss 1.301712, disc_loss 0.897277\n",
      "batch 147, gen_loss 1.432480, disc_loss 0.922314\n",
      "batch 148, gen_loss 1.519161, disc_loss 0.947066\n",
      "batch 149, gen_loss 1.599872, disc_loss 0.962974\n",
      "batch 150, gen_loss 1.633144, disc_loss 0.915007\n",
      "batch 151, gen_loss 1.478266, disc_loss 0.955034\n",
      "batch 152, gen_loss 1.443721, disc_loss 0.880720\n",
      "batch 153, gen_loss 1.462385, disc_loss 0.913361\n",
      "batch 154, gen_loss 1.264096, disc_loss 0.890757\n",
      "batch 155, gen_loss 1.540506, disc_loss 0.897123\n",
      "batch 156, gen_loss 1.539057, disc_loss 0.979332\n",
      "batch 157, gen_loss 1.638671, disc_loss 0.913478\n",
      "batch 158, gen_loss 1.539916, disc_loss 0.847264\n",
      "batch 159, gen_loss 1.424596, disc_loss 0.894833\n",
      "batch 160, gen_loss 1.295731, disc_loss 0.969982\n",
      "batch 161, gen_loss 1.396451, disc_loss 0.916972\n",
      "batch 162, gen_loss 1.481244, disc_loss 0.913410\n",
      "batch 163, gen_loss 1.584532, disc_loss 0.898406\n",
      "batch 164, gen_loss 1.567799, disc_loss 0.952343\n",
      "batch 165, gen_loss 1.593761, disc_loss 0.868912\n",
      "batch 166, gen_loss 1.454715, disc_loss 0.846410\n",
      "batch 167, gen_loss 1.486366, disc_loss 0.853968\n",
      "batch 168, gen_loss 1.508438, disc_loss 0.907720\n",
      "batch 169, gen_loss 1.478251, disc_loss 0.907589\n",
      "batch 170, gen_loss 1.570514, disc_loss 0.878478\n",
      "batch 171, gen_loss 1.545664, disc_loss 0.852946\n",
      "batch 172, gen_loss 1.600857, disc_loss 0.824093\n",
      "batch 173, gen_loss 1.624011, disc_loss 0.942821\n",
      "batch 174, gen_loss 1.624231, disc_loss 0.832081\n",
      "batch 175, gen_loss 1.620448, disc_loss 0.786987\n",
      "batch 176, gen_loss 1.587194, disc_loss 0.806672\n",
      "batch 177, gen_loss 1.545251, disc_loss 0.860542\n",
      "batch 178, gen_loss 1.528304, disc_loss 0.949026\n",
      "batch 179, gen_loss 1.480699, disc_loss 0.911316\n",
      "batch 180, gen_loss 1.455337, disc_loss 0.773163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 181, gen_loss 1.497833, disc_loss 0.869233\n",
      "batch 182, gen_loss 1.568723, disc_loss 0.935001\n",
      "batch 183, gen_loss 1.692158, disc_loss 0.819158\n",
      "batch 184, gen_loss 1.660941, disc_loss 0.882287\n",
      "batch 185, gen_loss 1.577106, disc_loss 0.900597\n",
      "batch 186, gen_loss 1.527973, disc_loss 0.841860\n",
      "batch 187, gen_loss 1.496082, disc_loss 0.900376\n",
      "batch 188, gen_loss 1.478613, disc_loss 1.007159\n",
      "batch 189, gen_loss 1.448452, disc_loss 0.891696\n",
      "batch 190, gen_loss 1.468850, disc_loss 0.990777\n",
      "batch 191, gen_loss 1.550339, disc_loss 0.845237\n",
      "batch 192, gen_loss 1.611106, disc_loss 0.844845\n",
      "batch 193, gen_loss 1.497834, disc_loss 0.954935\n",
      "batch 194, gen_loss 1.523134, disc_loss 0.965324\n",
      "batch 195, gen_loss 1.477909, disc_loss 0.895284\n",
      "batch 196, gen_loss 1.421482, disc_loss 0.922695\n",
      "batch 197, gen_loss 1.584834, disc_loss 0.938392\n",
      "batch 198, gen_loss 1.565901, disc_loss 0.936339\n",
      "batch 199, gen_loss 1.479998, disc_loss 0.926975\n",
      "batch 200, gen_loss 1.325557, disc_loss 0.990125\n",
      "batch 201, gen_loss 1.448681, disc_loss 0.921428\n",
      "batch 202, gen_loss 1.437982, disc_loss 0.899026\n",
      "batch 203, gen_loss 1.473922, disc_loss 0.940942\n",
      "batch 204, gen_loss 1.549426, disc_loss 0.923169\n",
      "batch 205, gen_loss 1.680715, disc_loss 0.864430\n",
      "batch 206, gen_loss 1.539661, disc_loss 0.981486\n",
      "batch 207, gen_loss 1.443666, disc_loss 0.972149\n",
      "batch 208, gen_loss 1.390844, disc_loss 1.007582\n",
      "batch 209, gen_loss 1.464616, disc_loss 0.900805\n",
      "batch 210, gen_loss 1.447583, disc_loss 0.961534\n",
      "batch 211, gen_loss 1.364096, disc_loss 0.916798\n",
      "batch 212, gen_loss 1.432502, disc_loss 0.975209\n",
      "batch 213, gen_loss 1.537304, disc_loss 0.863196\n",
      "batch 214, gen_loss 1.685662, disc_loss 0.818957\n",
      "batch 215, gen_loss 1.625756, disc_loss 0.945395\n",
      "batch 216, gen_loss 1.492151, disc_loss 0.895910\n",
      "batch 217, gen_loss 1.400364, disc_loss 0.977088\n",
      "batch 218, gen_loss 1.411232, disc_loss 0.906165\n",
      "batch 219, gen_loss 1.477616, disc_loss 0.886083\n",
      "batch 220, gen_loss 1.468705, disc_loss 0.961309\n",
      "batch 221, gen_loss 1.533105, disc_loss 0.964499\n",
      "batch 222, gen_loss 1.393649, disc_loss 0.961733\n",
      "batch 223, gen_loss 1.325852, disc_loss 0.950757\n",
      "batch 224, gen_loss 1.407287, disc_loss 1.017895\n",
      "batch 225, gen_loss 1.422073, disc_loss 0.910682\n",
      "batch 226, gen_loss 1.540930, disc_loss 0.977374\n",
      "batch 227, gen_loss 1.545329, disc_loss 0.955436\n",
      "batch 228, gen_loss 1.348922, disc_loss 1.013237\n",
      "batch 229, gen_loss 1.300937, disc_loss 0.968606\n",
      "batch 230, gen_loss 1.395612, disc_loss 0.987469\n",
      "batch 231, gen_loss 1.452445, disc_loss 0.993204\n",
      "batch 232, gen_loss 1.423909, disc_loss 1.009681\n",
      "batch 233, gen_loss 1.587956, disc_loss 1.041127\n",
      "batch 234, gen_loss 1.338866, disc_loss 0.969178\n",
      "Time for epoch45is 7.69320011138916 sec\n",
      "batch 0, gen_loss 1.277228, disc_loss 1.017657\n",
      "batch 1, gen_loss 1.352178, disc_loss 1.000523\n",
      "batch 2, gen_loss 1.404811, disc_loss 1.065006\n",
      "batch 3, gen_loss 1.439094, disc_loss 1.077152\n",
      "batch 4, gen_loss 1.383295, disc_loss 1.120766\n",
      "batch 5, gen_loss 1.405795, disc_loss 1.021599\n",
      "batch 6, gen_loss 1.357625, disc_loss 1.056107\n",
      "batch 7, gen_loss 1.324002, disc_loss 1.061393\n",
      "batch 8, gen_loss 1.240034, disc_loss 1.051733\n",
      "batch 9, gen_loss 1.364130, disc_loss 1.033854\n",
      "batch 10, gen_loss 1.381450, disc_loss 1.163657\n",
      "batch 11, gen_loss 1.543007, disc_loss 1.149598\n",
      "batch 12, gen_loss 1.331602, disc_loss 1.133451\n",
      "batch 13, gen_loss 1.351983, disc_loss 1.050885\n",
      "batch 14, gen_loss 1.333254, disc_loss 1.205489\n",
      "batch 15, gen_loss 1.249003, disc_loss 1.209424\n",
      "batch 16, gen_loss 1.270381, disc_loss 1.189463\n",
      "batch 17, gen_loss 1.395228, disc_loss 1.146775\n",
      "batch 18, gen_loss 1.303804, disc_loss 1.239686\n",
      "batch 19, gen_loss 1.249167, disc_loss 1.170051\n",
      "batch 20, gen_loss 1.220762, disc_loss 1.239126\n",
      "batch 21, gen_loss 1.265861, disc_loss 1.224673\n",
      "batch 22, gen_loss 1.305050, disc_loss 1.073478\n",
      "batch 23, gen_loss 1.519690, disc_loss 1.008291\n",
      "batch 24, gen_loss 1.395414, disc_loss 1.104333\n",
      "batch 25, gen_loss 1.345388, disc_loss 1.096370\n",
      "batch 26, gen_loss 1.189248, disc_loss 1.095907\n",
      "batch 27, gen_loss 1.265739, disc_loss 1.104367\n",
      "batch 28, gen_loss 1.433383, disc_loss 1.098966\n",
      "batch 29, gen_loss 1.457439, disc_loss 1.053994\n",
      "batch 30, gen_loss 1.462889, disc_loss 1.057812\n",
      "batch 31, gen_loss 1.438305, disc_loss 1.051722\n",
      "batch 32, gen_loss 1.292000, disc_loss 1.058423\n",
      "batch 33, gen_loss 1.275829, disc_loss 0.968700\n",
      "batch 34, gen_loss 1.343370, disc_loss 1.064169\n",
      "batch 35, gen_loss 1.484665, disc_loss 0.997493\n",
      "batch 36, gen_loss 1.506596, disc_loss 0.860350\n",
      "batch 37, gen_loss 1.549850, disc_loss 0.948225\n",
      "batch 38, gen_loss 1.573781, disc_loss 0.972530\n",
      "batch 39, gen_loss 1.551620, disc_loss 0.882459\n",
      "batch 40, gen_loss 1.341339, disc_loss 0.883787\n",
      "batch 41, gen_loss 1.340026, disc_loss 0.910928\n",
      "batch 42, gen_loss 1.620580, disc_loss 0.828248\n",
      "batch 43, gen_loss 1.673703, disc_loss 0.780435\n",
      "batch 44, gen_loss 1.739375, disc_loss 0.830138\n",
      "batch 45, gen_loss 1.655079, disc_loss 0.813008\n",
      "batch 46, gen_loss 1.416746, disc_loss 0.868161\n",
      "batch 47, gen_loss 1.423239, disc_loss 0.854936\n",
      "batch 48, gen_loss 1.317358, disc_loss 0.829213\n",
      "batch 49, gen_loss 1.495353, disc_loss 0.788019\n",
      "batch 50, gen_loss 1.693174, disc_loss 0.861905\n",
      "batch 51, gen_loss 1.949546, disc_loss 0.739181\n",
      "batch 52, gen_loss 1.796873, disc_loss 0.826390\n",
      "batch 53, gen_loss 1.623262, disc_loss 0.764848\n",
      "batch 54, gen_loss 1.592564, disc_loss 0.815603\n",
      "batch 55, gen_loss 1.477332, disc_loss 0.690789\n",
      "batch 56, gen_loss 1.480852, disc_loss 0.820087\n",
      "batch 57, gen_loss 1.661707, disc_loss 0.828851\n",
      "batch 58, gen_loss 1.757565, disc_loss 0.855270\n",
      "batch 59, gen_loss 1.747748, disc_loss 0.834688\n",
      "batch 60, gen_loss 1.560784, disc_loss 0.764507\n",
      "batch 61, gen_loss 1.555263, disc_loss 0.757724\n",
      "batch 62, gen_loss 1.487662, disc_loss 0.787496\n",
      "batch 63, gen_loss 1.680254, disc_loss 0.648968\n",
      "batch 64, gen_loss 1.681541, disc_loss 0.762481\n",
      "batch 65, gen_loss 1.743679, disc_loss 0.774963\n",
      "batch 66, gen_loss 1.902038, disc_loss 0.775014\n",
      "batch 67, gen_loss 1.754203, disc_loss 0.775918\n",
      "batch 68, gen_loss 1.644996, disc_loss 0.758713\n",
      "batch 69, gen_loss 1.475907, disc_loss 0.755367\n",
      "batch 70, gen_loss 1.454913, disc_loss 0.765395\n",
      "batch 71, gen_loss 1.609044, disc_loss 0.689513\n",
      "batch 72, gen_loss 1.633881, disc_loss 0.845099\n",
      "batch 73, gen_loss 1.721573, disc_loss 0.774982\n",
      "batch 74, gen_loss 1.728495, disc_loss 0.811543\n",
      "batch 75, gen_loss 1.656337, disc_loss 0.758262\n",
      "batch 76, gen_loss 1.642743, disc_loss 0.714681\n",
      "batch 77, gen_loss 1.647144, disc_loss 0.797466\n",
      "batch 78, gen_loss 1.618502, disc_loss 0.758051\n",
      "batch 79, gen_loss 1.589454, disc_loss 0.779766\n",
      "batch 80, gen_loss 1.634576, disc_loss 0.742212\n",
      "batch 81, gen_loss 1.583894, disc_loss 0.833109\n",
      "batch 82, gen_loss 1.719076, disc_loss 0.803555\n",
      "batch 83, gen_loss 1.651529, disc_loss 0.793499\n",
      "batch 84, gen_loss 1.426402, disc_loss 0.843182\n",
      "batch 85, gen_loss 1.586431, disc_loss 0.815625\n",
      "batch 86, gen_loss 1.517568, disc_loss 0.893372\n",
      "batch 87, gen_loss 1.532089, disc_loss 0.850762\n",
      "batch 88, gen_loss 1.461418, disc_loss 0.871268\n",
      "batch 89, gen_loss 1.603153, disc_loss 0.827960\n",
      "batch 90, gen_loss 1.694748, disc_loss 0.870449\n",
      "batch 91, gen_loss 1.588819, disc_loss 0.922059\n",
      "batch 92, gen_loss 1.517433, disc_loss 0.886761\n",
      "batch 93, gen_loss 1.420070, disc_loss 0.968796\n",
      "batch 94, gen_loss 1.470919, disc_loss 0.892814\n",
      "batch 95, gen_loss 1.392951, disc_loss 0.958475\n",
      "batch 96, gen_loss 1.400871, disc_loss 0.939521\n",
      "batch 97, gen_loss 1.468541, disc_loss 0.905607\n",
      "batch 98, gen_loss 1.473193, disc_loss 0.922054\n",
      "batch 99, gen_loss 1.535434, disc_loss 0.916613\n",
      "batch 100, gen_loss 1.580766, disc_loss 0.943143\n",
      "batch 101, gen_loss 1.463022, disc_loss 1.098526\n",
      "batch 102, gen_loss 1.402442, disc_loss 0.908898\n",
      "batch 103, gen_loss 1.161921, disc_loss 1.058446\n",
      "batch 104, gen_loss 1.264008, disc_loss 0.981207\n",
      "batch 105, gen_loss 1.469430, disc_loss 0.995752\n",
      "batch 106, gen_loss 1.649896, disc_loss 0.970121\n",
      "batch 107, gen_loss 1.639371, disc_loss 1.078728\n",
      "batch 108, gen_loss 1.531289, disc_loss 0.937677\n",
      "batch 109, gen_loss 1.386889, disc_loss 0.901123\n",
      "batch 110, gen_loss 1.218589, disc_loss 0.982943\n",
      "batch 111, gen_loss 1.417221, disc_loss 0.984771\n",
      "batch 112, gen_loss 1.544429, disc_loss 1.011786\n",
      "batch 113, gen_loss 1.506961, disc_loss 1.044091\n",
      "batch 114, gen_loss 1.375524, disc_loss 1.073773\n",
      "batch 115, gen_loss 1.437853, disc_loss 0.920629\n",
      "batch 116, gen_loss 1.520237, disc_loss 1.090128\n",
      "batch 117, gen_loss 1.379397, disc_loss 0.979696\n",
      "batch 118, gen_loss 1.355877, disc_loss 0.946107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 119, gen_loss 1.340701, disc_loss 0.973314\n",
      "batch 120, gen_loss 1.393774, disc_loss 0.944615\n",
      "batch 121, gen_loss 1.622087, disc_loss 1.038765\n",
      "batch 122, gen_loss 1.551780, disc_loss 0.965382\n",
      "batch 123, gen_loss 1.538653, disc_loss 0.930648\n",
      "batch 124, gen_loss 1.389960, disc_loss 0.950401\n",
      "batch 125, gen_loss 1.348064, disc_loss 0.990656\n",
      "batch 126, gen_loss 1.426920, disc_loss 0.897530\n",
      "batch 127, gen_loss 1.398057, disc_loss 0.924730\n",
      "batch 128, gen_loss 1.402481, disc_loss 1.032703\n",
      "batch 129, gen_loss 1.683860, disc_loss 0.885084\n",
      "batch 130, gen_loss 1.638100, disc_loss 0.868822\n",
      "batch 131, gen_loss 1.704382, disc_loss 0.865649\n",
      "batch 132, gen_loss 1.451619, disc_loss 0.873194\n",
      "batch 133, gen_loss 1.409822, disc_loss 0.952197\n",
      "batch 134, gen_loss 1.305794, disc_loss 0.911100\n",
      "batch 135, gen_loss 1.363847, disc_loss 0.943535\n",
      "batch 136, gen_loss 1.456270, disc_loss 0.883457\n",
      "batch 137, gen_loss 1.622035, disc_loss 0.912472\n",
      "batch 138, gen_loss 1.615110, disc_loss 0.952265\n",
      "batch 139, gen_loss 1.646907, disc_loss 0.876771\n",
      "batch 140, gen_loss 1.534559, disc_loss 0.912995\n",
      "batch 141, gen_loss 1.495641, disc_loss 0.868451\n",
      "batch 142, gen_loss 1.475194, disc_loss 0.927761\n",
      "batch 143, gen_loss 1.461139, disc_loss 0.831696\n",
      "batch 144, gen_loss 1.387617, disc_loss 0.803278\n",
      "batch 145, gen_loss 1.585448, disc_loss 0.917727\n",
      "batch 146, gen_loss 1.658099, disc_loss 0.929372\n",
      "batch 147, gen_loss 1.725938, disc_loss 0.805495\n",
      "batch 148, gen_loss 1.635677, disc_loss 0.914087\n",
      "batch 149, gen_loss 1.464192, disc_loss 0.763539\n",
      "batch 150, gen_loss 1.360918, disc_loss 0.945284\n",
      "batch 151, gen_loss 1.392636, disc_loss 0.846395\n",
      "batch 152, gen_loss 1.343154, disc_loss 0.880454\n",
      "batch 153, gen_loss 1.522574, disc_loss 0.937140\n",
      "batch 154, gen_loss 1.590576, disc_loss 0.856871\n",
      "batch 155, gen_loss 1.625124, disc_loss 0.929523\n",
      "batch 156, gen_loss 1.549382, disc_loss 0.980142\n",
      "batch 157, gen_loss 1.373642, disc_loss 0.986222\n",
      "batch 158, gen_loss 1.345837, disc_loss 0.956944\n",
      "batch 159, gen_loss 1.333735, disc_loss 0.980412\n",
      "batch 160, gen_loss 1.261737, disc_loss 1.021566\n",
      "batch 161, gen_loss 1.454376, disc_loss 0.941609\n",
      "batch 162, gen_loss 1.527442, disc_loss 0.991842\n",
      "batch 163, gen_loss 1.500728, disc_loss 0.975205\n",
      "batch 164, gen_loss 1.553137, disc_loss 1.028753\n",
      "batch 165, gen_loss 1.343742, disc_loss 0.928838\n",
      "batch 166, gen_loss 1.303779, disc_loss 1.002761\n",
      "batch 167, gen_loss 1.175645, disc_loss 1.125672\n",
      "batch 168, gen_loss 1.244712, disc_loss 0.982204\n",
      "batch 169, gen_loss 1.275859, disc_loss 1.116315\n",
      "batch 170, gen_loss 1.479285, disc_loss 1.040262\n",
      "batch 171, gen_loss 1.672903, disc_loss 1.069768\n",
      "batch 172, gen_loss 1.588688, disc_loss 1.090826\n",
      "batch 173, gen_loss 1.214633, disc_loss 1.090702\n",
      "batch 174, gen_loss 1.109970, disc_loss 1.059560\n",
      "batch 175, gen_loss 1.140497, disc_loss 1.118565\n",
      "batch 176, gen_loss 1.271681, disc_loss 0.987718\n",
      "batch 177, gen_loss 1.556120, disc_loss 1.088247\n",
      "batch 178, gen_loss 1.524001, disc_loss 1.054368\n",
      "batch 179, gen_loss 1.417198, disc_loss 1.100027\n",
      "batch 180, gen_loss 1.271992, disc_loss 0.990722\n",
      "batch 181, gen_loss 1.119467, disc_loss 1.156989\n",
      "batch 182, gen_loss 1.107716, disc_loss 1.080381\n",
      "batch 183, gen_loss 1.323518, disc_loss 1.051409\n",
      "batch 184, gen_loss 1.556033, disc_loss 1.097442\n",
      "batch 185, gen_loss 1.554153, disc_loss 0.995964\n",
      "batch 186, gen_loss 1.570314, disc_loss 0.968364\n",
      "batch 187, gen_loss 1.425849, disc_loss 0.936171\n",
      "batch 188, gen_loss 1.310801, disc_loss 0.954204\n",
      "batch 189, gen_loss 1.347031, disc_loss 0.909308\n",
      "batch 190, gen_loss 1.322644, disc_loss 0.966559\n",
      "batch 191, gen_loss 1.387523, disc_loss 0.962793\n",
      "batch 192, gen_loss 1.380499, disc_loss 0.938074\n",
      "batch 193, gen_loss 1.545195, disc_loss 0.879142\n",
      "batch 194, gen_loss 1.533150, disc_loss 0.958432\n",
      "batch 195, gen_loss 1.448519, disc_loss 0.889518\n",
      "batch 196, gen_loss 1.470618, disc_loss 0.866774\n",
      "batch 197, gen_loss 1.347722, disc_loss 0.916366\n",
      "batch 198, gen_loss 1.436855, disc_loss 0.914576\n",
      "batch 199, gen_loss 1.326484, disc_loss 0.918403\n",
      "batch 200, gen_loss 1.295646, disc_loss 0.935952\n",
      "batch 201, gen_loss 1.434294, disc_loss 0.870358\n",
      "batch 202, gen_loss 1.457826, disc_loss 0.877206\n",
      "batch 203, gen_loss 1.603709, disc_loss 0.880416\n",
      "batch 204, gen_loss 1.598509, disc_loss 0.791187\n",
      "batch 205, gen_loss 1.537247, disc_loss 0.779841\n",
      "batch 206, gen_loss 1.519845, disc_loss 0.899028\n",
      "batch 207, gen_loss 1.334629, disc_loss 0.888879\n",
      "batch 208, gen_loss 1.369083, disc_loss 0.860264\n",
      "batch 209, gen_loss 1.457537, disc_loss 0.820443\n",
      "batch 210, gen_loss 1.527143, disc_loss 0.749814\n",
      "batch 211, gen_loss 1.536205, disc_loss 0.829731\n",
      "batch 212, gen_loss 1.620296, disc_loss 0.848780\n",
      "batch 213, gen_loss 1.583956, disc_loss 0.851256\n",
      "batch 214, gen_loss 1.419293, disc_loss 0.862928\n",
      "batch 215, gen_loss 1.362610, disc_loss 0.852762\n",
      "batch 216, gen_loss 1.445911, disc_loss 0.809002\n",
      "batch 217, gen_loss 1.379215, disc_loss 0.925948\n",
      "batch 218, gen_loss 1.504490, disc_loss 0.841739\n",
      "batch 219, gen_loss 1.573873, disc_loss 0.878744\n",
      "batch 220, gen_loss 1.460109, disc_loss 0.824758\n",
      "batch 221, gen_loss 1.542630, disc_loss 0.850684\n",
      "batch 222, gen_loss 1.450582, disc_loss 0.892256\n",
      "batch 223, gen_loss 1.467424, disc_loss 0.850403\n",
      "batch 224, gen_loss 1.400305, disc_loss 0.830454\n",
      "batch 225, gen_loss 1.383895, disc_loss 0.921025\n",
      "batch 226, gen_loss 1.566929, disc_loss 0.888742\n",
      "batch 227, gen_loss 1.418264, disc_loss 0.896279\n",
      "batch 228, gen_loss 1.421475, disc_loss 0.890206\n",
      "batch 229, gen_loss 1.391694, disc_loss 0.864860\n",
      "batch 230, gen_loss 1.446624, disc_loss 0.880636\n",
      "batch 231, gen_loss 1.473378, disc_loss 1.009886\n",
      "batch 232, gen_loss 1.542749, disc_loss 0.864096\n",
      "batch 233, gen_loss 1.496958, disc_loss 0.927992\n",
      "batch 234, gen_loss 1.455594, disc_loss 0.911003\n",
      "Time for epoch46is 7.601614475250244 sec\n",
      "batch 0, gen_loss 1.391529, disc_loss 0.921834\n",
      "batch 1, gen_loss 1.360667, disc_loss 0.893543\n",
      "batch 2, gen_loss 1.353730, disc_loss 0.962365\n",
      "batch 3, gen_loss 1.487098, disc_loss 0.938260\n",
      "batch 4, gen_loss 1.437208, disc_loss 0.960889\n",
      "batch 5, gen_loss 1.437427, disc_loss 1.004467\n",
      "batch 6, gen_loss 1.326411, disc_loss 1.008872\n",
      "batch 7, gen_loss 1.466441, disc_loss 0.884222\n",
      "batch 8, gen_loss 1.293091, disc_loss 0.983888\n",
      "batch 9, gen_loss 1.356844, disc_loss 0.955602\n",
      "batch 10, gen_loss 1.397275, disc_loss 1.007549\n",
      "batch 11, gen_loss 1.322780, disc_loss 0.964801\n",
      "batch 12, gen_loss 1.357984, disc_loss 0.928065\n",
      "batch 13, gen_loss 1.486029, disc_loss 0.934662\n",
      "batch 14, gen_loss 1.488282, disc_loss 1.021174\n",
      "batch 15, gen_loss 1.333045, disc_loss 0.982677\n",
      "batch 16, gen_loss 1.312121, disc_loss 0.965480\n",
      "batch 17, gen_loss 1.431739, disc_loss 0.917210\n",
      "batch 18, gen_loss 1.512074, disc_loss 0.914539\n",
      "batch 19, gen_loss 1.559854, disc_loss 1.027122\n",
      "batch 20, gen_loss 1.505866, disc_loss 0.939242\n",
      "batch 21, gen_loss 1.464699, disc_loss 0.898754\n",
      "batch 22, gen_loss 1.364479, disc_loss 0.937066\n",
      "batch 23, gen_loss 1.265333, disc_loss 0.971642\n",
      "batch 24, gen_loss 1.421192, disc_loss 0.872292\n",
      "batch 25, gen_loss 1.532040, disc_loss 0.988388\n",
      "batch 26, gen_loss 1.476989, disc_loss 0.950093\n",
      "batch 27, gen_loss 1.469308, disc_loss 0.904628\n",
      "batch 28, gen_loss 1.536320, disc_loss 0.962880\n",
      "batch 29, gen_loss 1.420074, disc_loss 0.987578\n",
      "batch 30, gen_loss 1.377764, disc_loss 0.942231\n",
      "batch 31, gen_loss 1.326614, disc_loss 0.897171\n",
      "batch 32, gen_loss 1.331521, disc_loss 0.896298\n",
      "batch 33, gen_loss 1.326916, disc_loss 0.910906\n",
      "batch 34, gen_loss 1.432028, disc_loss 0.897825\n",
      "batch 35, gen_loss 1.539334, disc_loss 0.994130\n",
      "batch 36, gen_loss 1.576114, disc_loss 0.901141\n",
      "batch 37, gen_loss 1.569821, disc_loss 0.987030\n",
      "batch 38, gen_loss 1.487779, disc_loss 0.880063\n",
      "batch 39, gen_loss 1.401917, disc_loss 0.875332\n",
      "batch 40, gen_loss 1.375117, disc_loss 0.982652\n",
      "batch 41, gen_loss 1.429847, disc_loss 0.927964\n",
      "batch 42, gen_loss 1.566022, disc_loss 0.890440\n",
      "batch 43, gen_loss 1.560124, disc_loss 0.884300\n",
      "batch 44, gen_loss 1.512533, disc_loss 0.875518\n",
      "batch 45, gen_loss 1.532406, disc_loss 0.869729\n",
      "batch 46, gen_loss 1.531629, disc_loss 0.950558\n",
      "batch 47, gen_loss 1.494994, disc_loss 0.849513\n",
      "batch 48, gen_loss 1.418193, disc_loss 0.909253\n",
      "batch 49, gen_loss 1.270501, disc_loss 0.929704\n",
      "batch 50, gen_loss 1.359523, disc_loss 0.843656\n",
      "batch 51, gen_loss 1.464355, disc_loss 0.948421\n",
      "batch 52, gen_loss 1.636759, disc_loss 0.820652\n",
      "batch 53, gen_loss 1.639723, disc_loss 0.954473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 54, gen_loss 1.517961, disc_loss 0.944567\n",
      "batch 55, gen_loss 1.391273, disc_loss 0.885974\n",
      "batch 56, gen_loss 1.285741, disc_loss 0.896982\n",
      "batch 57, gen_loss 1.423399, disc_loss 0.955363\n",
      "batch 58, gen_loss 1.567417, disc_loss 0.836316\n",
      "batch 59, gen_loss 1.479882, disc_loss 0.921565\n",
      "batch 60, gen_loss 1.450814, disc_loss 0.897147\n",
      "batch 61, gen_loss 1.492574, disc_loss 0.936209\n",
      "batch 62, gen_loss 1.530965, disc_loss 0.852904\n",
      "batch 63, gen_loss 1.456386, disc_loss 0.884914\n",
      "batch 64, gen_loss 1.411102, disc_loss 0.968006\n",
      "batch 65, gen_loss 1.491992, disc_loss 0.846454\n",
      "batch 66, gen_loss 1.481406, disc_loss 0.987462\n",
      "batch 67, gen_loss 1.485061, disc_loss 0.922166\n",
      "batch 68, gen_loss 1.501598, disc_loss 0.991136\n",
      "batch 69, gen_loss 1.464134, disc_loss 0.965516\n",
      "batch 70, gen_loss 1.440630, disc_loss 0.892965\n",
      "batch 71, gen_loss 1.328621, disc_loss 0.988365\n",
      "batch 72, gen_loss 1.438843, disc_loss 1.043782\n",
      "batch 73, gen_loss 1.353639, disc_loss 0.975613\n",
      "batch 74, gen_loss 1.461712, disc_loss 0.939529\n",
      "batch 75, gen_loss 1.410535, disc_loss 1.014976\n",
      "batch 76, gen_loss 1.353528, disc_loss 0.953320\n",
      "batch 77, gen_loss 1.457119, disc_loss 0.996191\n",
      "batch 78, gen_loss 1.491493, disc_loss 1.092450\n",
      "batch 79, gen_loss 1.377005, disc_loss 1.005620\n",
      "batch 80, gen_loss 1.270128, disc_loss 0.985566\n",
      "batch 81, gen_loss 1.229595, disc_loss 0.930751\n",
      "batch 82, gen_loss 1.371157, disc_loss 0.860453\n",
      "batch 83, gen_loss 1.527107, disc_loss 1.062302\n",
      "batch 84, gen_loss 1.644308, disc_loss 1.042821\n",
      "batch 85, gen_loss 1.621080, disc_loss 1.016930\n",
      "batch 86, gen_loss 1.304761, disc_loss 1.081017\n",
      "batch 87, gen_loss 1.346340, disc_loss 0.979090\n",
      "batch 88, gen_loss 1.313686, disc_loss 0.976092\n",
      "batch 89, gen_loss 1.326597, disc_loss 0.940985\n",
      "batch 90, gen_loss 1.326377, disc_loss 1.071227\n",
      "batch 91, gen_loss 1.516300, disc_loss 0.980528\n",
      "batch 92, gen_loss 1.560488, disc_loss 1.072968\n",
      "batch 93, gen_loss 1.658965, disc_loss 0.972032\n",
      "batch 94, gen_loss 1.663526, disc_loss 0.889591\n",
      "batch 95, gen_loss 1.501522, disc_loss 0.967659\n",
      "batch 96, gen_loss 1.293263, disc_loss 0.940180\n",
      "batch 97, gen_loss 1.243054, disc_loss 0.958338\n",
      "batch 98, gen_loss 1.262185, disc_loss 0.991106\n",
      "batch 99, gen_loss 1.484895, disc_loss 0.996081\n",
      "batch 100, gen_loss 1.541339, disc_loss 1.003495\n",
      "batch 101, gen_loss 1.584822, disc_loss 0.939883\n",
      "batch 102, gen_loss 1.466893, disc_loss 0.985461\n",
      "batch 103, gen_loss 1.366487, disc_loss 0.952300\n",
      "batch 104, gen_loss 1.221546, disc_loss 1.096887\n",
      "batch 105, gen_loss 1.469924, disc_loss 0.930034\n",
      "batch 106, gen_loss 1.465504, disc_loss 1.004381\n",
      "batch 107, gen_loss 1.515688, disc_loss 1.013202\n",
      "batch 108, gen_loss 1.662613, disc_loss 0.934138\n",
      "batch 109, gen_loss 1.612928, disc_loss 0.979162\n",
      "batch 110, gen_loss 1.394603, disc_loss 1.014139\n",
      "batch 111, gen_loss 1.321712, disc_loss 0.986975\n",
      "batch 112, gen_loss 1.272195, disc_loss 1.017281\n",
      "batch 113, gen_loss 1.288795, disc_loss 1.023544\n",
      "batch 114, gen_loss 1.443701, disc_loss 0.963930\n",
      "batch 115, gen_loss 1.569993, disc_loss 0.934994\n",
      "batch 116, gen_loss 1.669083, disc_loss 0.972508\n",
      "batch 117, gen_loss 1.575282, disc_loss 1.141032\n",
      "batch 118, gen_loss 1.359389, disc_loss 1.036266\n",
      "batch 119, gen_loss 1.181049, disc_loss 0.973170\n",
      "batch 120, gen_loss 1.050534, disc_loss 1.093516\n",
      "batch 121, gen_loss 1.192746, disc_loss 1.137972\n",
      "batch 122, gen_loss 1.516289, disc_loss 0.955271\n",
      "batch 123, gen_loss 1.768823, disc_loss 1.053360\n",
      "batch 124, gen_loss 1.750377, disc_loss 0.944272\n",
      "batch 125, gen_loss 1.503486, disc_loss 1.039721\n",
      "batch 126, gen_loss 1.402478, disc_loss 0.985475\n",
      "batch 127, gen_loss 1.343510, disc_loss 0.974650\n",
      "batch 128, gen_loss 1.272196, disc_loss 0.967988\n",
      "batch 129, gen_loss 1.270969, disc_loss 0.981092\n",
      "batch 130, gen_loss 1.400980, disc_loss 0.977967\n",
      "batch 131, gen_loss 1.525014, disc_loss 1.022707\n",
      "batch 132, gen_loss 1.613479, disc_loss 0.970610\n",
      "batch 133, gen_loss 1.591252, disc_loss 1.107233\n",
      "batch 134, gen_loss 1.459288, disc_loss 1.047415\n",
      "batch 135, gen_loss 1.426575, disc_loss 0.970366\n",
      "batch 136, gen_loss 1.285994, disc_loss 0.921839\n",
      "batch 137, gen_loss 1.200649, disc_loss 1.007306\n",
      "batch 138, gen_loss 1.560775, disc_loss 0.913378\n",
      "batch 139, gen_loss 1.655854, disc_loss 1.055354\n",
      "batch 140, gen_loss 1.701438, disc_loss 0.958044\n",
      "batch 141, gen_loss 1.617040, disc_loss 0.933610\n",
      "batch 142, gen_loss 1.400694, disc_loss 1.020189\n",
      "batch 143, gen_loss 1.242049, disc_loss 1.090264\n",
      "batch 144, gen_loss 1.256481, disc_loss 0.938866\n",
      "batch 145, gen_loss 1.331087, disc_loss 0.921754\n",
      "batch 146, gen_loss 1.465812, disc_loss 0.959231\n",
      "batch 147, gen_loss 1.732976, disc_loss 1.013931\n",
      "batch 148, gen_loss 1.653791, disc_loss 1.018064\n",
      "batch 149, gen_loss 1.447508, disc_loss 0.960809\n",
      "batch 150, gen_loss 1.235981, disc_loss 0.993199\n",
      "batch 151, gen_loss 1.297959, disc_loss 0.986741\n",
      "batch 152, gen_loss 1.382074, disc_loss 0.982733\n",
      "batch 153, gen_loss 1.413363, disc_loss 0.987467\n",
      "batch 154, gen_loss 1.592219, disc_loss 0.967801\n",
      "batch 155, gen_loss 1.638314, disc_loss 0.938082\n",
      "batch 156, gen_loss 1.606416, disc_loss 0.914096\n",
      "batch 157, gen_loss 1.406089, disc_loss 1.015579\n",
      "batch 158, gen_loss 1.421582, disc_loss 1.030508\n",
      "batch 159, gen_loss 1.370964, disc_loss 0.974177\n",
      "batch 160, gen_loss 1.331362, disc_loss 1.018860\n",
      "batch 161, gen_loss 1.467039, disc_loss 0.996974\n",
      "batch 162, gen_loss 1.489850, disc_loss 1.006921\n",
      "batch 163, gen_loss 1.487460, disc_loss 0.981059\n",
      "batch 164, gen_loss 1.364330, disc_loss 0.919146\n",
      "batch 165, gen_loss 1.342726, disc_loss 0.920158\n",
      "batch 166, gen_loss 1.480642, disc_loss 0.864313\n",
      "batch 167, gen_loss 1.546779, disc_loss 1.016185\n",
      "batch 168, gen_loss 1.566604, disc_loss 0.910743\n",
      "batch 169, gen_loss 1.534975, disc_loss 0.940513\n",
      "batch 170, gen_loss 1.506215, disc_loss 0.889818\n",
      "batch 171, gen_loss 1.411355, disc_loss 0.863656\n",
      "batch 172, gen_loss 1.337231, disc_loss 0.868177\n",
      "batch 173, gen_loss 1.562408, disc_loss 0.811633\n",
      "batch 174, gen_loss 1.698177, disc_loss 0.876454\n",
      "batch 175, gen_loss 1.739784, disc_loss 0.805477\n",
      "batch 176, gen_loss 1.669050, disc_loss 0.922773\n",
      "batch 177, gen_loss 1.581553, disc_loss 0.827708\n",
      "batch 178, gen_loss 1.537098, disc_loss 0.791109\n",
      "batch 179, gen_loss 1.485987, disc_loss 0.811736\n",
      "batch 180, gen_loss 1.651177, disc_loss 0.825009\n",
      "batch 181, gen_loss 1.581735, disc_loss 0.795226\n",
      "batch 182, gen_loss 1.592029, disc_loss 0.836600\n",
      "batch 183, gen_loss 1.683462, disc_loss 0.724485\n",
      "batch 184, gen_loss 1.760735, disc_loss 0.751379\n",
      "batch 185, gen_loss 1.758440, disc_loss 0.811220\n",
      "batch 186, gen_loss 1.710654, disc_loss 0.748095\n",
      "batch 187, gen_loss 1.642889, disc_loss 0.761834\n",
      "batch 188, gen_loss 1.405904, disc_loss 0.780342\n",
      "batch 189, gen_loss 1.540451, disc_loss 0.725988\n",
      "batch 190, gen_loss 1.614778, disc_loss 0.830644\n",
      "batch 191, gen_loss 1.799553, disc_loss 0.754971\n",
      "batch 192, gen_loss 1.805024, disc_loss 0.752304\n",
      "batch 193, gen_loss 1.828751, disc_loss 0.811089\n",
      "batch 194, gen_loss 1.598922, disc_loss 0.745345\n",
      "batch 195, gen_loss 1.454484, disc_loss 0.820112\n",
      "batch 196, gen_loss 1.475280, disc_loss 0.851528\n",
      "batch 197, gen_loss 1.514328, disc_loss 0.796490\n",
      "batch 198, gen_loss 1.595356, disc_loss 0.745846\n",
      "batch 199, gen_loss 1.746058, disc_loss 0.718993\n",
      "batch 200, gen_loss 1.741516, disc_loss 0.815739\n",
      "batch 201, gen_loss 1.778274, disc_loss 0.811273\n",
      "batch 202, gen_loss 1.592846, disc_loss 0.791561\n",
      "batch 203, gen_loss 1.571900, disc_loss 0.789211\n",
      "batch 204, gen_loss 1.476138, disc_loss 0.794597\n",
      "batch 205, gen_loss 1.564617, disc_loss 0.784461\n",
      "batch 206, gen_loss 1.711640, disc_loss 0.856433\n",
      "batch 207, gen_loss 1.817786, disc_loss 0.829951\n",
      "batch 208, gen_loss 1.789565, disc_loss 0.778849\n",
      "batch 209, gen_loss 1.576305, disc_loss 0.789603\n",
      "batch 210, gen_loss 1.453726, disc_loss 0.814742\n",
      "batch 211, gen_loss 1.346940, disc_loss 0.922729\n",
      "batch 212, gen_loss 1.462197, disc_loss 0.873821\n",
      "batch 213, gen_loss 1.706551, disc_loss 0.783943\n",
      "batch 214, gen_loss 1.780297, disc_loss 0.944724\n",
      "batch 215, gen_loss 1.781352, disc_loss 0.885469\n",
      "batch 216, gen_loss 1.690898, disc_loss 0.841433\n",
      "batch 217, gen_loss 1.418178, disc_loss 1.076462\n",
      "batch 218, gen_loss 1.388925, disc_loss 0.967739\n",
      "batch 219, gen_loss 1.508701, disc_loss 0.991508\n",
      "batch 220, gen_loss 1.502267, disc_loss 0.888390\n",
      "batch 221, gen_loss 1.633944, disc_loss 0.916442\n",
      "batch 222, gen_loss 1.752348, disc_loss 0.978218\n",
      "batch 223, gen_loss 1.700721, disc_loss 0.963202\n",
      "batch 224, gen_loss 1.566410, disc_loss 0.923124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 225, gen_loss 1.462574, disc_loss 1.016105\n",
      "batch 226, gen_loss 1.332058, disc_loss 0.925703\n",
      "batch 227, gen_loss 1.460902, disc_loss 0.969721\n",
      "batch 228, gen_loss 1.632344, disc_loss 0.982945\n",
      "batch 229, gen_loss 1.580480, disc_loss 0.995128\n",
      "batch 230, gen_loss 1.622574, disc_loss 1.029570\n",
      "batch 231, gen_loss 1.550381, disc_loss 0.996145\n",
      "batch 232, gen_loss 1.407282, disc_loss 1.125693\n",
      "batch 233, gen_loss 1.323442, disc_loss 0.977261\n",
      "batch 234, gen_loss 1.347881, disc_loss 0.926306\n",
      "Time for epoch47is 8.065379619598389 sec\n",
      "batch 0, gen_loss 1.390559, disc_loss 0.997624\n",
      "batch 1, gen_loss 1.609143, disc_loss 0.904782\n",
      "batch 2, gen_loss 1.636536, disc_loss 0.957077\n",
      "batch 3, gen_loss 1.618842, disc_loss 0.977147\n",
      "batch 4, gen_loss 1.490931, disc_loss 0.951330\n",
      "batch 5, gen_loss 1.319661, disc_loss 0.946970\n",
      "batch 6, gen_loss 1.250356, disc_loss 0.977483\n",
      "batch 7, gen_loss 1.399863, disc_loss 0.868092\n",
      "batch 8, gen_loss 1.734249, disc_loss 0.924461\n",
      "batch 9, gen_loss 1.869412, disc_loss 0.886364\n",
      "batch 10, gen_loss 1.712676, disc_loss 0.946589\n",
      "batch 11, gen_loss 1.603574, disc_loss 0.770847\n",
      "batch 12, gen_loss 1.440614, disc_loss 0.813556\n",
      "batch 13, gen_loss 1.432890, disc_loss 0.863107\n",
      "batch 14, gen_loss 1.575416, disc_loss 0.860029\n",
      "batch 15, gen_loss 1.637173, disc_loss 0.828909\n",
      "batch 16, gen_loss 1.628238, disc_loss 0.715822\n",
      "batch 17, gen_loss 1.630752, disc_loss 0.832404\n",
      "batch 18, gen_loss 1.647492, disc_loss 0.795301\n",
      "batch 19, gen_loss 1.707653, disc_loss 0.758095\n",
      "batch 20, gen_loss 1.750463, disc_loss 0.814815\n",
      "batch 21, gen_loss 1.619266, disc_loss 0.720533\n",
      "batch 22, gen_loss 1.625306, disc_loss 0.765129\n",
      "batch 23, gen_loss 1.598167, disc_loss 0.799017\n",
      "batch 24, gen_loss 1.700709, disc_loss 0.855992\n",
      "batch 25, gen_loss 1.794931, disc_loss 0.765578\n",
      "batch 26, gen_loss 1.672675, disc_loss 0.862467\n",
      "batch 27, gen_loss 1.519964, disc_loss 0.901710\n",
      "batch 28, gen_loss 1.461155, disc_loss 0.868734\n",
      "batch 29, gen_loss 1.448897, disc_loss 0.860066\n",
      "batch 30, gen_loss 1.571206, disc_loss 0.874991\n",
      "batch 31, gen_loss 1.683545, disc_loss 0.762051\n",
      "batch 32, gen_loss 1.785458, disc_loss 0.789769\n",
      "batch 33, gen_loss 1.585709, disc_loss 0.917157\n",
      "batch 34, gen_loss 1.616509, disc_loss 0.779187\n",
      "batch 35, gen_loss 1.509028, disc_loss 0.886061\n",
      "batch 36, gen_loss 1.451592, disc_loss 0.895419\n",
      "batch 37, gen_loss 1.459274, disc_loss 0.865146\n",
      "batch 38, gen_loss 1.534830, disc_loss 0.799252\n",
      "batch 39, gen_loss 1.592593, disc_loss 0.885627\n",
      "batch 40, gen_loss 1.550493, disc_loss 0.887686\n",
      "batch 41, gen_loss 1.593077, disc_loss 0.836015\n",
      "batch 42, gen_loss 1.502299, disc_loss 0.880854\n",
      "batch 43, gen_loss 1.454535, disc_loss 0.937446\n",
      "batch 44, gen_loss 1.363627, disc_loss 0.921567\n",
      "batch 45, gen_loss 1.340621, disc_loss 0.926780\n",
      "batch 46, gen_loss 1.531369, disc_loss 0.822330\n",
      "batch 47, gen_loss 1.698262, disc_loss 0.895900\n",
      "batch 48, gen_loss 1.806906, disc_loss 1.003567\n",
      "batch 49, gen_loss 1.787608, disc_loss 0.923810\n",
      "batch 50, gen_loss 1.547181, disc_loss 0.900341\n",
      "batch 51, gen_loss 1.375433, disc_loss 0.900681\n",
      "batch 52, gen_loss 1.257041, disc_loss 0.903039\n",
      "batch 53, gen_loss 1.317527, disc_loss 1.009288\n",
      "batch 54, gen_loss 1.564676, disc_loss 0.885431\n",
      "batch 55, gen_loss 1.680861, disc_loss 0.905282\n",
      "batch 56, gen_loss 1.710035, disc_loss 0.957374\n",
      "batch 57, gen_loss 1.582061, disc_loss 0.947338\n",
      "batch 58, gen_loss 1.423001, disc_loss 0.955386\n",
      "batch 59, gen_loss 1.323700, disc_loss 1.013944\n",
      "batch 60, gen_loss 1.380610, disc_loss 0.966061\n",
      "batch 61, gen_loss 1.390107, disc_loss 0.917027\n",
      "batch 62, gen_loss 1.501775, disc_loss 0.955133\n",
      "batch 63, gen_loss 1.558087, disc_loss 0.897753\n",
      "batch 64, gen_loss 1.574083, disc_loss 1.031914\n",
      "batch 65, gen_loss 1.465917, disc_loss 1.063286\n",
      "batch 66, gen_loss 1.480984, disc_loss 0.984292\n",
      "batch 67, gen_loss 1.357106, disc_loss 0.932601\n",
      "batch 68, gen_loss 1.281882, disc_loss 1.047021\n",
      "batch 69, gen_loss 1.345957, disc_loss 0.920864\n",
      "batch 70, gen_loss 1.484111, disc_loss 0.975900\n",
      "batch 71, gen_loss 1.529346, disc_loss 0.890885\n",
      "batch 72, gen_loss 1.519028, disc_loss 0.939613\n",
      "batch 73, gen_loss 1.516414, disc_loss 0.827020\n",
      "batch 74, gen_loss 1.467161, disc_loss 0.906050\n",
      "batch 75, gen_loss 1.421793, disc_loss 0.932602\n",
      "batch 76, gen_loss 1.515229, disc_loss 0.918760\n",
      "batch 77, gen_loss 1.494240, disc_loss 0.858660\n",
      "batch 78, gen_loss 1.459596, disc_loss 0.922607\n",
      "batch 79, gen_loss 1.453473, disc_loss 0.974533\n",
      "batch 80, gen_loss 1.486607, disc_loss 0.929866\n",
      "batch 81, gen_loss 1.395951, disc_loss 0.866643\n",
      "batch 82, gen_loss 1.434195, disc_loss 0.913872\n",
      "batch 83, gen_loss 1.545193, disc_loss 0.871698\n",
      "batch 84, gen_loss 1.530820, disc_loss 0.909610\n",
      "batch 85, gen_loss 1.552087, disc_loss 0.909695\n",
      "batch 86, gen_loss 1.522201, disc_loss 0.878381\n",
      "batch 87, gen_loss 1.474503, disc_loss 0.869955\n",
      "batch 88, gen_loss 1.446467, disc_loss 0.875286\n",
      "batch 89, gen_loss 1.484525, disc_loss 0.930467\n",
      "batch 90, gen_loss 1.638169, disc_loss 0.806635\n",
      "batch 91, gen_loss 1.597095, disc_loss 0.899854\n",
      "batch 92, gen_loss 1.519608, disc_loss 0.867886\n",
      "batch 93, gen_loss 1.525599, disc_loss 0.859608\n",
      "batch 94, gen_loss 1.443207, disc_loss 0.824627\n",
      "batch 95, gen_loss 1.493547, disc_loss 0.818552\n",
      "batch 96, gen_loss 1.582063, disc_loss 0.782511\n",
      "batch 97, gen_loss 1.634493, disc_loss 0.849448\n",
      "batch 98, gen_loss 1.627586, disc_loss 0.806035\n",
      "batch 99, gen_loss 1.632013, disc_loss 0.829157\n",
      "batch 100, gen_loss 1.689227, disc_loss 0.785478\n",
      "batch 101, gen_loss 1.578573, disc_loss 0.864037\n",
      "batch 102, gen_loss 1.566705, disc_loss 0.755017\n",
      "batch 103, gen_loss 1.506322, disc_loss 0.837332\n",
      "batch 104, gen_loss 1.514880, disc_loss 0.800523\n",
      "batch 105, gen_loss 1.689787, disc_loss 0.853341\n",
      "batch 106, gen_loss 1.628252, disc_loss 0.834096\n",
      "batch 107, gen_loss 1.582414, disc_loss 0.811399\n",
      "batch 108, gen_loss 1.545370, disc_loss 0.851034\n",
      "batch 109, gen_loss 1.478249, disc_loss 0.834496\n",
      "batch 110, gen_loss 1.518946, disc_loss 0.751901\n",
      "batch 111, gen_loss 1.578737, disc_loss 0.813834\n",
      "batch 112, gen_loss 1.671491, disc_loss 0.797273\n",
      "batch 113, gen_loss 1.702961, disc_loss 0.852655\n",
      "batch 114, gen_loss 1.490308, disc_loss 0.844999\n",
      "batch 115, gen_loss 1.583084, disc_loss 0.792643\n",
      "batch 116, gen_loss 1.440105, disc_loss 0.847033\n",
      "batch 117, gen_loss 1.425088, disc_loss 0.826719\n",
      "batch 118, gen_loss 1.642285, disc_loss 0.791682\n",
      "batch 119, gen_loss 1.602754, disc_loss 0.828603\n",
      "batch 120, gen_loss 1.634960, disc_loss 0.760882\n",
      "batch 121, gen_loss 1.685867, disc_loss 0.795499\n",
      "batch 122, gen_loss 1.448298, disc_loss 0.912963\n",
      "batch 123, gen_loss 1.570846, disc_loss 0.797521\n",
      "batch 124, gen_loss 1.576339, disc_loss 0.834711\n",
      "batch 125, gen_loss 1.552222, disc_loss 0.799868\n",
      "batch 126, gen_loss 1.631869, disc_loss 0.788627\n",
      "batch 127, gen_loss 1.505184, disc_loss 0.884387\n",
      "batch 128, gen_loss 1.565373, disc_loss 0.847977\n",
      "batch 129, gen_loss 1.444711, disc_loss 0.835780\n",
      "batch 130, gen_loss 1.518881, disc_loss 0.760606\n",
      "batch 131, gen_loss 1.580240, disc_loss 0.810401\n",
      "batch 132, gen_loss 1.642078, disc_loss 0.734906\n",
      "batch 133, gen_loss 1.656947, disc_loss 0.764951\n",
      "batch 134, gen_loss 1.523555, disc_loss 0.842415\n",
      "batch 135, gen_loss 1.671364, disc_loss 0.842290\n",
      "batch 136, gen_loss 1.586441, disc_loss 0.752220\n",
      "batch 137, gen_loss 1.544627, disc_loss 0.801016\n",
      "batch 138, gen_loss 1.568013, disc_loss 0.910014\n",
      "batch 139, gen_loss 1.546605, disc_loss 0.794704\n",
      "batch 140, gen_loss 1.483041, disc_loss 0.848529\n",
      "batch 141, gen_loss 1.655507, disc_loss 0.768205\n",
      "batch 142, gen_loss 1.612299, disc_loss 0.816612\n",
      "batch 143, gen_loss 1.613696, disc_loss 0.893119\n",
      "batch 144, gen_loss 1.751065, disc_loss 0.818608\n",
      "batch 145, gen_loss 1.576040, disc_loss 0.864218\n",
      "batch 146, gen_loss 1.487730, disc_loss 0.774136\n",
      "batch 147, gen_loss 1.468472, disc_loss 0.809108\n",
      "batch 148, gen_loss 1.450425, disc_loss 0.894651\n",
      "batch 149, gen_loss 1.699574, disc_loss 0.776676\n",
      "batch 150, gen_loss 1.626557, disc_loss 0.852928\n",
      "batch 151, gen_loss 1.556840, disc_loss 0.819400\n",
      "batch 152, gen_loss 1.691705, disc_loss 0.774999\n",
      "batch 153, gen_loss 1.623066, disc_loss 0.830375\n",
      "batch 154, gen_loss 1.604105, disc_loss 0.755390\n",
      "batch 155, gen_loss 1.603650, disc_loss 0.856354\n",
      "batch 156, gen_loss 1.463366, disc_loss 0.869951\n",
      "batch 157, gen_loss 1.492753, disc_loss 0.793606\n",
      "batch 158, gen_loss 1.507577, disc_loss 0.866246\n",
      "batch 159, gen_loss 1.586136, disc_loss 0.870407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 160, gen_loss 1.873824, disc_loss 0.913667\n",
      "batch 161, gen_loss 1.919150, disc_loss 0.750529\n",
      "batch 162, gen_loss 1.707995, disc_loss 0.830935\n",
      "batch 163, gen_loss 1.431155, disc_loss 0.853685\n",
      "batch 164, gen_loss 1.311116, disc_loss 0.851966\n",
      "batch 165, gen_loss 1.521475, disc_loss 0.795830\n",
      "batch 166, gen_loss 1.817680, disc_loss 0.786645\n",
      "batch 167, gen_loss 1.817739, disc_loss 0.835631\n",
      "batch 168, gen_loss 1.798085, disc_loss 0.800227\n",
      "batch 169, gen_loss 1.593482, disc_loss 0.841765\n",
      "batch 170, gen_loss 1.510374, disc_loss 0.871060\n",
      "batch 171, gen_loss 1.370049, disc_loss 0.846369\n",
      "batch 172, gen_loss 1.483742, disc_loss 0.858273\n",
      "batch 173, gen_loss 1.697657, disc_loss 0.889232\n",
      "batch 174, gen_loss 1.781472, disc_loss 0.830111\n",
      "batch 175, gen_loss 1.658910, disc_loss 0.878177\n",
      "batch 176, gen_loss 1.625117, disc_loss 0.917392\n",
      "batch 177, gen_loss 1.476817, disc_loss 0.883893\n",
      "batch 178, gen_loss 1.561782, disc_loss 0.884182\n",
      "batch 179, gen_loss 1.500835, disc_loss 0.833999\n",
      "batch 180, gen_loss 1.596096, disc_loss 0.888930\n",
      "batch 181, gen_loss 1.669997, disc_loss 0.929418\n",
      "batch 182, gen_loss 1.605032, disc_loss 0.924211\n",
      "batch 183, gen_loss 1.618636, disc_loss 0.925536\n",
      "batch 184, gen_loss 1.409538, disc_loss 0.954903\n",
      "batch 185, gen_loss 1.304358, disc_loss 1.034644\n",
      "batch 186, gen_loss 1.408245, disc_loss 0.904390\n",
      "batch 187, gen_loss 1.527556, disc_loss 0.978689\n",
      "batch 188, gen_loss 1.592788, disc_loss 0.947255\n",
      "batch 189, gen_loss 1.649894, disc_loss 0.886859\n",
      "batch 190, gen_loss 1.557030, disc_loss 1.015236\n",
      "batch 191, gen_loss 1.389637, disc_loss 1.011967\n",
      "batch 192, gen_loss 1.293296, disc_loss 1.024368\n",
      "batch 193, gen_loss 1.374412, disc_loss 0.996348\n",
      "batch 194, gen_loss 1.442407, disc_loss 0.941910\n",
      "batch 195, gen_loss 1.477953, disc_loss 0.951178\n",
      "batch 196, gen_loss 1.615938, disc_loss 0.946891\n",
      "batch 197, gen_loss 1.435542, disc_loss 1.005539\n",
      "batch 198, gen_loss 1.457368, disc_loss 0.989732\n",
      "batch 199, gen_loss 1.380865, disc_loss 1.020335\n",
      "batch 200, gen_loss 1.310056, disc_loss 1.050092\n",
      "batch 201, gen_loss 1.321862, disc_loss 1.050290\n",
      "batch 202, gen_loss 1.613822, disc_loss 0.993181\n",
      "batch 203, gen_loss 1.567554, disc_loss 0.983595\n",
      "batch 204, gen_loss 1.588538, disc_loss 0.977675\n",
      "batch 205, gen_loss 1.546135, disc_loss 0.909504\n",
      "batch 206, gen_loss 1.369585, disc_loss 0.920953\n",
      "batch 207, gen_loss 1.387935, disc_loss 0.981944\n",
      "batch 208, gen_loss 1.426448, disc_loss 0.909314\n",
      "batch 209, gen_loss 1.519248, disc_loss 0.924013\n",
      "batch 210, gen_loss 1.699344, disc_loss 0.899251\n",
      "batch 211, gen_loss 1.672273, disc_loss 0.912234\n",
      "batch 212, gen_loss 1.604163, disc_loss 0.833709\n",
      "batch 213, gen_loss 1.570438, disc_loss 0.929255\n",
      "batch 214, gen_loss 1.364956, disc_loss 0.909395\n",
      "batch 215, gen_loss 1.397156, disc_loss 0.915968\n",
      "batch 216, gen_loss 1.434370, disc_loss 0.939018\n",
      "batch 217, gen_loss 1.605480, disc_loss 0.861089\n",
      "batch 218, gen_loss 1.639639, disc_loss 0.870275\n",
      "batch 219, gen_loss 1.698804, disc_loss 0.814492\n",
      "batch 220, gen_loss 1.560516, disc_loss 0.803401\n",
      "batch 221, gen_loss 1.688825, disc_loss 0.876096\n",
      "batch 222, gen_loss 1.695858, disc_loss 0.783151\n",
      "batch 223, gen_loss 1.545059, disc_loss 0.894107\n",
      "batch 224, gen_loss 1.509329, disc_loss 0.814036\n",
      "batch 225, gen_loss 1.585718, disc_loss 0.875731\n",
      "batch 226, gen_loss 1.705696, disc_loss 0.800988\n",
      "batch 227, gen_loss 1.790484, disc_loss 0.733737\n",
      "batch 228, gen_loss 1.624730, disc_loss 0.845973\n",
      "batch 229, gen_loss 1.742455, disc_loss 0.751807\n",
      "batch 230, gen_loss 1.661627, disc_loss 0.802032\n",
      "batch 231, gen_loss 1.787929, disc_loss 0.788156\n",
      "batch 232, gen_loss 1.717350, disc_loss 0.770169\n",
      "batch 233, gen_loss 1.599857, disc_loss 0.908908\n",
      "batch 234, gen_loss 1.617442, disc_loss 0.734332\n",
      "Time for epoch48is 7.671066761016846 sec\n",
      "batch 0, gen_loss 1.566512, disc_loss 0.803620\n",
      "batch 1, gen_loss 1.708855, disc_loss 0.816301\n",
      "batch 2, gen_loss 1.823717, disc_loss 0.821843\n",
      "batch 3, gen_loss 1.725272, disc_loss 0.708645\n",
      "batch 4, gen_loss 1.688544, disc_loss 0.724843\n",
      "batch 5, gen_loss 1.714331, disc_loss 0.784386\n",
      "batch 6, gen_loss 1.751914, disc_loss 0.709056\n",
      "batch 7, gen_loss 2.112720, disc_loss 0.750555\n",
      "batch 8, gen_loss 1.875047, disc_loss 0.732583\n",
      "batch 9, gen_loss 1.754979, disc_loss 0.725213\n",
      "batch 10, gen_loss 1.629150, disc_loss 0.709079\n",
      "batch 11, gen_loss 1.568880, disc_loss 0.717434\n",
      "batch 12, gen_loss 1.730608, disc_loss 0.698889\n",
      "batch 13, gen_loss 1.880391, disc_loss 0.766075\n",
      "batch 14, gen_loss 2.065926, disc_loss 0.653021\n",
      "batch 15, gen_loss 2.031211, disc_loss 0.680426\n",
      "batch 16, gen_loss 1.855188, disc_loss 0.715421\n",
      "batch 17, gen_loss 1.824438, disc_loss 0.675736\n",
      "batch 18, gen_loss 1.750162, disc_loss 0.657375\n",
      "batch 19, gen_loss 1.655680, disc_loss 0.727699\n",
      "batch 20, gen_loss 1.824610, disc_loss 0.670194\n",
      "batch 21, gen_loss 1.858142, disc_loss 0.699888\n",
      "batch 22, gen_loss 1.873869, disc_loss 0.689087\n",
      "batch 23, gen_loss 1.833008, disc_loss 0.714449\n",
      "batch 24, gen_loss 1.771064, disc_loss 0.793869\n",
      "batch 25, gen_loss 1.731686, disc_loss 0.672632\n",
      "batch 26, gen_loss 1.637138, disc_loss 0.735556\n",
      "batch 27, gen_loss 1.683023, disc_loss 0.764405\n",
      "batch 28, gen_loss 1.625946, disc_loss 0.744194\n",
      "batch 29, gen_loss 1.648992, disc_loss 0.857649\n",
      "batch 30, gen_loss 1.726828, disc_loss 0.706327\n",
      "batch 31, gen_loss 1.851279, disc_loss 0.768029\n",
      "batch 32, gen_loss 1.691227, disc_loss 0.840713\n",
      "batch 33, gen_loss 1.701368, disc_loss 0.779406\n",
      "batch 34, gen_loss 1.847583, disc_loss 0.786188\n",
      "batch 35, gen_loss 1.691955, disc_loss 0.800172\n",
      "batch 36, gen_loss 1.715490, disc_loss 0.828504\n",
      "batch 37, gen_loss 1.742698, disc_loss 0.842627\n",
      "batch 38, gen_loss 1.786402, disc_loss 0.820377\n",
      "batch 39, gen_loss 1.732571, disc_loss 0.810573\n",
      "batch 40, gen_loss 1.904945, disc_loss 0.706734\n",
      "batch 41, gen_loss 1.759121, disc_loss 0.920434\n",
      "batch 42, gen_loss 1.793092, disc_loss 0.833275\n",
      "batch 43, gen_loss 1.647667, disc_loss 0.784845\n",
      "batch 44, gen_loss 1.621312, disc_loss 0.993325\n",
      "batch 45, gen_loss 1.472867, disc_loss 0.879380\n",
      "batch 46, gen_loss 1.572068, disc_loss 0.916251\n",
      "batch 47, gen_loss 1.654756, disc_loss 0.881498\n",
      "batch 48, gen_loss 1.810296, disc_loss 0.894291\n",
      "batch 49, gen_loss 1.717176, disc_loss 0.881721\n",
      "batch 50, gen_loss 1.929898, disc_loss 0.811938\n",
      "batch 51, gen_loss 1.748588, disc_loss 0.906297\n",
      "batch 52, gen_loss 1.475477, disc_loss 0.897573\n",
      "batch 53, gen_loss 1.497560, disc_loss 0.896512\n",
      "batch 54, gen_loss 1.477111, disc_loss 0.886566\n",
      "batch 55, gen_loss 1.571862, disc_loss 0.855553\n",
      "batch 56, gen_loss 1.641403, disc_loss 0.984345\n",
      "batch 57, gen_loss 1.774612, disc_loss 0.868905\n",
      "batch 58, gen_loss 1.716224, disc_loss 0.857630\n",
      "batch 59, gen_loss 1.539479, disc_loss 0.928128\n",
      "batch 60, gen_loss 1.446789, disc_loss 0.963104\n",
      "batch 61, gen_loss 1.428857, disc_loss 0.932935\n",
      "batch 62, gen_loss 1.553080, disc_loss 0.947560\n",
      "batch 63, gen_loss 1.550500, disc_loss 0.919562\n",
      "batch 64, gen_loss 1.540943, disc_loss 0.980887\n",
      "batch 65, gen_loss 1.614557, disc_loss 0.903541\n",
      "batch 66, gen_loss 1.651140, disc_loss 0.915859\n",
      "batch 67, gen_loss 1.599739, disc_loss 0.913606\n",
      "batch 68, gen_loss 1.540073, disc_loss 0.925101\n",
      "batch 69, gen_loss 1.554900, disc_loss 0.920629\n",
      "batch 70, gen_loss 1.524563, disc_loss 0.975358\n",
      "batch 71, gen_loss 1.675612, disc_loss 0.936219\n",
      "batch 72, gen_loss 1.569122, disc_loss 0.934905\n",
      "batch 73, gen_loss 1.606588, disc_loss 1.022907\n",
      "batch 74, gen_loss 1.386978, disc_loss 1.014816\n",
      "batch 75, gen_loss 1.408945, disc_loss 1.012221\n",
      "batch 76, gen_loss 1.396122, disc_loss 1.083555\n",
      "batch 77, gen_loss 1.455835, disc_loss 0.944752\n",
      "batch 78, gen_loss 1.344907, disc_loss 1.099657\n",
      "batch 79, gen_loss 1.515458, disc_loss 1.001112\n",
      "batch 80, gen_loss 1.571197, disc_loss 0.973722\n",
      "batch 81, gen_loss 1.619573, disc_loss 0.931602\n",
      "batch 82, gen_loss 1.430225, disc_loss 1.007659\n",
      "batch 83, gen_loss 1.475872, disc_loss 0.969187\n",
      "batch 84, gen_loss 1.377212, disc_loss 1.074180\n",
      "batch 85, gen_loss 1.481886, disc_loss 1.106473\n",
      "batch 86, gen_loss 1.548918, disc_loss 1.028245\n",
      "batch 87, gen_loss 1.407681, disc_loss 1.013955\n",
      "batch 88, gen_loss 1.329757, disc_loss 1.033354\n",
      "batch 89, gen_loss 1.459365, disc_loss 1.056662\n",
      "batch 90, gen_loss 1.502844, disc_loss 1.081758\n",
      "batch 91, gen_loss 1.372345, disc_loss 1.094685\n",
      "batch 92, gen_loss 1.209664, disc_loss 1.110117\n",
      "batch 93, gen_loss 1.459278, disc_loss 1.008462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 94, gen_loss 1.563666, disc_loss 1.033107\n",
      "batch 95, gen_loss 1.569310, disc_loss 0.959390\n",
      "batch 96, gen_loss 1.534545, disc_loss 0.967833\n",
      "batch 97, gen_loss 1.474413, disc_loss 1.037344\n",
      "batch 98, gen_loss 1.439855, disc_loss 1.011489\n",
      "batch 99, gen_loss 1.336631, disc_loss 0.948332\n",
      "batch 100, gen_loss 1.339915, disc_loss 0.950280\n",
      "batch 101, gen_loss 1.359849, disc_loss 0.957665\n",
      "batch 102, gen_loss 1.492176, disc_loss 0.977010\n",
      "batch 103, gen_loss 1.562831, disc_loss 0.925067\n",
      "batch 104, gen_loss 1.635754, disc_loss 0.869525\n",
      "batch 105, gen_loss 1.472318, disc_loss 0.866212\n",
      "batch 106, gen_loss 1.551351, disc_loss 0.873628\n",
      "batch 107, gen_loss 1.371249, disc_loss 0.900285\n",
      "batch 108, gen_loss 1.453297, disc_loss 0.900509\n",
      "batch 109, gen_loss 1.545022, disc_loss 0.872784\n",
      "batch 110, gen_loss 1.573634, disc_loss 0.866467\n",
      "batch 111, gen_loss 1.483735, disc_loss 0.905217\n",
      "batch 112, gen_loss 1.512072, disc_loss 0.945729\n",
      "batch 113, gen_loss 1.398097, disc_loss 0.941451\n",
      "batch 114, gen_loss 1.395127, disc_loss 0.960850\n",
      "batch 115, gen_loss 1.373540, disc_loss 0.936250\n",
      "batch 116, gen_loss 1.394292, disc_loss 0.927032\n",
      "batch 117, gen_loss 1.607595, disc_loss 0.868099\n",
      "batch 118, gen_loss 1.614192, disc_loss 0.895733\n",
      "batch 119, gen_loss 1.628936, disc_loss 0.833471\n",
      "batch 120, gen_loss 1.514654, disc_loss 0.879354\n",
      "batch 121, gen_loss 1.314287, disc_loss 0.900878\n",
      "batch 122, gen_loss 1.399199, disc_loss 0.892623\n",
      "batch 123, gen_loss 1.498896, disc_loss 0.883251\n",
      "batch 124, gen_loss 1.656241, disc_loss 0.829939\n",
      "batch 125, gen_loss 1.687267, disc_loss 0.824810\n",
      "batch 126, gen_loss 1.506125, disc_loss 0.840361\n",
      "batch 127, gen_loss 1.475504, disc_loss 0.806182\n",
      "batch 128, gen_loss 1.413559, disc_loss 0.874728\n",
      "batch 129, gen_loss 1.556105, disc_loss 0.798526\n",
      "batch 130, gen_loss 1.549161, disc_loss 0.826919\n",
      "batch 131, gen_loss 1.603278, disc_loss 0.828159\n",
      "batch 132, gen_loss 1.612305, disc_loss 0.940102\n",
      "batch 133, gen_loss 1.492500, disc_loss 0.887503\n",
      "batch 134, gen_loss 1.381312, disc_loss 0.921722\n",
      "batch 135, gen_loss 1.371299, disc_loss 1.005474\n",
      "batch 136, gen_loss 1.432179, disc_loss 0.856276\n",
      "batch 137, gen_loss 1.353678, disc_loss 0.976661\n",
      "batch 138, gen_loss 1.393564, disc_loss 0.908351\n",
      "batch 139, gen_loss 1.479034, disc_loss 0.901542\n",
      "batch 140, gen_loss 1.495109, disc_loss 0.932185\n",
      "batch 141, gen_loss 1.458375, disc_loss 0.889596\n",
      "batch 142, gen_loss 1.528548, disc_loss 0.993342\n",
      "batch 143, gen_loss 1.559960, disc_loss 0.935107\n",
      "batch 144, gen_loss 1.382174, disc_loss 0.881565\n",
      "batch 145, gen_loss 1.386505, disc_loss 0.952236\n",
      "batch 146, gen_loss 1.450610, disc_loss 0.929923\n",
      "batch 147, gen_loss 1.484169, disc_loss 0.889320\n",
      "batch 148, gen_loss 1.652328, disc_loss 0.912173\n",
      "batch 149, gen_loss 1.470294, disc_loss 0.975758\n",
      "batch 150, gen_loss 1.397801, disc_loss 0.957785\n",
      "batch 151, gen_loss 1.369212, disc_loss 0.910754\n",
      "batch 152, gen_loss 1.337019, disc_loss 0.935321\n",
      "batch 153, gen_loss 1.477114, disc_loss 0.896096\n",
      "batch 154, gen_loss 1.421464, disc_loss 1.040522\n",
      "batch 155, gen_loss 1.639171, disc_loss 0.978493\n",
      "batch 156, gen_loss 1.532813, disc_loss 0.932941\n",
      "batch 157, gen_loss 1.408799, disc_loss 0.949403\n",
      "batch 158, gen_loss 1.370988, disc_loss 0.919013\n",
      "batch 159, gen_loss 1.391335, disc_loss 0.914739\n",
      "batch 160, gen_loss 1.543755, disc_loss 0.897332\n",
      "batch 161, gen_loss 1.457512, disc_loss 1.008262\n",
      "batch 162, gen_loss 1.491750, disc_loss 0.947561\n",
      "batch 163, gen_loss 1.442585, disc_loss 0.860996\n",
      "batch 164, gen_loss 1.415275, disc_loss 0.868181\n",
      "batch 165, gen_loss 1.498999, disc_loss 0.931342\n",
      "batch 166, gen_loss 1.516516, disc_loss 0.930297\n",
      "batch 167, gen_loss 1.437307, disc_loss 0.949027\n",
      "batch 168, gen_loss 1.409269, disc_loss 0.915793\n",
      "batch 169, gen_loss 1.483199, disc_loss 0.908152\n",
      "batch 170, gen_loss 1.476200, disc_loss 0.871661\n",
      "batch 171, gen_loss 1.618363, disc_loss 0.839465\n",
      "batch 172, gen_loss 1.629707, disc_loss 0.936277\n",
      "batch 173, gen_loss 1.519493, disc_loss 0.905782\n",
      "batch 174, gen_loss 1.445539, disc_loss 0.825555\n",
      "batch 175, gen_loss 1.580010, disc_loss 0.859159\n",
      "batch 176, gen_loss 1.538484, disc_loss 0.831536\n",
      "batch 177, gen_loss 1.488740, disc_loss 0.830506\n",
      "batch 178, gen_loss 1.425391, disc_loss 0.893991\n",
      "batch 179, gen_loss 1.643656, disc_loss 0.823432\n",
      "batch 180, gen_loss 1.663870, disc_loss 0.880037\n",
      "batch 181, gen_loss 1.650956, disc_loss 0.842916\n",
      "batch 182, gen_loss 1.601937, disc_loss 0.847062\n",
      "batch 183, gen_loss 1.462864, disc_loss 0.794352\n",
      "batch 184, gen_loss 1.463399, disc_loss 0.763977\n",
      "batch 185, gen_loss 1.593334, disc_loss 0.879054\n",
      "batch 186, gen_loss 1.725720, disc_loss 0.832291\n",
      "batch 187, gen_loss 1.791283, disc_loss 0.756371\n",
      "batch 188, gen_loss 1.727931, disc_loss 0.751337\n",
      "batch 189, gen_loss 1.647919, disc_loss 0.725483\n",
      "batch 190, gen_loss 1.645909, disc_loss 0.841398\n",
      "batch 191, gen_loss 1.466237, disc_loss 0.843827\n",
      "batch 192, gen_loss 1.527781, disc_loss 0.726155\n",
      "batch 193, gen_loss 1.597048, disc_loss 0.841405\n",
      "batch 194, gen_loss 1.659561, disc_loss 0.788770\n",
      "batch 195, gen_loss 1.696641, disc_loss 0.804738\n",
      "batch 196, gen_loss 1.697087, disc_loss 0.785279\n",
      "batch 197, gen_loss 1.541957, disc_loss 0.814561\n",
      "batch 198, gen_loss 1.544756, disc_loss 0.804239\n",
      "batch 199, gen_loss 1.538965, disc_loss 0.796241\n",
      "batch 200, gen_loss 1.611955, disc_loss 0.830186\n",
      "batch 201, gen_loss 1.531336, disc_loss 0.876927\n",
      "batch 202, gen_loss 1.527299, disc_loss 0.815685\n",
      "batch 203, gen_loss 1.575200, disc_loss 0.845615\n",
      "batch 204, gen_loss 1.563648, disc_loss 0.868737\n",
      "batch 205, gen_loss 1.652998, disc_loss 0.832481\n",
      "batch 206, gen_loss 1.613108, disc_loss 0.898634\n",
      "batch 207, gen_loss 1.520318, disc_loss 0.947139\n",
      "batch 208, gen_loss 1.354170, disc_loss 0.914476\n",
      "batch 209, gen_loss 1.213498, disc_loss 1.029065\n",
      "batch 210, gen_loss 1.367638, disc_loss 0.993660\n",
      "batch 211, gen_loss 1.446718, disc_loss 0.950296\n",
      "batch 212, gen_loss 1.434054, disc_loss 0.983241\n",
      "batch 213, gen_loss 1.444646, disc_loss 1.032456\n",
      "batch 214, gen_loss 1.455881, disc_loss 1.010832\n",
      "batch 215, gen_loss 1.458694, disc_loss 1.060987\n",
      "batch 216, gen_loss 1.322604, disc_loss 1.063508\n",
      "batch 217, gen_loss 1.253338, disc_loss 1.058500\n",
      "batch 218, gen_loss 1.064221, disc_loss 1.180651\n",
      "batch 219, gen_loss 1.304507, disc_loss 1.064222\n",
      "batch 220, gen_loss 1.480292, disc_loss 1.208678\n",
      "batch 221, gen_loss 1.531742, disc_loss 1.144912\n",
      "batch 222, gen_loss 1.505418, disc_loss 1.089014\n",
      "batch 223, gen_loss 1.258672, disc_loss 1.199143\n",
      "batch 224, gen_loss 1.020713, disc_loss 1.146394\n",
      "batch 225, gen_loss 1.072234, disc_loss 1.223227\n",
      "batch 226, gen_loss 1.167707, disc_loss 1.224963\n",
      "batch 227, gen_loss 1.437683, disc_loss 1.303778\n",
      "batch 228, gen_loss 1.449407, disc_loss 1.257743\n",
      "batch 229, gen_loss 1.305467, disc_loss 1.196320\n",
      "batch 230, gen_loss 1.119771, disc_loss 1.215082\n",
      "batch 231, gen_loss 1.070721, disc_loss 1.227242\n",
      "batch 232, gen_loss 1.096228, disc_loss 1.241311\n",
      "batch 233, gen_loss 1.236798, disc_loss 1.109738\n",
      "batch 234, gen_loss 1.372715, disc_loss 1.069494\n",
      "Time for epoch49is 7.901298761367798 sec\n",
      "batch 0, gen_loss 1.498917, disc_loss 1.283118\n",
      "batch 1, gen_loss 1.531358, disc_loss 1.083856\n",
      "batch 2, gen_loss 1.346673, disc_loss 1.145422\n",
      "batch 3, gen_loss 1.109252, disc_loss 1.176481\n",
      "batch 4, gen_loss 1.021812, disc_loss 1.139850\n",
      "batch 5, gen_loss 1.098951, disc_loss 1.160927\n",
      "batch 6, gen_loss 1.394464, disc_loss 1.109894\n",
      "batch 7, gen_loss 1.637318, disc_loss 1.136365\n",
      "batch 8, gen_loss 1.514825, disc_loss 1.058008\n",
      "batch 9, gen_loss 1.343749, disc_loss 1.087996\n",
      "batch 10, gen_loss 1.187366, disc_loss 1.121519\n",
      "batch 11, gen_loss 1.230858, disc_loss 0.954381\n",
      "batch 12, gen_loss 1.254252, disc_loss 1.036240\n",
      "batch 13, gen_loss 1.439604, disc_loss 1.023553\n",
      "batch 14, gen_loss 1.618254, disc_loss 1.031262\n",
      "batch 15, gen_loss 1.552204, disc_loss 0.949080\n",
      "batch 16, gen_loss 1.353784, disc_loss 1.025907\n",
      "batch 17, gen_loss 1.275178, disc_loss 0.974481\n",
      "batch 18, gen_loss 1.382242, disc_loss 0.852631\n",
      "batch 19, gen_loss 1.449928, disc_loss 0.948454\n",
      "batch 20, gen_loss 1.452251, disc_loss 0.875752\n",
      "batch 21, gen_loss 1.640216, disc_loss 0.917509\n",
      "batch 22, gen_loss 1.563311, disc_loss 0.956804\n",
      "batch 23, gen_loss 1.515767, disc_loss 0.844144\n",
      "batch 24, gen_loss 1.513865, disc_loss 0.835863\n",
      "batch 25, gen_loss 1.345148, disc_loss 0.841437\n",
      "batch 26, gen_loss 1.447958, disc_loss 0.833639\n",
      "batch 27, gen_loss 1.620124, disc_loss 0.817931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 28, gen_loss 1.691946, disc_loss 0.749538\n",
      "batch 29, gen_loss 1.702228, disc_loss 0.749363\n",
      "batch 30, gen_loss 1.611542, disc_loss 0.839592\n",
      "batch 31, gen_loss 1.556623, disc_loss 0.773727\n",
      "batch 32, gen_loss 1.505432, disc_loss 0.765417\n",
      "batch 33, gen_loss 1.596548, disc_loss 0.792794\n",
      "batch 34, gen_loss 1.734937, disc_loss 0.740226\n",
      "batch 35, gen_loss 1.692373, disc_loss 0.759008\n",
      "batch 36, gen_loss 1.623569, disc_loss 0.753509\n",
      "batch 37, gen_loss 1.585306, disc_loss 0.776707\n",
      "batch 38, gen_loss 1.745411, disc_loss 0.701769\n",
      "batch 39, gen_loss 1.587103, disc_loss 0.755057\n",
      "batch 40, gen_loss 1.606849, disc_loss 0.818334\n",
      "batch 41, gen_loss 1.712042, disc_loss 0.753159\n",
      "batch 42, gen_loss 1.685016, disc_loss 0.801328\n",
      "batch 43, gen_loss 1.636655, disc_loss 0.744821\n",
      "batch 44, gen_loss 1.657700, disc_loss 0.712092\n",
      "batch 45, gen_loss 1.702391, disc_loss 0.770197\n",
      "batch 46, gen_loss 1.704322, disc_loss 0.722999\n",
      "batch 47, gen_loss 1.677612, disc_loss 0.771100\n",
      "batch 48, gen_loss 1.671960, disc_loss 0.761175\n",
      "batch 49, gen_loss 1.589467, disc_loss 0.702044\n",
      "batch 50, gen_loss 1.793559, disc_loss 0.660094\n",
      "batch 51, gen_loss 1.679866, disc_loss 0.728610\n",
      "batch 52, gen_loss 1.648833, disc_loss 0.747213\n",
      "batch 53, gen_loss 1.770425, disc_loss 0.733658\n",
      "batch 54, gen_loss 1.728463, disc_loss 0.669704\n",
      "batch 55, gen_loss 1.678610, disc_loss 0.801241\n",
      "batch 56, gen_loss 1.711972, disc_loss 0.725004\n",
      "batch 57, gen_loss 1.649428, disc_loss 0.764903\n",
      "batch 58, gen_loss 1.583698, disc_loss 0.744366\n",
      "batch 59, gen_loss 1.556270, disc_loss 0.858858\n",
      "batch 60, gen_loss 1.604478, disc_loss 0.774500\n",
      "batch 61, gen_loss 1.658839, disc_loss 0.810117\n",
      "batch 62, gen_loss 1.612453, disc_loss 0.700543\n",
      "batch 63, gen_loss 1.667735, disc_loss 0.778910\n",
      "batch 64, gen_loss 1.709296, disc_loss 0.806580\n",
      "batch 65, gen_loss 1.634294, disc_loss 0.771170\n",
      "batch 66, gen_loss 1.513791, disc_loss 0.810495\n",
      "batch 67, gen_loss 1.459690, disc_loss 0.878962\n",
      "batch 68, gen_loss 1.604987, disc_loss 0.806149\n",
      "batch 69, gen_loss 1.738446, disc_loss 0.802640\n",
      "batch 70, gen_loss 1.707584, disc_loss 0.790246\n",
      "batch 71, gen_loss 1.653078, disc_loss 0.877700\n",
      "batch 72, gen_loss 1.493621, disc_loss 0.837105\n",
      "batch 73, gen_loss 1.435792, disc_loss 0.812658\n",
      "batch 74, gen_loss 1.496506, disc_loss 0.836999\n",
      "batch 75, gen_loss 1.549960, disc_loss 0.936643\n",
      "batch 76, gen_loss 1.736143, disc_loss 0.891858\n",
      "batch 77, gen_loss 1.669871, disc_loss 0.863653\n",
      "batch 78, gen_loss 1.610483, disc_loss 0.919419\n",
      "batch 79, gen_loss 1.351995, disc_loss 0.828996\n",
      "batch 80, gen_loss 1.327311, disc_loss 0.815038\n",
      "batch 81, gen_loss 1.330261, disc_loss 0.894908\n",
      "batch 82, gen_loss 1.723039, disc_loss 0.832784\n",
      "batch 83, gen_loss 1.798661, disc_loss 1.122484\n",
      "batch 84, gen_loss 1.904536, disc_loss 0.871164\n",
      "batch 85, gen_loss 1.558859, disc_loss 0.857107\n",
      "batch 86, gen_loss 1.293822, disc_loss 0.969924\n",
      "batch 87, gen_loss 1.239380, disc_loss 0.954240\n",
      "batch 88, gen_loss 1.312624, disc_loss 0.905791\n",
      "batch 89, gen_loss 1.576303, disc_loss 0.989294\n",
      "batch 90, gen_loss 1.722580, disc_loss 1.029098\n",
      "batch 91, gen_loss 1.680848, disc_loss 0.955651\n",
      "batch 92, gen_loss 1.427951, disc_loss 0.901801\n",
      "batch 93, gen_loss 1.371883, disc_loss 0.943177\n",
      "batch 94, gen_loss 1.408108, disc_loss 0.911836\n",
      "batch 95, gen_loss 1.446246, disc_loss 0.862067\n",
      "batch 96, gen_loss 1.632449, disc_loss 0.878346\n",
      "batch 97, gen_loss 1.625536, disc_loss 0.918566\n",
      "batch 98, gen_loss 1.658226, disc_loss 0.945322\n",
      "batch 99, gen_loss 1.568928, disc_loss 0.923288\n",
      "batch 100, gen_loss 1.445462, disc_loss 0.949158\n",
      "batch 101, gen_loss 1.376564, disc_loss 0.872012\n",
      "batch 102, gen_loss 1.415766, disc_loss 0.829091\n",
      "batch 103, gen_loss 1.481446, disc_loss 0.978121\n",
      "batch 104, gen_loss 1.733034, disc_loss 0.864669\n",
      "batch 105, gen_loss 1.736476, disc_loss 0.968910\n",
      "batch 106, gen_loss 1.669425, disc_loss 0.947576\n",
      "batch 107, gen_loss 1.355278, disc_loss 0.908123\n",
      "batch 108, gen_loss 1.353400, disc_loss 0.948865\n",
      "batch 109, gen_loss 1.348864, disc_loss 0.948382\n",
      "batch 110, gen_loss 1.530049, disc_loss 0.872617\n",
      "batch 111, gen_loss 1.664294, disc_loss 0.804502\n",
      "batch 112, gen_loss 1.701419, disc_loss 0.862912\n",
      "batch 113, gen_loss 1.580703, disc_loss 0.852177\n",
      "batch 114, gen_loss 1.679926, disc_loss 0.842088\n",
      "batch 115, gen_loss 1.633028, disc_loss 0.950315\n",
      "batch 116, gen_loss 1.626529, disc_loss 0.878235\n",
      "batch 117, gen_loss 1.542572, disc_loss 0.883484\n",
      "batch 118, gen_loss 1.488708, disc_loss 0.854606\n",
      "batch 119, gen_loss 1.442717, disc_loss 0.853427\n",
      "batch 120, gen_loss 1.616627, disc_loss 0.887524\n",
      "batch 121, gen_loss 1.629825, disc_loss 0.788960\n",
      "batch 122, gen_loss 1.608471, disc_loss 0.844292\n",
      "batch 123, gen_loss 1.549778, disc_loss 0.864015\n",
      "batch 124, gen_loss 1.633044, disc_loss 0.812050\n",
      "batch 125, gen_loss 1.687922, disc_loss 0.752086\n",
      "batch 126, gen_loss 1.613999, disc_loss 0.795925\n",
      "batch 127, gen_loss 1.561804, disc_loss 0.888863\n",
      "batch 128, gen_loss 1.532103, disc_loss 0.795119\n",
      "batch 129, gen_loss 1.604191, disc_loss 0.759934\n",
      "batch 130, gen_loss 1.638932, disc_loss 0.793005\n",
      "batch 131, gen_loss 1.657830, disc_loss 0.867608\n",
      "batch 132, gen_loss 1.763901, disc_loss 0.775048\n",
      "batch 133, gen_loss 1.693697, disc_loss 0.777085\n",
      "batch 134, gen_loss 1.651238, disc_loss 0.851789\n",
      "batch 135, gen_loss 1.638383, disc_loss 0.840232\n",
      "batch 136, gen_loss 1.524707, disc_loss 0.873269\n",
      "batch 137, gen_loss 1.492948, disc_loss 0.856189\n",
      "batch 138, gen_loss 1.618134, disc_loss 0.785198\n",
      "batch 139, gen_loss 1.640661, disc_loss 0.805033\n",
      "batch 140, gen_loss 1.749943, disc_loss 0.811301\n",
      "batch 141, gen_loss 1.710674, disc_loss 0.830500\n",
      "batch 142, gen_loss 1.433357, disc_loss 0.861824\n",
      "batch 143, gen_loss 1.531876, disc_loss 0.823410\n",
      "batch 144, gen_loss 1.424338, disc_loss 0.828767\n",
      "batch 145, gen_loss 1.629361, disc_loss 0.692987\n",
      "batch 146, gen_loss 1.724322, disc_loss 0.839431\n",
      "batch 147, gen_loss 1.889032, disc_loss 0.827744\n",
      "batch 148, gen_loss 1.743522, disc_loss 0.843313\n",
      "batch 149, gen_loss 1.593078, disc_loss 0.763977\n",
      "batch 150, gen_loss 1.406920, disc_loss 0.875560\n",
      "batch 151, gen_loss 1.513914, disc_loss 0.818295\n",
      "batch 152, gen_loss 1.445301, disc_loss 0.912447\n",
      "batch 153, gen_loss 1.741324, disc_loss 0.723646\n",
      "batch 154, gen_loss 1.707139, disc_loss 0.857204\n",
      "batch 155, gen_loss 1.702790, disc_loss 0.927547\n",
      "batch 156, gen_loss 1.615579, disc_loss 0.838257\n",
      "batch 157, gen_loss 1.444069, disc_loss 0.884359\n",
      "batch 158, gen_loss 1.391799, disc_loss 0.946444\n",
      "batch 159, gen_loss 1.422509, disc_loss 0.904419\n",
      "batch 160, gen_loss 1.512897, disc_loss 0.881950\n",
      "batch 161, gen_loss 1.557142, disc_loss 0.855143\n",
      "batch 162, gen_loss 1.646149, disc_loss 0.852289\n",
      "batch 163, gen_loss 1.680173, disc_loss 0.945298\n",
      "batch 164, gen_loss 1.662608, disc_loss 0.858678\n",
      "batch 165, gen_loss 1.599377, disc_loss 0.928821\n",
      "batch 166, gen_loss 1.558689, disc_loss 0.865381\n",
      "batch 167, gen_loss 1.444098, disc_loss 0.941382\n",
      "batch 168, gen_loss 1.413339, disc_loss 0.992987\n",
      "batch 169, gen_loss 1.427733, disc_loss 0.872208\n",
      "batch 170, gen_loss 1.504909, disc_loss 1.040009\n",
      "batch 171, gen_loss 1.679573, disc_loss 0.965220\n",
      "batch 172, gen_loss 1.655882, disc_loss 0.970920\n",
      "batch 173, gen_loss 1.421859, disc_loss 0.973773\n",
      "batch 174, gen_loss 1.303040, disc_loss 1.000190\n",
      "batch 175, gen_loss 1.225342, disc_loss 1.082950\n",
      "batch 176, gen_loss 1.456092, disc_loss 0.933978\n",
      "batch 177, gen_loss 1.466619, disc_loss 0.976327\n",
      "batch 178, gen_loss 1.480307, disc_loss 1.028191\n",
      "batch 179, gen_loss 1.435065, disc_loss 1.128358\n",
      "batch 180, gen_loss 1.555542, disc_loss 1.017256\n",
      "batch 181, gen_loss 1.376923, disc_loss 0.987091\n",
      "batch 182, gen_loss 1.351814, disc_loss 1.083740\n",
      "batch 183, gen_loss 1.386478, disc_loss 1.074014\n",
      "batch 184, gen_loss 1.291540, disc_loss 1.034558\n",
      "batch 185, gen_loss 1.396681, disc_loss 1.035702\n",
      "batch 186, gen_loss 1.656739, disc_loss 1.052828\n",
      "batch 187, gen_loss 1.569546, disc_loss 1.023054\n",
      "batch 188, gen_loss 1.310745, disc_loss 1.091636\n",
      "batch 189, gen_loss 1.257515, disc_loss 0.996264\n",
      "batch 190, gen_loss 1.282506, disc_loss 1.018371\n",
      "batch 191, gen_loss 1.456238, disc_loss 0.973757\n",
      "batch 192, gen_loss 1.540914, disc_loss 1.029207\n",
      "batch 193, gen_loss 1.527327, disc_loss 0.955228\n",
      "batch 194, gen_loss 1.719185, disc_loss 0.935335\n",
      "batch 195, gen_loss 1.512913, disc_loss 1.002405\n",
      "batch 196, gen_loss 1.353276, disc_loss 0.918086\n",
      "batch 197, gen_loss 1.223132, disc_loss 0.991198\n",
      "batch 198, gen_loss 1.307116, disc_loss 0.925376\n",
      "batch 199, gen_loss 1.436837, disc_loss 0.975173\n",
      "batch 200, gen_loss 1.639217, disc_loss 0.932587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 201, gen_loss 1.488700, disc_loss 0.981258\n",
      "batch 202, gen_loss 1.511537, disc_loss 0.843209\n",
      "batch 203, gen_loss 1.375104, disc_loss 0.917131\n",
      "batch 204, gen_loss 1.278287, disc_loss 0.881644\n",
      "batch 205, gen_loss 1.413212, disc_loss 0.921438\n",
      "batch 206, gen_loss 1.651294, disc_loss 0.784544\n",
      "batch 207, gen_loss 1.809171, disc_loss 0.801008\n",
      "batch 208, gen_loss 1.666559, disc_loss 0.913092\n",
      "batch 209, gen_loss 1.504950, disc_loss 0.790336\n",
      "batch 210, gen_loss 1.378323, disc_loss 0.754695\n",
      "batch 211, gen_loss 1.353703, disc_loss 0.849448\n",
      "batch 212, gen_loss 1.359272, disc_loss 0.812661\n",
      "batch 213, gen_loss 1.575652, disc_loss 0.735970\n",
      "batch 214, gen_loss 1.557344, disc_loss 0.723716\n",
      "batch 215, gen_loss 1.657678, disc_loss 0.780024\n",
      "batch 216, gen_loss 1.683686, disc_loss 0.800611\n",
      "batch 217, gen_loss 1.586697, disc_loss 0.770529\n",
      "batch 218, gen_loss 1.352142, disc_loss 0.772545\n",
      "batch 219, gen_loss 1.417931, disc_loss 0.766827\n",
      "batch 220, gen_loss 1.596773, disc_loss 0.751738\n",
      "batch 221, gen_loss 1.618982, disc_loss 0.783133\n",
      "batch 222, gen_loss 1.554609, disc_loss 0.822541\n",
      "batch 223, gen_loss 1.450668, disc_loss 0.768050\n",
      "batch 224, gen_loss 1.600178, disc_loss 0.727839\n",
      "batch 225, gen_loss 1.660388, disc_loss 0.727962\n",
      "batch 226, gen_loss 1.537472, disc_loss 0.762646\n",
      "batch 227, gen_loss 1.524112, disc_loss 0.820492\n",
      "batch 228, gen_loss 1.606079, disc_loss 0.790433\n",
      "batch 229, gen_loss 1.528838, disc_loss 0.759444\n",
      "batch 230, gen_loss 1.563582, disc_loss 0.757198\n",
      "batch 231, gen_loss 1.526476, disc_loss 0.826930\n",
      "batch 232, gen_loss 1.641793, disc_loss 0.796960\n",
      "batch 233, gen_loss 1.515543, disc_loss 0.837132\n",
      "batch 234, gen_loss 1.470142, disc_loss 0.729467\n",
      "Time for epoch50is 7.8007423877716064 sec\n",
      "CPU times: user 5min 33s, sys: 1min 1s, total: 6min 35s\n",
      "Wall time: 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(train_dataset, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_input = tf.random.normal([16, 100])\n",
    "generate_images(generator, test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## anime-faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51223\n",
      "['903d68683065961dc9d991447f910dbc-0.jpg', '3ffa87a7f805fb48aa37da3576a381dc-0.jpg', 'e9a14640d078ad0e507ff5401e638f23-0.jpg', '9d720c90b79b6eef10c6c6f2742cbfeb-0.jpg', '063bf9a2307926370d2fb333c576d2da-0.jpg', '16a8bbe161c77409183139ab8e1f2166-0.jpg', '4e5429a86304b69f26d147a4fce54628-0.jpg', '0cccefeb5c74c8c9a60babfed86a6302-0.jpg', 'bc7bfa67b2a8a525fcd66139492f34a4-0.jpg', 'a5b17c482a35f169bd40ada152420962-1.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "image_root = \"data/anime-faces\"\n",
    "image_names = os.listdir(image_root)\n",
    "print(len(image_names))\n",
    "print(image_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 3) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdf60f5bf40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "img = plt.imread(os.path.join(image_root, image_names[0]))\n",
    "print(img.shape, type(img))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "x = []\n",
    "for name in tqdm(image_names):\n",
    "    img = plt.imread(os.path.join(image_root, name))\n",
    "    x.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "x = (x - 127.5) / 127.5\n",
    "buffer_size = 60000\n",
    "batch_size = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256,use_bias=False,input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7,7,256)))\n",
    "    assert model.output_shape == (None,7,7,256)#注意：batch size没有限制\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=False))\n",
    "    assert model.output_shape == (None,7,7,128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))\n",
    "    assert model.output_shape == (None,14,14,64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1,(5,5),strides=(2,2),padding='same',use_bias=False,activation='tanh'))\n",
    "    assert model.output_shape == (None,28,28,1)\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8(DeepL)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
